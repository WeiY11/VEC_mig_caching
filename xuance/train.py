#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
XuanCeé£æ ¼è®­ç»ƒè„šæœ¬ - VECè¾¹ç¼˜è®¡ç®—ç³»ç»Ÿ

æœ¬è„šæœ¬é‡‡ç”¨XuanCeæ¡†æ¶çš„æ ‡å‡†è®­ç»ƒæµç¨‹ï¼Œæ”¯æŒï¼š
- YAMLé…ç½®æ–‡ä»¶ç®¡ç†
- å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
- å¤šç§DRLç®—æ³•ï¼ˆTD3, SAC, PPO, DDPGï¼‰
- TensorBoard/WandBå¯è§†åŒ–
- æ¨¡å‹ä¿å­˜ä¸åŠ è½½

ä½¿ç”¨æ–¹å¼ï¼š
    # ä½¿ç”¨é»˜è®¤OPTIMIZED_TD3é…ç½®è®­ç»ƒ
    python xuance/train.py
    
    # æŒ‡å®šç®—æ³•å’Œé…ç½®æ–‡ä»¶
    python xuance/train.py --method td3 --config xuance/configs/td3_vec.yaml
    
    # å‘½ä»¤è¡Œè¦†ç›–å‚æ•°
    python xuance/train.py --method sac --episodes 500 --device cuda:0
    
    # è¿è¡Œå¯¹æ¯”æ–¹æ¡ˆ
    python xuance/train.py --method local --episodes 50

ä½œè€…: VEC Team
"""

from __future__ import annotations

import argparse
import os
import sys
import time
from copy import deepcopy
from pathlib import Path
from typing import Any, Dict, Optional

import numpy as np

# è®¾ç½®Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))  # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•

# å¯¼å…¥YAMLè§£æ
try:
    import yaml
    HAS_YAML = True
except ImportError:
    HAS_YAML = False
    print("âš ï¸ PyYAMLæœªå®‰è£…ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")

# å¯¼å…¥PyTorch
try:
    import torch
    HAS_TORCH = True
except ImportError:
    HAS_TORCH = False
    print("âŒ PyTorchæœªå®‰è£…ï¼Œæ— æ³•è¿è¡Œ")
    sys.exit(1)

# å¯¼å…¥XuanCe
try:
    import xuance
    from xuance.common import get_configs, recursive_dict_update
    from xuance.environment import make_envs
    from xuance.torch.utils.operations import set_seed
    HAS_XUANCE = True
except ImportError:
    HAS_XUANCE = False
    print("âš ï¸ XuanCeæœªå®‰è£…ï¼Œå°†ä½¿ç”¨æœ¬åœ°å®ç°")

# å¯¼å…¥VECç¯å¢ƒ
try:
    from xuance.vec_env import VECEnv, register_vec_env
except ImportError:
    # å…è®¸ç›´æ¥è¿è¡Œ
    from vec_env import VECEnv, register_vec_env


def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°ï¼ˆXuanCeé£æ ¼ï¼‰"""
    parser = argparse.ArgumentParser(
        description="VECè¾¹ç¼˜è®¡ç®—ç³»ç»Ÿ - XuanCeè®­ç»ƒè„šæœ¬",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    # ç®—æ³•é€‰æ‹© - æ”¯æŒæ‰€æœ‰åŸæœ‰ç®—æ³•å’Œå¯¹æ¯”æ–¹æ¡ˆ
    parser.add_argument("--method", "-m", type=str, default="optimized_td3",
                        choices=[
                            # DRLç®—æ³•
                            "td3", "sac", "ppo", "ddpg", "dqn",
                            "optimized_td3", "cam_td3", "td3_le", "td3-le",
                            # å¯¹æ¯”æ–¹æ¡ˆ (Benchmarks)
                            "local", "heuristic", "sa",
                            "benchmark_td3", "benchmark_ddpg", "benchmark_sac"
                        ],
                        help="è®­ç»ƒç®—æ³•: DRL(optimized_td3,td3,sac,ppo,ddpg,dqn,cam_td3,td3_le) æˆ– Baseline(local,heuristic,sa,benchmark_*)")
    
    # é…ç½®æ–‡ä»¶
    parser.add_argument("--config", "-c", type=str, default=None,
                        help="YAMLé…ç½®æ–‡ä»¶è·¯å¾„")
    
    # ç¯å¢ƒé…ç½®
    parser.add_argument("--env-name", type=str, default="VEC",
                        help="ç¯å¢ƒåç§°")
    parser.add_argument("--env-id", type=str, default="VEC-v1",
                        help="ç¯å¢ƒID")
    
    # VECç‰¹å®šå‚æ•°
    parser.add_argument("--num-vehicles", type=int, default=None,
                        help="è½¦è¾†æ•°é‡")
    parser.add_argument("--num-rsus", type=int, default=None,
                        help="RSUæ•°é‡")
    parser.add_argument("--num-uavs", type=int, default=None,
                        help="UAVæ•°é‡")
    parser.add_argument("--arrival-rate", type=float, default=None,
                        help="ä»»åŠ¡åˆ°è¾¾ç‡")
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument("--episodes", type=int, default=None,
                        help="è®­ç»ƒè½®æ¬¡ï¼ˆè‡ªåŠ¨è½¬æ¢ä¸ºrunning_stepsï¼‰")
    parser.add_argument("--max-steps", type=int, default=200,
                        help="æ¯è½®æœ€å¤§æ­¥æ•°")
    parser.add_argument("--running-steps", type=int, default=None,
                        help="æ€»è®­ç»ƒæ­¥æ•°")
    parser.add_argument("--seed", type=int, default=42,
                        help="éšæœºç§å­")
    
    # ç¡¬ä»¶é…ç½®
    parser.add_argument("--device", type=str, default="cuda:0",
                        help="è®¡ç®—è®¾å¤‡")
    parser.add_argument("--parallels", type=int, default=1,
                        help="å¹¶è¡Œç¯å¢ƒæ•°")
    
    # è¯„ä¼°ä¸æ—¥å¿—
    parser.add_argument("--eval-interval", type=int, default=10000,
                        help="è¯„ä¼°é—´éš”ï¼ˆæ­¥æ•°ï¼‰")
    parser.add_argument("--test-episode", type=int, default=5,
                        help="æµ‹è¯•è½®æ¬¡")
    parser.add_argument("--logger", type=str, default="tensorboard",
                        choices=["tensorboard", "wandb"],
                        help="æ—¥å¿—å·¥å…·")
    
    # æ¨¡å¼é€‰æ‹©
    parser.add_argument("--test", action="store_true",
                        help="æµ‹è¯•æ¨¡å¼")
    parser.add_argument("--benchmark", action="store_true",
                        help="åŸºå‡†æµ‹è¯•æ¨¡å¼")
    parser.add_argument("--model-path", type=str, default=None,
                        help="æ¨¡å‹åŠ è½½è·¯å¾„")
    
    # è¾“å‡ºé…ç½®
    parser.add_argument("--log-dir", type=str, default="./logs/",
                        help="æ—¥å¿—ç›®å½•")
    parser.add_argument("--model-dir", type=str, default="./models/",
                        help="æ¨¡å‹ä¿å­˜ç›®å½•")
    parser.add_argument("--verbose", "-v", action="store_true",
                        help="è¯¦ç»†è¾“å‡º")
    
    return parser.parse_args()


def get_default_config(method: str) -> Dict[str, Any]:
    """è·å–é»˜è®¤é…ç½®"""
    base_config = {
        "dl_toolbox": "torch",
        "project_name": "VEC_Edge_Computing",
        "logger": "tensorboard",
        "render": False,
        "render_mode": "rgb_array",
        "test_mode": False,
        "device": "cuda:0" if torch.cuda.is_available() else "cpu",
        "distributed_training": False,
        
        "env_name": "VEC",
        "env_id": "VEC-v1",
        "env_seed": 42,
        "vectorize": "DummyVecEnv",
        
        "representation": "Basic_MLP",
        "representation_hidden_size": [256, 256],
        "actor_hidden_size": [256, 256],
        "critic_hidden_size": [256, 256],
        "activation": "relu",
        "activation_action": "tanh",
        
        "seed": 42,
        "parallels": 1,
        "running_steps": 200000,
        
        "gamma": 0.99,
        "use_grad_clip": True,
        "grad_clip_norm": 0.5,
        
        "use_obsnorm": False,
        "use_rewnorm": False,
        "obsnorm_range": 5,
        "rewnorm_range": 5,
        
        "test_steps": 10000,
        "eval_interval": 10000,
        "test_episode": 5,
        
        "log_dir": "./logs/",
        "model_dir": "./models/",
        
        "vec_config": {
            "num_vehicles": 12,
            "num_rsus": 4,
            "num_uavs": 2,
            "arrival_rate": 3.5,
            "max_episode_steps": 200,
            "use_enhanced_cache": True,
            "disable_migration": False,
            "reward_weight_delay": 0.5,
            "reward_weight_energy": 0.5,
            "reward_penalty_dropped": 1.0,
        }
    }
    
    # ç®—æ³•ç‰¹å®šé…ç½®
    if method.lower() == "td3":
        base_config.update({
            "agent": "TD3",
            "learner": "TD3_Learner",
            "policy": "DeterministicPolicy",
            "actor_learning_rate": 9e-5,
            "critic_learning_rate": 9e-5,
            "tau": 0.005,
            "batch_size": 384,
            "buffer_size": 100000,
            "start_training": 1000,
            "training_frequency": 1,
            "actor_update_delay": 2,
            # TD3 noise parameters (xuance required)
            "start_noise": 0.18,
            "end_noise": 0.05,
            "explore_noise": 0.18,
            "target_noise": 0.05,
            "noise_clip": 0.2,
        })
    elif method.lower() == "sac":
        base_config.update({
            "agent": "SAC",
            "learner": "SAC_Learner",
            "policy": "Gaussian_SAC",
            "actor_learning_rate": 3e-4,
            "critic_learning_rate": 3e-4,
            "alpha_learning_rate": 3e-4,
            "tau": 0.005,
            "batch_size": 256,
            "buffer_size": 100000,
            "start_training": 1000,
            "training_frequency": 1,
            "alpha": 0.2,
            "use_automatic_entropy_tuning": True,
        })
    elif method.lower() == "ppo":
        base_config.update({
            "agent": "PPO_Clip",
            "learner": "PPOCLIP_Learner",
            "policy": "Gaussian_AC",
            "learning_rate": 3e-4,
            "horizon_size": 256,
            "n_epochs": 10,
            "n_minibatch": 4,
            "clip_range": 0.2,
            "vf_coef": 0.5,
            "ent_coef": 0.01,
            "use_gae": True,
            "gae_lambda": 0.95,
            "use_advnorm": True,
            "use_obsnorm": True,
            "use_rewnorm": True,
            "parallels": 4,
        })
    elif method.lower() == "ddpg":
        base_config.update({
            "agent": "DDPG",
            "learner": "DDPG_Learner",
            "policy": "Deterministic_Policy",
            "actor_learning_rate": 1e-4,
            "critic_learning_rate": 1e-3,
            "tau": 0.005,
            "batch_size": 256,
            "buffer_size": 100000,
            "start_training": 1000,
            "training_frequency": 1,
            "explore_noise": 0.1,
        })
    
    return base_config


def load_yaml_config(config_path: str) -> Dict[str, Any]:
    """åŠ è½½YAMLé…ç½®æ–‡ä»¶"""
    if not HAS_YAML:
        return {}
    
    path = Path(config_path)
    if not path.exists():
        print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return {}
    
    with open(path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f) or {}


def merge_configs(base: Dict, *updates: Dict) -> Dict:
    """é€’å½’åˆå¹¶é…ç½®"""
    result = deepcopy(base)
    for update in updates:
        if update:
            for key, value in update.items():
                if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                    result[key] = merge_configs(result[key], value)
                elif value is not None:
                    result[key] = value
    return result


def apply_args_to_config(config: Dict, args: argparse.Namespace) -> Dict:
    """åº”ç”¨å‘½ä»¤è¡Œå‚æ•°åˆ°é…ç½®"""
    # ç›´æ¥æ˜ å°„
    direct_mappings = {
        'device': 'device',
        'seed': 'seed',
        'parallels': 'parallels',
        'running_steps': 'running_steps',
        'eval_interval': 'eval_interval',
        'test_episode': 'test_episode',
        'logger': 'logger',
        'log_dir': 'log_dir',
        'model_dir': 'model_dir',
    }
    
    for arg_name, config_key in direct_mappings.items():
        value = getattr(args, arg_name, None)
        if value is not None:
            config[config_key] = value
    
    # è®¡ç®—running_steps
    if args.episodes is not None:
        config['running_steps'] = args.episodes * args.max_steps * config.get('parallels', 1)
    
    # VECç‰¹å®šå‚æ•°
    vec_config = config.setdefault('vec_config', {})
    if args.num_vehicles is not None:
        vec_config['num_vehicles'] = args.num_vehicles
    if args.num_rsus is not None:
        vec_config['num_rsus'] = args.num_rsus
    if args.num_uavs is not None:
        vec_config['num_uavs'] = args.num_uavs
    if args.arrival_rate is not None:
        vec_config['arrival_rate'] = args.arrival_rate
    vec_config['max_episode_steps'] = args.max_steps
    
    # æµ‹è¯•æ¨¡å¼
    config['test_mode'] = args.test
    
    # æ›´æ–°è·¯å¾„
    method = args.method.lower()
    if config['log_dir'] == "./logs/":
        config['log_dir'] = f"./logs/{method}_vec/"
    if config['model_dir'] == "./models/":
        config['model_dir'] = f"./models/{method}_vec/"
    
    return config


def create_vec_envs(config: Dict, parallels: int = 1):
    """åˆ›å»ºVECç¯å¢ƒ"""
    from argparse import Namespace
    
    config_ns = Namespace(**config)
    
    if parallels == 1:
        return VECEnv(config=config_ns)
    else:
        # åˆ›å»ºå‘é‡åŒ–ç¯å¢ƒ
        def make_env():
            return VECEnv(config=config_ns)
        
        envs = [make_env() for _ in range(parallels)]
        # ç®€å•åŒ…è£…
        return envs[0]  # æš‚æ—¶è¿”å›å•ä¸ªç¯å¢ƒ


def train_with_xuance(config: Dict, args: argparse.Namespace):
    """ä½¿ç”¨XuanCeæ¡†æ¶è®­ç»ƒ"""
    from argparse import Namespace
    
    print("\n" + "="*60)
    print("ğŸš€ ä½¿ç”¨XuanCeæ¡†æ¶è®­ç»ƒ")
    print("="*60)
    
    # æ³¨å†ŒVECç¯å¢ƒ
    register_vec_env()
    
    # è®¾ç½®éšæœºç§å­
    set_seed(config['seed'])
    
    # åˆ›å»ºç¯å¢ƒ
    config_ns = Namespace(**config)
    envs = make_envs(config_ns)
    
    # è·å–Agentç±»
    from xuance.torch.agents import REGISTRY_Agents
    agent_name = config['agent']
    if agent_name not in REGISTRY_Agents:
        print(f"âŒ ä¸æ”¯æŒçš„ç®—æ³•: {agent_name}")
        print(f"   å¯ç”¨ç®—æ³•: {list(REGISTRY_Agents.keys())}")
        return None
    
    Agent_cls = REGISTRY_Agents[agent_name]
    agent = Agent_cls(config=config_ns, envs=envs)
    
    # æ‰“å°è®­ç»ƒä¿¡æ¯
    print(f"\nğŸ“‹ è®­ç»ƒé…ç½®:")
    print(f"   ç®—æ³•: {config['agent']}")
    print(f"   è®¾å¤‡: {config['device']}")
    print(f"   ç¯å¢ƒ: {config['env_name']} / {config['env_id']}")
    print(f"   è®­ç»ƒæ­¥æ•°: {config['running_steps']}")
    print(f"   å¹¶è¡Œç¯å¢ƒ: {config['parallels']}")
    
    # è®­ç»ƒæˆ–æµ‹è¯•
    if args.test:
        print("\nğŸ§ª æµ‹è¯•æ¨¡å¼")
        if args.model_path:
            agent.load_model(path=args.model_path)
        
        def env_fn():
            return make_envs(config_ns)
        
        scores = agent.test(env_fn, config['test_episode'])
        print(f"   å¹³å‡å¾—åˆ†: {np.mean(scores):.4f} Â± {np.std(scores):.4f}")
    
    elif args.benchmark:
        print("\nğŸ“Š åŸºå‡†æµ‹è¯•æ¨¡å¼")
        
        def env_fn():
            cfg_test = deepcopy(config_ns)
            cfg_test.parallels = config['test_episode']
            return make_envs(cfg_test)
        
        train_steps = config['running_steps'] // config['parallels']
        eval_interval = config['eval_interval'] // config['parallels']
        num_epochs = train_steps // eval_interval
        
        best_score = -float('inf')
        for epoch in range(num_epochs):
            print(f"\nEpoch {epoch+1}/{num_epochs}")
            agent.train(eval_interval)
            
            scores = agent.test(env_fn, config['test_episode'])
            mean_score = np.mean(scores)
            print(f"   è¯„ä¼°å¾—åˆ†: {mean_score:.4f} Â± {np.std(scores):.4f}")
            
            if mean_score > best_score:
                best_score = mean_score
                agent.save_model(model_name="best_model.pth")
                print(f"   âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (å¾—åˆ†: {best_score:.4f})")
        
        print(f"\nğŸ† æœ€ä½³å¾—åˆ†: {best_score:.4f}")
    
    else:
        print("\nğŸ¯ è®­ç»ƒæ¨¡å¼")
        start_time = time.time()
        
        train_steps = config['running_steps'] // config['parallels']
        agent.train(train_steps)
        agent.save_model("final_model.pth")
        
        training_time = time.time() - start_time
        print(f"\nâœ… è®­ç»ƒå®Œæˆ!")
        print(f"   è€—æ—¶: {training_time/3600:.2f}å°æ—¶")
        print(f"   æ¨¡å‹ä¿å­˜è‡³: {config['model_dir']}")
    
    agent.finish()
    envs.close()
    
    return agent


def train_with_benchmark(config: Dict, args: argparse.Namespace):
    """ä½¿ç”¨å¯¹æ¯”æ–¹æ¡ˆè®­ç»ƒ/è¯„ä¼° (Benchmarks)"""
    print("\n" + "="*60)
    print("[Benchmark] å¯¹æ¯”æ–¹æ¡ˆè¯„ä¼°")
    print("="*60)
    
    method = args.method.lower()
    episodes = config['running_steps'] // config['vec_config']['max_episode_steps']
    seed = config.get('seed', 42)
    
    # ç¯å¢ƒé…ç½® (ä½¿ç”¨VecEnvWrapperçš„å‚æ•°å)
    env_cfg = {
        'num_vehicles': config['vec_config']['num_vehicles'],
        'num_rsus': config['vec_config']['num_rsus'],
        'num_uavs': config['vec_config']['num_uavs'],
        'task_arrival_rate': config['vec_config'].get('arrival_rate', 3.5),
    }
    
    print(f"\n[Config] å¯¹æ¯”æ–¹æ¡ˆé…ç½®:")
    print(f"   ç®—æ³•: {method}")
    print(f"   è¯„ä¼°è½®æ¬¡: {episodes}")
    print(f"   ç¯å¢ƒ: {env_cfg}")
    
    # å¯¼å…¥Benchmarksæ¨¡å—
    try:
        from Benchmarks.run_benchmarks_vs_optimized_td3 import (
            run_rl, run_local, run_heuristic, run_sa, set_global_seeds
        )
        
        set_global_seeds(seed)
        
        if method == 'local':
            results = run_local(env_cfg, episodes, seed)
            alg_name = "Local-Only"
        elif method == 'heuristic':
            results = run_heuristic(env_cfg, episodes, seed)
            alg_name = "Dynamic-Heuristic"
        elif method == 'sa':
            results = run_sa(env_cfg, episodes, seed)
            alg_name = "Simulated-Annealing"
        elif method == 'benchmark_td3':
            results = run_rl('td3', episodes, seed, env_cfg)
            alg_name = "Benchmark-TD3"
        elif method == 'benchmark_ddpg':
            results = run_rl('ddpg', episodes, seed, env_cfg)
            alg_name = "Benchmark-DDPG"
        elif method == 'benchmark_sac':
            results = run_rl('sac', episodes, seed, env_cfg)
            alg_name = "Benchmark-SAC"
        else:
            print(f"[Error] æœªçŸ¥çš„å¯¹æ¯”æ–¹æ¡ˆ: {method}")
            return None
        
        # æ‰“å°ç»“æœ
        print(f"\n[OK] {alg_name} è¯„ä¼°å®Œæˆ!")
        if results and 'episode_rewards' in results:
            rewards = results['episode_rewards']
            print(f"   è½®æ¬¡: {len(rewards)}")
            print(f"   å¹³å‡å¥–åŠ±: {np.mean(rewards):.4f}")
            print(f"   æœ€ç»ˆå¥–åŠ±: {rewards[-1]:.4f}")
            
            if 'episode_metrics' in results:
                metrics = results['episode_metrics']
                if 'avg_task_delay' in metrics:
                    print(f"   å¹³å‡å»¶è¿Ÿ: {np.mean(metrics['avg_task_delay']):.4f}s")
                if 'task_completion_rate' in metrics:
                    print(f"   å®Œæˆç‡: {np.mean(metrics['task_completion_rate'])*100:.2f}%")
        
        return results
        
    except ImportError as e:
        print(f"[Error] æ— æ³•å¯¼å…¥Benchmarksæ¨¡å—: {e}")
        print("   è¯·ç¡®ä¿ Benchmarks/ ç›®å½•å­˜åœ¨")
        return None
    except Exception as e:
        print(f"[Error] å¯¹æ¯”æ–¹æ¡ˆè¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def train_with_local(config: Dict, args: argparse.Namespace):
    """ä½¿ç”¨æœ¬åœ°å®ç°è®­ç»ƒï¼ˆå½“XuanCeä¸å¯ç”¨æ—¶ï¼‰"""
    print("\n" + "="*60)
    print("ğŸ”§ ä½¿ç”¨æœ¬åœ°å®ç°è®­ç»ƒ")
    print("="*60)
    
    # æ³¨å†Œç¯å¢ƒ
    register_vec_env()
    
    # è®¾ç½®éšæœºç§å­
    np.random.seed(config['seed'])
    torch.manual_seed(config['seed'])
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(config['seed'])
    
    # å¯¼å…¥æœ¬åœ°ç®—æ³•
    method = args.method.lower()
    
    # ç®—æ³•åç§°æ˜ å°„ï¼ˆå°å†™ -> train_single_agentè¦æ±‚çš„æ ¼å¼ï¼‰
    algorithm_map = {
        'td3': 'TD3',
        'sac': 'SAC',
        'ppo': 'PPO',
        'ddpg': 'DDPG',
        'dqn': 'DQN',
        'optimized_td3': 'OPTIMIZED_TD3',
        'cam_td3': 'CAM_TD3',
        'td3_le': 'TD3-LE',
        'td3-le': 'TD3-LE',
    }
    
    algorithm_name = algorithm_map.get(method)
    if not algorithm_name:
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¯¹æ¯”æ–¹æ¡ˆ
        if method in ['local', 'heuristic', 'sa', 'benchmark_td3', 'benchmark_ddpg', 'benchmark_sac']:
            return train_with_benchmark(config, args)
        print(f"[Error] ä¸æ”¯æŒçš„ç®—æ³•: {method}")
        print(f"   DRLç®—æ³•: {list(algorithm_map.keys())}")
        print(f"   å¯¹æ¯”æ–¹æ¡ˆ: local, heuristic, sa, benchmark_td3, benchmark_ddpg, benchmark_sac")
        return None
    
    # è®¡ç®—è®­ç»ƒè½®æ¬¡
    episodes = config['running_steps'] // config['vec_config']['max_episode_steps']
    
    print(f"\n[Config] è®­ç»ƒé…ç½®:")
    print(f"   ç®—æ³•: {algorithm_name}")
    print(f"   è®­ç»ƒè½®æ¬¡: {episodes}")
    print(f"   æ¯è½®æ­¥æ•°: {config['vec_config']['max_episode_steps']}")
    
    # ä½¿ç”¨ç°æœ‰è®­ç»ƒè„šæœ¬
    from train_single_agent import train_single_algorithm
    
    override_scenario = {
        'num_vehicles': config['vec_config']['num_vehicles'],
        'num_rsus': config['vec_config']['num_rsus'],
        'num_uavs': config['vec_config']['num_uavs'],
    }
    
    # è®¾ç½®éšæœºç§å­
    import random
    seed = config.get('seed', 42)
    random.seed(seed)
    np.random.seed(seed)
    
    results = train_single_algorithm(
        algorithm=algorithm_name,
        num_episodes=episodes,
        override_scenario=override_scenario,
        use_enhanced_cache=config['vec_config']['use_enhanced_cache'],
        disable_migration=config['vec_config']['disable_migration'],
    )
    
    print(f"\n[OK] è®­ç»ƒå®Œæˆ!")
    if results:
        print(f"   æœ€ç»ˆå¥–åŠ±: {results.get('final_reward', 'N/A')}")
    
    return results


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‚æ•°
    args = parse_args()
    
    print("\n" + "="*60)
    print("ğŸ® VECè¾¹ç¼˜è®¡ç®—ç³»ç»Ÿ - XuanCeè®­ç»ƒè„šæœ¬")
    print("="*60)
    
    # è·å–é»˜è®¤é…ç½®
    config = get_default_config(args.method)
    
    # åŠ è½½YAMLé…ç½®
    if args.config:
        yaml_config = load_yaml_config(args.config)
        config = merge_configs(config, yaml_config)
    else:
        # å°è¯•åŠ è½½é»˜è®¤é…ç½®æ–‡ä»¶
        # æ”¯æŒä¸¤ç§è·¯å¾„: xuance/configs/ æˆ– xuance_configs/
        script_dir = Path(__file__).parent
        config_paths = [
            script_dir / "configs" / f"{args.method.lower()}_vec.yaml",
            Path(f"xuance/configs/{args.method.lower()}_vec.yaml"),
            Path(f"xuance_configs/{args.method.lower()}_vec.yaml"),
        ]
        for config_path in config_paths:
            if config_path.exists():
                yaml_config = load_yaml_config(str(config_path))
                config = merge_configs(config, yaml_config)
                break
    
    # åº”ç”¨å‘½ä»¤è¡Œå‚æ•°
    config = apply_args_to_config(config, args)
    
    # åˆ›å»ºç›®å½•
    Path(config['log_dir']).mkdir(parents=True, exist_ok=True)
    Path(config['model_dir']).mkdir(parents=True, exist_ok=True)
    
    # æ‰“å°é…ç½®æ‘˜è¦
    if args.verbose:
        print("\nğŸ“‹ å®Œæ•´é…ç½®:")
        for key, value in config.items():
            if isinstance(value, dict):
                print(f"   {key}:")
                for k, v in value.items():
                    print(f"      {k}: {v}")
            else:
                print(f"   {key}: {value}")
    
    # é€‰æ‹©è®­ç»ƒæ–¹å¼
    # æœ¬åœ°DRLç®—æ³•åˆ—è¡¨
    local_drl_algorithms = ['td3', 'ddpg', 'sac', 'ppo', 'dqn', 
                            'optimized_td3', 'cam_td3', 'td3_le', 'td3-le']
    # å¯¹æ¯”æ–¹æ¡ˆåˆ—è¡¨
    benchmark_algorithms = ['local', 'heuristic', 'sa', 
                           'benchmark_td3', 'benchmark_ddpg', 'benchmark_sac']
    
    method = args.method.lower()
    
    if method in benchmark_algorithms:
        # è¿è¡Œå¯¹æ¯”æ–¹æ¡ˆ
        train_with_benchmark(config, args)
    elif not HAS_XUANCE or method in local_drl_algorithms:
        # ä½¿ç”¨æœ¬åœ°DRLå®ç°
        train_with_local(config, args)
    else:
        # ä½¿ç”¨XuanCeæ¡†æ¶
        train_with_xuance(config, args)


if __name__ == "__main__":
    main()
