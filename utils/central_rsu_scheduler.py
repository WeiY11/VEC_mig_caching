#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ä¸­å¤®RSUéª¨å¹²è°ƒåº¦ç³»ç»Ÿ
åŸºäºç°æœ‰ä¸­å¤®RSUå®ç°å…¨å±€è´Ÿè½½æ”¶é›†ä¸ä»»åŠ¡è°ƒåº¦
"""

import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, field
from collections import defaultdict, deque
import time
import logging


@dataclass
class RSULoadInfo:
    """RSUè´Ÿè½½ä¿¡æ¯æ•°æ®ç»“æ„"""
    rsu_id: str
    position: np.ndarray
    
    # é˜Ÿåˆ—çŠ¶æ€
    queue_length: int = 0
    queue_tasks: List[Dict] = field(default_factory=list)
    
    # è®¡ç®—èµ„æº
    cpu_usage: float = 0.0
    cpu_frequency: float = 0.0
    available_compute: float = 0.0
    
    # ç¼“å­˜çŠ¶æ€
    cache_usage: float = 0.0
    cache_hit_rate: float = 0.0
    cached_content_count: int = 0
    
    # ç½‘ç»œçŠ¶æ€
    served_vehicles: int = 0
    coverage_vehicles: int = 0
    network_bandwidth_usage: float = 0.0
    
    # æ€§èƒ½æŒ‡æ ‡
    avg_response_time: float = 0.0
    task_completion_rate: float = 0.0
    energy_consumption: float = 0.0
    
    # æ—¶é—´æˆ³
    last_updated: float = field(default_factory=time.time)


@dataclass
class GlobalSchedulingDecision:
    """å…¨å±€è°ƒåº¦å†³ç­–"""
    target_rsu_id: str
    task_allocation_ratio: float  # åˆ†é…ç»™è¯¥RSUçš„ä»»åŠ¡æ¯”ä¾‹
    priority_level: int          # ä¼˜å…ˆçº§ (1-5, 5æœ€é«˜)
    expected_response_time: float
    reason: str                  # è°ƒåº¦åŸå› 


class CentralRSUScheduler:
    """ğŸ¢ ä¸­å¤®RSUéª¨å¹²è°ƒåº¦ç³»ç»Ÿ"""
    
    def __init__(self, central_rsu_id: str = "RSU_2", history_window: int = 20):
        """
        åˆå§‹åŒ–ä¸­å¤®RSUè°ƒåº¦å™¨
        
        Args:
            central_rsu_id: ä¸­å¤®RSUçš„ID (é€šå¸¸æ˜¯RSU_2ï¼Œä½äºä¸­å¤®ä½ç½®)
            history_window: è´Ÿè½½å†å²è®°å½•çª—å£å¤§å°
        """
        self.central_rsu_id = central_rsu_id
        self.history_window = history_window
        
        # ğŸ“Š RSUè´Ÿè½½ä¿¡æ¯æ”¶é›†
        self.rsu_loads: Dict[str, RSULoadInfo] = {}
        self.load_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=history_window))
        
        # ğŸ¯ å…¨å±€è°ƒåº¦å†³ç­–
        self.scheduling_decisions: Dict[str, GlobalSchedulingDecision] = {}
        self.task_allocation_matrix: np.ndarray = None  # RSUé—´ä»»åŠ¡åˆ†é…çŸ©é˜µ
        
        # ğŸ“ˆ æ€§èƒ½ç›‘æ§
        self.global_metrics = {
            'total_system_load': 0.0,
            'load_balance_index': 0.0,  # è´Ÿè½½å‡è¡¡æŒ‡æ•° (0-1, 1ä¸ºå®Œå…¨å‡è¡¡)
            'global_response_time': 0.0,
            'system_throughput': 0.0,
            'scheduling_decisions_count': 0,
            'successful_migrations': 0,
            'last_scheduling_time': 0.0
        }
        
        # âš™ï¸ è°ƒåº¦ç­–ç•¥é…ç½®
        self.config = {
            'load_balance_threshold': 0.7,      # è´Ÿè½½å‡è¡¡é˜ˆå€¼
            'response_time_threshold': 100.0,   # å“åº”æ—¶é—´é˜ˆå€¼(ms)
            'min_allocation_ratio': 0.1,        # æœ€å°åˆ†é…æ¯”ä¾‹
            'max_allocation_ratio': 0.4,        # æœ€å¤§åˆ†é…æ¯”ä¾‹
            'scheduling_interval': 1.0,         # è°ƒåº¦é—´éš”(ç§’)
            'load_prediction_weight': 0.3,      # è´Ÿè½½é¢„æµ‹æƒé‡
            'fairness_weight': 0.4,             # å…¬å¹³æ€§æƒé‡
            'efficiency_weight': 0.3            # æ•ˆç‡æ€§æƒé‡
        }
        
        # ğŸ§  æ™ºèƒ½è°ƒåº¦ç®—æ³•
        self.load_predictor = LoadPredictor()
        self.allocation_optimizer = AllocationOptimizer()
        
        logging.info(f"ğŸ¢ ä¸­å¤®RSUè°ƒåº¦å™¨åˆå§‹åŒ–å®Œæˆï¼Œè°ƒåº¦ä¸­å¿ƒ: {central_rsu_id}")
    
    def collect_rsu_load_info(self, rsu_data: Dict) -> RSULoadInfo:
        """
        ğŸ” æ”¶é›†å•ä¸ªRSUçš„è´Ÿè½½ä¿¡æ¯
        
        Args:
            rsu_data: RSUçŠ¶æ€æ•°æ®å­—å…¸
            
        Returns:
            RSULoadInfo: ç»“æ„åŒ–çš„è´Ÿè½½ä¿¡æ¯
        """
        rsu_id = rsu_data.get('id', 'unknown')
        
        # æå–è´Ÿè½½ä¿¡æ¯
        load_info = RSULoadInfo(
            rsu_id=rsu_id,
            position=np.array(rsu_data.get('position', [0, 0])),
            
            # é˜Ÿåˆ—çŠ¶æ€
            queue_length=len(rsu_data.get('computation_queue', [])),
            queue_tasks=rsu_data.get('computation_queue', []),
            
            # è®¡ç®—èµ„æº
            cpu_usage=rsu_data.get('cpu_usage', 0.0),
            cpu_frequency=rsu_data.get('cpu_frequency', 0.0),
            available_compute=max(0, rsu_data.get('cpu_frequency', 0.0) * (1 - rsu_data.get('cpu_usage', 0.0))),
            
            # ç¼“å­˜çŠ¶æ€
            cache_usage=rsu_data.get('cache_usage', 0.0),
            cache_hit_rate=rsu_data.get('cache_hit_rate', 0.0),
            cached_content_count=len(rsu_data.get('cached_content', {})),
            
            # ç½‘ç»œçŠ¶æ€
            served_vehicles=rsu_data.get('served_vehicles', 0),
            coverage_vehicles=rsu_data.get('coverage_vehicles', 0),
            network_bandwidth_usage=rsu_data.get('bandwidth_usage', 0.0),
            
            # æ€§èƒ½æŒ‡æ ‡
            avg_response_time=rsu_data.get('avg_response_time', 0.0),
            task_completion_rate=rsu_data.get('task_completion_rate', 0.0),
            energy_consumption=rsu_data.get('energy_consumption', 0.0)
        )
        
        # æ›´æ–°å†å²è®°å½•
        self.rsu_loads[rsu_id] = load_info
        self.load_history[rsu_id].append(load_info.cpu_usage)
        
        return load_info
    
    def collect_all_rsu_loads(self, rsu_list: List[Dict]) -> Dict[str, RSULoadInfo]:
        """
        ğŸ“Š æ”¶é›†æ‰€æœ‰æ¥å…¥RSUçš„è´Ÿè½½ä¿¡æ¯
        
        Args:
            rsu_list: æ‰€æœ‰RSUçš„çŠ¶æ€æ•°æ®åˆ—è¡¨
            
        Returns:
            Dict[str, RSULoadInfo]: RSUè´Ÿè½½ä¿¡æ¯å­—å…¸
        """
        collected_loads = {}
        
        for rsu_data in rsu_list:
            rsu_id = rsu_data.get('id', 'unknown')
            
            # è·³è¿‡ä¸­å¤®RSUè‡ªå·±ï¼ˆè°ƒåº¦ä¸­å¿ƒï¼‰
            if rsu_id == self.central_rsu_id:
                continue
                
            load_info = self.collect_rsu_load_info(rsu_data)
            collected_loads[rsu_id] = load_info
            
        # è®¡ç®—å…¨å±€æŒ‡æ ‡
        self._update_global_metrics()
        
        logging.debug(f"ğŸ“Š æ”¶é›†äº† {len(collected_loads)} ä¸ªRSUçš„è´Ÿè½½ä¿¡æ¯")
        return collected_loads
    
    def global_load_balance_scheduling(self, incoming_task_count: int = 1) -> Dict[str, GlobalSchedulingDecision]:
        """
        ğŸ¯ å…¨å±€è´Ÿè½½å‡è¡¡è°ƒåº¦ç®—æ³•
        
        Args:
            incoming_task_count: å³å°†åˆ°è¾¾çš„ä»»åŠ¡æ•°é‡
            
        Returns:
            Dict[str, GlobalSchedulingDecision]: å…¨å±€è°ƒåº¦å†³ç­–
        """
        if not self.rsu_loads:
            logging.warning("âš ï¸ æ— RSUè´Ÿè½½ä¿¡æ¯ï¼Œè·³è¿‡è°ƒåº¦")
            return {}
        
        # 1ï¸âƒ£ è®¡ç®—è´Ÿè½½å‡è¡¡æŒ‡æ•°
        load_balance_index = self._calculate_load_balance_index()
        
        # 2ï¸âƒ£ è´Ÿè½½é¢„æµ‹
        predicted_loads = self.load_predictor.predict_future_loads(self.load_history, steps=3)
        
        # 3ï¸âƒ£ ä¼˜åŒ–ä»»åŠ¡åˆ†é…
        allocation_matrix = self.allocation_optimizer.optimize_allocation(
            current_loads=self.rsu_loads,
            predicted_loads=predicted_loads,
            incoming_tasks=incoming_task_count,
            fairness_weight=self.config['fairness_weight'],
            efficiency_weight=self.config['efficiency_weight']
        )
        
        # 4ï¸âƒ£ ç”Ÿæˆè°ƒåº¦å†³ç­–
        scheduling_decisions = {}
        
        for rsu_id, load_info in self.rsu_loads.items():
            # è®¡ç®—åˆ†é…æ¯”ä¾‹
            allocation_ratio = allocation_matrix.get(rsu_id, 0.0)
            
            # é™åˆ¶åˆ†é…èŒƒå›´
            allocation_ratio = np.clip(
                allocation_ratio,
                self.config['min_allocation_ratio'],
                self.config['max_allocation_ratio']
            )
            
            # è®¡ç®—ä¼˜å…ˆçº§
            priority = self._calculate_priority(load_info, predicted_loads.get(rsu_id, 0.0))
            
            # é¢„æµ‹å“åº”æ—¶é—´
            expected_response_time = self._estimate_response_time(
                load_info, allocation_ratio * incoming_task_count
            )
            
            # ç”Ÿæˆè°ƒåº¦åŸå› 
            reason = self._generate_scheduling_reason(load_info, allocation_ratio, priority)
            
            # åˆ›å»ºè°ƒåº¦å†³ç­–
            decision = GlobalSchedulingDecision(
                target_rsu_id=rsu_id,
                task_allocation_ratio=allocation_ratio,
                priority_level=priority,
                expected_response_time=expected_response_time,
                reason=reason
            )
            
            scheduling_decisions[rsu_id] = decision
        
        # 5ï¸âƒ£ æ›´æ–°è°ƒåº¦ç»Ÿè®¡
        self.scheduling_decisions = scheduling_decisions
        self.global_metrics['scheduling_decisions_count'] += 1
        self.global_metrics['last_scheduling_time'] = time.time()
        
        logging.info(f"ğŸ¯ ç”Ÿæˆå…¨å±€è°ƒåº¦å†³ç­–ï¼Œç›®æ ‡RSUæ•°é‡: {len(scheduling_decisions)}")
        return scheduling_decisions
    
    def intelligent_migration_coordination(self, overload_threshold: float = 0.8) -> List[Dict]:
        """
        ğŸš€ æ™ºèƒ½è¿ç§»åè°ƒ - åŸºäºå…¨å±€è§†è§’çš„ä»»åŠ¡è¿ç§»
        
        Args:
            overload_threshold: è¿‡è½½é˜ˆå€¼
            
        Returns:
            List[Dict]: è¿ç§»æŒ‡ä»¤åˆ—è¡¨
        """
        migration_commands = []
        
        if not self.rsu_loads:
            return migration_commands
        
        # ğŸ” è¯†åˆ«è¿‡è½½å’Œç©ºé—²èŠ‚ç‚¹
        overloaded_rsus = []
        underloaded_rsus = []
        
        for rsu_id, load_info in self.rsu_loads.items():
            load_factor = self._calculate_normalized_load(load_info)
            
            if load_factor > overload_threshold:
                overloaded_rsus.append((rsu_id, load_info, load_factor))
            elif load_factor < 0.3:  # ç©ºé—²é˜ˆå€¼
                underloaded_rsus.append((rsu_id, load_info, load_factor))
        
        # âš–ï¸ æ‰§è¡Œè´Ÿè½½å‡è¡¡è¿ç§»
        for source_rsu_id, source_load, source_factor in overloaded_rsus:
            # é€‰æ‹©æœ€ä½³ç›®æ ‡RSU
            if underloaded_rsus:
                # æŒ‰è´Ÿè½½å’Œè·ç¦»é€‰æ‹©ç›®æ ‡
                target_candidates = []
                source_pos = source_load.position
                
                for target_rsu_id, target_load, target_factor in underloaded_rsus:
                    target_pos = target_load.position
                    distance = np.linalg.norm(source_pos - target_pos)
                    
                    # ç»¼åˆè¯„åˆ†ï¼šè´Ÿè½½ä½ + è·ç¦»è¿‘
                    score = (1 - target_factor) * 0.7 + (1 / (distance + 1)) * 0.3
                    target_candidates.append((target_rsu_id, target_load, score))
                
                # é€‰æ‹©æœ€ä½³ç›®æ ‡
                if target_candidates:
                    best_target = max(target_candidates, key=lambda x: x[2])
                    target_rsu_id, target_load, _ = best_target
                    
                    # è®¡ç®—è¿ç§»ä»»åŠ¡æ•°é‡
                    migrate_count = max(1, int(source_load.queue_length * 0.3))
                    
                    # ğŸ”Œ è®¡ç®—æœ‰çº¿ä¼ è¾“æˆæœ¬
                    migration_data_size = migrate_count * 2.0  # MB per task
                    try:
                        from utils.wired_backhaul_model import get_backhaul_model
                        backhaul = get_backhaul_model()
                        cost_info = backhaul.estimate_migration_cost(
                            migration_data_size, source_rsu_id, target_rsu_id
                        )
                        wired_delay = cost_info['transmission_delay']
                        wired_energy = cost_info['energy_consumption']
                        total_cost = cost_info['total_cost']
                    except Exception:
                        # å›é€€åˆ°ç®€åŒ–æˆæœ¬æ¨¡å‹
                        wired_delay = 0.01   # 10ms
                        wired_energy = 0.5   # 0.5J
                        total_cost = 1.0
                    
                    # ğŸ¯ è¯„ä¼°è¿ç§»æ”¶ç›Š (è€ƒè™‘æœ‰çº¿ä¼ è¾“æˆæœ¬)
                    load_benefit = source_factor - target_load.cpu_usage  # è´Ÿè½½å‡è¡¡æ”¶ç›Š
                    transmission_cost = total_cost * 0.05  # ğŸ”§ é™ä½ä¼ è¾“æˆæœ¬æƒé‡ä»0.1åˆ°0.05
                    net_benefit = load_benefit - transmission_cost
                    
                    # ğŸ”§ é™ä½æ”¶ç›Šé˜ˆå€¼ï¼Œæ›´å®¹æ˜“è§¦å‘è¿ç§»
                    if net_benefit > 0.05:  # ä»0.1é™ä½åˆ°0.05
                        # ç”Ÿæˆè¿ç§»æŒ‡ä»¤
                        migration_cmd = {
                            'type': 'task_migration',
                            'source_rsu': source_rsu_id,
                            'target_rsu': target_rsu_id,
                            'task_count': migrate_count,
                            'urgency': 'high' if source_factor > 0.9 else 'medium',
                            'expected_benefit': net_benefit,
                            'wired_transmission': {
                                'data_size_mb': migration_data_size,
                                'delay_ms': wired_delay * 1000,
                                'energy_j': wired_energy,
                                'total_cost': total_cost
                            },
                            'coordination_time': time.time()
                        }
                        
                        migration_commands.append(migration_cmd)
                        
                        # æ›´æ–°ç›®æ ‡è´Ÿè½½ï¼ˆé¢„ä¼°ï¼‰
                        target_load.queue_length += migrate_count
                        target_load.cpu_usage = min(1.0, target_load.cpu_usage + 0.1)
        
        logging.info(f"ğŸš€ ç”Ÿæˆæ™ºèƒ½è¿ç§»åè°ƒæŒ‡ä»¤: {len(migration_commands)} æ¡")
        return migration_commands
    
    def get_global_scheduling_status(self) -> Dict[str, Any]:
        """
        ğŸ“ˆ è·å–å…¨å±€è°ƒåº¦çŠ¶æ€æŠ¥å‘Š
        
        Returns:
            Dict: å…¨å±€è°ƒåº¦çŠ¶æ€ä¿¡æ¯
        """
        status = {
            'central_rsu_id': self.central_rsu_id,
            'managed_rsu_count': len(self.rsu_loads),
            'global_metrics': self.global_metrics.copy(),
            'current_decisions': len(self.scheduling_decisions),
            'system_health': self._assess_system_health(),
            'load_distribution': self._get_load_distribution(),
            'scheduling_efficiency': self._calculate_scheduling_efficiency(),
            'timestamp': time.time()
        }
        
        return status
    
    # ==================== ç§æœ‰æ–¹æ³• ====================
    
    def _calculate_load_balance_index(self) -> float:
        """è®¡ç®—è´Ÿè½½å‡è¡¡æŒ‡æ•°"""
        if not self.rsu_loads:
            return 0.0
        
        loads = [info.cpu_usage for info in self.rsu_loads.values()]
        if not loads:
            return 0.0
        
        mean_load = np.mean(loads)
        std_load = np.std(loads)
        
        # è´Ÿè½½å‡è¡¡æŒ‡æ•° = 1 - (æ ‡å‡†å·® / å‡å€¼)ï¼Œå€¼è¶Šå¤§è¶Šå‡è¡¡
        balance_index = max(0.0, 1.0 - (std_load / (mean_load + 1e-6)))
        return balance_index
    
    def _calculate_normalized_load(self, load_info: RSULoadInfo) -> float:
        """è®¡ç®—æ ‡å‡†åŒ–è´Ÿè½½å› å­"""
        # ç»¼åˆCPUã€é˜Ÿåˆ—å’Œç½‘ç»œè´Ÿè½½
        cpu_factor = load_info.cpu_usage
        queue_factor = min(1.0, load_info.queue_length / 10.0)  # é˜Ÿåˆ—é•¿åº¦æ ‡å‡†åŒ–
        network_factor = load_info.network_bandwidth_usage
        
        # åŠ æƒç»¼åˆè´Ÿè½½
        normalized_load = (cpu_factor * 0.5 + queue_factor * 0.3 + network_factor * 0.2)
        return min(1.0, normalized_load)
    
    def _calculate_priority(self, load_info: RSULoadInfo, predicted_load: float) -> int:
        """è®¡ç®—è°ƒåº¦ä¼˜å…ˆçº§ (1-5)"""
        current_load = self._calculate_normalized_load(load_info)
        
        # ç»¼åˆå½“å‰è´Ÿè½½å’Œé¢„æµ‹è´Ÿè½½
        combined_load = current_load * 0.7 + predicted_load * 0.3
        
        if combined_load < 0.2:
            return 5  # æœ€é«˜ä¼˜å…ˆçº§ï¼Œç©ºé—²èŠ‚ç‚¹
        elif combined_load < 0.4:
            return 4
        elif combined_load < 0.6:
            return 3
        elif combined_load < 0.8:
            return 2
        else:
            return 1  # æœ€ä½ä¼˜å…ˆçº§ï¼Œè¿‡è½½èŠ‚ç‚¹
    
    def _estimate_response_time(self, load_info: RSULoadInfo, additional_tasks: float) -> float:
        """é¢„æµ‹å“åº”æ—¶é—´"""
        # åŸºç¡€å“åº”æ—¶é—´
        base_time = 50.0  # ms
        
        # é˜Ÿåˆ—å»¶è¿Ÿ
        queue_delay = (load_info.queue_length + additional_tasks) * 10.0
        
        # CPUè´Ÿè½½å»¶è¿Ÿ
        cpu_delay = load_info.cpu_usage * 30.0
        
        # ç½‘ç»œå»¶è¿Ÿ
        network_delay = load_info.network_bandwidth_usage * 20.0
        
        total_response_time = base_time + queue_delay + cpu_delay + network_delay
        return total_response_time
    
    def _generate_scheduling_reason(self, load_info: RSULoadInfo, allocation_ratio: float, priority: int) -> str:
        """ç”Ÿæˆè°ƒåº¦åŸå› è¯´æ˜"""
        reasons = []
        
        if priority >= 4:
            reasons.append("èŠ‚ç‚¹ç©ºé—²ï¼Œé«˜ä¼˜å…ˆçº§åˆ†é…")
        elif priority <= 2:
            reasons.append("èŠ‚ç‚¹è¿‡è½½ï¼Œé™åˆ¶åˆ†é…")
        
        if load_info.cache_hit_rate > 0.7:
            reasons.append("ç¼“å­˜å‘½ä¸­ç‡é«˜")
        
        if load_info.queue_length == 0:
            reasons.append("æ— é˜Ÿåˆ—ç§¯å‹")
        
        if allocation_ratio > 0.3:
            reasons.append("å¤§æ¯”ä¾‹ä»»åŠ¡åˆ†é…")
        
        return "; ".join(reasons) if reasons else "æ ‡å‡†è´Ÿè½½å‡è¡¡åˆ†é…"
    
    def _update_global_metrics(self):
        """æ›´æ–°å…¨å±€æ€§èƒ½æŒ‡æ ‡"""
        if not self.rsu_loads:
            return
        
        # æ€»ç³»ç»Ÿè´Ÿè½½
        total_load = sum(self._calculate_normalized_load(info) for info in self.rsu_loads.values())
        self.global_metrics['total_system_load'] = total_load / len(self.rsu_loads)
        
        # è´Ÿè½½å‡è¡¡æŒ‡æ•°
        self.global_metrics['load_balance_index'] = self._calculate_load_balance_index()
        
        # å…¨å±€å“åº”æ—¶é—´
        response_times = [info.avg_response_time for info in self.rsu_loads.values() if info.avg_response_time > 0]
        self.global_metrics['global_response_time'] = np.mean(response_times) if response_times else 0.0
        
        # ç³»ç»Ÿååé‡
        completion_rates = [info.task_completion_rate for info in self.rsu_loads.values()]
        self.global_metrics['system_throughput'] = np.sum(completion_rates)
    
    def _assess_system_health(self) -> str:
        """è¯„ä¼°ç³»ç»Ÿå¥åº·çŠ¶æ€"""
        balance_index = self.global_metrics['load_balance_index']
        avg_response_time = self.global_metrics['global_response_time']
        
        if balance_index > 0.8 and avg_response_time < 100:
            return "excellent"
        elif balance_index > 0.6 and avg_response_time < 200:
            return "good"
        elif balance_index > 0.4 and avg_response_time < 300:
            return "fair"
        else:
            return "poor"
    
    def _get_load_distribution(self) -> Dict[str, float]:
        """è·å–è´Ÿè½½åˆ†å¸ƒæƒ…å†µ"""
        distribution = {}
        for rsu_id, load_info in self.rsu_loads.items():
            distribution[rsu_id] = self._calculate_normalized_load(load_info)
        return distribution
    
    def _calculate_scheduling_efficiency(self) -> float:
        """è®¡ç®—è°ƒåº¦æ•ˆç‡"""
        if self.global_metrics['scheduling_decisions_count'] == 0:
            return 0.0
        
        # åŸºäºè´Ÿè½½å‡è¡¡æŒ‡æ•°å’Œç³»ç»Ÿååé‡
        balance_score = self.global_metrics['load_balance_index']
        throughput_score = min(1.0, self.global_metrics['system_throughput'] / 100.0)
        
        efficiency = (balance_score * 0.6 + throughput_score * 0.4)
        return efficiency


class LoadPredictor:
    """ğŸ“ˆ è´Ÿè½½é¢„æµ‹å™¨"""
    
    def __init__(self):
        self.prediction_model = 'exponential_smoothing'  # æŒ‡æ•°å¹³æ»‘
        self.alpha = 0.3  # å¹³æ»‘å‚æ•°
    
    def predict_future_loads(self, load_history: Dict[str, deque], steps: int = 3) -> Dict[str, float]:
        """
        é¢„æµ‹æœªæ¥è´Ÿè½½
        
        Args:
            load_history: è´Ÿè½½å†å²æ•°æ®
            steps: é¢„æµ‹æ­¥æ•°
            
        Returns:
            Dict[str, float]: é¢„æµ‹çš„è´Ÿè½½å€¼
        """
        predictions = {}
        
        for rsu_id, history in load_history.items():
            if len(history) < 2:
                predictions[rsu_id] = history[-1] if history else 0.0
                continue
            
            # æŒ‡æ•°å¹³æ»‘é¢„æµ‹
            recent_loads = list(history)
            if self.prediction_model == 'exponential_smoothing':
                predicted_load = self._exponential_smoothing_prediction(recent_loads, steps)
            else:
                predicted_load = np.mean(recent_loads[-3:])  # ç®€å•å¹³å‡
            
            predictions[rsu_id] = max(0.0, min(1.0, predicted_load))
        
        return predictions
    
    def _exponential_smoothing_prediction(self, history: List[float], steps: int) -> float:
        """æŒ‡æ•°å¹³æ»‘é¢„æµ‹"""
        if len(history) < 2:
            return history[-1] if history else 0.0
        
        # åˆå§‹å€¼
        smoothed = history[0]
        
        # æŒ‡æ•°å¹³æ»‘
        for value in history[1:]:
            smoothed = self.alpha * value + (1 - self.alpha) * smoothed
        
        # ç®€å•åœ°è¿”å›å½“å‰å¹³æ»‘å€¼ä½œä¸ºæœªæ¥é¢„æµ‹
        return smoothed


class AllocationOptimizer:
    """ğŸ¯ åˆ†é…ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.optimization_method = 'weighted_fair_allocation'
    
    def optimize_allocation(self, 
                          current_loads: Dict[str, RSULoadInfo],
                          predicted_loads: Dict[str, float],
                          incoming_tasks: int,
                          fairness_weight: float = 0.4,
                          efficiency_weight: float = 0.3) -> Dict[str, float]:
        """
        ä¼˜åŒ–ä»»åŠ¡åˆ†é…
        
        Args:
            current_loads: å½“å‰è´Ÿè½½ä¿¡æ¯
            predicted_loads: é¢„æµ‹è´Ÿè½½
            incoming_tasks: æ–°å¢ä»»åŠ¡æ•°
            fairness_weight: å…¬å¹³æ€§æƒé‡
            efficiency_weight: æ•ˆç‡æ€§æƒé‡
            
        Returns:
            Dict[str, float]: åˆ†é…æ¯”ä¾‹å­—å…¸
        """
        if not current_loads:
            return {}
        
        allocation = {}
        
        if self.optimization_method == 'weighted_fair_allocation':
            allocation = self._weighted_fair_allocation(
                current_loads, predicted_loads, incoming_tasks, fairness_weight, efficiency_weight
            )
        
        # ç¡®ä¿åˆ†é…æ¯”ä¾‹æ€»å’Œä¸º1.0
        total_allocation = sum(allocation.values())
        if total_allocation > 0:
            allocation = {rsu_id: ratio / total_allocation for rsu_id, ratio in allocation.items()}
        
        return allocation
    
    def _weighted_fair_allocation(self, 
                                current_loads: Dict[str, RSULoadInfo],
                                predicted_loads: Dict[str, float],
                                incoming_tasks: int,
                                fairness_weight: float,
                                efficiency_weight: float) -> Dict[str, float]:
        """åŠ æƒå…¬å¹³åˆ†é…ç®—æ³•"""
        allocation = {}
        
        # è®¡ç®—æ¯ä¸ªRSUçš„åˆ†é…æƒé‡
        for rsu_id, load_info in current_loads.items():
            # å½“å‰è´Ÿè½½å› å­ï¼ˆè´Ÿè½½è¶Šé«˜ï¼Œæƒé‡è¶Šä½ï¼‰
            current_load_factor = load_info.cpu_usage
            load_weight = max(0.1, 1.0 - current_load_factor)
            
            # é¢„æµ‹è´Ÿè½½å› å­
            predicted_load_factor = predicted_loads.get(rsu_id, current_load_factor)
            prediction_weight = max(0.1, 1.0 - predicted_load_factor)
            
            # è®¡ç®—èƒ½åŠ›å› å­ï¼ˆåŸºäºCPUé¢‘ç‡å’Œç¼“å­˜å‘½ä¸­ç‡ï¼‰
            capacity_factor = load_info.cpu_frequency / 1e10  # æ ‡å‡†åŒ–åˆ°0-1
            cache_factor = load_info.cache_hit_rate
            efficiency_factor = (capacity_factor * 0.7 + cache_factor * 0.3)
            
            # ç»¼åˆæƒé‡
            total_weight = (
                load_weight * fairness_weight +
                prediction_weight * 0.3 +
                efficiency_factor * efficiency_weight
            )
            
            allocation[rsu_id] = max(0.05, total_weight)  # æœ€å°åˆ†é…ä¿è¯
        
        return allocation


# ==================== å…¨å±€è°ƒåº¦æ¥å£ ====================

def create_central_scheduler(central_rsu_id: str = "RSU_2") -> CentralRSUScheduler:
    """
    ğŸ—ï¸ åˆ›å»ºä¸­å¤®RSUè°ƒåº¦å™¨å®ä¾‹
    
    Args:
        central_rsu_id: ä¸­å¤®RSU ID
        
    Returns:
        CentralRSUScheduler: è°ƒåº¦å™¨å®ä¾‹
    """
    scheduler = CentralRSUScheduler(central_rsu_id=central_rsu_id)
    logging.info(f"ğŸ¢ åˆ›å»ºä¸­å¤®RSUè°ƒåº¦å™¨: {central_rsu_id}")
    return scheduler


if __name__ == "__main__":
    # ğŸ§ª æµ‹è¯•ä¸­å¤®RSUè°ƒåº¦å™¨
    logging.basicConfig(level=logging.INFO)
    
    # åˆ›å»ºè°ƒåº¦å™¨
    scheduler = create_central_scheduler("RSU_2")
    
    # æ¨¡æ‹ŸRSUæ•°æ®
    mock_rsu_data = [
        {
            'id': 'RSU_0', 'position': [100, 100], 'cpu_usage': 0.3,
            'cpu_frequency': 8e9, 'computation_queue': [1, 2], 'cache_hit_rate': 0.6
        },
        {
            'id': 'RSU_1', 'position': [200, 200], 'cpu_usage': 0.8,
            'cpu_frequency': 6e9, 'computation_queue': [1, 2, 3, 4, 5], 'cache_hit_rate': 0.4
        },
        {
            'id': 'RSU_3', 'position': [300, 100], 'cpu_usage': 0.1,
            'cpu_frequency': 10e9, 'computation_queue': [], 'cache_hit_rate': 0.9
        },
    ]
    
    # æ”¶é›†è´Ÿè½½ä¿¡æ¯
    loads = scheduler.collect_all_rsu_loads(mock_rsu_data)
    
    # æ‰§è¡Œè°ƒåº¦
    decisions = scheduler.global_load_balance_scheduling(incoming_task_count=5)
    
    # ç”Ÿæˆè¿ç§»æŒ‡ä»¤
    migrations = scheduler.intelligent_migration_coordination()
    
    # è·å–çŠ¶æ€æŠ¥å‘Š
    status = scheduler.get_global_scheduling_status()
    
    print("ğŸ¢ ä¸­å¤®RSUè°ƒåº¦å™¨æµ‹è¯•å®Œæˆ")
    print(f"ğŸ“Š è´Ÿè½½æ”¶é›†: {len(loads)} ä¸ªRSU")
    print(f"ğŸ¯ è°ƒåº¦å†³ç­–: {len(decisions)} æ¡")
    print(f"ğŸš€ è¿ç§»æŒ‡ä»¤: {len(migrations)} æ¡")
    print(f"ğŸ“ˆ ç³»ç»Ÿå¥åº·: {status['system_health']}")
