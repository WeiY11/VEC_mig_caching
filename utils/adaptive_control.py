#!/usr/bin/env python3
"""
è‡ªé€‚åº”ç¼“å­˜å’Œè¿ç§»æ§åˆ¶ç»„ä»¶
å…è®¸æ™ºèƒ½ä½“å­¦ä¹ å’Œæ§åˆ¶ç¼“å­˜è¿ç§»çš„å…³é”®å‚æ•°
"""

import numpy as np
from typing import Dict, List, Tuple, Optional
import time
from collections import defaultdict
import os
# ğŸ”§ ä¿®å¤ï¼šå¯¼å…¥ç»Ÿä¸€æ—¶é—´ç®¡ç†å™¨
from .unified_time_manager import get_simulation_time

class AdaptiveCacheController:
    """
    è‡ªé€‚åº”ç¼“å­˜æ§åˆ¶å™¨
    æ™ºèƒ½ä½“å¯ä»¥æ§åˆ¶ç¼“å­˜ç­–ç•¥çš„å…³é”®å‚æ•°
    """

    def __init__(self, cache_capacity: float = 100.0):
        self.cache_capacity = cache_capacity

        # ğŸ”§ ä¿®å¤ï¼šé™ä½ç¼“å­˜é˜ˆå€¼ï¼Œæé«˜å‘½ä¸­ç‡
        self.agent_params = {
            'heat_threshold_high': 0.5,      # é™ä½é«˜çƒ­åº¦é˜ˆå€¼ï¼š50% [ä»0.7é™åˆ°0.5]
            'heat_threshold_medium': 0.25,   # é™ä½ä¸­çƒ­åº¦é˜ˆå€¼ï¼š25% [ä»0.35é™åˆ°0.25]
            'prefetch_ratio': 0.08,          # é™ä½é¢„å–æ¯”ä¾‹ï¼š8% [ä»0.05é™åˆ°0.08ï¼Œæ›´ç§¯æç¼“å­˜]
            'collaboration_weight': 0.5      # å¢åŠ åä½œæƒé‡ï¼š50% [ä»0.3å¢åˆ°0.5]
        }

        # ğŸ”§ ä¼˜åŒ–ï¼šè°ƒæ•´å‚æ•°æœ‰æ•ˆèŒƒå›´ï¼Œæ›´é€‚åˆå®é™…ç¼“å­˜åœºæ™¯
        self.param_bounds = {
            'heat_threshold_high': (0.5, 0.9),      # é«˜çƒ­åº¦é˜ˆå€¼èŒƒå›´ç¼©å°
            'heat_threshold_medium': (0.2, 0.6),    # ä¸­çƒ­åº¦é˜ˆå€¼èŒƒå›´è°ƒæ•´
            'prefetch_ratio': (0.02, 0.15),         # é¢„å–æ¯”ä¾‹èŒƒå›´ç¼©å°ï¼Œé¿å…è¿‡åº¦é¢„å–
            'collaboration_weight': (0.0, 0.8)      # åä½œæƒé‡ä¸Šé™é™ä½
        }

        # ç¼“å­˜ç»Ÿè®¡
        self.cache_stats = {
            'total_requests': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'current_utilization': 0.0,
            'hit_rate_history': [],
            'evicted_items': 0,
            'collaborative_writes': 0,
            'prefetch_events': 0
        }

        # çƒ­åº¦è®¡ç®—
        self.content_heat = defaultdict(float)
        self.access_history = defaultdict(list)

        # è”åŠ¨æ§åˆ¶å‚æ•°ï¼ˆç”±ç­–ç•¥åè°ƒå™¨/æ™ºèƒ½ä½“åŠ¨æ€è°ƒæ•´ï¼‰
        self.joint_params = {
            'prefetch_lead_time': 0.4,  # ç§’ï¼Œæ›´ä¿å®ˆçš„é¢„å–çª—å£
            'migration_backoff': 0.2,   # åˆå§‹é€€é¿ç³»æ•°ï¼Œé€æ­¥æ”¾å¼€
        }

        print(f"ğŸ¤– è‡ªé€‚åº”ç¼“å­˜æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")

    def update_agent_params(self, agent_actions: Dict[str, float]):
        """
        æ ¹æ®æ™ºèƒ½ä½“åŠ¨ä½œæ›´æ–°ç¼“å­˜å‚æ•°

        Args:
            agent_actions: æ ¼å¼ {'cache_param_0': 0.7, 'cache_param_1': -0.4, ...}
        """
        if not isinstance(agent_actions, dict):
            return

        param_names = list(self.param_bounds.keys())

        # ğŸ”§ ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨è¯­ä¹‰åŒ–å‚æ•°åæ˜ å°„
        param_mapping = {
            'heat_threshold_high': 'heat_threshold_high',
            'heat_threshold_medium': 'heat_threshold_medium', 
            'prefetch_ratio': 'prefetch_ratio',
            'collaboration_weight': 'collaboration_weight'
        }

        for param_name, action_key in param_mapping.items():
            if action_key in agent_actions:
                # å°†æ™ºèƒ½ä½“åŠ¨ä½œ [-1,1] æ˜ å°„åˆ°å‚æ•°èŒƒå›´
                action_value = np.clip(agent_actions[action_key], -1.0, 1.0)
                param_min, param_max = self.param_bounds[param_name]

                # çº¿æ€§æ˜ å°„: [-1,1] â†’ [param_min, param_max]
                normalized_value = (action_value + 1.0) / 2.0
                param_value = param_min + normalized_value * (param_max - param_min)

                self.agent_params[param_name] = param_value

        # ç¡®ä¿å‚æ•°é€»è¾‘ä¸€è‡´æ€§ï¼šä¸­é˜ˆå€¼ < é«˜é˜ˆå€¼
        if self.agent_params['heat_threshold_medium'] >= self.agent_params['heat_threshold_high']:
            self.agent_params['heat_threshold_medium'] = self.agent_params['heat_threshold_high'] - 0.1

    def update_content_heat(self, content_id: str, access_weight: float = 1.0):
        """æ›´æ–°å†…å®¹çƒ­åº¦"""
        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€ä»¿çœŸæ—¶é—´
        current_time = get_simulation_time()

        # æ›´æ–°è®¿é—®å†å²
        self.access_history[content_id].append(current_time)

        # ä¿æŒå†å²é•¿åº¦
        if len(self.access_history[content_id]) > 50:
            self.access_history[content_id].pop(0)

        # ğŸ”§ ä¼˜åŒ–ï¼šæ”¹è¿›çƒ­åº¦è®¡ç®—ï¼Œæ›´é€‚åˆä»¿çœŸç¯å¢ƒ
        # è®¡ç®—æœ€è¿‘è®¿é—®çª—å£ï¼ˆä»1å°æ—¶æ”¹ä¸º10åˆ†é’Ÿï¼Œé€‚åº”ä»¿çœŸï¼‰
        recent_accesses = [t for t in self.access_history[content_id] 
                          if current_time - t < 600]  # 10åˆ†é’Ÿå†…çš„è®¿é—®ï¼Œé€‚åº”ä»¿çœŸæ—¶é—´

        # é¢‘ç‡çƒ­åº¦ï¼šä½¿ç”¨å¹³æ–¹æ ¹é¿å…æç«¯å€¼
        frequency_heat = min(1.0, np.sqrt(len(recent_accesses) / 5.0))  # ğŸ”§ ä»8æ¬¡é™åˆ°5æ¬¡ï¼Œæ›´å®¹æ˜“è¾¾åˆ°æ»¡çƒ­åº¦

        # æœ€è¿‘æ€§çƒ­åº¦ï¼šæŒ‡æ•°è¡°å‡æ›´å¹³æ»‘
        if self.access_history[content_id]:
            last_access = self.access_history[content_id][-1]
            time_since_last = current_time - last_access
            recency_heat = np.exp(-time_since_last / 120.0)  # 2åˆ†é’ŸåŠè¡°æœŸ
        else:
            recency_heat = 0.0

        # ğŸ”§ ä¼˜åŒ–ï¼šç»¼åˆçƒ­åº¦è®¡ç®—ï¼Œå¹³è¡¡é¢‘ç‡å’Œæœ€è¿‘æ€§
        self.content_heat[content_id] = min(1.0, 0.6 * frequency_heat + 0.4 * recency_heat)

    def should_cache_content(
        self,
        content_id: str,
        data_size: float,
        available_capacity: float,
        cache_snapshot: Dict,
        total_capacity_mb: float,
        cache_priority: float = 0.0  # ğŸ”§ ä¼˜åŒ–8: æ·»åŠ ç¼“å­˜ä¼˜å…ˆçº§å‚æ•°
    ) -> Tuple[bool, str, List[str]]:
        """
        Decide whether to cache a content item. Returns eviction candidates when needed.
        
        ğŸ”§ ä¼˜åŒ–: ç»“åˆä»»åŠ¡çš„cache_priorityè¿›è¡Œæ›´æ™ºèƒ½çš„å†³ç­–
        - é«˜ä¼˜å…ˆçº§ä»»åŠ¡æ›´å®¹æ˜“è¢«ç¼“å­˜
        - ä½ä¼˜å…ˆçº§ä»»åŠ¡éœ€è¦æ›´é«˜çš„çƒ­åº¦
        """
        heat = self.content_heat.get(content_id, 0.0)
        
        # ğŸ”§ ä¼˜åŒ–: ç»“åˆcache_priorityè°ƒæ•´çƒ­åº¦
        # é«˜ä¼˜å…ˆçº§ä»»åŠ¡ï¼ˆå¦‚video_processï¼‰å³ä½¿çƒ­åº¦è¾ƒä½ä¹Ÿå¯èƒ½è¢«ç¼“å­˜
        adjusted_heat = heat + cache_priority * 0.3  # cache_priorityæä¾›æœ€å¤š30%åŠ æˆ

        high_threshold = self.agent_params['heat_threshold_high']
        medium_threshold = self.agent_params['heat_threshold_medium']
        prefetch_ratio = self.agent_params['prefetch_ratio']

        capacity_reference = total_capacity_mb if total_capacity_mb > 0 else self.cache_capacity
        capacity_threshold = capacity_reference * prefetch_ratio
        utilization = 1.0 - (available_capacity / max(1.0, capacity_reference))
        eviction_candidates: List[str] = []

        current_time = get_simulation_time()

        def _select_evictions(required_space: float) -> List[str]:
            if not cache_snapshot or required_space <= 0:
                return []
            scored_items: List[Tuple[float, str]] = []
            max_capacity = max(1.0, capacity_reference)
            for cid, meta in cache_snapshot.items():
                size = float(meta.get('size', 0.0) or 0.0)
                if size <= 0.0:
                    size = 0.1
                history = self.access_history.get(cid, [])
                freq = float(len(history))
                last_access = history[-1] if history else float(meta.get('timestamp', 0.0) or 0.0)
                age = max(0.0, current_time - last_access)
                heat_score = float(self.content_heat.get(cid, 0.0))

                size_score = min(1.0, size / max_capacity)
                freq_score = 1.0 - np.tanh(freq / 5.0)  # é«˜é¢‘è¶Šå°å¾—åˆ†è¶Šä½
                age_score = np.tanh(age / 600.0)  # è¶…è¿‡10åˆ†é’Ÿé€æ­¥æ¥è¿‘1
                inverse_heat = 1.0 - heat_score

                value = 0.4 * inverse_heat + 0.3 * age_score + 0.2 * size_score + 0.1 * freq_score
                scored_items.append((value, cid))

            scored_items.sort(key=lambda x: x[0], reverse=True)
            removed: List[str] = []
            reclaimed = 0.0
            for value, cid in scored_items:
                size = float(cache_snapshot.get(cid, {}).get('size', 0.0) or 0.0)
                removed.append(cid)
                reclaimed += size
                if reclaimed >= required_space:
                    break
            return removed

        # ğŸ”§ ä¼˜åŒ–: ä½¿ç”¨adjusted_heatè¿›è¡Œå†³ç­–
        if adjusted_heat > high_threshold:
            if available_capacity > data_size:
                reason = f"High-heat cache (heat:{heat:.2f}"
                if cache_priority > 0:
                    reason += f"+priority:{cache_priority:.2f}"
                reason += f">{high_threshold:.2f})"
                return True, reason, eviction_candidates
            eviction_candidates = _select_evictions(data_size - available_capacity)
            if eviction_candidates:
                return True, f"High-heat cache with eviction x{len(eviction_candidates)}", eviction_candidates

        if adjusted_heat > medium_threshold and available_capacity > max(data_size, capacity_threshold):
            reason = f"Medium-heat prefetch (heat:{heat:.2f}"
            if cache_priority > 0:
                reason += f"+priority:{cache_priority:.2f}"
            reason += f">{medium_threshold:.2f})"
            return True, reason, eviction_candidates

        # ğŸ”§ ä¿®å¤ï¼šæ›´ç§¯æçš„ç¼“å­˜ç­–ç•¥ï¼Œé™ä½é˜ˆå€¼
        # å¯¹äºçƒ­åº¦>0.05çš„å†…å®¹ï¼Œå°±å¯èƒ½è¢«ç¼“å­˜
        if adjusted_heat > 0.05:
            collaboration_weight = self.agent_params['collaboration_weight']
            cache_probability = adjusted_heat * collaboration_weight * max(0.0, 1.2 - utilization)
            if np.random.random() < cache_probability:
                if available_capacity > data_size:
                    return True, f"Collaborative cache (p={cache_probability:.2f})", eviction_candidates
                eviction_candidates = _select_evictions(data_size - available_capacity)
                if eviction_candidates:
                    return True, f"Collaborative cache with eviction x{len(eviction_candidates)}", eviction_candidates

        return False, f"Skip cache (heat:{heat:.2f}, priority:{cache_priority:.2f}, free:{available_capacity:.1f}MB)", eviction_candidates

    def record_cache_result(self, content_id: str, was_hit: bool):
        """è®°å½•ç¼“å­˜ç»“æœ"""
        self.cache_stats['total_requests'] += 1

        if was_hit:
            self.cache_stats['cache_hits'] += 1
        else:
            self.cache_stats['cache_misses'] += 1

        # æ›´æ–°å‘½ä¸­ç‡å†å²
        if self.cache_stats['total_requests'] > 0:
            hit_rate = self.cache_stats['cache_hits'] / self.cache_stats['total_requests']
            self.cache_stats['hit_rate_history'].append(hit_rate)

            # ä¿æŒå†å²é•¿åº¦
            if len(self.cache_stats['hit_rate_history']) > 100:
                self.cache_stats['hit_rate_history'].pop(0)

    def get_cache_metrics(self) -> Dict:
        """è¿”å›ç¼“å­˜æ•ˆæœæŒ‡æ ‡ä¸å…³é”®å‚æ•°ã€‚"""
        total_requests = self.cache_stats['total_requests']
        if total_requests == 0:
            return {
                'hit_rate': 0.0,
                'miss_rate': 0.0,  # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ miss_rateå­—æ®µ
                'effectiveness': 0.0,
                'utilization': 0.0,
                'total_requests': 0,
                'evicted_items': 0,
                'collaborative_writes': 0,
                'prefetch_events': self.cache_stats['prefetch_events'],
                'agent_params': dict(self.agent_params),
                'joint_params': dict(self.joint_params)
            }

        hit_rate = self.cache_stats['cache_hits'] / total_requests
        miss_rate = 1.0 - hit_rate  # ğŸ”§ ä¿®å¤ï¼šè®¡ç®—miss_rate
        utilization = self.cache_stats['current_utilization']

        effectiveness = hit_rate * min(1.0, utilization)

        return {
            'hit_rate': hit_rate,
            'miss_rate': miss_rate,  # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ miss_rateåˆ°è¿”å›å€¼
            'effectiveness': effectiveness,
            'utilization': utilization,
            'total_requests': total_requests,
            'evicted_items': self.cache_stats['evicted_items'],
            'collaborative_writes': self.cache_stats['collaborative_writes'],
            'prefetch_events': self.cache_stats['prefetch_events'],
            'agent_params': dict(self.agent_params),
            'joint_params': dict(self.joint_params)
        }

    def apply_joint_params(self, joint_params: Dict[str, float]) -> None:
        """åº”ç”¨ç­–ç•¥åè°ƒå™¨ä¸‹å‘çš„è”åŠ¨å‚æ•°ï¼ˆå¦‚é¢„å–çª—å£ï¼‰ã€‚"""
        if not isinstance(joint_params, dict):
            return
        lead_time = joint_params.get('prefetch_lead_time')
        if lead_time is not None:
            lead_time = float(np.clip(lead_time, 0.0, 10.0))
            self.joint_params['prefetch_lead_time'] = lead_time

        backoff = joint_params.get('migration_backoff')
        if backoff is not None:
            backoff = float(np.clip(backoff, 0.0, 1.0))
            self.joint_params['migration_backoff'] = backoff

    def register_prefetch_event(self, count: int = 1) -> None:
        """è®°å½•ä¸€æ¬¡é¢„å–äº‹ä»¶ï¼Œä¾›ç›‘æ§å’Œå¥–åŠ±è®¡ç®—ä½¿ç”¨ã€‚"""
        try:
            count = int(max(0, count))
        except Exception:
            count = 0
        self.cache_stats['prefetch_events'] += count

    def get_joint_params_snapshot(self) -> Dict[str, float]:
        """è¿”å›å½“å‰ç¼“å­˜ä¾§çš„è”åŠ¨å‚æ•°é…ç½®ã€‚"""
        return dict(self.joint_params)
class AdaptiveMigrationController:
    """
    è‡ªé€‚åº”è¿ç§»æ§åˆ¶å™¨
    æ™ºèƒ½ä½“å¯ä»¥æ§åˆ¶è¿ç§»ç­–ç•¥çš„å…³é”®å‚æ•°
    """

    def __init__(self):
        # ğŸ¤– DRLå¯å­¦ä¹ çš„è¿ç§»å‚æ•°ï¼ˆåˆå§‹å€¼ä¸ºåˆç†é»˜è®¤å€¼ï¼‰
        self.agent_params = {
            'cpu_overload_threshold': 0.85,    # CPUè¿‡è½½é˜ˆå€¼ï¼ˆDRLå¯è°ƒæ•´70-95%ï¼‰
            'bandwidth_overload_threshold': 0.85,  # å¸¦å®½è¿‡è½½é˜ˆå€¼
            'load_diff_threshold': 0.20,       # è´Ÿè½½å·®è§¦å‘é˜ˆå€¼ï¼ˆDRLå¯è°ƒæ•´10-40%ï¼‰
            'uav_battery_threshold': 0.25,     # UAVç”µæ± é˜ˆå€¼
            'migration_cost_weight': 0.3,      # è¿ç§»æˆæœ¬æƒé‡
            'urgency_threshold_rsu': 0.1,      # RSUç´§æ€¥é˜ˆå€¼
            'urgency_threshold_uav': 0.15      # UAVç´§æ€¥é˜ˆå€¼
        }

        # ğŸ¯ DRLå¯è°ƒæ•´çš„å‚æ•°èŒƒå›´
        self.param_bounds = {
            'cpu_overload_threshold': (0.70, 0.95),      # CPUé˜ˆå€¼70-95%
            'bandwidth_overload_threshold': (0.70, 0.95), # å¸¦å®½é˜ˆå€¼70-95%
            'load_diff_threshold': (0.10, 0.40),         # è´Ÿè½½å·®é˜ˆå€¼10-40%
            'uav_battery_threshold': (0.15, 0.40),       # UAVç”µæ± 15-40%
            'migration_cost_weight': (0.1, 0.6),         # æˆæœ¬æƒé‡0.1-0.6
            'urgency_threshold_rsu': (0.05, 0.25),       # RSUç´§æ€¥åº¦5-25%
            'urgency_threshold_uav': (0.10, 0.30)        # UAVç´§æ€¥åº¦10-30%
        }

        # è¿ç§»ç»Ÿè®¡
        self.migration_stats = {
            'total_triggers': 0,
            'successful_migrations': 0,
            'total_cost': 0.0,
            'avg_delay_saved': 0.0,
            'success_rate_history': []
        }

        # èŠ‚ç‚¹çŠ¶æ€å†å²
        self.node_load_history = defaultdict(list)
        self.last_migration_time = defaultdict(float)

        # è”åŠ¨æ§åˆ¶çŠ¶æ€
        self.joint_backoff_factor = 0.2
        self.dynamic_threshold_scale = 1.0
        self.cache_feedback = {'hit_rate': 0.0, 'miss_rate': 0.0}

        print(f"ğŸ¤– è‡ªé€‚åº”è¿ç§»æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")

    def update_agent_params(self, agent_actions: Dict[str, float]):
        """
        ğŸ”§ æ ¹æ®æ™ºèƒ½ä½“åŠ¨ä½œæ›´æ–°è¿ç§»å‚æ•°ï¼ˆæ¿€æ´»DRLæ§åˆ¶ï¼‰

        Args:
            agent_actions: DRLè¾“å‡ºçš„è¿ç§»å‚æ•°å­—å…¸
                {
                    'cpu_overload_threshold': -1~1,
                    'bandwidth_overload_threshold': -1~1,
                    'load_diff_threshold': -1~1,
                    'uav_battery_threshold': -1~1
                }
        """
        if not isinstance(agent_actions, dict):
            return

        # ğŸ”§ æ¿€æ´»ï¼šå°†DRLåŠ¨ä½œæ˜ å°„åˆ°å®é™…å‚æ•°èŒƒå›´
        for param_name, action_value in agent_actions.items():
            if param_name in self.param_bounds:
                # åŠ¨ä½œå€¼ä»[-1, 1]æ˜ å°„åˆ°å‚æ•°èŒƒå›´
                action_value = np.clip(action_value, -1.0, 1.0)
                param_min, param_max = self.param_bounds[param_name]

                # å½’ä¸€åŒ–åˆ°[0, 1]å†æ˜ å°„åˆ°å®é™…èŒƒå›´
                normalized_value = (action_value + 1.0) / 2.0
                param_value = param_min + normalized_value * (param_max - param_min)

                # æ›´æ–°å‚æ•°
                self.agent_params[param_name] = param_value

    def apply_joint_params(self, joint_params: Dict[str, float]) -> None:
        """åº”ç”¨è”åˆç­–ç•¥å‚æ•°ï¼ˆå¦‚è¿ç§»é€€é¿ç³»æ•°ï¼‰ã€‚"""
        if not isinstance(joint_params, dict):
            return
        backoff = joint_params.get('migration_backoff')
        if backoff is not None:
            backoff = float(np.clip(backoff, 0.0, 1.0))
            self.joint_backoff_factor = backoff

    def ingest_cache_feedback(self, hit_rate: float, miss_rate: float) -> None:
        """æ ¹æ®ç¼“å­˜å‘½ä¸­ç‡åŠ¨æ€è°ƒæ•´è¿ç§»é˜ˆå€¼."""
        hit_rate = float(np.clip(hit_rate, 0.0, 1.0))
        miss_rate = float(np.clip(miss_rate, 0.0, 1.0))
        self.cache_feedback = {'hit_rate': hit_rate, 'miss_rate': miss_rate}

        # å‘½ä¸­ç‡è¶Šé«˜ï¼Œè¿ç§»é˜ˆå€¼è¶Šå®½æ¾ï¼›å‘½ä¸­ç‡ä¸‹é™åˆ™æ”¶ç´§
        # çº¿æ€§ç¼©æ”¾åˆ° [0.85, 1.15] åŒºé—´
        scale = 1.0 + 0.3 * (0.5 - miss_rate)
        self.dynamic_threshold_scale = float(np.clip(scale, 0.7, 1.2))

    def get_current_params(self) -> Dict[str, float]:
        """ğŸ”§ è·å–å½“å‰DRLæ§åˆ¶çš„è¿ç§»å‚æ•°ï¼ˆç”¨äºç›‘æ§å’Œè°ƒè¯•ï¼‰"""
        return {
            'cpu_threshold': self.agent_params.get('cpu_overload_threshold', 0.85),
            'bandwidth_threshold': self.agent_params.get('bandwidth_overload_threshold', 0.85),
            'load_diff_threshold': self.agent_params.get('load_diff_threshold', 0.20),
            'uav_battery_threshold': self.agent_params.get('uav_battery_threshold', 0.25),
        }

    def get_joint_params_snapshot(self) -> Dict[str, float]:
        """è¿”å›è¿ç§»ä¾§è”åŠ¨å‚æ•°ã€‚"""
        return {
            'migration_backoff': self.joint_backoff_factor,
            'threshold_scale': self.dynamic_threshold_scale,
            'cache_feedback': dict(self.cache_feedback)
        }

    def update_node_load(self, node_id: str, load_factor: float, battery_level: float = 1.0):
        """æ›´æ–°èŠ‚ç‚¹è´Ÿè½½å†å²"""
        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€ä»¿çœŸæ—¶é—´
        current_time = get_simulation_time()

        self.node_load_history[node_id].append({
            'time': current_time,
            'load': load_factor,
            'battery': battery_level
        })

        # ä¿æŒå†å²é•¿åº¦
        if len(self.node_load_history[node_id]) > 50:
            self.node_load_history[node_id].pop(0)

    def should_trigger_migration(self, node_id: str, current_state: Dict, neighbor_states: Dict = None) -> Tuple[bool, str, float]:
        """
        ğŸ¯ æ™ºèƒ½å¤šç»´åº¦è¿ç§»è§¦å‘æœºåˆ¶

        è§¦å‘æ¡ä»¶ï¼š
        1. èµ„æºé˜ˆå€¼è§¦å‘ï¼šCPU/å¸¦å®½/å­˜å‚¨ä»»ä¸€èµ„æº>85%
        2. è´Ÿè½½å·®è§¦å‘ï¼šä¸é‚»è¿‘èŠ‚ç‚¹è´Ÿè½½å·®>20%
        3. è·Ÿéšè¿ç§»ï¼šè½¦è¾†ç§»åŠ¨è¶…å‡ºé€šä¿¡è¦†ç›–

        Returns:
            (should_migrate, reason, urgency_score)
        """
        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€ä»¿çœŸæ—¶é—´
        current_time = get_simulation_time()

        # ğŸ”§ ç”¨æˆ·è¦æ±‚ï¼šç¼©çŸ­å†·å´æœŸåˆ°1ç§’ï¼Œå®ç°æ¯ç§’è§¦å‘è¿ç§»å†³ç­–
        cooldown = 1.0 + 4.0 * float(np.clip(self.joint_backoff_factor, 0.0, 1.0))
        if (node_id in self.last_migration_time and 
            current_time - self.last_migration_time[node_id] < cooldown):  # è”åŠ¨å†·å´æœŸ
            return False, "å†·å´æœŸå†…", 0.0

        # è·å–èŠ‚ç‚¹çŠ¶æ€
        cpu_load = current_state.get('cpu_load', current_state.get('load_factor', 0.0))
        bandwidth_load = current_state.get('bandwidth_load', 0.0)
        storage_load = current_state.get('storage_load', 0.0)
        battery_level = current_state.get('battery_level', 1.0)
        hotspot_intensity = float(np.clip(current_state.get('hotspot_intensity', 0.0), 0.0, 1.0))
        
        urgency_score = 0.0
        migration_reason = ""

        # ğŸ¯ å¤šç»´åº¦è§¦å‘æ¡ä»¶æ£€æŸ¥
        if node_id.startswith("rsu_"):
            # 1ï¸âƒ£ èµ„æºé˜ˆå€¼è§¦å‘ï¼ˆğŸ”§ ä½¿ç”¨DRLå¯è°ƒæ•´çš„é˜ˆå€¼ï¼‰
            resource_overload = False
            overload_resources = []

            # ğŸ”§ æ¿€æ´»DRLæ§åˆ¶ï¼šä½¿ç”¨agent_paramsä¸­çš„åŠ¨æ€é˜ˆå€¼
            cpu_threshold = self.agent_params.get('cpu_overload_threshold', 0.85)
            bw_threshold = self.agent_params.get('bandwidth_overload_threshold', 0.85)
            load_diff_threshold = self.agent_params.get('load_diff_threshold', 0.20)

            scale = float(np.clip(self.dynamic_threshold_scale, 0.7, 1.2))
            cpu_bounds = self.param_bounds['cpu_overload_threshold']
            bw_bounds = self.param_bounds['bandwidth_overload_threshold']
            diff_bounds = self.param_bounds['load_diff_threshold']
            cpu_threshold = float(np.clip(cpu_threshold * scale, cpu_bounds[0], cpu_bounds[1]))
            bw_threshold = float(np.clip(bw_threshold * scale, bw_bounds[0], bw_bounds[1]))
            load_diff_threshold = float(np.clip(load_diff_threshold * scale, diff_bounds[0], diff_bounds[1]))

            if hotspot_intensity > 0.0:
                cpu_threshold = max(
                    self.param_bounds['cpu_overload_threshold'][0],
                    cpu_threshold - 0.1 * hotspot_intensity
                )
                bw_threshold = max(
                    self.param_bounds['bandwidth_overload_threshold'][0],
                    bw_threshold - 0.05 * hotspot_intensity
                )
                load_diff_threshold = max(
                    self.param_bounds['load_diff_threshold'][0],
                    load_diff_threshold - 0.05 * hotspot_intensity
                )
                if not migration_reason:
                    migration_reason = "çƒ­é—¨å†…å®¹é¢„çƒ­"

            if cpu_load > cpu_threshold:  # DRLå¯è°ƒæ•´çš„CPUé˜ˆå€¼ï¼ˆ70-95%ï¼‰
                resource_overload = True
                overload_resources.append(f"CPU:{cpu_load:.1%}")
                urgency_score += (cpu_load - cpu_threshold) / (1.0 - cpu_threshold)

            if bandwidth_load > bw_threshold:  # DRLå¯è°ƒæ•´çš„å¸¦å®½é˜ˆå€¼ï¼ˆ70-95%ï¼‰
                resource_overload = True
                overload_resources.append(f"å¸¦å®½:{bandwidth_load:.1%}")
                urgency_score += (bandwidth_load - bw_threshold) / (1.0 - bw_threshold)

            if storage_load > 0.85:  # å­˜å‚¨é˜ˆå€¼ä¿æŒå›ºå®šï¼ˆè¾ƒå°‘æˆä¸ºç“¶é¢ˆï¼‰
                resource_overload = True
                overload_resources.append(f"å­˜å‚¨:{storage_load:.1%}")

            # 2ï¸âƒ£ è´Ÿè½½å·®è§¦å‘ï¼ˆğŸ”§ ä½¿ç”¨DRLå¯è°ƒæ•´çš„è´Ÿè½½å·®é˜ˆå€¼ï¼‰
            load_diff_trigger = False
            max_load_diff = 0.0

            # ğŸ”§ æ¿€æ´»DRLæ§åˆ¶ï¼šä½¿ç”¨åŠ¨æ€è´Ÿè½½å·®é˜ˆå€¼
            if neighbor_states:
                current_avg_load = (cpu_load + bandwidth_load + storage_load) / 3
                for neighbor_id, neighbor_state in neighbor_states.items():
                    if neighbor_id != node_id:
                        neighbor_cpu = neighbor_state.get('cpu_load', neighbor_state.get('load_factor', 0.0))
                        neighbor_bw = neighbor_state.get('bandwidth_load', 0.0)
                        neighbor_storage = neighbor_state.get('storage_load', 0.0)
                        neighbor_avg_load = (neighbor_cpu + neighbor_bw + neighbor_storage) / 3

                        load_diff = current_avg_load - neighbor_avg_load
                        max_load_diff = max(max_load_diff, load_diff)

                        # ğŸ”§ æ¿€æ´»DRLæ§åˆ¶ï¼šè´Ÿè½½å·®é˜ˆå€¼ç”±DRLåŠ¨æ€è°ƒæ•´ï¼ˆ10-40%ï¼‰
                        if load_diff > load_diff_threshold:
                            load_diff_trigger = True

            # ğŸ”¥ è®¡ç®—è¿ç§»ç´§æ€¥åº¦ï¼ˆğŸ”§ ä½¿ç”¨DRLå‚æ•°è®¡ç®—ï¼‰
            if resource_overload:
                # ä½¿ç”¨å®é™…è§¦å‘é˜ˆå€¼è®¡ç®—ç´§æ€¥åº¦
                resource_urgency = max(cpu_load - cpu_threshold, bandwidth_load - bw_threshold, 0.0)
                urgency_score += resource_urgency * 2.0  # èµ„æºè¿‡è½½æƒé‡é«˜
                overload_reason = f"èµ„æºè¿‡è½½({','.join(overload_resources)})"
                migration_reason = overload_reason if not migration_reason else f"{migration_reason} + {overload_reason}"

            if load_diff_trigger:
                diff_urgency = max_load_diff - load_diff_threshold
                urgency_score += diff_urgency * 1.5  # è´Ÿè½½å·®æƒé‡ä¸­ç­‰
                if migration_reason:
                    migration_reason += f" + è´Ÿè½½å·®({max_load_diff:.1%})"
                else:
                    migration_reason = f"è´Ÿè½½å·®è¿‡å¤§({max_load_diff:.1%})"

            # ğŸ”§ ä¼˜åŒ–ï¼šæ›´ç§¯æçš„è¿ç§»ç­–ç•¥ï¼Œæ•¢äºå°è¯•æœ‰é£é™©çš„è¿ç§»
            if urgency_score > 0.1:  # é˜ˆå€¼æ›´ä¿å®ˆï¼Œé¿å…æ—©æœŸè¿‡åº¦è¿ç§»
                self.migration_stats['total_triggers'] += 1
                self.last_migration_time[node_id] = current_time
                return True, migration_reason, urgency_score

        elif node_id.startswith("uav_"):
            # ğŸš UAVå¤šç»´åº¦è§¦å‘æ¡ä»¶ï¼ˆğŸ”§ æ¿€æ´»DRLæ§åˆ¶ï¼‰

            # ğŸ”§ è·å–DRLå¯è°ƒæ•´çš„é˜ˆå€¼
            uav_battery_threshold = self.agent_params.get('uav_battery_threshold', 0.25)
            cpu_threshold = self.agent_params.get('cpu_overload_threshold', 0.85)
            load_diff_threshold = self.agent_params.get('load_diff_threshold', 0.20)

            # 1ï¸âƒ£ ç”µæ± ç”µé‡è§¦å‘ï¼ˆDRLå¯è°ƒæ•´é˜ˆå€¼15-40%ï¼‰
            battery_urgency = 0.0
            if battery_level < uav_battery_threshold:
                battery_urgency = (uav_battery_threshold - battery_level) / max(0.01, uav_battery_threshold)
                urgency_score += battery_urgency * 3.0  # ç”µæ± ç´§æ€¥æƒé‡æœ€é«˜
                migration_reason = f"UAVç”µæ± ä½({battery_level:.1%})"

            # 2ï¸âƒ£ è´Ÿè½½è¿‡è½½è§¦å‘ï¼ˆğŸ”§ ä½¿ç”¨DRLå¯è°ƒæ•´çš„CPUé˜ˆå€¼ï¼‰
            # UAVä½¿ç”¨ç¨ä½çš„é˜ˆå€¼ï¼ˆ-5%ï¼‰ï¼Œå› ä¸ºUAVèµ„æºæ›´æœ‰é™
            scale = float(np.clip(self.dynamic_threshold_scale, 0.7, 1.2))
            uav_cpu_threshold_base = self.agent_params.get('cpu_overload_threshold', 0.85)
            uav_cpu_threshold_base = float(np.clip(uav_cpu_threshold_base * scale, self.param_bounds['cpu_overload_threshold'][0], self.param_bounds['cpu_overload_threshold'][1]))
            uav_cpu_threshold = max(0.70, uav_cpu_threshold_base - 0.05)
            load_diff_threshold = float(np.clip(load_diff_threshold * scale, self.param_bounds['load_diff_threshold'][0], self.param_bounds['load_diff_threshold'][1]))
            if cpu_load > uav_cpu_threshold:
                load_urgency = (cpu_load - uav_cpu_threshold) / (1.0 - uav_cpu_threshold)
                urgency_score += load_urgency * 2.0
                if migration_reason:
                    migration_reason += f" + CPUè¿‡è½½({cpu_load:.1%})"
                else:
                    migration_reason = f"UAV CPUè¿‡è½½({cpu_load:.1%})"

            # 3ï¸âƒ£ ä¸é‚»è¿‘RSUè´Ÿè½½å·®ï¼ˆğŸ”§ ä½¿ç”¨DRLå¯è°ƒæ•´çš„è´Ÿè½½å·®é˜ˆå€¼ï¼‰
            if neighbor_states:
                max_load_diff = 0.0
                for neighbor_id, neighbor_state in neighbor_states.items():
                    if neighbor_id.startswith("rsu_"):  # åªä¸RSUæ¯”è¾ƒ
                        neighbor_load = neighbor_state.get('cpu_load', neighbor_state.get('load_factor', 0.0))
                        load_diff = cpu_load - neighbor_load
                        max_load_diff = max(max_load_diff, load_diff)

                # ğŸ”§ æ¿€æ´»DRLæ§åˆ¶ï¼šè´Ÿè½½å·®é˜ˆå€¼åŠ¨æ€è°ƒæ•´ï¼ˆ10-40%ï¼‰
                if max_load_diff > load_diff_threshold:
                    diff_urgency = max_load_diff - load_diff_threshold
                    urgency_score += diff_urgency * 1.5
                    if migration_reason:
                        migration_reason += f" + è´Ÿè½½å·®({max_load_diff:.1%})"
                    else:
                        migration_reason = f"ä¸RSUè´Ÿè½½å·®è¿‡å¤§({max_load_diff:.1%})"

                # ğŸ”§ ä¼˜åŒ–ï¼šUAVä¹Ÿé‡‡ç”¨æ›´ç§¯æçš„è¿ç§»ç­–ç•¥
                if urgency_score > 0.12:  # é˜ˆå€¼æ›´ä¿å®ˆï¼Œé¿å…æ—©æœŸè¿‡åº¦è¿ç§»
                    self.migration_stats['total_triggers'] += 1
                    self.last_migration_time[node_id] = current_time
                    return True, migration_reason, urgency_score

        return False, f"æ— éœ€è¿ç§» (CPU:{cpu_load:.1%}, ç”µæ± :{battery_level:.1%})", urgency_score

    def _calculate_load_trend(self, node_id: str) -> float:
        """è®¡ç®—è´Ÿè½½è¶‹åŠ¿"""
        history = self.node_load_history.get(node_id, [])
        if len(history) < 3:
            return 0.0

        # è®¡ç®—æœ€è¿‘çš„è´Ÿè½½å˜åŒ–è¶‹åŠ¿
        recent_loads = [entry['load'] for entry in history[-5:]]
        if len(recent_loads) < 2:
            return 0.0

        # ç®€å•çº¿æ€§è¶‹åŠ¿
        trend = (recent_loads[-1] - recent_loads[0]) / len(recent_loads)
        return np.clip(trend * 5, -1.0, 1.0)  # å½’ä¸€åŒ–è¶‹åŠ¿

    def record_migration_result(self, success: bool, cost: float = 0.0, delay_saved: float = 0.0):
        """è®°å½•è¿ç§»ç»“æœ"""
        if success:
            self.migration_stats['successful_migrations'] += 1
            self.migration_stats['total_cost'] += cost
            self.migration_stats['avg_delay_saved'] = (
                (self.migration_stats['avg_delay_saved'] * (self.migration_stats['successful_migrations'] - 1) + delay_saved) /
                self.migration_stats['successful_migrations']
            )

        # æ›´æ–°æˆåŠŸç‡å†å²
        if self.migration_stats['total_triggers'] > 0:
            success_rate = self.migration_stats['successful_migrations'] / self.migration_stats['total_triggers']
            self.migration_stats['success_rate_history'].append(success_rate)

            if len(self.migration_stats['success_rate_history']) > 100:
                self.migration_stats['success_rate_history'].pop(0)

    def get_migration_metrics(self) -> Dict:
        """è·å–è¿ç§»æ•ˆæœæŒ‡æ ‡"""
        total_triggers = self.migration_stats['total_triggers']
        if total_triggers == 0:
            return {
                'success_rate': 0.0,
                'effectiveness': 0.0,
                'avg_cost': 0.0,
                'total_triggers': 0,
                'avg_delay_saved': self.migration_stats['avg_delay_saved'],
                'agent_params': dict(self.agent_params),
                'joint_params': self.get_joint_params_snapshot()
            }

        success_rate = self.migration_stats['successful_migrations'] / total_triggers
        avg_cost = self.migration_stats['total_cost'] / max(1, self.migration_stats['successful_migrations'])

        # æ•ˆæœæŒ‡æ ‡ï¼šæˆåŠŸç‡ Ã— (1 - å½’ä¸€åŒ–æˆæœ¬)
        cost_factor = min(1.0, avg_cost / 100.0)  # å‡è®¾100ä¸ºæœ€å¤§æˆæœ¬
        effectiveness = success_rate * (1.0 - cost_factor * self.agent_params['migration_cost_weight'])

        return {
            'success_rate': success_rate,
            'effectiveness': effectiveness,
            'avg_cost': avg_cost,
            'total_triggers': total_triggers,
            'avg_delay_saved': self.migration_stats['avg_delay_saved'],
            'agent_params': dict(self.agent_params),
            'joint_params': self.get_joint_params_snapshot()
        }


def map_agent_actions_to_params(agent_actions: np.ndarray) -> Tuple[Dict, Dict, Dict]:
    """Map continuous actions to semantic cache/migration/joint parameters."""
    if len(agent_actions) < 10:
        agent_actions = np.pad(agent_actions, (0, 10 - len(agent_actions)), mode='constant', constant_values=0.0)

    clipped_actions = np.clip(agent_actions, -1.0, 1.0)
    try:
        action_scale = float(os.environ.get("CACHE_ACTION_SCALE", 1.0))
    except Exception:
        action_scale = 1.0
    scaled_actions = clipped_actions * action_scale  # æ”¾å¤§å¯æ§å¹…åº¦ï¼Œæå‡ç¼“å­˜/è¿ç§»å¯è°ƒæ€§

    def _map_to_range(value: float, low: float, high: float) -> float:
        value = np.clip(value, -1.0, 1.0)
        return low + ((value + 1.0) * 0.5) * (high - low)

    cache_params = {
        'heat_threshold_high': scaled_actions[0],
        'heat_threshold_medium': scaled_actions[1],
        'prefetch_ratio': scaled_actions[2],
        'collaboration_weight': scaled_actions[3],
    }

    migration_params = {
        'cpu_overload_threshold': scaled_actions[4],
        'bandwidth_overload_threshold': scaled_actions[5],
        'uav_battery_threshold': scaled_actions[6],
        'load_diff_threshold': scaled_actions[7],
    }

    joint_params = {
        'prefetch_lead_time': _map_to_range(scaled_actions[8], 0.0, 5.0),
        'migration_backoff': _map_to_range(scaled_actions[9], 0.0, 1.0)
    }

    return cache_params, migration_params, joint_params
