#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SACä¸“ç”¨å¥–åŠ±è®¡ç®—å™¨
è§£å†³SAC"åªä¼˜åŒ–èƒ½è€—ä¸ä¼˜åŒ–å»¶è¿Ÿ"çš„é—®é¢˜

ä¸simple_reward_calculatorçš„å…³é”®åŒºåˆ«ï¼š
1. å¹³è¡¡çš„å½’ä¸€åŒ–å› å­ï¼ˆå»¶è¿Ÿå’Œèƒ½è€—æ•°å€¼èŒƒå›´ä¸€è‡´ï¼‰
2. æ›´æ¿€è¿›çš„å»¶è¿Ÿæƒ©ç½š
3. æ­£å‘å¥–åŠ±æœºåˆ¶ï¼ˆè®©SACçŸ¥é“ä»€ä¹ˆæ˜¯å¥½çš„ï¼‰
4. å…è®¸æ­£å€¼å¥–åŠ±èŒƒå›´

ä¸å½±å“å…¶ä»–ç®—æ³•ï¼ˆTD3ã€DDPGç­‰ï¼‰
"""

import numpy as np
from typing import Dict
from config import config

class SACRewardCalculator:
    """
    SACä¸“ç”¨å¥–åŠ±è®¡ç®—å™¨
    é’ˆå¯¹SACçš„æœ€å¤§ç†µæ¡†æ¶ä¼˜åŒ–å¥–åŠ±ä¿¡å·
    """

    def __init__(self):
        # ä»é…ç½®åŠ è½½åŸºç¡€æƒé‡
        self.weight_delay = config.rl.reward_weight_delay
        self.weight_energy = config.rl.reward_weight_energy
        self.weight_loss = config.rl.reward_weight_loss
        self.penalty_weight_dropped = config.rl.reward_penalty_dropped
        
        # ğŸ”§ SACä¸“ç”¨ï¼šå¹³è¡¡çš„å½’ä¸€åŒ–å› å­
        # ç›®æ ‡ï¼šå»¶è¿Ÿ0.2så’Œèƒ½è€—1000Jå½’ä¸€åŒ–åæ•°å€¼æ¥è¿‘
        self.delay_normalizer = 0.3      # 0.2s â†’ 0.67
        self.energy_normalizer = 1500.0  # 1000J â†’ 0.67
        self.loss_normalizer = 1.0       # MB
        
        # ğŸ”§ SACä¸“ç”¨ï¼šå…è®¸æ­£å€¼å¥–åŠ±
        self.reward_clip_range = (-20.0, 5.0)  # å…è®¸æ­£å‘æ¿€åŠ±
        
        print("[OK] SACä¸“ç”¨å¥–åŠ±å‡½æ•°åˆå§‹åŒ– (SACRewardCalculator)")
        print(f"   åŸºç¡€æƒé‡: Delay={self.weight_delay}, Energy={self.weight_energy}, Loss={self.weight_loss}")
        print(f"   SACä¼˜åŒ–å½’ä¸€åŒ–: Delay={self.delay_normalizer}, Energy={self.energy_normalizer}")
        print(f"   å¥–åŠ±èŒƒå›´: {self.reward_clip_range} (å…è®¸æ­£å€¼)")
        print(f"   ç‰¹æ€§: å¹³è¡¡å»¶è¿Ÿ/èƒ½è€— + æ­£å‘æ¿€åŠ± + æ¿€è¿›å»¶è¿Ÿæƒ©ç½š")

    def calculate_reward(self, system_metrics: Dict) -> float:
        """
        è®¡ç®—SACä¸“ç”¨å¥–åŠ±
        """
        # æå–æ ¸å¿ƒæŒ‡æ ‡
        avg_delay = max(0.0, float(system_metrics.get('avg_task_delay', 0.0)))
        total_energy = max(0.0, float(system_metrics.get('total_energy_consumption', 0.0)))
        
        # æ•°æ®ä¸¢å¤±é‡ï¼ˆbytesè½¬MBï¼‰
        data_loss_bytes = max(0.0, float(system_metrics.get('data_loss_bytes', 0.0)))
        data_loss_mb = data_loss_bytes / 1e6
        
        # ä¸¢å¼ƒä»»åŠ¡æ•°
        dropped_tasks = int(system_metrics.get('dropped_tasks', 0))
        
        # ğŸ”§ SACä¼˜åŒ–ï¼šå¹³è¡¡çš„å½’ä¸€åŒ–
        norm_delay = avg_delay / self.delay_normalizer
        norm_energy = total_energy / self.energy_normalizer
        norm_loss = data_loss_mb / self.loss_normalizer
        
        # åŸºç¡€æˆæœ¬
        base_cost = (self.weight_delay * norm_delay +
                     self.weight_energy * norm_energy +
                     self.weight_loss * norm_loss)
        
        # åŸºç¡€æƒ©ç½š
        penalty = self.penalty_weight_dropped * dropped_tasks
        
        # ğŸ”§ SACä¼˜åŒ–ï¼šæ¿€è¿›çš„å»¶è¿Ÿæƒ©ç½šï¼ˆç¡®ä¿SACé‡è§†å»¶è¿Ÿï¼‰
        delay_penalty = max(0, (avg_delay - 0.20) * 10.0) if avg_delay > 0.20 else 0
        energy_penalty = max(0, (total_energy - 2000) / 800.0) if total_energy > 2000 else 0
        
        # æ€»æˆæœ¬
        total_cost = base_cost + penalty + delay_penalty + energy_penalty
        
        # ğŸ”§ å…³é”®åˆ›æ–°ï¼šæ­£å‘å¥–åŠ±æœºåˆ¶ï¼ˆSACçš„æœ€å¤§ç†µéœ€è¦æ˜ç¡®çš„"å¥½"ä¿¡å·ï¼‰
        bonus = 0.0
        
        # å»¶è¿Ÿä¼˜ç§€å¥–åŠ±
        if avg_delay < 0.18:
            bonus += (0.18 - avg_delay) * 5.0
        
        # èƒ½è€—ä¼˜ç§€å¥–åŠ±
        if total_energy < 1500:
            bonus += (1500 - total_energy) / 500.0
        
        # å®Œæˆç‡ä¼˜ç§€å¥–åŠ±
        completion_rate = system_metrics.get('task_completion_rate', 0.0)
        if completion_rate > 0.95:
            bonus += (completion_rate - 0.95) * 20.0
        
        # ğŸ”§ SACæœ€ç»ˆå¥–åŠ± = æ­£å‘æ¿€åŠ± - æˆæœ¬æƒ©ç½š
        reward = bonus - total_cost
        
        # è£å‰ªåˆ°SACä¸“ç”¨èŒƒå›´
        clipped_reward = np.clip(reward, self.reward_clip_range[0], self.reward_clip_range[1])
        
        return clipped_reward

# å…¨å±€SACä¸“ç”¨å®ä¾‹
_sac_reward_calculator = SACRewardCalculator()

def calculate_sac_reward(system_metrics: Dict) -> float:
    """
    ä¾›SACç®—æ³•è°ƒç”¨çš„ä¸“ç”¨æ¥å£
    """
    return _sac_reward_calculator.calculate_reward(system_metrics)



