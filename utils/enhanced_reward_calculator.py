#!/usr/bin/env python3
"""
å¢å¼ºçš„å¥–åŠ±è®¡ç®—å™¨
é’ˆå¯¹ç¼“å­˜ã€å¸è½½ã€è¿ç§»ä¸‰ä¸ªå­é—®é¢˜æä¾›ä¸“é—¨çš„å¥–åŠ±ä¿¡å·
"""

import numpy as np
from typing import Dict, Optional
from config import config

class EnhancedRewardCalculator:
    """
    å¢å¼ºå¥–åŠ±è®¡ç®—å™¨
    ä¸ºDRLæä¾›é’ˆå¯¹æ€§çš„å¥–åŠ±ä¿¡å·ï¼ŒæŒ‡å¯¼ç¼“å­˜å’Œè¿ç§»ç­–ç•¥å­¦ä¹ 
    """
    
    def __init__(self):
        # ä»é…ç½®åŠ è½½åŸºç¡€æƒé‡
        self.weight_delay = config.rl.reward_weight_delay
        self.weight_energy = config.rl.reward_weight_energy
        self.weight_loss = config.rl.reward_weight_loss
        
        # ğŸ”§ æ–°å¢ï¼šå­ç³»ç»Ÿå¥–åŠ±æƒé‡
        self.weight_cache = 0.3        # ç¼“å­˜æ€§èƒ½æƒé‡
        self.weight_migration = 0.2    # è¿ç§»æ€§èƒ½æƒé‡
        self.weight_coordination = 0.1 # åè°ƒå¥–åŠ±æƒé‡
        
        # å½’ä¸€åŒ–å› å­
        self.delay_normalizer = 1.0
        self.energy_normalizer = 1000.0  # ä¿®æ­£ä¸ºåˆç†å€¼
        self.cache_normalizer = 1.0
        
        # å¥–åŠ±èŒƒå›´
        self.reward_clip_range = (-10.0, 2.0)  # å…è®¸å°‘é‡æ­£å¥–åŠ±
        
        print("âœ… å¢å¼ºå¥–åŠ±è®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   åŸºç¡€æƒé‡: Delay={self.weight_delay}, Energy={self.weight_energy}, Loss={self.weight_loss}")
        print(f"   å­ç³»ç»Ÿæƒé‡: Cache={self.weight_cache}, Migration={self.weight_migration}")
    
    def calculate_enhanced_reward(self, system_metrics: Dict, 
                                cache_metrics: Optional[Dict] = None,
                                migration_metrics: Optional[Dict] = None) -> Dict[str, float]:
        """
        è®¡ç®—å¢å¼ºå¥–åŠ±ï¼ŒåŒ…å«æ€»å¥–åŠ±å’Œåˆ†è§£å¥–åŠ±
        
        Returns:
            {
                'total_reward': float,
                'delay_reward': float,
                'energy_reward': float, 
                'cache_reward': float,
                'migration_reward': float,
                'coordination_reward': float
            }
        """
        # åŸºç¡€æŒ‡æ ‡å¥–åŠ±
        delay_reward = self._calculate_delay_reward(system_metrics)
        energy_reward = self._calculate_energy_reward(system_metrics)
        loss_reward = self._calculate_loss_reward(system_metrics)
        
        # å­ç³»ç»Ÿä¸“é—¨å¥–åŠ±
        cache_reward = self._calculate_cache_reward(system_metrics, cache_metrics)
        migration_reward = self._calculate_migration_reward(system_metrics, migration_metrics)
        
        # åè°ƒå¥–åŠ±ï¼ˆå¥–åŠ±ç³»ç»Ÿé—´çš„åä½œï¼‰
        coordination_reward = self._calculate_coordination_reward(
            system_metrics, cache_metrics, migration_metrics
        )
        
        # æ€»å¥–åŠ±
        total_reward = (
            self.weight_delay * delay_reward +
            self.weight_energy * energy_reward +
            self.weight_loss * loss_reward +
            self.weight_cache * cache_reward +
            self.weight_migration * migration_reward +
            self.weight_coordination * coordination_reward
        )
        
        # é™åˆ¶å¥–åŠ±èŒƒå›´
        total_reward = np.clip(total_reward, *self.reward_clip_range)
        
        return {
            'total_reward': total_reward,
            'delay_reward': delay_reward,
            'energy_reward': energy_reward,
            'loss_reward': loss_reward,
            'cache_reward': cache_reward,
            'migration_reward': migration_reward,
            'coordination_reward': coordination_reward
        }
    
    def _calculate_delay_reward(self, system_metrics: Dict) -> float:
        """è®¡ç®—æ—¶å»¶å¥–åŠ±"""
        avg_delay = max(0.0, float(system_metrics.get('avg_task_delay', 0.0)))
        
        # éçº¿æ€§æƒ©ç½šï¼šæ—¶å»¶è¶Šé«˜æƒ©ç½šè¶Šé‡
        delay_penalty = -(avg_delay / self.delay_normalizer) ** 1.5
        
        # æ—¶å»¶ç›®æ ‡å¥–åŠ±ï¼šä½äº0.2ç§’ç»™äºˆå¥–åŠ±
        if avg_delay < 0.2:
            delay_bonus = 0.1 * (0.2 - avg_delay) / 0.2
        else:
            delay_bonus = 0.0
        
        return delay_penalty + delay_bonus
    
    def _calculate_energy_reward(self, system_metrics: Dict) -> float:
        """è®¡ç®—èƒ½è€—å¥–åŠ±"""
        total_energy = max(0.0, float(system_metrics.get('total_energy_consumption', 0.0)))
        
        # èƒ½è€—æƒ©ç½š
        energy_penalty = -(total_energy / self.energy_normalizer)
        
        # èƒ½æ•ˆå¥–åŠ±ï¼šèƒ½è€—ä½äº800ç„¦è€³ç»™äºˆå¥–åŠ±
        if total_energy < 800.0:
            energy_bonus = 0.05 * (800.0 - total_energy) / 800.0
        else:
            energy_bonus = 0.0
        
        return energy_penalty + energy_bonus
    
    def _calculate_loss_reward(self, system_metrics: Dict) -> float:
        """è®¡ç®—æ•°æ®ä¸¢å¤±å¥–åŠ±"""
        completion_rate = max(0.0, min(1.0, float(system_metrics.get('task_completion_rate', 0.0))))
        
        # å®Œæˆç‡å¥–åŠ±
        completion_bonus = completion_rate * 0.2  # æœ€é«˜0.2å¥–åŠ±
        
        # æ•°æ®ä¸¢å¤±æƒ©ç½š
        loss_rate = 1.0 - completion_rate
        loss_penalty = -(loss_rate ** 2) * 2.0  # éçº¿æ€§æƒ©ç½š
        
        return completion_bonus + loss_penalty
    
    def _calculate_cache_reward(self, system_metrics: Dict, cache_metrics: Optional[Dict]) -> float:
        """
        ğŸ”§ æ–°å¢ï¼šè®¡ç®—ç¼“å­˜ä¸“é—¨å¥–åŠ±
        """
        if not cache_metrics:
            return 0.0
        
        cache_hit_rate = cache_metrics.get('hit_rate', 0.0)
        cache_utilization = cache_metrics.get('utilization', 0.0)
        
        # ç¼“å­˜å‘½ä¸­ç‡å¥–åŠ±
        hit_rate_reward = cache_hit_rate * 0.3  # æœ€é«˜0.3å¥–åŠ±
        
        # ç¼“å­˜åˆ©ç”¨ç‡å¥–åŠ±ï¼ˆé¼“åŠ±åˆç†åˆ©ç”¨ï¼‰
        if 0.6 <= cache_utilization <= 0.9:
            utilization_reward = 0.1
        elif cache_utilization > 0.9:
            utilization_reward = -0.1  # è¿‡åº¦åˆ©ç”¨æƒ©ç½š
        else:
            utilization_reward = 0.0
        
        # ç¼“å­˜æ•ˆç‡å¥–åŠ±
        effectiveness = cache_metrics.get('effectiveness', 0.0)
        efficiency_reward = effectiveness * 0.2
        
        return hit_rate_reward + utilization_reward + efficiency_reward
    
    def _calculate_migration_reward(self, system_metrics: Dict, migration_metrics: Optional[Dict]) -> float:
        """
        ğŸ”§ æ–°å¢ï¼šè®¡ç®—è¿ç§»ä¸“é—¨å¥–åŠ±
        """
        if not migration_metrics:
            return 0.0
        
        migration_success_rate = migration_metrics.get('success_rate', 0.0)
        avg_delay_saved = migration_metrics.get('avg_delay_saved', 0.0)
        migration_frequency = migration_metrics.get('frequency', 0.0)
        
        # è¿ç§»æˆåŠŸç‡å¥–åŠ±
        success_reward = migration_success_rate * 0.15
        
        # æ—¶å»¶èŠ‚çœå¥–åŠ±
        delay_saved_reward = min(0.1, avg_delay_saved * 0.1)
        
        # è¿ç§»é¢‘ç‡å¹³è¡¡ï¼ˆè¿‡å¤šæˆ–è¿‡å°‘éƒ½ä¸å¥½ï¼‰
        optimal_frequency = 0.1  # æ¯10æ­¥1æ¬¡è¿ç§»ä¸ºç†æƒ³
        frequency_penalty = -abs(migration_frequency - optimal_frequency) * 0.5
        
        return success_reward + delay_saved_reward + frequency_penalty
    
    def _calculate_coordination_reward(self, system_metrics: Dict, 
                                     cache_metrics: Optional[Dict],
                                     migration_metrics: Optional[Dict]) -> float:
        """
        ğŸ”§ æ–°å¢ï¼šè®¡ç®—åè°ƒå¥–åŠ±ï¼Œé¼“åŠ±å­ç³»ç»Ÿé—´åä½œ
        """
        coordination_reward = 0.0
        
        if cache_metrics and migration_metrics:
            cache_hit_rate = cache_metrics.get('hit_rate', 0.0)
            migration_success_rate = migration_metrics.get('success_rate', 0.0)
            
            # åŒé«˜åè°ƒå¥–åŠ±ï¼šç¼“å­˜å’Œè¿ç§»éƒ½è¡¨ç°å¥½
            if cache_hit_rate > 0.7 and migration_success_rate > 0.8:
                coordination_reward += 0.1
            
            # è´Ÿè½½å‡è¡¡åè°ƒï¼šå¦‚æœè¿ç§»æœ‰æ•ˆé™ä½äº†å»¶è¿Ÿä¸”ç¼“å­˜å‘½ä¸­ç‡ç¨³å®š
            avg_delay = system_metrics.get('avg_task_delay', 1.0)
            if avg_delay < 0.3 and cache_hit_rate > 0.6:
                coordination_reward += 0.05
        
        return coordination_reward
    
    def get_reward_breakdown(self, system_metrics: Dict,
                           cache_metrics: Optional[Dict] = None,
                           migration_metrics: Optional[Dict] = None) -> str:
        """
        è·å–å¥–åŠ±åˆ†è§£çš„å¯è¯»æŠ¥å‘Š
        """
        rewards = self.calculate_enhanced_reward(system_metrics, cache_metrics, migration_metrics)
        
        breakdown = f"""
å¥–åŠ±åˆ†è§£æŠ¥å‘Š:
â”œâ”€â”€ æ€»å¥–åŠ±: {rewards['total_reward']:.3f}
â”œâ”€â”€ æ—¶å»¶å¥–åŠ±: {rewards['delay_reward']:.3f}
â”œâ”€â”€ èƒ½è€—å¥–åŠ±: {rewards['energy_reward']:.3f}  
â”œâ”€â”€ æ•°æ®ä¸¢å¤±: {rewards['loss_reward']:.3f}
â”œâ”€â”€ ç¼“å­˜å¥–åŠ±: {rewards['cache_reward']:.3f}
â”œâ”€â”€ è¿ç§»å¥–åŠ±: {rewards['migration_reward']:.3f}
â””â”€â”€ åè°ƒå¥–åŠ±: {rewards['coordination_reward']:.3f}
        """
        
        return breakdown.strip()

# å…¨å±€å¢å¼ºå¥–åŠ±è®¡ç®—å™¨
_enhanced_reward_calculator = EnhancedRewardCalculator()

def calculate_enhanced_reward(system_metrics: Dict,
                            cache_metrics: Optional[Dict] = None,
                            migration_metrics: Optional[Dict] = None) -> float:
    """
    ä¾›å¤–éƒ¨è°ƒç”¨çš„å¢å¼ºå¥–åŠ±æ¥å£
    """
    result = _enhanced_reward_calculator.calculate_enhanced_reward(
        system_metrics, cache_metrics, migration_metrics
    )
    return result['total_reward']

def get_reward_breakdown(system_metrics: Dict,
                        cache_metrics: Optional[Dict] = None, 
                        migration_metrics: Optional[Dict] = None) -> str:
    """
    è·å–å¥–åŠ±åˆ†è§£æŠ¥å‘Š
    """
    return _enhanced_reward_calculator.get_reward_breakdown(
        system_metrics, cache_metrics, migration_metrics
    )
