#!/usr/bin/env python3
"""
å¢å¼ºçš„å¥–åŠ±è®¡ç®—å™¨
é’ˆå¯¹ç¼“å­˜ã€å¸è½½ã€è¿ç§»ä¸‰ä¸ªå­é—®é¢˜æä¾›ä¸“é—¨çš„å¥–åŠ±ä¿¡å·
"""

import numpy as np
from typing import Dict, Optional
from config import config

class EnhancedRewardCalculator:
    """
    å¢å¼ºå¥–åŠ±è®¡ç®—å™¨
    ä¸ºDRLæä¾›é’ˆå¯¹æ€§çš„å¥–åŠ±ä¿¡å·ï¼ŒæŒ‡å¯¼ç¼“å­˜å’Œè¿ç§»ç­–ç•¥å­¦ä¹ 
    """
    
    def __init__(self):
        # ä»é…ç½®åŠ è½½åŸºç¡€æƒé‡
        self.weight_delay = config.rl.reward_weight_delay
        self.weight_energy = config.rl.reward_weight_energy * 1.5  # ğŸ”§ å¢åŠ èƒ½è€—æƒé‡50%ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆåˆ°é«˜èƒ½è€—ç­–ç•¥
        self.weight_loss = config.rl.reward_weight_loss
        
        # ğŸ”§ æ–°å¢ï¼šå­ç³»ç»Ÿå¥–åŠ±æƒé‡
        self.weight_cache = 0.3        # ç¼“å­˜æ€§èƒ½æƒé‡
        self.weight_migration = 0.2    # è¿ç§»æ€§èƒ½æƒé‡
        self.weight_coordination = 0.1 # åè°ƒå¥–åŠ±æƒé‡
        
        # å½’ä¸€åŒ–å› å­
        self.delay_normalizer = 1.0
        self.energy_normalizer = 1000.0  # ä¿®æ­£ä¸ºåˆç†å€¼
        self.cache_normalizer = 1.0
        
        # ğŸ”§ ä¿®å¤ï¼šå¥–åŠ±å¿…é¡»å§‹ç»ˆä¸ºè´Ÿå€¼ï¼Œç¬¦åˆVECæˆæœ¬æœ€å°åŒ–åŸåˆ™
        self.reward_clip_range = (-15.0, -0.01)  # ç¡®ä¿å¥–åŠ±å§‹ç»ˆä¸ºè´Ÿå€¼
        
        print("âœ… å¢å¼ºå¥–åŠ±è®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   åŸºç¡€æƒé‡: Delay={self.weight_delay}, Energy={self.weight_energy}, Loss={self.weight_loss}")
        print(f"   å­ç³»ç»Ÿæƒé‡: Cache={self.weight_cache}, Migration={self.weight_migration}")
    
    def calculate_enhanced_reward(self, system_metrics: Dict, 
                                cache_metrics: Optional[Dict] = None,
                                migration_metrics: Optional[Dict] = None) -> Dict[str, float]:
        """
        è®¡ç®—å¢å¼ºå¥–åŠ±ï¼ŒåŒ…å«æ€»å¥–åŠ±å’Œåˆ†è§£å¥–åŠ±
        
        Returns:
            {
                'total_reward': float,
                'delay_reward': float,
                'energy_reward': float, 
                'cache_reward': float,
                'migration_reward': float,
                'coordination_reward': float
            }
        """
        # åŸºç¡€æŒ‡æ ‡å¥–åŠ±
        delay_reward = self._calculate_delay_reward(system_metrics)
        energy_reward = self._calculate_energy_reward(system_metrics)
        loss_reward = self._calculate_loss_reward(system_metrics)
        
        # å­ç³»ç»Ÿä¸“é—¨å¥–åŠ±
        cache_reward = self._calculate_cache_reward(system_metrics, cache_metrics)
        migration_reward = self._calculate_migration_reward(system_metrics, migration_metrics)
        
        # åè°ƒå¥–åŠ±ï¼ˆå¥–åŠ±ç³»ç»Ÿé—´çš„åä½œï¼‰
        coordination_reward = self._calculate_coordination_reward(
            system_metrics, cache_metrics, migration_metrics
        )
        
        # æ€»å¥–åŠ±
        total_reward = (
            self.weight_delay * delay_reward +
            self.weight_energy * energy_reward +
            self.weight_loss * loss_reward +
            self.weight_cache * cache_reward +
            self.weight_migration * migration_reward +
            self.weight_coordination * coordination_reward
        )
        
        # é™åˆ¶å¥–åŠ±èŒƒå›´
        total_reward = np.clip(total_reward, *self.reward_clip_range)
        
        return {
            'total_reward': total_reward,
            'delay_reward': delay_reward,
            'energy_reward': energy_reward,
            'loss_reward': loss_reward,
            'cache_reward': cache_reward,
            'migration_reward': migration_reward,
            'coordination_reward': coordination_reward
        }
    
    def _calculate_delay_reward(self, system_metrics: Dict) -> float:
        """
        ğŸ”§ ä¿®å¤ï¼šè®¡ç®—æ—¶å»¶æˆæœ¬ï¼ˆçº¯è´Ÿå€¼ï¼‰
        """
        avg_delay = max(0.0, float(system_metrics.get('avg_task_delay', 0.0)))
        
        # æ—¶å»¶æˆæœ¬ï¼šæ—¶å»¶è¶Šé«˜æˆæœ¬è¶Šé«˜
        # ä½¿ç”¨å¹³æ–¹æƒ©ç½šï¼Œé¼“åŠ±æ›´ä½æ—¶å»¶
        delay_cost = -(avg_delay / self.delay_normalizer) ** 1.2
        
        # ğŸ”§ ç§»é™¤æ­£å‘å¥–åŠ±ï¼Œæ”¹ä¸ºæˆæœ¬å‡å…
        if avg_delay < 0.2:
            # ä½æ—¶å»¶æ—¶æˆæœ¬å‡å…ï¼Œä½†ä»ä¸ºè´Ÿå€¼
            cost_reduction = delay_cost * 0.5  # å‡å…50%æˆæœ¬ï¼Œä½†æ€»ä½“ä»ä¸ºè´Ÿ
        else:
            cost_reduction = 0.0
        
        return delay_cost + cost_reduction  # ä»ç„¶ä¸ºè´Ÿå€¼
    
    def _calculate_energy_reward(self, system_metrics: Dict) -> float:
        """
        ğŸ”§ ä¿®å¤ï¼šè®¡ç®—èƒ½è€—æˆæœ¬ï¼ˆçº¯è´Ÿå€¼ï¼‰
        """
        total_energy = max(0.0, float(system_metrics.get('total_energy_consumption', 0.0)))
        
        # èƒ½è€—æˆæœ¬ï¼šèƒ½è€—è¶Šé«˜æˆæœ¬è¶Šé«˜
        energy_cost = -(total_energy / self.energy_normalizer)
        
        # ğŸ”§ ç§»é™¤æ­£å‘å¥–åŠ±ï¼Œæ”¹ä¸ºæˆæœ¬å‡å…
        if total_energy < 800.0:
            # ä½èƒ½è€—æ—¶æˆæœ¬å‡å…ï¼Œä½†ä»ä¸ºè´Ÿå€¼
            cost_reduction = energy_cost * 0.3  # å‡å…30%æˆæœ¬ï¼Œä½†æ€»ä½“ä»ä¸ºè´Ÿ
        else:
            cost_reduction = 0.0
        
        return energy_cost + cost_reduction  # ä»ç„¶ä¸ºè´Ÿå€¼
    
    def _calculate_loss_reward(self, system_metrics: Dict) -> float:
        """
        ğŸ”§ ä¿®å¤ï¼šè®¡ç®—æ•°æ®ä¸¢å¤±æˆæœ¬ï¼ˆçº¯è´Ÿå€¼ï¼‰
        """
        completion_rate = max(0.0, min(1.0, float(system_metrics.get('task_completion_rate', 0.0))))
        
        # æ•°æ®ä¸¢å¤±æˆæœ¬ï¼šä¸¢å¤±ç‡è¶Šé«˜æˆæœ¬è¶Šé«˜
        loss_rate = 1.0 - completion_rate
        loss_cost = -(loss_rate ** 2) * 3.0  # éçº¿æ€§æˆæœ¬
        
        # ğŸ”§ ç§»é™¤æ­£å‘å¥–åŠ±ï¼Œæ”¹ä¸ºåŸºäºå®Œæˆç‡çš„æˆæœ¬å‡å…
        if completion_rate > 0.9:
            # é«˜å®Œæˆç‡æ—¶æˆæœ¬å‡å…ï¼Œä½†ä»ä¸ºè´Ÿå€¼
            cost_reduction = loss_cost * 0.4  # å‡å…40%æˆæœ¬
        else:
            cost_reduction = 0.0
        
        return loss_cost + cost_reduction  # ä»ç„¶ä¸ºè´Ÿå€¼
    
    def _calculate_cache_reward(self, system_metrics: Dict, cache_metrics: Optional[Dict]) -> float:
        """
        ğŸ”§ ä¿®å¤ï¼šè®¡ç®—ç¼“å­˜æˆæœ¬ï¼ˆçº¯è´Ÿå€¼ï¼‰
        """
        if not cache_metrics:
            return -0.1  # æ— ç¼“å­˜æ•°æ®æ—¶çš„é»˜è®¤æˆæœ¬
        
        cache_hit_rate = cache_metrics.get('hit_rate', 0.0)
        cache_utilization = cache_metrics.get('utilization', 0.0)
        
        # ç¼“å­˜missæˆæœ¬ï¼šå‘½ä¸­ç‡è¶Šä½æˆæœ¬è¶Šé«˜
        cache_miss_rate = 1.0 - cache_hit_rate
        cache_miss_cost = -(cache_miss_rate ** 1.5) * 0.5
        
        # ç¼“å­˜ç®¡ç†æˆæœ¬
        if cache_utilization > 0.9:
            management_cost = -0.2  # è¿‡åº¦åˆ©ç”¨é¢å¤–æˆæœ¬
        elif cache_utilization < 0.3:
            management_cost = -0.1  # åˆ©ç”¨ä¸è¶³çš„æœºä¼šæˆæœ¬
        else:
            management_cost = -0.05  # æ­£å¸¸ç®¡ç†æˆæœ¬
        
        return cache_miss_cost + management_cost  # æ€»æ˜¯è´Ÿå€¼
    
    def _calculate_migration_reward(self, system_metrics: Dict, migration_metrics: Optional[Dict]) -> float:
        """
        ğŸ”§ ä¿®å¤ï¼šè®¡ç®—è¿ç§»æˆæœ¬ï¼ˆçº¯è´Ÿå€¼ï¼‰
        """
        if not migration_metrics:
            return -0.05  # æ— è¿ç§»æ•°æ®æ—¶çš„é»˜è®¤æˆæœ¬
        
        migration_success_rate = migration_metrics.get('success_rate', 0.0)
        migration_frequency = migration_metrics.get('frequency', 0.0)
        
        # è¿ç§»å¤±è´¥æˆæœ¬ï¼šå¤±è´¥ç‡è¶Šé«˜æˆæœ¬è¶Šé«˜
        migration_failure_rate = 1.0 - migration_success_rate
        migration_failure_cost = -(migration_failure_rate ** 2) * 0.3
        
        # è¿ç§»æ“ä½œæˆæœ¬ï¼šé¢‘ç‡è¿‡é«˜æœ‰é¢å¤–æˆæœ¬
        if migration_frequency > 0.15:  # é¢‘ç¹è¿ç§»
            operation_cost = -migration_frequency * 0.2
        else:
            operation_cost = -0.02  # åŸºç¡€è¿ç§»ç®¡ç†æˆæœ¬
        
        return migration_failure_cost + operation_cost  # æ€»æ˜¯è´Ÿå€¼
    
    def _calculate_coordination_reward(self, system_metrics: Dict, 
                                     cache_metrics: Optional[Dict],
                                     migration_metrics: Optional[Dict]) -> float:
        """
        ğŸ”§ ä¿®å¤ï¼šè®¡ç®—ç³»ç»Ÿåè°ƒæˆæœ¬ï¼ˆçº¯è´Ÿå€¼ï¼‰
        """
        if not cache_metrics or not migration_metrics:
            return -0.03  # ç¼ºä¹åè°ƒæ•°æ®çš„æˆæœ¬
        
        cache_hit_rate = cache_metrics.get('hit_rate', 0.0)
        migration_success_rate = migration_metrics.get('success_rate', 0.0)
        avg_delay = system_metrics.get('avg_task_delay', 1.0)
        
        # ç³»ç»Ÿåè°ƒä¸è‰¯æˆæœ¬
        coordination_cost = -0.1  # åŸºç¡€åè°ƒç®¡ç†æˆæœ¬
        
        # ğŸ”§ åŸºäºç³»ç»Ÿåè°ƒæ•ˆæœçš„æˆæœ¬å‡å…ï¼ˆä½†ä»ä¸ºè´Ÿå€¼ï¼‰
        if cache_hit_rate > 0.7 and migration_success_rate > 0.7:
            # åŒç³»ç»Ÿåè°ƒè‰¯å¥½æ—¶ï¼Œå‡å…éƒ¨åˆ†æˆæœ¬
            coordination_cost *= 0.5  # å‡å…50%åè°ƒæˆæœ¬
        
        if avg_delay < 0.3:
            # ä½å»¶è¿Ÿæ—¶ï¼Œè¯æ˜åè°ƒæœ‰æ•ˆï¼Œè¿›ä¸€æ­¥å‡å…æˆæœ¬
            coordination_cost *= 0.7  # å†å‡å…30%
        
        return coordination_cost  # å§‹ç»ˆä¸ºè´Ÿå€¼
    
    def get_reward_breakdown(self, system_metrics: Dict,
                           cache_metrics: Optional[Dict] = None,
                           migration_metrics: Optional[Dict] = None) -> str:
        """
        è·å–å¥–åŠ±åˆ†è§£çš„å¯è¯»æŠ¥å‘Š
        """
        rewards = self.calculate_enhanced_reward(system_metrics, cache_metrics, migration_metrics)
        
        breakdown = f"""
å¥–åŠ±åˆ†è§£æŠ¥å‘Š:
â”œâ”€â”€ æ€»å¥–åŠ±: {rewards['total_reward']:.3f}
â”œâ”€â”€ æ—¶å»¶å¥–åŠ±: {rewards['delay_reward']:.3f}
â”œâ”€â”€ èƒ½è€—å¥–åŠ±: {rewards['energy_reward']:.3f}  
â”œâ”€â”€ æ•°æ®ä¸¢å¤±: {rewards['loss_reward']:.3f}
â”œâ”€â”€ ç¼“å­˜å¥–åŠ±: {rewards['cache_reward']:.3f}
â”œâ”€â”€ è¿ç§»å¥–åŠ±: {rewards['migration_reward']:.3f}
â””â”€â”€ åè°ƒå¥–åŠ±: {rewards['coordination_reward']:.3f}
        """
        
        return breakdown.strip()

# å…¨å±€å¢å¼ºå¥–åŠ±è®¡ç®—å™¨
_enhanced_reward_calculator = EnhancedRewardCalculator()

def calculate_enhanced_reward(system_metrics: Dict,
                            cache_metrics: Optional[Dict] = None,
                            migration_metrics: Optional[Dict] = None) -> float:
    """
    ä¾›å¤–éƒ¨è°ƒç”¨çš„å¢å¼ºå¥–åŠ±æ¥å£
    """
    result = _enhanced_reward_calculator.calculate_enhanced_reward(
        system_metrics, cache_metrics, migration_metrics
    )
    return result['total_reward']

def get_reward_breakdown(system_metrics: Dict,
                        cache_metrics: Optional[Dict] = None, 
                        migration_metrics: Optional[Dict] = None) -> str:
    """
    è·å–å¥–åŠ±åˆ†è§£æŠ¥å‘Š
    """
    return _enhanced_reward_calculator.get_reward_breakdown(
        system_metrics, cache_metrics, migration_metrics
    )
