#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸš€ å¹¶è¡Œç¯å¢ƒé‡‡æ ·å™¨ - æé«˜CPUåˆ©ç”¨ç‡

é€šè¿‡å¤šè¿›ç¨‹å¹¶è¡Œè¿è¡Œå¤šä¸ªç¯å¢ƒå®ä¾‹ï¼ŒåŠ é€Ÿæ•°æ®é‡‡é›†ã€‚
é€‚ç”¨äºå¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸­CPUåˆ©ç”¨ç‡ä½çš„æƒ…å†µã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
    from utils.parallel_env_sampler import ParallelEnvSampler
    
    sampler = ParallelEnvSampler(
        env_fn=create_env_fn,
        num_envs=4,  # å¹¶è¡Œç¯å¢ƒæ•°
    )
    
    # å¹¶è¡Œé‡‡æ ·
    experiences = sampler.sample(agent, num_steps=100)

ä½œè€…ï¼šVEC_mig_caching Team
"""

import os
import numpy as np
from typing import Callable, List, Dict, Any, Optional, Tuple
from multiprocessing import Process, Pipe, Queue
import queue
import threading
import time


class EnvWorker(Process):
    """ç¯å¢ƒå·¥ä½œè¿›ç¨‹"""
    
    def __init__(
        self,
        env_fn: Callable,
        conn,
        worker_id: int,
    ):
        super().__init__()
        self.env_fn = env_fn
        self.conn = conn
        self.worker_id = worker_id
        
    def run(self):
        """å·¥ä½œè¿›ç¨‹ä¸»å¾ªç¯"""
        env = self.env_fn()
        
        while True:
            try:
                cmd, data = self.conn.recv()
                
                if cmd == 'step':
                    action = data
                    next_state, reward, done, info = env.step(action)
                    if done:
                        next_state = env.reset()
                    self.conn.send(('step_result', (next_state, reward, done, info)))
                    
                elif cmd == 'reset':
                    state = env.reset()
                    self.conn.send(('reset_result', state))
                    
                elif cmd == 'get_state':
                    state = env.get_state()
                    self.conn.send(('state', state))
                    
                elif cmd == 'close':
                    break
                    
            except EOFError:
                break
                
        env.close() if hasattr(env, 'close') else None


class ParallelEnvSampler:
    """
    å¹¶è¡Œç¯å¢ƒé‡‡æ ·å™¨
    
    é€šè¿‡å¤šè¿›ç¨‹å¹¶è¡Œè¿è¡Œå¤šä¸ªç¯å¢ƒå®ä¾‹ï¼ŒåŠ é€Ÿæ•°æ®é‡‡é›†ã€‚
    """
    
    def __init__(
        self,
        env_fn: Callable,
        num_envs: int = 4,
    ):
        """
        åˆå§‹åŒ–å¹¶è¡Œé‡‡æ ·å™¨
        
        Args:
            env_fn: åˆ›å»ºç¯å¢ƒçš„å‡½æ•°
            num_envs: å¹¶è¡Œç¯å¢ƒæ•°é‡ï¼ˆå»ºè®®è®¾ä¸ºCPUæ ¸å¿ƒæ•°çš„1/2åˆ°1å€ï¼‰
        """
        self.env_fn = env_fn
        self.num_envs = num_envs
        
        self.workers = []
        self.parent_conns = []
        
        # åˆ›å»ºå·¥ä½œè¿›ç¨‹
        for i in range(num_envs):
            parent_conn, child_conn = Pipe()
            worker = EnvWorker(env_fn, child_conn, i)
            worker.start()
            self.workers.append(worker)
            self.parent_conns.append(parent_conn)
        
        # é‡ç½®æ‰€æœ‰ç¯å¢ƒè·å–åˆå§‹çŠ¶æ€
        self.states = self._reset_all()
        
        print(f"[ParallelEnvSampler] å·²åˆ›å»º {num_envs} ä¸ªå¹¶è¡Œç¯å¢ƒ")
    
    def _reset_all(self) -> List[np.ndarray]:
        """é‡ç½®æ‰€æœ‰ç¯å¢ƒ"""
        for conn in self.parent_conns:
            conn.send(('reset', None))
        
        states = []
        for conn in self.parent_conns:
            _, state = conn.recv()
            states.append(state)
        
        return states
    
    def step(self, actions: List[np.ndarray]) -> Tuple[List, List, List, List]:
        """
        å¹¶è¡Œæ‰§è¡Œä¸€æ­¥
        
        Args:
            actions: æ¯ä¸ªç¯å¢ƒçš„åŠ¨ä½œåˆ—è¡¨
            
        Returns:
            next_states, rewards, dones, infos
        """
        # å‘é€åŠ¨ä½œ
        for conn, action in zip(self.parent_conns, actions):
            conn.send(('step', action))
        
        # æ¥æ”¶ç»“æœ
        next_states, rewards, dones, infos = [], [], [], []
        for i, conn in enumerate(self.parent_conns):
            _, (next_state, reward, done, info) = conn.recv()
            next_states.append(next_state)
            rewards.append(reward)
            dones.append(done)
            infos.append(info)
            self.states[i] = next_state
        
        return next_states, rewards, dones, infos
    
    def sample_batch(
        self,
        agent,
        num_steps: int = 100,
        training: bool = True,
    ) -> List[Dict[str, Any]]:
        """
        å¹¶è¡Œé‡‡æ ·ä¸€æ‰¹ç»éªŒ
        
        Args:
            agent: æ™ºèƒ½ä½“ï¼ˆéœ€è¦æœ‰select_actionæ–¹æ³•ï¼‰
            num_steps: é‡‡æ ·æ­¥æ•°
            training: æ˜¯å¦è®­ç»ƒæ¨¡å¼
            
        Returns:
            ç»éªŒåˆ—è¡¨ [{'state', 'action', 'reward', 'next_state', 'done'}, ...]
        """
        experiences = []
        
        for _ in range(num_steps):
            # å¹¶è¡Œè·å–åŠ¨ä½œ
            actions = []
            for state in self.states:
                action = agent.select_action(state, training=training)
                actions.append(action)
            
            # å¹¶è¡Œæ‰§è¡Œæ­¥éª¤
            current_states = [s.copy() for s in self.states]
            next_states, rewards, dones, infos = self.step(actions)
            
            # æ”¶é›†ç»éªŒ
            for i in range(self.num_envs):
                experiences.append({
                    'state': current_states[i],
                    'action': actions[i],
                    'reward': rewards[i],
                    'next_state': next_states[i],
                    'done': dones[i],
                    'info': infos[i],
                })
        
        return experiences
    
    def close(self):
        """å…³é—­æ‰€æœ‰å·¥ä½œè¿›ç¨‹"""
        for conn in self.parent_conns:
            conn.send(('close', None))
        
        for worker in self.workers:
            worker.join(timeout=1)
            if worker.is_alive():
                worker.terminate()
        
        print("[ParallelEnvSampler] æ‰€æœ‰ç¯å¢ƒå·²å…³é—­")


class AsyncExperienceBuffer:
    """
    å¼‚æ­¥ç»éªŒç¼“å†²åŒº
    
    ä½¿ç”¨åå°çº¿ç¨‹é¢„å–ä¸‹ä¸€æ‰¹ç»éªŒï¼Œå‡å°‘ç­‰å¾…æ—¶é—´ã€‚
    """
    
    def __init__(
        self,
        sampler: ParallelEnvSampler,
        agent,
        buffer_size: int = 2,
        steps_per_batch: int = 50,
    ):
        """
        åˆå§‹åŒ–å¼‚æ­¥ç¼“å†²åŒº
        
        Args:
            sampler: å¹¶è¡Œé‡‡æ ·å™¨
            agent: æ™ºèƒ½ä½“
            buffer_size: é¢„å–ç¼“å†²åŒºå¤§å°
            steps_per_batch: æ¯æ‰¹é‡‡æ ·æ­¥æ•°
        """
        self.sampler = sampler
        self.agent = agent
        self.buffer_size = buffer_size
        self.steps_per_batch = steps_per_batch
        
        self.buffer = Queue(maxsize=buffer_size)
        self.running = True
        
        # å¯åŠ¨åå°é‡‡æ ·çº¿ç¨‹
        self.sample_thread = threading.Thread(target=self._sample_loop, daemon=True)
        self.sample_thread.start()
    
    def _sample_loop(self):
        """åå°é‡‡æ ·å¾ªç¯"""
        while self.running:
            try:
                experiences = self.sampler.sample_batch(
                    self.agent,
                    num_steps=self.steps_per_batch,
                    training=True,
                )
                self.buffer.put(experiences, timeout=1)
            except queue.Full:
                continue
            except Exception as e:
                print(f"[AsyncBuffer] é‡‡æ ·é”™è¯¯: {e}")
                break
    
    def get_batch(self, timeout: float = 5.0) -> Optional[List[Dict]]:
        """è·å–ä¸€æ‰¹ç»éªŒ"""
        try:
            return self.buffer.get(timeout=timeout)
        except queue.Empty:
            return None
    
    def stop(self):
        """åœæ­¢åå°é‡‡æ ·"""
        self.running = False
        self.sample_thread.join(timeout=2)


def get_optimal_num_envs() -> int:
    """
    è·å–æœ€ä¼˜å¹¶è¡Œç¯å¢ƒæ•°é‡
    
    åŸºäºCPUæ ¸å¿ƒæ•°è‡ªåŠ¨ç¡®å®š
    """
    import multiprocessing
    cpu_count = multiprocessing.cpu_count()
    
    # é€šå¸¸ä½¿ç”¨CPUæ ¸å¿ƒæ•°çš„1/2åˆ°3/4
    optimal = max(2, cpu_count // 2)
    
    # é™åˆ¶æœ€å¤§å€¼é¿å…è¿‡å¤šè¿›ç¨‹
    return min(optimal, 8)


def setup_gpu_optimization():
    """
    è®¾ç½®GPUä¼˜åŒ–ç¯å¢ƒå˜é‡
    
    è°ƒç”¨æ­¤å‡½æ•°å¯ä»¥ä¼˜åŒ–PyTorchçš„GPUæ€§èƒ½
    """
    # å†…å­˜åˆ†é…ä¼˜åŒ–
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb=512'
    
    # å¤šçº¿ç¨‹ä¼˜åŒ–
    os.environ['OMP_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
    os.environ['MKL_NUM_THREADS'] = str(max(1, os.cpu_count() // 2))
    
    # cuDNNä¼˜åŒ–
    try:
        import torch
        if torch.cuda.is_available():
            # å¯ç”¨cuDNNè‡ªåŠ¨è°ƒä¼˜
            torch.backends.cudnn.benchmark = False
            # ä½¿ç”¨ç¡®å®šæ€§ç®—æ³•ï¼ˆå¯é€‰ï¼Œå¯èƒ½é™ä½æ€§èƒ½ï¼‰
            # torch.backends.cudnn.deterministic = True
            
            print(f"[GPUä¼˜åŒ–] cuDNN benchmarkå·²å¯ç”¨")
            print(f"[GPUä¼˜åŒ–] GPU: {torch.cuda.get_device_name(0)}")
            print(f"[GPUä¼˜åŒ–] å¯ç”¨æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    except ImportError:
        pass
    
    print(f"[CPUä¼˜åŒ–] OMP_NUM_THREADS = {os.environ.get('OMP_NUM_THREADS')}")
    print(f"[CPUä¼˜åŒ–] æ¨èå¹¶è¡Œç¯å¢ƒæ•°: {get_optimal_num_envs()}")


if __name__ == "__main__":
    # æµ‹è¯•GPUä¼˜åŒ–è®¾ç½®
    setup_gpu_optimization()
