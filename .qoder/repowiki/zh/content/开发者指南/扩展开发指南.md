
# 扩展开发指南

<cite>
**本文档引用的文件**
- [qmix.py](file://algorithms/qmix.py)
- [base_node.py](file://models/base_node.py)
- [uav_node.py](file://models/uav_node.py)
- [rsu_node.py](file://models/rsu_node.py)
- [vehicle_node.py](file://models/vehicle_node.py)
- [offloading_manager.py](file://decision/offloading_manager.py)
- [algorithm_config.py](file://config/algorithm_config.py)
- [td3.py](file://single_agent/td3.py)
- [ppo.py](file://single_agent/ppo.py)
</cite>

## 目录
1. [引言](#引言)
2. [扩展多智能体算法](#扩展多智能体算法)
3. [定义新节点类型](#定义新节点类型)
4. [兼容性处理](#兼容性处理)
5. [扩展单智能体算法](#扩展单智能体算法)
6. [测试与验证](#测试与验证)

## 引言
本指南旨在为开发者提供安全扩展系统功能的详细步骤。系统采用多智能体深度强化学习框架，支持多种算法和节点类型。通过继承基类和实现必要接口，开发者可以轻松添加新功能。本指南将详细介绍如何扩展多智能体算法、定义新节点类型、处理兼容性问题以及扩展单智能体算法。

## 扩展多智能体算法
要添加新的多智能体算法（如QMIX变体），需要继承`algorithms/`目录中的基类，并实现必要的策略网络和训练逻辑。

### 继承基类
在`algorithms/`目录中，所有多智能体算法都继承自一个共同的基类结构。以`qmix.py`为例，该文件实现了QMIX算法，包含`QMIXAgent`、`QMIXMixer`和`QMIXEnvironment`等核心组件。

```mermaid
classDiagram
class QMIXEnvironment {
+agent_networks : Dict[str, QMIXAgent]
+target_agent_networks : Dict[str, QMIXAgent]
+mixer : QMIXMixer
+target_mixer : QMIXMixer
+replay_buffer : QMIXReplayBuffer
+get_actions(states : Dict[str, np.ndarray], training : bool) Dict[str, int]
+train_step(states : Dict[str, np.ndarray], actions : Dict[str, int], rewards : Dict[str, float], next_states : Dict[str, np.ndarray], dones : Dict[str, bool]) Dict
+save_models(filepath : str) void
+load_models(filepath : str) void
}
class QMIXAgent {
+input_dim : int
+output_dim : int
+hidden_dim : int
+rnn_hidden_dim : int
+fc1 : nn.Linear
+rnn : nn.GRU
+fc2 : nn.Linear
+output : nn.Linear
+forward(inputs : torch.Tensor, hidden_state : Optional[torch.Tensor]) Tuple[torch.Tensor, torch.Tensor]
+init_hidden(batch_size : int) torch.Tensor
}
class QMIXMixer {
+num_agents : int
+state_dim : int
+hidden_dim : int
+hyper_w1 : nn.Linear
+hyper_w2 : nn.Linear
+hyper_b1 : nn.Linear
+hyper_b2 : nn.Sequential
+forward(agent_qs : torch.Tensor, states : torch.Tensor) torch.Tensor
}
class QMIXReplayBuffer {
+capacity : int
+num_agents : int
+buffer : deque
+push(states : Dict[str, np.ndarray], actions : Dict[str, int], rewards : Dict[str, float], next_states : Dict[str, np.ndarray], dones : Dict[str, bool], global_state : np.ndarray, next_global_state : np.ndarray) void
+sample(batch_size : int) Dict
+__len__() int
}
QMIXEnvironment --> QMIXAgent : "包含"
QMIXEnvironment --> QMIXMixer : "包含"
QMIXEnvironment --> QMIXReplayBuffer : "包含"
```

**图表来源**
- [qmix.py](file://algorithms/qmix.py#L18-L598)

### 实现策略网络和训练逻辑
新算法需要实现策略网络和训练逻辑。以`QMIXAgent`为例，它使用RNN处理部分可观测环境，包含输入层、RNN层和输出层。

```mermaid
flowchart TD
Start([开始]) --> Init["初始化网络权重"]
Init --> Forward["前向传播"]
Forward --> CheckInput["检查输入维度"]
CheckInput --> |单步输入| Reshape1["转换为序列格式"]
CheckInput --> |序列输入| ProcessInput["处理输入"]
Reshape1 --> ProcessInput
ProcessInput --> FC1["第一层全连接"]
FC1 --> RNN["RNN层"]
RNN --> FC2["输出层"]
FC2 --> Reshape2["重新形状"]
Reshape2 --> |单步输入| Squeeze["挤压维度"]
Reshape2 --> |序列输入| Output["输出Q值"]
Squeeze --> Output
Output --> End([结束])
```

**图表来源**
- [qmix.py](file://algorithms/qmix.py#L100-L180)

### 注册配置项
在`algorithm_config.py`中注册新算法的配置项。该文件定义了`AlgorithmConfig`类，包含各种算法的配置。

```mermaid
classDiagram
class AlgorithmConfig {
+matd3_config : Dict[str, Any]
+maddpg_config : Dict[str, Any]
+ddpg_config : Dict[str, Any]
+ppo_config : Dict[str, Any]
+__init__() void
+get_algorithm_config(algorithm : str) Dict[str, Any]
+update_algorithm_config(algorithm : str, **kwargs) void
}
```

**图表来源**
- [algorithm_config.py](file://config/algorithm_config.py#L1-L73)

**扩展多智能体算法**
- [qmix.py](file://algorithms/qmix.py#L1-L598)
- [algorithm_config.py](file://config/algorithm_config.py#L1-L73)

## 定义新节点类型
要定义新的节点类型（如新型UAV），需要继承`models/base_node.py`并实现状态更新和通信接口。

### 继承BaseNode
`BaseNode`是所有计算节点的抽象基类，定义了通用接口和属性。新节点类型需要继承此类并实现抽象方法。

```mermaid
classDiagram
class BaseNode {
+node_id : str
+node_type : NodeType
+state : NodeState
+queues : Dict[Tuple[int, int], QueueSlot]
+processed_tasks : List[Task]
+dropped_tasks : List[Task]
+energy_consumption_history : List[float]
+_avg_task_complexity : float
+avg_arrival_rate : ExponentialMovingAverage
+avg_service_rate : ExponentialMovingAverage
+avg_waiting_time : ExponentialMovingAverage
+__init__(node_id : str, node_type : NodeType, position : Position) void
+_initialize_queues() void
+get_processing_capacity() float
+calculate_processing_delay(task : Task) float
+calculate_energy_consumption(processing_time : float) float
+add_task_to_queue(task : Task) bool
+_check_queue_capacity() bool
+get_next_task_to_process() Optional[Task]
+process_task(task : Task) bool
+_remove_task_from_queue(task : Task) void
+predict_waiting_time(task : Task) float
+_calculate_arrival_rates_by_priority() Dict[int, float]
+_calculate_service_rate() float
+_update_statistics() void
+update_queue_lifetimes() void
+get_state_vector() np.ndarray
}
class UAVNode {
+kappa3 : float
+state.hover_power : float
+state.battery_level : float
+battery_capacity : float
+min_battery_threshold : float
+is_hovering : bool
+hover_efficiency : float
+coverage_radius : float
+altitude : float
+max_concurrent_tasks : int
+service_area_center : Position
+migration_cooldown : int
+is_migration_source : bool
+__init__(uav_id : str, position : Position) void
+get_processing_capacity() float
+calculate_processing_delay(task : Task) float
+calculate_energy_consumption(processing_time : float) float
+calculate_communication_energy(data_size : float, communication_time : float) float
+_update_battery_level(energy_consumed : float) void
+is_battery_low() bool
+can_accept_task(task : Task) bool
+_estimate_task_energy(task : Task) float
+process_offloaded_task(task : Task) Tuple[bool, float]
+is_overloaded() bool
+calculate_migration_urgency() float
+get_coverage_vehicles(vehicle_positions : Dict) List[str]
+optimize_position(vehicle_positions : Dict) void
+recharge_battery(recharge_rate : float) void
+step(time_step : float, vehicle_positions : Optional[Dict]) List[Task]
+get_state_vector() np.ndarray
}
class RSUNode {
+cache_capacity : float
+cached_results : Dict[str, Task]
+cache_decisions : Dict[str, bool]
+cache_hit_count : int
+cache_miss_count : int
+request_history : Dict[str, List[float]]
+cache_heat_map : Dict[str, float]
+migration_bandwidth : float
+is_migration_target : bool
+migration_cooldown : int
+kappa2 : float
+coverage_radius : float
+neighbor_rsus : Set[str]
+__init__(rsu_id : str, position : Position) void
+get_processing_capacity() float
+calculate_processing_delay(task : Task) float
+calculate_energy_consumption(processing_time : float) float
+check_cache_hit(task : Task) bool
+predict_cache_request_probability(task : Task) float
+calculate_cache_hit_rate() float
+make_cache_decision(task : Task) bool
+_cache_replacement(required_size : float) bool
+_lru_replacement(required_size : float) bool
+_lfu_replacement(required_size : float) bool
+_random_replacement(required_size : float) bool
+process_offloaded_task(task : Task) Tuple[bool, float]
+calculate_migration_cost(task : Task, target_rsu_id : str) float
+is_overloaded() bool
+is_underloaded() bool
+get_coverage_vehicles(vehicle_positions : Dict[str, Position]) List[str]
+step(time_step : float) List[Task]
+get_state_vector() np.ndarray
}
class VehicleNode {
+velocity : np.ndarray
+max_speed : float
+trajectory : List[Position]
+task_generation_rate : float
+generated_tasks : List[Task]
+kappa1 : float
+kappa2 : float
+static_power : float
+idle_power : float
+__init__(vehicle_id : str, initial_position : Position) void
+_setup_compute_resources() void
+get_processing_capacity() float
+calculate_processing_delay(task : Task) float
+calculate_energy_consumption(processing_time : float) float
+generate_tasks(current_time_slot : int) List[Task]
+_create_random_task() Task
+update_position(time_step : float) void
+set_random_velocity() void
+step(time_step : float) Tuple[List[Task], List[Task]]
+can_process_immediately(task : Task) bool
+process_task_immediately(task : Task) Tuple[bool, float]
}
BaseNode <|-- UAVNode : "继承"
BaseNode <|-- RSUNode : "继承"
BaseNode <|-- VehicleNode : "继承"
```

**图表来源**
- [base_node.py](file://models/base_node.py#L18-L312)
- [uav_node.py](file://models/uav_node.py#L1-L360)
- [rsu_node.py](file://models/rsu_node.py#L1-L423)
- [vehicle_node.py](file://models/vehicle_node.py#L1-L300)

### 实现状态更新和通信接口
新节点类型需要实现状态更新和通信接口。以`UAVNode`为例，它实现了`step`方法来更新节点状态。

```mermaid
flowchart TD
Start([开始]) --> UpdateQueues["更新队列生命周期"]
UpdateQueues --> UpdateCooldown["更新迁移冷却"]
UpdateCooldown --> OptimizePosition["优化位置"]
OptimizePosition --> ProcessTasks["处理队列中的任务"]
ProcessTasks --> CheckCapacity["检查处理能力"]
CheckCapacity --> |有容量| GetNextTask["获取下一个任务"]
CheckCapacity --> |无容量| UpdateHoverEnergy["更新悬停能耗"]
GetNextTask --> |有任务| ProcessTask["处理任务"]
GetNextTask --> |无任务| UpdateHoverEnergy
ProcessTask --> UpdateStatistics["更新统计信息"]
UpdateHoverEnergy --> UpdateStatistics
UpdateStatistics --> CheckMigration["检查是否需要紧急迁移"]
CheckMigration --> End([结束])
```

**图表来源**
- [uav_node.py](file://models/uav_node.py#L280-L360)

**定义新节点类型**
- [base_node.py](file://models/base_node.py#L18-L312)
- [uav_node.py](file://models/uav_node.py#L1-L360)
- [rsu_node.py](file://models/rsu_node.py#L1-L423)
- [vehicle_node.py](file://models/vehicle_node.py#L1-L300)

## 兼容性处理
新节点需要与`decision/offloading_manager.py`兼容，确保能参与任务卸载决策。

### 任务分类与卸载决策
`OffloadingDecisionMaker`类负责制定卸载决策，整合任务分类和评估。

```mermaid
sequenceDiagram
participant Task as "任务"
participant Classifier as "TaskClassifier"
participant Evaluator as "ProcessingModeEvaluator"
participant DecisionMaker as "OffloadingDecisionMaker"
Task->>DecisionMaker : make_offloading_decision()
DecisionMaker->>Classifier : classify_task()
Classifier-->>DecisionMaker : 任务类型
DecisionMaker->>Classifier : get_candidate_nodes()
Classifier-->>DecisionMaker : 候选节点
DecisionMaker->>Evaluator : evaluate_all_modes()
Evaluator-->>DecisionMaker : 处理选项
DecisionMaker->>Evaluator : select_best_option()
Evaluator-->>DecisionMaker : 最佳选项
DecisionMaker-->>Task : 返回最佳处理选项
```

**图表来源**
- [offloading_manager.py](file://decision/offloading_manager.py#L1-L625)

### 处理模式评估
`ProcessingModeEvaluator`类评估所有可行的处理模式，包括本地计算、RSU卸载、RSU间迁移和UAV卸载。

```mermaid
flowchart TD
Start([开始]) --> LoopNodes["遍历候选节点"]
LoopNodes --> CheckNode["检查节点类型"]
CheckNode --> |车辆节点| EvaluateLocal["评估本地计算"]
CheckNode --> |RSU节点| EvaluateRSU["评估RSU卸载"]
CheckNode --> |UAV节点| EvaluateUAV["评估UAV卸载"]
EvaluateLocal --> AddOption["添加处理选项"]
EvaluateRSU --> AddOption
EvaluateUAV --> AddOption
AddOption --> CheckNextNode["检查下一个节点"]
CheckNextNode --> |有节点| LoopNodes
CheckNextNode --> |无节点| ReturnOptions["返回处理选项"]
ReturnOptions --> End([结束])
```

**图表来源**
- [offloading_manager.py](file://decision/offloading_manager.py#L1-L625)

**兼容性处理**
- [offloading_manager.py](file://decision/offloading_manager.py#L1-L625)

## 扩展单智能体算法
提供扩展`single_agent/`算法的示例，说明如何保持接口一致性。

### 继承单智能体基类
`single_agent/`目录中的算法都遵循类似的结构。以`td3.py`为例，它实现了TD3算法。

```mermaid
classDiagram
class TD3Environment {
+config : TD3Config
+state_dim : int
+action_dim : int
+agent : TD3Agent
+episode_count : int
+step_count : int
+__init__() void
+get_state_vector(node_states : Dict, system_metrics : Dict) np.ndarray
+decompose_action(action : np.ndarray) Dict[str, np.ndarray]
+get_actions(state : np.ndarray, training : bool) Dict[str, np.ndarray]
+calculate_reward(system_metrics : Dict) float
+train_step(state : np.ndarray, action : Union[np.ndarray, int], reward : float, next_state : np.ndarray, done : bool) Dict
+save_models(filepath : str) void
+load_models(filepath : str) void
+store_experience(state : np.ndarray, action : np.ndarray, reward : float, next_state : np.ndarray, done : bool, log_prob : float, value : float) void
+update(last_value : float) Dict
+get_training_stats() Dict
}
class TD3Agent {
+state_dim : int
+action_dim : int
+config : TD3Config
+optimized_batch_size : int
+device : torch.device
+actor : TD3Actor
+critic : TD3Critic
+target_actor : TD3Actor
+target_critic : TD3Critic
+actor_optimizer : optim.Adam
+critic_optimizer : optim.Adam
+actor_lr_scheduler : optim.lr_scheduler.ExponentialLR
+critic_lr_scheduler : optim.lr_scheduler.ExponentialLR
+replay_buffer : TD3ReplayBuffer
+beta : float
+beta_increment : float
+exploration_noise : float
+step_count : int
+update_count : int
+actor_losses : List[float]
+critic_losses : List[float]
+__init__(state_dim : int, action_dim : int, config : TD3Config) void
+select_action(state : np.ndarray, training : bool) np.ndarray
+store_experience(state : np.ndarray, action : np.ndarray, reward : float, next_state : np.ndarray, done : bool) void
+update() Dict[str, float]
+_update_critic(states : torch.Tensor, actions : torch.Tensor, rewards : torch.Tensor, next_states : torch.Tensor, dones : torch.Tensor, weights : torch.Tensor) Tuple[float, torch.Tensor]
+_update_actor(states : torch.Tensor) float
+soft_update(target : nn.Module, source : nn.Module, tau : float) void
+hard_update(target : nn.Module, source : nn.Module) void
+save_model(filepath : str) void
+load_model(filepath : str) void
}
TD3Environment --> TD3Agent : "包含"
```

**图表来源**
- [td3.py](file://single_agent/td3.py#L1-L546)

### 保持接口一致性
新单智能体算法需要保持与现有算法的接口一致性。以`PPOEnvironment`为例，它实现了与`TD3Environment`相同的接口。

```mermaid
classDiagram
    class PPOEnvironment {
        +config: PPOConfig
        +state_dim: int
        +action_dim: int
        +