# =============================================================================
# XuanCe VEC Environment - TD3 Configuration
# VEC边缘计算系统 - TD3算法配置
# =============================================================================

# Deep learning toolbox
dl_toolbox: "torch"

# Project settings
project_name: "VEC_Edge_Computing"
logger: "tensorboard"
wandb_user_name: "vec_user"
render: false
render_mode: "rgb_array"
fps: 30
test_mode: false

# Device settings
device: "cuda:0"
distributed_training: false
master_port: "12355"

# Algorithm settings
agent: "TD3"
env_name: "VEC"
env_id: "VEC-v1"
env_seed: 42
vectorize: "DummyVecEnv"
learner: "TD3_Learner"
policy: "Deterministic_DoubleQPolicy"
representation: "Basic_MLP"

# Network architecture
representation_hidden_size: [256, 256]
actor_hidden_size: [256, 256]
critic_hidden_size: [256, 256]
activation: "relu"
activation_action: "tanh"

# Random seed
seed: 42

# Parallel environments
parallels: 1

# Training settings
running_steps: 200000
start_training: 1000
training_frequency: 1

# TD3 specific parameters
actor_learning_rate: 0.00009
critic_learning_rate: 0.00009
gamma: 0.99
tau: 0.005
batch_size: 384
buffer_size: 100000

# TD3 noise and delay
actor_update_delay: 2
explore_noise: 0.18
target_noise: 0.05
noise_clip: 0.2

# Gradient clipping
use_grad_clip: true
grad_clip_norm: 0.5

# Normalization
use_obsnorm: false
use_rewnorm: false
obsnorm_range: 5
rewnorm_range: 5

# Evaluation
test_steps: 10000
eval_interval: 10000
test_episode: 5

# Logging
log_dir: "./logs/td3_vec/"
model_dir: "./models/td3_vec/"

# =============================================================================
# VEC Environment Specific Settings
# =============================================================================
vec_config:
  # Network topology
  num_vehicles: 12
  num_rsus: 4
  num_uavs: 2
  
  # Task settings
  arrival_rate: 3.5
  
  # Episode settings
  max_episode_steps: 200
  
  # Feature flags
  use_enhanced_cache: true
  disable_migration: false
  
  # Reward weights
  reward_weight_delay: 0.5
  reward_weight_energy: 0.5
  reward_penalty_dropped: 1.0
