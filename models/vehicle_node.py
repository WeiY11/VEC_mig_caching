"""
è½¦è¾†èŠ‚ç‚¹å®ç° - å¯¹åº”è®ºæ–‡ç¬¬2.1èŠ‚å’Œç¬¬5.1èŠ‚
å®ç°è½¦è¾†çš„æœ¬åœ°è®¡ç®—ã€ä»»åŠ¡ç”Ÿæˆå’Œç§»åŠ¨æ¨¡å‹
"""
import numpy as np
import time
import math
from typing import List, Optional, Tuple

from .base_node import BaseNode
from .data_structures import Task, Position, NodeType, TaskType
from config import config
from utils import (
    generate_poisson_arrivals, 
    sample_zipf_content_id, 
    sample_heavy_tailed_task_size
)


class VehicleNode(BaseNode):
    """
    è½¦è¾†èŠ‚ç‚¹ç±» - å¯¹åº”è®ºæ–‡è½¦è¾†æ¨¡å‹ v âˆˆ V
    
    ä¸»è¦åŠŸèƒ½:
    1. ä»»åŠ¡ç”Ÿæˆ (æŒ‰æ³Šæ¾è¿‡ç¨‹)
    2. æœ¬åœ°è®¡ç®—å¤„ç†
    3. è½¦è¾†ç§»åŠ¨æ¨¡æ‹Ÿ
    4. èƒ½è€—æ¨¡å‹ (å¯¹åº”è®ºæ–‡å¼5-9)
    """
    
    def __init__(self, vehicle_id: str, initial_position: Position):
        super().__init__(vehicle_id, NodeType.VEHICLE, initial_position)
        
        # è½¦è¾†ç‰¹æœ‰å±æ€§
        self.velocity = np.array([0.0, 0.0])  # é€Ÿåº¦å‘é‡ (m/s)
        self.max_speed = 60.0  # æœ€å¤§é€Ÿåº¦ (m/s) - é«˜é€Ÿå…¬è·¯åœºæ™¯ (216 km/h)
        self.trajectory: List[Position] = [initial_position]
        
        # è®¡ç®—èµ„æºé…ç½® - å¯¹åº”è®ºæ–‡ç¬¬5.1èŠ‚
        self._setup_compute_resources()
        
        # ä»»åŠ¡ç”Ÿæˆå‚æ•°
        self.task_generation_rate = config.task.arrival_rate
        self.generated_tasks: List[Task] = []
        
        # èƒ½è€—æ¨¡å‹å‚æ•° - è®ºæ–‡å¼(5)
        self.kappa1 = config.compute.vehicle_kappa1
        self.kappa2 = config.compute.vehicle_kappa2  
        self.static_power = config.compute.vehicle_static_power
        self.idle_power = config.compute.vehicle_static_power
        
        # ä¼ è¾“åŠŸç‡
        self.state.tx_power = config.communication.vehicle_tx_power
    
    def _setup_compute_resources(self):
        """è®¾ç½®è½¦è¾†è®¡ç®—èµ„æº"""
        # ä»é…ç½®èŒƒå›´ä¸­éšæœºé€‰æ‹©CPUé¢‘ç‡
        freq_range = config.compute.vehicle_cpu_freq_range
        self.state.cpu_frequency = np.random.uniform(freq_range[0], freq_range[1])
        
        # è®¾ç½®å¯ç”¨å¸¦å®½
        self.state.available_bandwidth = config.communication.total_bandwidth / config.network.num_vehicles
    
    def get_processing_capacity(self) -> float:
        """
        é‘¾å³°å½‡æï¹ç· éˆî„€æ¹´æ¾¶å‹­æ‚Šé‘³è—‰å§ (bytes/éƒå •æ®­) - ç€µç‘°ç°²ç’çƒ˜æƒå¯®?5)
        D^local_n = (f_n * è–t) / c
        """
        delta_t = config.network.time_slot_duration
        compute_density = config.task.task_compute_density
        parallel_efficiency = config.compute.parallel_efficiency
        bits_capacity = (self.state.cpu_frequency * delta_t * parallel_efficiency) / compute_density
        return bits_capacity / 8.0

    def calculate_processing_delay(self, task: Task) -> float:
        """
        è®¡ç®—æœ¬åœ°å¤„ç†æ—¶å»¶ - å¯¹åº”è®ºæ–‡å¼(6)
        T_comp,j,n = C_j / (f_n * Î·_parallel)
        """
        parallel_efficiency = config.compute.parallel_efficiency
        return task.compute_cycles / (self.state.cpu_frequency * parallel_efficiency)
    
    def calculate_energy_consumption(self, processing_time: float) -> float:
        """
        ç’ï¼„ç•»æ¾¶å‹­æ‚Šé‘³å€Ÿâ‚¬?- ç€µç‘°ç°²ç’çƒ˜æƒå¯®?7)-(9)
        P^comp_n(f_n, U_n) = é­éˆ§ä¹«_né² + é­éˆ§ä¿§_nè™U_n + P_static
        """
        slot_duration = max(config.network.time_slot_duration, 1e-9)
        utilization = min(1.0, processing_time / slot_duration)
        
        # é”ã„¦â‚¬ä½¸å§›éœå›¨Äé¨?- ç€µç‘°ç°²ç’çƒ˜æƒå¯®?7)
        dynamic_power = (self.kappa1 * (self.state.cpu_frequency ** 3) +
                        self.kappa2 * (self.state.cpu_frequency ** 2) * utilization +
                        self.static_power)
        
        total_energy = dynamic_power * processing_time
        
        # é‡å­˜æŸŠé”ç†»â‚¬æ¥ƒå§¸é¬?
        self.state.current_power = dynamic_power
        
        return total_energy

    def generate_tasks(self, current_time_slot: int) -> List[Task]:
        """
        ç”Ÿæˆæ–°ä»»åŠ¡ - æŒ‰æ³Šæ¾è¿‡ç¨‹åˆ°è¾¾
        å¯¹åº”è®ºæ–‡ç¬¬2.1èŠ‚ä»»åŠ¡æ¨¡å‹
        """
        # æŒ‰æ³Šæ¾è¿‡ç¨‹ç”Ÿæˆä»»åŠ¡æ•°é‡
        num_tasks = generate_poisson_arrivals(
            self.task_generation_rate, 
            config.network.time_slot_duration
        )
        
        new_tasks = []
        for _ in range(num_tasks):
            task = self._create_random_task()
            new_tasks.append(task)
            self.generated_tasks.append(task)
        
        return new_tasks
    
    def _create_random_task(self) -> Task:
        """
        åˆ›å»ºéšæœºä»»åŠ¡ - ä¼˜åŒ–ç‰ˆ
        
        ã€åŠŸèƒ½ã€‘åŸºäºåœºæ™¯ç”ŸæˆçœŸå®ä»»åŠ¡ï¼Œæ”¯æŒï¼š
        1. åœºæ™¯åŒ–ä»»åŠ¡ç”Ÿæˆï¼ˆ8ç§åº”ç”¨åœºæ™¯ï¼‰
        2. é‡å°¾æ•°æ®å¤§å°åˆ†å¸ƒï¼ˆå¸•ç´¯æ‰˜åˆ†å¸ƒï¼‰
        3. Zipfå†…å®¹çƒ­åº¦åˆ†å¸ƒï¼ˆåä½œç¼“å­˜ï¼‰
        4. åˆç†çš„å±æ€§ç»„åˆï¼ˆé¿å…ä¸å¯èƒ½å®Œæˆçš„ä»»åŠ¡ï¼‰
        
        ã€æ”¹è¿›è¯´æ˜ã€‘
        - âœ… åŸºäºåœºæ™¯æŠ½æ ·ï¼šæŒ‰æƒé‡é€‰æ‹©åº”ç”¨åœºæ™¯
        - âœ… é‡å°¾åˆ†å¸ƒï¼šæ•°æ®å¤§å°ç¬¦åˆå¸•ç´¯æ‰˜åˆ†å¸ƒï¼ˆå¤§é‡å°ä»»åŠ¡+å°‘é‡å¤§ä»»åŠ¡ï¼‰
        - âœ… Zipfçƒ­åº¦ï¼šå†…å®¹è®¿é—®ç¬¦åˆZipfåˆ†å¸ƒï¼ˆå°‘æ•°çƒ­é—¨+å¤§é‡å†·é—¨ï¼‰
        - âœ… å±æ€§åˆç†ï¼šç´§æ€¥ä»»åŠ¡å°æ•°æ®+çŸ­æœŸé™ï¼Œå®¹å¿ä»»åŠ¡å¤§æ•°æ®+é•¿æœŸé™
        
        ã€è®ºæ–‡å¯¹åº”ã€‘
        - åœºæ™¯å®šä¹‰ï¼šSection 2.1 "Task Model"
        - Zipfåˆ†å¸ƒï¼šSection 2.7 "Collaborative Caching"
        - é‡å°¾åˆ†å¸ƒï¼šçœŸå®ä»»åŠ¡æµé‡ç‰¹å¾
        """
        # ========== æ­¥éª¤1ï¼šåŸºäºæƒé‡é€‰æ‹©åº”ç”¨åœºæ™¯ ==========
        scenario = config.task.sample_scenario()
        scenario_name = scenario.name
        task_type_value = scenario.task_type
        
        # ========== æ­¥éª¤2ï¼šè·å–åœºæ™¯è§„æ ¼å’Œå‚æ•° ==========
        profile = config.task.get_profile(task_type_value)
        data_range = profile.data_range
        compute_density = profile.compute_density
        
        # ========== æ­¥éª¤3ï¼šç”Ÿæˆæ•°æ®å¤§å°ï¼ˆé‡å°¾åˆ†å¸ƒï¼‰ ==========
        # ä½¿ç”¨å¸•ç´¯æ‰˜åˆ†å¸ƒæ¨¡æ‹ŸçœŸå®ä»»åŠ¡å¤§å°åˆ†å¸ƒ
        # shape=1.5: æ¸©å’Œçš„é‡å°¾ï¼ˆçº¦70%å°ä»»åŠ¡ï¼Œ30%ä¸­å¤§ä»»åŠ¡ï¼‰
        data_size = sample_heavy_tailed_task_size(
            min_size=data_range[0],
            max_size=data_range[1],
            shape=1.5  # å¸•ç´¯æ‰˜å½¢çŠ¶å‚æ•°
        )
        
        # ========== æ­¥éª¤4ï¼šè®¡ç®—ä»»åŠ¡è®¡ç®—é‡ ==========
        # è®¡ç®—å¯†åº¦éšåœºæ™¯ç±»å‹å˜åŒ–
        # ç±»å‹1ï¼ˆç´§æ€¥ï¼‰ï¼šä½è®¡ç®—å¯†åº¦ï¼ˆ60 cycles/bitï¼‰
        # ç±»å‹4ï¼ˆåˆ†æï¼‰ï¼šé«˜è®¡ç®—å¯†åº¦ï¼ˆ150 cycles/bitï¼‰
        compute_cycles = data_size * 8 * compute_density  # å­—èŠ‚è½¬æ¯”ç‰¹
        result_size = data_size * config.task.task_output_ratio
        
        # ========== æ­¥éª¤5ï¼šç¡®å®šæˆªæ­¢æ—¶é—´ ==========
        # åŸºäºåœºæ™¯è§„æ ¼çš„æˆªæ­¢æ—¶é—´èŒƒå›´
        deadline_seconds = np.random.uniform(
            scenario.min_deadline,
            scenario.max_deadline
        )
        
        # è½¬æ¢ä¸ºæ—¶éš™æ•°
        time_slot_duration = config.network.time_slot_duration
        max_delay_slots = max(1, int(deadline_seconds / time_slot_duration))
        
        # ========== æ­¥éª¤6ï¼šåŠ¨æ€è°ƒæ•´ä»»åŠ¡åˆ†ç±» ==========
        # è€ƒè™‘æ•°æ®å¤§å°ã€è®¡ç®—é‡ã€ç³»ç»Ÿè´Ÿè½½ç­‰å¤šç»´ç‰¹å¾
        system_load = self.state.load_factor if hasattr(self, 'state') else None
        
        # ğŸ”§ ä¿®å¤ï¼šæ‰©å¤§å¯ç¼“å­˜ä»»åŠ¡èŒƒèŒƒå›´ä»¥æå‡ç¼“å­˜å‘½ä¸­ç‡
        # åˆ¤æ–­ä»»åŠ¡æ˜¯å¦å¯ç¼“å­˜ - åŸºäºVECåº”ç”¨å®é™…æƒ…å†µ
        # ç±»å‹1ï¼ˆç´§æ€¥ï¼‰: 50%å¯ç¼“å­˜ï¼ˆå®‰å…¨è­¦æŠ¥ã€ç´§æ€¥é€šçŸ¥ç­‰åŒºåŸŸç›¸å…³ä¿¡æ¯ï¼‰
        # ç±»å‹2ï¼ˆå¯¼èˆªï¼‰: 80%å¯ç¼“å­˜ï¼ˆåœ°å›¾ã€POIã€è·¯çº¿ä¿¡æ¯ï¼‰
        # ç±»å‹3ï¼ˆè§†é¢‘ï¼‰: 90%å¯ç¼“å­˜ï¼ˆæµåª’ä½“ã€å¨±ä¹å†…å®¹ï¼‰
        # ç±»å‹4ï¼ˆåˆ†æï¼‰: 85%å¯ç¼“å­˜ï¼ˆæ•°æ®åˆ†æç»“æœã€è®¡ç®—ç»“æœï¼‰
        cacheable_probs = {
            1: 0.50,  # ç´§æ€¥ä»»åŠ¡ï¼šéƒ¨åˆ†å¯ç¼“å­˜
            2: 0.80,  # å¯¼èˆªä»»åŠ¡ï¼šé«˜åº¦å¯ç¼“å­˜
            3: 0.90,  # è§†é¢‘ä»»åŠ¡ï¼šæœ€å¯ç¼“å­˜
            4: 0.85   # åˆ†æä»»åŠ¡ï¼šé«˜åº¦å¯ç¼“å­˜
        }
        is_cacheable = np.random.random() < cacheable_probs.get(task_type_value, 0.5)
        
        task_type_adjusted = config.task.get_task_type(
            max_delay_slots=max_delay_slots,
            data_size=data_size,
            compute_cycles=compute_cycles,
            compute_density=compute_density,
            time_slot=time_slot_duration,
            system_load=system_load,
            is_cacheable=is_cacheable
        )
        task_type = TaskType(task_type_adjusted)
        
        # ========== æ­¥éª¤7ï¼šåˆ†é…ä¼˜å…ˆçº§ ==========
        # ä¼˜å…ˆçº§ä¸ä»»åŠ¡ç±»å‹ç›¸å…³ (ç±»å‹å€¼å°çš„ä¼˜å…ˆçº§é«˜)
        # ç±»å‹1ï¼šä¼˜å…ˆçº§1-2ï¼ˆæœ€é«˜ï¼‰
        # ç±»å‹2ï¼šä¼˜å…ˆçº§2-3
        # ç±»å‹3ï¼šä¼˜å…ˆçº§3-4
        # ç±»å‹4ï¼šä¼˜å…ˆçº§4ï¼ˆæœ€ä½ï¼‰
        priority = task_type_adjusted + np.random.randint(0, 2)
        priority = min(priority, config.task.num_priority_levels)
        
        # ========== æ­¥éª¤8ï¼šç”Ÿæˆå†…å®¹IDï¼ˆZipfåˆ†å¸ƒï¼‰ ==========
        content_id = None
        if is_cacheable:
            # å¯ç¼“å­˜ä»»åŠ¡ï¼šæŒ‰Zipfåˆ†å¸ƒé€‰æ‹©å†…å®¹
            # å†…å®¹åº“å¤§å°1000ï¼ŒZipfæŒ‡æ•°0.8
            content_id = sample_zipf_content_id(num_contents=1000, exponent=0.8)
        
        # ========== æ­¥éª¤9ï¼šåˆ›å»ºä»»åŠ¡å¯¹è±¡ ==========
        task = Task(
            data_size=data_size,
            compute_cycles=compute_cycles,
            result_size=result_size,
            max_delay_slots=max_delay_slots,
            task_type=task_type,
            priority=priority,
            source_vehicle_id=self.node_id,
            content_id=content_id,
            is_cacheable=is_cacheable,
            scenario_name=scenario_name
        )
        
        return task
    
    def update_position(self, time_step: float):
        """
        æ›´æ–°è½¦è¾†ä½ç½®
        ç®€å•çš„ç§»åŠ¨æ¨¡å‹ï¼šåŒ€é€Ÿç›´çº¿è¿åŠ¨ï¼Œåˆ°è¾¹ç•Œæ—¶è½¬å‘
        """
        # æ›´æ–°ä½ç½®
        new_x = self.state.position.x + self.velocity[0] * time_step
        new_y = self.state.position.y + self.velocity[1] * time_step
        
        # è¾¹ç•Œæ£€æŸ¥å’Œè½¬å‘
        area_width = config.network.area_width
        area_height = config.network.area_height
        
        if new_x <= 0 or new_x >= area_width:
            self.velocity[0] = -self.velocity[0]
            new_x = max(0, min(area_width, new_x))
        
        if new_y <= 0 or new_y >= area_height:
            self.velocity[1] = -self.velocity[1]
            new_y = max(0, min(area_height, new_y))
        
        # æ›´æ–°ä½ç½®
        self.state.position.x = new_x
        self.state.position.y = new_y
        
        # è®°å½•è½¨è¿¹
        self.trajectory.append(Position(new_x, new_y, 0))
        
        # é™åˆ¶è½¨è¿¹å†å²é•¿åº¦
        if len(self.trajectory) > 100:
            self.trajectory.pop(0)
    
    def set_random_velocity(self):
        """è®¾ç½®éšæœºé€Ÿåº¦"""
        # éšæœºæ–¹å‘
        angle = np.random.uniform(0, 2 * math.pi)
        # éšæœºé€Ÿåº¦å¤§å° (30-60 m/sï¼Œé«˜é€Ÿå…¬è·¯åœºæ™¯)
        speed = np.random.uniform(30.0, self.max_speed)
        
        self.velocity[0] = speed * math.cos(angle)
        self.velocity[1] = speed * math.sin(angle)
    
    def step(self, time_step: float) -> Tuple[List[Task], List[Task]]:
        """
        è½¦è¾†èŠ‚ç‚¹å•æ­¥æ›´æ–°
        
        Returns:
            (æ–°ç”Ÿæˆçš„ä»»åŠ¡åˆ—è¡¨, æœ¬åœ°å¤„ç†å®Œæˆçš„ä»»åŠ¡åˆ—è¡¨)
        """
        # 1. æ›´æ–°ä½ç½®
        self.update_position(time_step)
        
        # 2. æ›´æ–°é˜Ÿåˆ—ç”Ÿå‘½å‘¨æœŸ
        self.update_queue_lifetimes()
        
        # 3. ç”Ÿæˆæ–°ä»»åŠ¡
        current_slot = int(time.time() / config.network.time_slot_duration)
        new_tasks = self.generate_tasks(current_slot)
        
        # 4. å¤„ç†æœ¬åœ°é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        processed_tasks = []
        
        # è·å–æœ¬æ—¶éš™å¯å¤„ç†çš„æ•°æ®é‡
        processing_capacity = self.get_processing_capacity()
        remaining_capacity = processing_capacity
        
        # æ³¨æ„ï¼šæ–°ç”Ÿæˆçš„ä»»åŠ¡ä¸åœ¨è¿™é‡Œç›´æ¥å¤„ç†
        # å®ƒä»¬å°†è¢«é€åˆ°å¸è½½å†³ç­–å™¨è¿›è¡Œå†³ç­–
        
        # å¤„ç†é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        while remaining_capacity > 0:
            next_task = self.get_next_task_to_process()
            if next_task is None:
                break
            
            if next_task.data_size <= remaining_capacity:
                if self.process_task(next_task):
                    processed_tasks.append(next_task)
                    remaining_capacity -= next_task.data_size
                else:
                    break
            else:
                # ä»»åŠ¡å¤ªå¤§ï¼Œæ— æ³•åœ¨æœ¬æ—¶éš™å®Œæˆ
                break
        
        # 5. é‡å­˜æŸŠç¼ç†»î…¸æ·‡â„ƒä¼…
        self._update_statistics()
        
        # 6. éºæ—æ«ç»Œæ´ªæ£¿éƒå •æ£¿éå‘®å¢é—‡â‚¬é¨å‹«â‚¬å¥¸å™º
        self._apply_idle_energy(time_step, processed_tasks)
        
        return new_tasks, processed_tasks
    
    def _apply_idle_energy(self, time_step: float, processed_tasks: List[Task]) -> None:
        """ç¼ç†»î…¸å§£å¿›æ®­éšåº¤î—é™æˆ£æ£é¨å‹«â‚¬å¥¸å™ºé”›å±¼è´Ÿé—ˆæ¬“å™·é—‚æ’®æ½¤é¸?"""
        total_processing_time = sum(getattr(task, 'processing_delay', 0.0) for task in processed_tasks)
        idle_time = max(0.0, time_step - total_processing_time)
        if idle_time <= 0 or self.idle_power <= 0:
            return
        idle_energy = self.idle_power * idle_time
        self._record_energy_usage(idle_energy)

    def can_process_immediately(self, task: Task) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦èƒ½ç«‹å³æœ¬åœ°å¤„ç†ä»»åŠ¡
        
        Args:
            task: è¦æ£€æŸ¥çš„ä»»åŠ¡
            
        Returns:
            bool: æ˜¯å¦èƒ½ç«‹å³å¤„ç†
        """
        # æ£€æŸ¥CPUèµ„æºæ˜¯å¦è¶³å¤Ÿ
        processing_capacity = self.get_processing_capacity()
        
        # æ£€æŸ¥å½“å‰è´Ÿè½½
        current_load = self.state.load_factor
        
        # å¦‚æœå½“å‰è´Ÿè½½è¿‡é«˜ï¼Œæ— æ³•ç«‹å³å¤„ç†
        if current_load > 0.9:
            return False
        
        # æ£€æŸ¥ä»»åŠ¡å¤§å°æ˜¯å¦åœ¨å¤„ç†èƒ½åŠ›èŒƒå›´å†…
        if task.data_size > processing_capacity:
            return False
        
        return True
    
    def process_task_immediately(self, task: Task) -> Tuple[bool, float]:
        """
        ç«‹å³å¤„ç†ä»»åŠ¡
        
        Args:
            task: è¦å¤„ç†çš„ä»»åŠ¡
            
        Returns:
            Tuple[bool, float]: (æ˜¯å¦æˆåŠŸ, å¤„ç†å»¶è¿Ÿ)
        """
        if not self.can_process_immediately(task):
            return False, 0.0
        
        # è®¡ç®—å¤„ç†å»¶è¿Ÿ
        processing_delay = self.calculate_processing_delay(task)
        
        # æ£€æŸ¥æ˜¯å¦æ»¡è¶³å»¶è¿Ÿè¦æ±‚
        max_allowed_delay = task.max_delay_slots * config.network.time_slot_duration
        if processing_delay > max_allowed_delay:
            return False, 0.0
        
        # æ›´æ–°è´Ÿè½½çŠ¶æ€
        time_slot_duration = config.network.time_slot_duration
        load_increase = processing_delay / time_slot_duration
        self.state.load_factor = min(1.0, self.state.load_factor + load_increase)
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯ - ä½¿ç”¨åŸºç±»çš„ç»Ÿè®¡æ–¹æ³•
        if hasattr(self, 'statistics'):
            self.statistics['processed_tasks'] = self.statistics.get('processed_tasks', 0) + 1

        

        return True, processing_delay

