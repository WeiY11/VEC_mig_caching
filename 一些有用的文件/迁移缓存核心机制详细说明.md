# VEC ç³»ç»Ÿæ ¸å¿ƒæœºåˆ¶è¯¦ç»†è¯´æ˜

## ç›®å½•

1. [è¿ç§»æœºåˆ¶è¯¦è§£](#1-è¿ç§»æœºåˆ¶è¯¦è§£)
2. [ç¼“å­˜æœºåˆ¶è¯¦è§£](#2-ç¼“å­˜æœºåˆ¶è¯¦è§£)
3. [é˜Ÿåˆ—æœºåˆ¶è¯¦è§£](#3-é˜Ÿåˆ—æœºåˆ¶è¯¦è§£)

---

## 1. è¿ç§»æœºåˆ¶è¯¦è§£

### 1.1 è¿ç§»è§¦å‘ç®—æ³•

**ç®—æ³•æµç¨‹**ï¼š

```
æ¯ä¸ªæ—¶éš™æ‰§è¡Œ check_migration_needs():
â”œâ”€ éå†æ‰€æœ‰èŠ‚ç‚¹
â”‚  â”œâ”€ æ£€æŸ¥å†·å´æœŸ (cooldown_period=60s)
â”‚  â”œâ”€ RSUèŠ‚ç‚¹:
â”‚  â”‚  â”œâ”€ ç»¼åˆè¯„ä¼°: _evaluate_rsu_migration_need()
â”‚  â”‚  â”‚  â”œâ”€ è´Ÿè½½è¶…é˜ˆå€¼? load_factor > threshold
â”‚  â”‚  â”‚  â”œâ”€ è®¡ç®—è¶…è½½ç¨‹åº¦: (load - threshold) / (1 - threshold)
â”‚  â”‚  â”‚  â””â”€ é˜Ÿåˆ—è¿‡é•¿? queue_length > 15 â†’ urgency *= 1.2
â”‚  â”‚  â””â”€ ç´§æ€¥åº¦è¿‡æ»¤: urgency_score > 1.2 æ‰è§¦å‘
â”‚  â””â”€ UAVèŠ‚ç‚¹:
â”‚     â””â”€ ç”µé‡æˆ–è´Ÿè½½: battery < 20% OR load > threshold
â”œâ”€ è‡ªé€‚åº”é˜ˆå€¼è°ƒæ•´ (æ¯50æ¬¡è¿ç§»):
â”‚  â”œâ”€ æˆåŠŸç‡ > 85% â†’ threshold -= 0.02 (æ›´æ¿€è¿›)
â”‚  â””â”€ æˆåŠŸç‡ < 65% â†’ threshold += 0.02 (æ›´ä¿å®ˆ)
â””â”€ æ‰¹é‡ä¼˜åŒ–: åˆå¹¶åŒæºåŒç›®æ ‡è®¡åˆ’
```

**ä¼ªä»£ç **ï¼š

```python
function check_migration_needs(node_states, positions):
    plans = []

    for node_id, state in node_states:
        # å†·å´æœŸæ£€æŸ¥
        if current_time - last_migration[node_id] < cooldown:
            continue

        # RSUè¿ç§»åˆ¤å®š
        if node_id.startswith("rsu_"):
            should_migrate, urgency = evaluate_rsu_need(state)
            if should_migrate and urgency > 1.2:
                target = find_best_target(node_id, node_states, positions)
                if target:
                    plan = create_migration_plan(node_id, target)
                    plan.urgency_score = urgency
                    plans.append(plan)

        # UAVè¿ç§»åˆ¤å®š
        elif node_id.startswith("uav_"):
            if state.battery < uav_min_battery or state.load > threshold:
                target = find_best_target(node_id, node_states, positions)
                if target:
                    plans.append(create_migration_plan(node_id, target))

    # æ‰¹é‡ä¼˜åŒ–
    plans = batch_optimize(plans)

    # æŒ‰ç´§æ€¥åº¦æ’åº
    return sort(plans, key=urgency_score, reverse=True)
```

### 1.2 ç›®æ ‡é€‰æ‹© - è½»é‡æ³¨æ„åŠ›æœºåˆ¶

**6 ç»´ç‰¹å¾è¯„åˆ†**ï¼š

```python
function score_target_node(target_id, source_id, positions, states):
    # 1. è´Ÿè½½è¯„åˆ† (è¶Šç©ºé—²è¶Šå¥½)
    load_score = 1.0 - min(1.0, target.load_factor)

    # 2. è·ç¦»è¯„åˆ† (è¶Šè¿‘è¶Šå¥½)
    distance = positions[source].distance_to(positions[target])
    distance_score = 1.0 / (1.0 + distance/1000)

    # 3. é˜Ÿåˆ—è¯„åˆ† (é˜Ÿåˆ—è¶ŠçŸ­è¶Šå¥½)
    queue_score = 1.0 - min(1.0, target.queue_length / capacity)

    # 4. å¸¦å®½è¯„åˆ† (å¸¦å®½è¶Šç©ºé—²è¶Šå¥½)
    bandwidth_score = 1.0 - target.bandwidth_util

    # 5. ğŸ†• ç¼“è§£æ”¶ç›Š (è´Ÿè½½å·®è¶Šå¤§è¶Šå¥½)
    relief_score = max(0, source.load - target.load)

    # 6. ğŸ†• å†å²å¯é æ€§
    reliability_score = migration_success_rate + 0.05

    # è½»é‡æ³¨æ„åŠ›èåˆ
    features = [load_score, queue_score, distance_score,
                relief_score, reliability_score, bandwidth_score]
    weights = [1.0, 1.0, 0.8, 1.5, 1.2, 0.6]  # åå‘æ”¶ç›Šå’Œå¯é æ€§

    # Softmaxå½’ä¸€åŒ–
    logits = features * weights
    attention = softmax(logits)

    # èåˆå¾—åˆ†
    attention_score = dot(attention, features)
    legacy_score = 0.4*load + 0.3*distance + 0.2*queue + 0.1*bandwidth

    return 0.55*attention_score + 0.45*legacy_score
```

### 1.3 æˆåŠŸç‡è®¡ç®— - å¤šå› ç´ æ¨¡å‹

**æ•°å­¦å…¬å¼**ï¼š

```
P_success = P_base - P_distance - P_source + B_target - P_network

å…¶ä¸­:
P_base = 0.9                              # åŸºç¡€æˆåŠŸç‡
P_distance = min(0.3, d/10000)            # è·ç¦»æƒ©ç½š
P_source = max(0, (Ï_s - 0.8) Ã— 0.5)      # æºè¿‡è½½æƒ©ç½š
B_target = (1 - Ï_t) Ã— 0.1                # ç›®æ ‡ç©ºé—²å¥–åŠ±
P_network = BW_util Ã— 0.1                 # ç½‘ç»œæ‹¥å¡æƒ©ç½š

æœ€ç»ˆ: P_success âˆˆ [0.4, 0.95]
```

### 1.4 Keep-Before-Break æ‰§è¡Œ

**ä¸‰é˜¶æ®µæ—¶é—´åˆ†é…**ï¼š

```
è¿ç§»ç±»å‹          å‡†å¤‡    åŒæ­¥    é™é»˜åˆ‡æ¢
RSU â†’ RSU        50%     40%     10%      (æœ‰çº¿ï¼Œdowntimeæœ€çŸ­)
RSU â†’ UAV        60%     35%     5%       (æ— çº¿ï¼ŒåŒæ­¥æ—¶é—´é•¿)
UAV â†’ RSU        55%     35%     10%      (å¹³è¡¡)
æŠ¢å å¼           70%     25%     5%       (å‡†å¤‡æ—¶é—´é•¿)
```

**æ‰§è¡Œæµç¨‹**ï¼š

```python
function execute_migration(plan, node_states, system_nodes):
    # 1. è‡ªé€‚åº”é˜¶æ®µåˆ’åˆ†
    prep_ratio, sync_ratio, down_ratio = adaptive_kbb_phases(plan.type)

    preparation_time = plan.delay * prep_ratio
    sync_time = plan.delay * sync_ratio
    downtime = plan.delay * down_ratio  # å®é™…æœåŠ¡ä¸­æ–­

    # 2. æˆåŠŸåˆ¤å®š
    if random() < plan.success_probability:
        # 3a. æˆåŠŸ: åº”ç”¨è¿ç§»æ•ˆæœ
        tasks = select_intelligent_tasks(source_queue, max_count)
        sync_cache_before_migration(source, target, tasks)
        move_tasks(source_queue â†’ target_queue, tasks)
        update_node_states()
        record_statistics()
    else:
        # 3b. å¤±è´¥: æŒ‡æ•°é€€é¿é‡è¯•
        schedule_retry(plan)  # 0.5s, 1s, 2s, 4s, 6s

    return success
```

### 1.5 æ™ºèƒ½ä»»åŠ¡é€‰æ‹©

**ç»¼åˆè¯„åˆ†æ¨¡å‹**ï¼š

```python
function select_intelligent_tasks(source_queue, max_count):
    scored_tasks = []

    for task in source_queue:
        # ç´§æ€¥åº¦ (å‰©ä½™æ—¶é—´è¶ŠçŸ­è¶Šç´§æ€¥)
        urgency = 1.0 / max(1, task.remaining_lifetime_slots)

        # ä¼˜å…ˆçº§æƒé‡ (priority=1æœ€é«˜)
        priority_weight = (5 - task.priority) / 4.0

        # å¤§å°æƒ©ç½š (MB)
        size_penalty = task.data_size / 1e6

        # ç»¼åˆè¯„åˆ†
        score = 0.5*urgency + 0.3*priority_weight - 0.2*size_penalty

        scored_tasks.append((task, score))

    # æŒ‰è¯„åˆ†æ’åºï¼Œå–top-K
    return topK(scored_tasks, max_count)
```

---

## 2. ç¼“å­˜æœºåˆ¶è¯¦è§£

### 2.1 ä¸‰ç»´çƒ­åº¦è®¡ç®—

**å…¬å¼ä½“ç³»**ï¼š

```
1. å†å²çƒ­åº¦ (æŒ‡æ•°ç§»åŠ¨å¹³å‡):
   H_hist(c) = Î± Â· H_hist_old(c) + w_access

   å…¶ä¸­:
   Î± = decay_factor âˆˆ [0.80, 0.92]  # è‡ªé€‚åº”è¡°å‡
   w_access = {1.0      # æ™®é€šè®¿é—®
              {1.5      # é«˜é¢‘è®¿é—® (é—´éš”<30s)

2. æ—¶é—´æ§½çƒ­åº¦:
   slot = âŒŠt / slot_durationâŒ‹ % total_slots
   H_slot(c, slot) += w_access

3. Zipfæµè¡Œåº¦:
   P_zipf(c) = 1 / rank^Î±,  Î±=0.8

4. ç»¼åˆçƒ­åº¦ (è®ºæ–‡å¼37):
   Heat(c) = Î· Â· H_hist(c) + (1-Î·) Â· H_slot(c,t)

   å…¶ä¸­: Î· = 0.6  (æ›´é‡è§†å†å²)
```

**è‡ªé€‚åº”è¡°å‡ç®—æ³•**ï¼š

```python
function update_heat(content_id, system_load):
    # æ ¹æ®ç³»ç»Ÿè´Ÿè½½è‡ªé€‚åº”è¡°å‡
    if system_load > 0.7:
        decay = 0.80  # é«˜è´Ÿè½½: æ¿€è¿›æ·˜æ±°
    else:
        decay = 0.92  # ä½è´Ÿè½½: ä¿å®ˆç¼“å­˜

    # è®¿é—®é—´éš”åŠ æƒ
    access_boost = 1.0
    if last_access_interval < 30.0:
        access_boost = 1.5  # é«˜é¢‘è®¿é—®boost

    # æ›´æ–°å†å²çƒ­åº¦
    H_hist[content_id] = decay * H_hist[content_id] + access_boost

    # æ›´æ–°æ§½çƒ­åº¦
    current_slot = int(time / slot_duration) % total_slots
    H_slot[content_id][current_slot] += 1.0
```

### 2.2 ç¼“å­˜ä¼˜å…ˆçº§å†³ç­–

**ç»¼åˆä¼˜å…ˆçº§å…¬å¼**ï¼š

```
Priority(c) = 0.5Â·Heat(c) + 0.2Â·Zipf(c) + 0.25Â·Recency(c) - 0.05Â·Size(c)

å…¶ä¸­:
Heat(c) = Î·Â·H_hist + (1-Î·)Â·H_slot       # ç»¼åˆçƒ­åº¦
Zipf(c) = 1/rank^0.8                     # Zipfæµè¡Œåº¦
Recency(c) = max(0, 1 - Î”t/600)         # æ–°é²œåº¦ (10åˆ†é’Ÿçª—å£)
Size(c) = log(1 + size_MB)              # å¤§å°æƒ©ç½š
```

### 2.3 å››ç±»ç¼“å­˜åŠ¨ä½œ

```python
function request_content(content_id, data_size):
    # æ›´æ–°çƒ­åº¦
    update_heat(content_id)

    # åŠ¨ä½œ0: æœ¬åœ°å‘½ä¸­
    if content_id in cache:
        update_access_count()
        return "cache_hit"

    # åŠ¨ä½œ1: é‚»å±…åä½œ
    if check_neighbor(content_id):
        cost = evaluate_collaboration_cost()
        if cost < local_cost * 1.2:
            return "neighbor_hit"

    # åŠ¨ä½œ2-4: å†³å®šç¼“å­˜ç­–ç•¥
    heat = calculate_combined_heat(content_id)
    available = capacity - current_usage

    # é«˜çƒ­åº¦ç›´æ¥ç¼“å­˜ (heat > 0.7)
    if heat > 0.7 and available > capacity*0.05:
        add_to_cache(content_id, data_size)
        return "cache_and_store"

    # ä¸­ç­‰çƒ­åº¦é¢„å– (0.4 < heat â‰¤ 0.7)
    elif 0.4 < heat <= 0.7:
        prefetch_content(content_id, data_size)
        return "prefetch"

    # å®¹é‡ä¸è¶³èƒŒåŒ…æ›¿æ¢
    elif available <= 0:
        knapsack_replacement(content_id, data_size)
        return "knapsack_replace"

    # ä¸ç¼“å­˜
    else:
        return "no_cache"
```

### 2.4 æ··åˆæ›¿æ¢ç­–ç•¥ - è‡ªé€‚åº”æƒé‡

**æƒé‡è°ƒæ•´è§„åˆ™**ï¼š

```python
function adaptive_hybrid_weights():
    usage_ratio = current_usage / capacity
    hit_rate = cache_hits / total_requests

    # é»˜è®¤æƒé‡
    weights = {recency: 0.4, frequency: 0.3, value: 0.3}

    # è§„åˆ™1: é«˜ä½¿ç”¨ç‡ (>80%) â†’ ä¿ç•™é«˜é¢‘å†…å®¹
    if usage_ratio > 0.8:
        weights = {recency: 0.3, frequency: 0.4, value: 0.3}

    # è§„åˆ™2: ä½å‘½ä¸­ç‡ (<60%) â†’ ä¼˜åŒ–çƒ­åº¦é€‰æ‹©
    if hit_rate < 0.6:
        weights = {recency: 0.35, frequency: 0.25, value: 0.4}

    # è§„åˆ™3: é«˜å‘½ä¸­ç‡ (>85%) â†’ åŠ å¿«æ›´æ–°
    if hit_rate > 0.85:
        weights = {recency: 0.5, frequency: 0.25, value: 0.25}

    return weights
```

**æ·˜æ±°è¯„åˆ†è®¡ç®—**ï¼š

```python
function hybrid_eviction(required_space):
    weights = adaptive_hybrid_weights()

    for item in cached_items:
        # ä¸‰ç»´è¯„åˆ† (åˆ†æ•°è¶Šé«˜è¶Šå®¹æ˜“è¢«æ›¿æ¢)
        recency_score = (current_time - item.last_access) / 600
        frequency_score = 1.0 / max(1, item.access_count)
        value_score = 1.0 / max(0.1, item.cache_value)

        total_score = (weights.recency * recency_score +
                      weights.frequency * frequency_score +
                      weights.value * value_score)

        scored_items.append((total_score, item))

    # æŒ‰åˆ†æ•°æ’åºï¼Œæ·˜æ±°é«˜åˆ†é¡¹
    sorted_items = sort(scored_items, reverse=True)

    # æ‰¹é‡æ·˜æ±° (é‡Šæ”¾120%ç©ºé—´)
    target_space = required_space * 1.2
    evict_until(sorted_items, target_space)
```

### 2.5 é¢„æµ‹å¼ç¼“å­˜

**å¢é•¿ç‡é¢„æµ‹ç®—æ³•**ï¼š

```python
function predictive_caching():
    predictions = []

    for content_id in access_history:
        times = access_history[content_id]

        # éœ€è¦è‡³å°‘3æ¬¡è®¿é—®
        if len(times) < 3:
            continue

        # è®¡ç®—è®¿é—®å¢é•¿ç‡
        recent = count([t for t in times if current - t < 60])   # æœ€è¿‘1åˆ†é’Ÿ
        older = count([t for t in times if 60 <= current - t < 120])  # 1-2åˆ†é’Ÿå‰

        if older > 0:
            growth_rate = recent / older

            # å¢é•¿è¶…è¿‡50%è§¦å‘é¢„æµ‹
            if growth_rate > 1.5:
                predicted_requests = recent * growth_rate
                predictions.append((content_id, predicted_requests))

    # è¿”å›é¢„æµ‹éœ€æ±‚æœ€é«˜çš„å‰Nä¸ª
    return topN(predictions, prediction_horizon)
```

---

## 3. é˜Ÿåˆ—æœºåˆ¶è¯¦è§£

### 3.1 M/M/1 ä¼˜å…ˆçº§é˜Ÿåˆ—æ¨¡å‹

**ç­‰å¾…æ—¶é—´é¢„æµ‹å…¬å¼** (è®ºæ–‡å¼ 2):

```
å¯¹äºä¼˜å…ˆçº§pçš„ä»»åŠ¡:

         1      Î£(i=1â†’p) Ï_i
W_p = â”€â”€â”€ Ã— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         Î¼     [1-Î£(i=1â†’p-1)Ï_i][1-Î£(i=1â†’p)Ï_i]

å…¶ä¸­:
Î¼ = service_rate (æœåŠ¡ç‡)
Ï_i = Î»_i / Î¼ (ä¼˜å…ˆçº§içš„è´Ÿè½½å› å­)
Î»_i = arrival_rate_i (ä¼˜å…ˆçº§içš„åˆ°è¾¾ç‡)
```

**åˆ›æ–°ä¼˜åŒ– - è´Ÿè½½è¶‹åŠ¿é¢„æµ‹**ï¼š

```python
function predict_waiting_time_mm1(task):
    priority = task.priority

    # ç¨³å®šæ€§æ£€æŸ¥
    total_rho = sum(load_factors.values())
    if total_rho >= 0.95:
        return inf  # ç³»ç»Ÿä¸ç¨³å®š

    # ğŸ†• çŸ­æœŸè´Ÿè½½è¶‹åŠ¿é¢„æµ‹
    trend_multiplier = 1.0
    if len(recent_arrivals) >= 3:
        recent_rhos = [arrivals / service_rate for arrivals in recent_arrivals[-3:]]
        trend = recent_rhos[-1] - recent_rhos[0]

        if trend > 0.05:    # ä¸Šå‡è¶‹åŠ¿
            trend_multiplier = 1.2
        elif trend < -0.05:  # ä¸‹é™è¶‹åŠ¿
            trend_multiplier = 0.9

    # M/M/1å…¬å¼è®¡ç®—
    numerator = sum(load_factors[i] for i in 1..priority)
    denom1 = 1 - sum(load_factors[i] for i in 1..priority-1)
    denom2 = 1 - sum(load_factors[i] for i in 1..priority)

    base_waiting = (1/service_rate) * numerator / (denom1 * denom2)

    # ğŸ†• åº”ç”¨è¶‹åŠ¿ä¿®æ­£
    waiting_time = base_waiting * trend_multiplier

    # ğŸ†• é˜Ÿåˆ—æ‹¥å¡ä¿®æ­£
    current_length = count_tasks_with_priority(priority)
    expected_length = load_factors[priority] / (1 - total_rho)

    if current_length > expected_length * 1.3:  # è¶…å‡ºé¢„æœŸ30%
        congestion = min(1.5, current_length / expected_length)
        waiting_time *= congestion

    return min(waiting_time, 100.0)  # ä¸Šé™100ç§’
```

### 3.2 åŠ¨æ€ä¼˜å…ˆçº§è€åŒ–

**é˜²æ­¢ä»»åŠ¡é¥¥é¥¿**ï¼š

```python
function get_next_task():
    AGING_FACTOR = 5.0  # æ¯0.1ç§’ç­‰å¾…ï¼Œä¼˜å…ˆçº§é™ä½0.5

    best_task = None
    best_effective_priority = inf

    for priority in 1..num_priorities:
        for lifetime in 1..max_lifetime:
            queue = queues[(lifetime, priority)]
            if not queue.is_empty():
                task = queue.task_list[0]

                # è®¡ç®—æœ‰æ•ˆä¼˜å…ˆçº§ (æ•°å€¼è¶Šå°è¶Šä¼˜å…ˆ)
                effective_priority = priority - (waiting_time * AGING_FACTOR)

                # å³å°†è¿‡æœŸä¿®æ­£
                if task.remaining_lifetime <= 1:
                    effective_priority -= 2.0

                if effective_priority < best_effective_priority:
                    best_effective_priority = effective_priority
                    best_task = task

    return best_task
```

### 3.3 é˜Ÿåˆ—æº¢å‡ºå¤„ç†

**æ™ºèƒ½ä¸¢å¼ƒç­–ç•¥**ï¼š

```python
function handle_queue_overflow(new_task):
    freed_space = 0

    # ä»æœ€ä½ä¼˜å…ˆçº§å¼€å§‹ä¸¢å¼ƒ
    for priority in num_priorities..1 (é™åº):
        if freed_space >= new_task.data_size:
            break

        for lifetime in max_lifetime..1 (é™åº):
            queue = queues[(lifetime, priority)]

            while not queue.is_empty() and freed_space < required:
                task = queue.pop_last()
                freed_space += task.data_size
                task.is_dropped = True
                statistics.total_drops += 1

    if freed_space >= new_task.data_size:
        add_task(new_task)  # é‡æ–°å°è¯•æ·»åŠ 
    else:
        drop(new_task)  # æ— æ³•è…¾å‡ºç©ºé—´
```

---

## é™„å½•: å…³é”®å‚æ•°é…ç½®

```python
# è¿ç§»å‚æ•°
rsu_overload_threshold = 0.80      # åŠ¨æ€è°ƒæ•´ [0.70, 0.90]
uav_min_battery = 0.20
cooldown_period = 60.0             # ç§’
retry_backoff = [0.5, 1, 2, 4, 6]  # æŒ‡æ•°é€€é¿

# ç¼“å­˜å‚æ•°
decay_factor = [0.80, 0.92]        # è‡ªé€‚åº”
heat_mix_factor = 0.6
zipf_exponent = 0.8
prediction_threshold = 1.5         # å¢é•¿ç‡>50%

# é˜Ÿåˆ—å‚æ•°
max_lifetime = 10                  # æ—¶éš™
num_priorities = 4
max_load_factor = 0.95
aging_factor = 5.0
```
