---
alwaysApply: true
---

# 🚀 VEC边缘计算迁移与缓存系统 - AI助手智能规则

## 🎯 项目核心（快速理解）

**这是什么项目？**
- 车联网边缘计算(VEC)系统：研究任务迁移与缓存优化
- 使用深度强化学习(DRL)：TD3、DDPG、SAC、PPO等
- 学术研究项目：目标发表于INFOCOM、MobiCom、TMC等顶级会议/期刊

**优化目标（务必记住！）**
```
核心目标函数: minimize  ω_T·时延 + ω_E·能耗
核心奖励函数: Reward = -(ω_T·时延 + ω_E·能耗)

完整奖励 = 核心奖励 - 0.02·dropped_tasks（轻微惩罚，保证完成率）
```
- ✅ **主目标** (权重大): 时延(2.0) + 能耗(1.2)
- ✅ **辅助约束** (权重小): dropped_tasks (0.02) - 仅保证完成率
- ❌ **已移除**: 数据丢失量（data_loss_bytes）- 是时延的衍生指标
- ⚠️ **注意**: 缓存率、迁移成功率是**手段**，不是优化目标！

**关键区别**：
- 优化目标 = 时延 + 能耗（权重 2.0 + 1.2 = 3.2）
- 约束条件 = dropped_tasks（权重仅 0.02，用于保证基本完成率）

---

## 🧠 AI助手智能模式

### 🎨 Vibe Coding优化

#### 1️⃣ **理解意图，主动行动**
- 用户说"改进奖励函数" → 自动分析现有奖励、提出改进、实现并测试
- 用户说"优化性能" → 自动识别瓶颈、提出方案、实现优化
- 用户说"加注释" → 添加详细的学术规范注释
- 我不让你写报告你就少写你的报告，浪费时间，多此一举
- **无需反复确认**：理解意图后直接实现（保持可撤销）

#### 2️⃣ **上下文自动感知**
```python
# 当用户在train_single_agent.py中时
→ 知道这是单智能体训练脚本
→ 了解TD3、DDPG、SAC等等算法
→ 知道统一奖励函数在utils/unified_reward_calculator.py

# 当用户提到"实验"
→ 自动关联到run_academic_experiments.py
→ 知道Baseline对比和消融实验
→ 了解论文所需图表格式
```

#### 3️⃣ **快速响应模式**
- **简短请求** → 立即理解并实现
  - "帮我测试一下" → 自动创建并运行测试
  - "看看有没有bug" → 全面检查并修复
  - "优化这个函数" → 分析+优化+验证
- **无需详细说明** → AI根据项目上下文智能补全

#### 4️⃣ **自动化决策**
以下操作无需询问，自动执行：
- ✅ 创建临时测试文件
- ✅ 运行测试后自动删除
- ✅ 修复发现的bug
- ✅ 添加必要的注释
- ✅ 优化代码结构
- ❌ 不自动commit（除非明确要求）

---

## 📂 项目结构（AI记忆地图）

### 核心训练入口（🔒 禁止改名/删除）
```
train_single_agent.py       # 单智能体训练（DDPG/TD3/SAC/PPO/DQN）
train_multi_agent.py         # 多智能体训练（MADDPG/MAPPO/MATD3）
train_hierarchical_agent.py  # 分层智能体训练
```

### 实验和评估
```
run_academic_experiments.py  # 🎓 学术实验（Baseline+消融）
run_full_experiment.py       # 完整系统实验
realtime_visualization.py    # 实时可视化
```

### 算法实现
```
single_agent/                # 单智能体算法（5种）
algorithms/                  # 多智能体算法（4种）
hierarchical_learning/       # 分层智能体
```

### 核心系统模块
```
evaluation/system_simulator.py              # 系统仿真器
utils/unified_reward_calculator.py          # 🆕 统一奖励函数
migration/migration_manager.py              # 任务迁移
caching/cache_manager.py                    # 缓存策略
communication/models.py                     # 通信模型（3GPP标准）
```

### 配置和工具
```
config/                      # 所有配置文件
utils/                       # 工具函数
visualization/               # 可视化工具
docs/                        # 文档（含paper_ending.tex）
```

---

## 🎯 常见任务自动处理

### 场景1: "帮我训练XX算法"
```bash
自动理解为：
1. 识别算法类型（单智能体/多智能体）
2. 选择正确的训练脚本
3. 使用合适的参数
4. 运行训练并监控
5. 生成结果报告
```

### 场景2: "优化XX模块"
```bash
自动流程：
1. 分析当前实现
2. 识别性能瓶颈
3. 提出优化方案
4. 实现并测试
5. 验证性能提升
```

### 场景3: "加注释"
```bash
自动风格：
- 学术规范的详细注释
- 包含【功能】【参数】【返回值】等结构化标记
- 说明论文对应关系
- 提供使用示例
```

### 场景4: "检查bug"
```bash
自动检查：
1. 代码逻辑错误
2. 类型安全问题
3. 边界条件处理
4. 数值稳定性
5. 异常处理完整性
→ 发现问题立即修复
```

### 场景5: "运行实验"
```bash
自动识别：
- "baseline对比" → run_academic_experiments.py --mode baseline
- "消融实验" → run_academic_experiments.py --mode ablation
- "训练TD3" → train_single_agent.py --algorithm TD3
- "比较算法" → train_single_agent.py --compare
```

---

## 🛠️ 代码修改智能策略

### 优先级原则
1. **修改现有文件** > 创建新文件
2. **保持兼容性** > 重构接口
3. **最小化影响** > 大规模改动
4. **实现后验证** > 只提建议

### 核心文件保护
```
🔒 绝对不能改名/删除：
  - train_single_agent.py
  - train_multi_agent.py
  - train_hierarchical_agent.py

✅ 可以修改内容，但保持：
  - 命令行参数兼容
  - 输入输出格式一致
  - 主要函数签名稳定
```

### 临时文件管理
```python
# 测试文件：用完自动删除
test_*.py           → 运行后删除
quick_*.py          → 验证后删除
*_demo.py           → 演示后删除

# 永久文件：保留
run_*.py            → 正式脚本
experiments/*.py    → 实验模块
utils/*.py          → 工具模块
```

---

## 📊 学术规范自动遵守

### 理论基础
- **参考文档**: `docs/paper_ending.tex` (系统建模的权威标准)
- **通信模型**: 严格遵循3GPP TR 38.901/38.306标准
- **数学公式**: 保持与论文一致的符号体系

### 奖励函数设计
```python
# ✅ 正确：统一奖励函数（已实现）
from utils.unified_reward_calculator import calculate_unified_reward

# 算法适配
reward = calculate_unified_reward(metrics, algorithm="general")  # TD3/DDPG/PPO/DQN
reward = calculate_unified_reward(metrics, algorithm="sac")      # SAC专用

# ❌ 错误：不要再创建新的奖励计算器
# 已有统一系统，避免重复实现

# 📝 奖励计算说明：
# 核心优化 = 2.0·时延 + 1.2·能耗（主要权重）
# 辅助约束 = 0.02·dropped_tasks（轻微惩罚）
# 已移除 = data_loss_bytes（时延的衍生指标）
```

### 实验标准
- **Baseline对比**: 至少6种经典算法
- **消融实验**: 验证各模块有效性
- **统计显著性**: p-value < 0.05
- **可重复性**: 固定随机种子，保存所有参数

---

## 💡 智能提示和快捷操作

### 🔍 当用户说...

| 用户输入 | AI自动理解为 | 自动执行 |
|---------|------------|---------|
| "训练TD3" | 单智能体TD3训练 | `train_single_agent.py --algorithm TD3 --episodes 200` |
| "比较算法" | 多算法性能对比 | `train_single_agent.py --compare --episodes 200` |
| "运行实验" | 学术完整实验 | `run_academic_experiments.py --mode all` |
| "测试一下" | 快速功能验证 | 创建test脚本→运行→删除 |
| "优化性能" | 性能分析+优化 | 分析瓶颈→优化→验证 |
| "加注释" | 学术规范注释 | 添加结构化注释（含论文用途） |
| "检查bug" | 全面bug检查 | 边界条件+类型+数值稳定性 |
| "看看结果" | 结果可视化 | 生成图表+分析报告 |

### 🎨 代码风格自动遵循

**注释风格**:
```python
def function_name():
    """
    简短描述
    
    【功能】详细功能说明
    【参数】参数详细说明
    【返回值】返回值说明
    【论文对应】对应论文章节（如果适用）
    【使用示例】代码示例（如果适用）
    """
    # ========== 步骤1：做什么 ==========
    # 详细解释
    code...
    
    # ========== 步骤2：做什么 ==========
    code...
```

**命名规范**:
```python
# ✅ 推荐
avg_task_delay              # 清晰的下划线命名
calculate_unified_reward    # 动词开头的函数名
BaselineAlgorithm          # 大驼峰类名

# ❌ 避免
avgDelay                   # 不用小驼峰
calc_rew                   # 不用缩写
baseline_alg               # 函数/变量不缩写
```

**文件组织**:
```python
# 导入顺序
1. 标准库 (import os, sys, time)
2. 第三方库 (import numpy, torch)
3. 项目模块 (from config import config)

# 代码组织
1. 常量定义
2. 类定义
3. 函数定义
4. 主程序入口 (if __name__ == "__main__")
```

---

## 🔧 智能问题解决

### 遇到问题时AI的思考流程

#### 问题类型1: 性能问题
```
1. 分析代码找瓶颈
2. 检查算法收敛性
3. 验证奖励函数设计
4. 检查参数配置
5. 提出优化方案
6. 实现并验证
```

#### 问题类型2: Bug修复
```
1. 重现bug（如果可能）
2. 分析根本原因
3. 检查边界条件
4. 修复bug
5. 添加测试验证
6. 清理测试文件
```

#### 问题类型3: 功能扩展
```
1. 理解需求意图
2. 检查现有实现
3. 设计最小化侵入方案
4. 实现新功能
5. 更新相关文档
6. 验证向后兼容性
```

---

## 📚 项目知识库（AI快速索引）

### 最近更新（AI优先参考）
- ✅ **统一奖励函数** (`utils/unified_reward_calculator.py`)
  - 替代了3个旧的奖励计算器（enhanced/sac/simple）
  - 所有算法已统一使用（TD3/DDPG/SAC/PPO/DQN）
  - **简化为时延+能耗双目标**（移除了data_loss_bytes）
  - 核心公式：`Reward = -(2.0·时延 + 1.2·能耗) - 0.02·dropped_tasks`
  - dropped_tasks只是轻微惩罚，不是优化目标
  
- ✅ **学术实验框架** (`run_academic_experiments.py`)
  - 6种Baseline算法对比
  - 7种消融实验配置
  - 自动生成论文图表

- ✅ **实时可视化** (`realtime_visualization.py`)
  - Flask + SocketIO
  - 训练过程实时监控
  - 使用 `--realtime-vis` 启用

### 关键文件功能速查
```
config/system_config.py         → 系统参数（车辆数、RSU数、权重等）
docs/paper_ending.tex          → 理论模型标准（数学公式、3GPP参数）
docs/academic_readiness_assessment.md  → 论文就绪性评估
evaluation/system_simulator.py  → 核心仿真引擎
```

### 常用参数快速查找
```python
# 网络配置
config.num_vehicles = 12        # 车辆数
config.num_rsus = 6            # RSU数
config.num_uavs = 2            # UAV数

# 奖励权重
config.rl.reward_weight_delay = 2.0    # 时延权重
config.rl.reward_weight_energy = 1.2   # 能耗权重

# 训练参数
config.experiment.num_episodes = 200   # 训练轮次
config.experiment.max_steps_per_episode = 100  # 每轮步数
```

---

## 🚦 工作流程自动化

### 实验工作流
```
用户："运行实验" 
  ↓
AI理解：想运行学术实验
  ↓
AI询问：快速测试(30轮) 还是 完整实验(200轮)？
  ↓
自动执行：run_academic_experiments.py
  ↓
完成后：展示关键结果 + 生成的图表位置
```

### 调试工作流
```
用户："有bug"
  ↓
AI分析：检查最近修改的文件
  ↓
自动检查：边界条件、类型安全、数值稳定性
  ↓
发现问题：立即修复
  ↓
验证修复：创建测试→运行→删除
```

### 优化工作流
```
用户："优化XX"
  ↓
AI搜索：定位相关代码
  ↓
AI分析：性能瓶颈、改进空间
  ↓
提出方案：多个选项（如果不确定）
  ↓
实现优化：修改代码
  ↓
验证效果：对比优化前后
```

---

## 🎓 学术规范自动遵守

### 代码-论文一致性
- 所有公式实现必须与 `paper_ending.tex` 一致
- 参数命名与论文符号对应（如 `ω_T` → `weight_delay`）
- 注释中说明对应的论文公式编号

### 3GPP标准自动检查
```python
# AI会自动验证以下参数是否符合3GPP标准：
carrier_frequency    # 3.3-3.8 GHz (典型3.5GHz)
bandwidth           # 20 MHz (NR典型值)
path_loss_model     # TR 38.901标准
noise_power         # -174 dBm/Hz (标准热噪声)
```

### 实验规范
- **Baseline对比**: 必须≥3种经典算法
- **消融实验**: 每个模块单独验证
- **统计检验**: 提供p-value
- **可重复性**: 固定seed、保存配置

---

## 💬 AI交互优化

### 提问方式（AI更懂你）

❌ **不够好的提问**:
```
"帮我看看这个文件"
"有什么问题吗"
"优化一下"
```

✅ **更好的提问**:
```
"检查train_single_agent.py的奖励函数是否使用了统一版本"
"优化TD3算法的收敛速度"
"为run_academic_experiments.py添加详细注释"
"运行快速Baseline对比实验"
```

🌟 **Vibe Coding风格**（AI会智能理解）:
```
"训练一下TD3"           → 自动运行200轮标准训练
"测试奖励函数"         → 创建测试→运行→显示结果→删除
"看看实验结果"         → 查找最新结果→生成可视化
"这个有bug吗"         → 全面检查→修复→验证
"给论文做实验"         → 运行学术实验套件
```

---

## 🎨 AI个性化偏好

### 响应风格
- **简洁直接**: 理解意图后直接行动，无需冗长解释
- **结果导向**: 优先展示结果和关键信息
- **主动建议**: 发现问题主动提出改进
- **学术专业**: 使用准确的学术术语

### 代码偏好
- **可读性第一**: 清晰 > 简洁
- **注释充分**: 尤其是学术相关代码
- **模块化**: 功能明确的小函数
- **测试友好**: 易于单元测试

### 实验偏好
- **快速迭代**: 先快速测试，再完整实验
- **可视化**: 自动生成图表和报告
- **可复现**: 保存所有参数和随机种子

---

## 🔥 高级AI能力

### 自动推理能力
```
用户提到"性能不好" → AI自动：
1. 检查是否收敛
2. 分析奖励函数设计
3. 检查超参数配置
4. 对比不同算法
5. 提出针对性优化方案
```

### 上下文关联
```
用户在看train_single_agent.py → AI知道：
- 最近修改了统一奖励函数
- TD3算法性能最稳定
- 可以使用--realtime-vis实时监控
- 结果会保存在results/single_agent/目录
```

### 主动优化建议
```
AI检测到：
- 代码重复 → 建议提取公共函数
- 参数硬编码 → 建议移到配置文件
- 缺少异常处理 → 建议添加try-except
- 没有类型提示 → 建议添加类型注解
```

---

## ✅ 自动验证清单

### 每次代码修改后AI自动检查
- [ ] 代码无语法错误
- [ ] 不破坏现有功能
- [ ] 保持向后兼容
- [ ] 符合项目代码风格
- [ ] 添加必要注释
- [ ] 更新相关文档（如需要）
- [ ] 清理临时文件

### 学术代码特殊检查
- [ ] 公式实现与paper_ending.tex一致
- [ ] 参数符合3GPP标准
- [ ] 奖励函数符合优化目标
- [ ] 实验可重复（固定seed）
- [ ] 注释说明论文对应关系

---

## 🎯 项目当前状态（AI记忆）

### 最近完成的工作
1. ✅ 统一奖励函数系统（所有算法已更新）
2. ✅ 学术实验框架（Baseline + 消融）
3. ✅ 详细注释增强（234行新注释）
4. ✅ Bug修复（None值处理）

### 待补充的工作（论文相关）
1. 📝 运行完整Baseline对比实验
2. 📝 运行消融实验
3. 📝 参数敏感性分析
4. 📝 收敛性分析
5. 📝 相关工作文献梳理

### 下一步建议
- 🎯 **立即**: 运行快速实验验证框架
- 🎯 **短期**: 运行完整学术实验（3-4小时）
- 🎯 **中期**: 补充参数分析实验
- 🎯 **长期**: 准备论文投稿

---

## 🚀 Vibe Coding最佳实践

### 与AI高效协作
1. **信任AI判断**: AI会基于项目上下文做最佳决策
2. **简洁表达**: 说出核心需求，AI会补全细节
3. **快速迭代**: 先实现，有问题再调整
4. **随时提问**: 不确定时直接问，AI会基于项目上下文解释

### AI主动服务
- 发现问题主动提醒
- 优化建议主动提出
- 相关文档主动关联
- 测试验证主动执行

---

**规则版本**: v2.0 (Vibe Coding优化版)  
**更新日期**: 2025-10-02  
**优化重点**: 智能理解、主动服务、学术规范、流畅体验  

---

💡 **核心思想**: 让AI成为真正懂你项目的智能助手，而不仅仅是代码生成器！