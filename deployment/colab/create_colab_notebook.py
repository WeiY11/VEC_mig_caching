#!/usr/bin/env python3
"""ç”ŸæˆKaggleç¬”è®°æœ¬çš„è„šæœ¬"""
import json
import os

# Kaggleç¬”è®°æœ¬ç»“æ„
notebook = {
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "cells": []
}

# å•å…ƒæ ¼1: æ ‡é¢˜è¯´æ˜
notebook["cells"].append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "# ğŸš€ VECç³»ç»Ÿ - RSUè®¡ç®—èµ„æºå¯¹æ¯”å®éªŒ (Kaggle)\n",
        "\n",
        "## ğŸ“‹ å®éªŒé…ç½®\n",
        "- **å®éªŒç±»å‹**: RSUè®¡ç®—èµ„æºæ•æ„Ÿæ€§åˆ†æ\n",
        "- **è®­ç»ƒè½®æ¬¡**: 1500 episodes\n",
        "- **éšæœºç§å­**: 42\n",
        "- **é¢„è®¡æ—¶é•¿**: 2-3å°æ—¶ (P100 GPU)\n",
        "\n",
        "## âš™ï¸ ä½¿ç”¨å‰å‡†å¤‡\n",
        "1. å³ä¾§è®¾ç½®é¢æ¿é€‰æ‹© **GPU P100** æˆ– **GPU T4**\n",
        "2. å¼€å¯ **Internet** è¿æ¥\n",
        "3. æŒ‰é¡ºåºè¿è¡Œä¸‹é¢çš„å•å…ƒæ ¼"
    ]
})

# å•å…ƒæ ¼2: åŠ è½½é¡¹ç›®ä»£ç 
notebook["cells"].append({
    "cell_type": "markdown",
    "metadata": {},
    "source": ["## ğŸ“¦ æ­¥éª¤1ï¼šåŠ è½½é¡¹ç›®ä»£ç "]
})

notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# æ–¹æ³•1ï¼šä»GitHubå…‹éš†ï¼ˆæ¨èï¼‰\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# ğŸ“Œ ä¿®æ”¹è¿™é‡Œï¼šå¡«å…¥ä½ çš„Gitä»“åº“åœ°å€\n",
        "GIT_REPO_URL = 'https://github.com/WeiY11/VEC_mig_caching.git'  # â† ä¿®æ”¹ä¸ºä½ çš„ä»“åº“\n",
        "\n",
        "# åˆ‡æ¢åˆ°å·¥ä½œç›®å½•\n",
        "os.chdir('/kaggle/working')\n",
        "\n",
        "# åˆ é™¤æ—§ç›®å½•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰\n",
        "!rm -rf VEC_mig_caching\n",
        "\n",
        "print(f'ğŸ“¦ æ­£åœ¨å…‹éš†: {GIT_REPO_URL}')\n",
        "result = subprocess.run(['git', 'clone', GIT_REPO_URL, 'VEC_mig_caching'], \n",
        "                       capture_output=True, text=True)\n",
        "\n",
        "if result.returncode != 0:\n",
        "    print('âŒ å…‹éš†å¤±è´¥ï¼')\n",
        "    print('é”™è¯¯ä¿¡æ¯:', result.stderr)\n",
        "    print('\\nğŸ’¡ å¯èƒ½çš„åŸå› :')\n",
        "    print('1. ä»“åº“æ˜¯ç§æœ‰çš„ â†’ éœ€è¦ä½¿ç”¨Tokenï¼ˆè§ä¸‹æ–¹å¤‡ç”¨ä»£ç ï¼‰')\n",
        "    print('2. ä»“åº“åœ°å€é”™è¯¯ â†’ æ£€æŸ¥GIT_REPO_URL')\n",
        "    print('3. ç½‘ç»œé—®é¢˜ â†’ æ£€æŸ¥Kaggleçš„Internetè®¾ç½®æ˜¯å¦å¼€å¯')\n",
        "else:\n",
        "    os.chdir('VEC_mig_caching')\n",
        "    print(f'âœ… é¡¹ç›®ç›®å½•: {os.getcwd()}')\n",
        "    !ls -la | head -15"
    ]
})

# å¤‡ç”¨ï¼šç§æœ‰ä»“åº“å…‹éš†
notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# æ–¹æ³•2ï¼šå…‹éš†ç§æœ‰ä»“åº“ï¼ˆéœ€è¦Tokenï¼‰\n",
        "# å¦‚æœä¸Šé¢çš„å…‹éš†å¤±è´¥ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Š\n",
        "\n",
        "# from getpass import getpass\n",
        "# import os\n",
        "# import subprocess\n",
        "# \n",
        "# os.chdir('/kaggle/working')\n",
        "# !rm -rf VEC_mig_caching\n",
        "# \n",
        "# GITHUB_USERNAME = 'WeiY11'\n",
        "# REPO_NAME = 'VEC_mig_caching'\n",
        "# \n",
        "# print('ğŸ”‘ è¯·è¾“å…¥GitHub Token:')\n",
        "# print('   è·å–åœ°å€: https://github.com/settings/tokens')\n",
        "# print('   éœ€è¦æƒé™: repo (Full control of private repositories)')\n",
        "# TOKEN = getpass('Token: ')\n",
        "# \n",
        "# repo_url = f'https://{TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git'\n",
        "# result = subprocess.run(['git', 'clone', repo_url, 'VEC_mig_caching'],\n",
        "#                        capture_output=True, text=True)\n",
        "# \n",
        "# if result.returncode == 0:\n",
        "#     os.chdir('VEC_mig_caching')\n",
        "#     print(f'âœ… é¡¹ç›®ç›®å½•: {os.getcwd()}')\n",
        "#     !ls -la | head -15\n",
        "# else:\n",
        "#     print('âŒ å…‹éš†å¤±è´¥:', result.stderr)"
    ]
})

# å¤‡ç”¨ï¼šDatasetæ–¹å¼
notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# æ–¹æ³•2ï¼šä»Kaggle DatasetåŠ è½½ï¼ˆå¦‚æœä½ ä¸Šä¼ äº†Datasetï¼‰\n",
        "# å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šæ¥ä½¿ç”¨\n",
        "\n",
        "# import shutil\n",
        "# import os\n",
        "# \n",
        "# dataset_path = '/kaggle/input/vec-migration-caching'  # â† ä¿®æ”¹ä¸ºDatasetåç§°\n",
        "# work_path = '/kaggle/working/VEC_mig_caching'\n",
        "# \n",
        "# if os.path.exists(work_path):\n",
        "#     shutil.rmtree(work_path)\n",
        "# shutil.copytree(dataset_path, work_path)\n",
        "# os.chdir(work_path)\n",
        "# print(f'âœ… é¡¹ç›®åŠ è½½å®Œæˆ: {os.getcwd()}')"
    ]
})

# å•å…ƒæ ¼3ï¼šå®‰è£…ä¾èµ–
notebook["cells"].append({
    "cell_type": "markdown",
    "metadata": {},
    "source": ["## ğŸ”§ æ­¥éª¤2ï¼šå®‰è£…ä¾èµ–"]
})

notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# å®‰è£…ä¾èµ–\n",
        "!pip install flask-socketio pyyaml -q\n",
        "\n",
        "# åˆ›å»ºç›®å½•\n",
        "!mkdir -p results/td3_strategy_suite academic_figures\n",
        "\n",
        "print('âœ… ä¾èµ–å®‰è£…å®Œæˆ')"
    ]
})

notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# éªŒè¯GPU\n",
        "import torch\n",
        "print(f'PyTorch: {torch.__version__}')\n",
        "print(f'CUDA: {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
    ]
})

# å•å…ƒæ ¼4ï¼šè¿è¡Œå®éªŒ
notebook["cells"].append({
    "cell_type": "markdown",
    "metadata": {},
    "source": ["## ğŸ¯ æ­¥éª¤3ï¼šè¿è¡ŒRSUè®¡ç®—èµ„æºå®éªŒ"]
})

notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# ğŸš€ è¿è¡Œå®Œæ•´å®éªŒï¼ˆ1500è½®ï¼‰\n",
        "!python experiments/td3_strategy_suite/run_bandwidth_cost_comparison.py \\\n",
        "    --experiment-types rsu_compute \\\n",
        "    --rsu-compute-levels default \\\n",
        "    --episodes 1500 \\\n",
        "    --seed 42"
    ]
})

notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# ğŸ’¡ å¿«é€ŸéªŒè¯æ¨¡å¼ï¼ˆ500è½®ï¼Œä»…ç”¨äºæµ‹è¯•ï¼‰\n",
        "# !python experiments/td3_strategy_suite/run_bandwidth_cost_comparison.py \\\n",
        "#     --experiment-types rsu_compute \\\n",
        "#     --rsu-compute-levels default \\\n",
        "#     --episodes 500 \\\n",
        "#     --seed 42"
    ]
})

# å•å…ƒæ ¼5ï¼šæŸ¥çœ‹ç»“æœ
notebook["cells"].append({
    "cell_type": "markdown",
    "metadata": {},
    "source": ["## ğŸ“Š æ­¥éª¤4ï¼šæŸ¥çœ‹ç»“æœ"]
})

notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# æŸ¥çœ‹ç»“æœæ–‡ä»¶\n",
        "print('ğŸ“ å®éªŒç»“æœ:')\n",
        "!ls -lh results/td3_strategy_suite/ | grep rsu_compute\n",
        "\n",
        "print('\\nğŸ“Š ç”Ÿæˆå›¾è¡¨:')\n",
        "!ls -lh academic_figures/ | tail -10"
    ]
})

# å•å…ƒæ ¼6ï¼šä¿å­˜ç»“æœ
notebook["cells"].append({
    "cell_type": "markdown",
    "metadata": {},
    "source": ["## ğŸ’¾ æ­¥éª¤5ï¼šä¿å­˜ç»“æœ"]
})

notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# æ‰“åŒ…ç»“æœ\n",
        "from datetime import datetime\n",
        "import shutil\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "result_zip = f'rsu_results_{timestamp}'\n",
        "figure_zip = f'rsu_figures_{timestamp}'\n",
        "\n",
        "shutil.make_archive(result_zip, 'zip', 'results/td3_strategy_suite')\n",
        "shutil.make_archive(figure_zip, 'zip', 'academic_figures')\n",
        "\n",
        "print(f'âœ… ç»“æœå·²æ‰“åŒ…ï¼š')\n",
        "print(f'   {result_zip}.zip')\n",
        "print(f'   {figure_zip}.zip')\n",
        "print('\\nğŸ“‚ å¯åœ¨Kaggle Outputä¸­ä¸‹è½½')"
    ]
})

# ä¿å­˜ç¬”è®°æœ¬
output_dir = os.path.dirname(__file__)
kaggle_output = os.path.join(os.path.dirname(output_dir), 'kaggle', 'VEC_RSU_Compute_Kaggle.ipynb')
with open(kaggle_output, 'w', encoding='utf-8') as f:
    json.dump(notebook, f, ensure_ascii=False, indent=2)

print(f"âœ… Kaggleç¬”è®°æœ¬å·²ç”Ÿæˆ: {kaggle_output}")

# Colabç¬”è®°æœ¬ç»“æ„
notebook = {
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": []
}

# å•å…ƒæ ¼1: æ ‡é¢˜è¯´æ˜
notebook["cells"].append({
    "cell_type": "markdown",
    "metadata": {"id": "header"},
    "source": [
        "# ğŸš€ VECç³»ç»Ÿ - RSUè®¡ç®—èµ„æºå¯¹æ¯”å®éªŒ\n",
        "\n",
        "## ğŸ“‹ å®éªŒé…ç½®\n",
        "- **å®éªŒç±»å‹**: RSUè®¡ç®—èµ„æºæ•æ„Ÿæ€§åˆ†æ\n",
        "- **è®­ç»ƒè½®æ¬¡**: 1500 episodes\n",
        "- **éšæœºç§å­**: 42\n",
        "- **é¢„è®¡æ—¶é•¿**: 2-3å°æ—¶ï¼ˆT4 GPUï¼‰\n",
        "\n",
        "## âš™ï¸ ä½¿ç”¨å‰å‡†å¤‡\n",
        "1. èœå•æ : **ä»£ç æ‰§è¡Œç¨‹åº** â†’ **æ›´æ”¹è¿è¡Œæ—¶ç±»å‹** â†’ é€‰æ‹© **T4 GPU**\n",
        "2. ä¾æ¬¡è¿è¡Œä¸‹é¢çš„å•å…ƒæ ¼"
    ]
})

# å•å…ƒæ ¼2: æ£€æŸ¥GPUå¹¶æŒ‚è½½Drive
notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {"id": "setup_gpu"},
    "outputs": [],
    "source": [
        "# æ£€æŸ¥GPU\n",
        "import torch\n",
        "print(f'PyTorch: {torch.__version__}')\n",
        "print(f'CUDA: {torch.cuda.is_available()}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
        "else:\n",
        "    print('âš ï¸ è¯·åœ¨èœå•æ é€‰æ‹©GPUè¿è¡Œæ—¶ï¼')\n",
        "\n",
        "# æŒ‚è½½Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "save_dir = '/content/drive/MyDrive/VEC_results'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "print(f'âœ… ç»“æœä¿å­˜ç›®å½•: {save_dir}')"
    ]
})

# å•å…ƒæ ¼3: å…‹éš†Gitä»“åº“
notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {"id": "clone_project"},
    "outputs": [],
    "source": [
        "# æ–¹æ³•1ï¼šä»GitHubå…‹éš†é¡¹ç›®ï¼ˆæ¨èï¼‰\n",
        "import os\n",
        "\n",
        "# ğŸ“Œ ä¿®æ”¹è¿™é‡Œï¼šå¡«å…¥ä½ çš„Gitä»“åº“åœ°å€\n",
        "GIT_REPO_URL = 'https://github.com/YOUR_USERNAME/VEC_mig_caching.git'  # â† ä¿®æ”¹ä¸ºä½ çš„ä»“åº“åœ°å€\n",
        "\n",
        "print(f'ğŸ“¦ æ­£åœ¨å…‹éš†ä»“åº“: {GIT_REPO_URL}')\n",
        "!git clone {GIT_REPO_URL} /content/VEC_mig_caching\n",
        "\n",
        "# è¿›å…¥é¡¹ç›®ç›®å½•\n",
        "os.chdir('/content/VEC_mig_caching')\n",
        "print(f'âœ… é¡¹ç›®ç›®å½•: {os.getcwd()}')\n",
        "\n",
        "# æŸ¥çœ‹ç›®å½•ç»“æ„\n",
        "!ls -la | head -15"
    ]
})

# å•å…ƒæ ¼3å¤‡ç”¨: ä¸Šä¼ ZIPï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {"id": "upload_project_alternative"},
    "outputs": [],
    "source": [
        "# æ–¹æ³•2ï¼šä¸Šä¼ ZIPæ–‡ä»¶ï¼ˆå¦‚æœæ²¡æœ‰Gitä»“åº“ï¼Œä½¿ç”¨æ­¤æ–¹æ³•ï¼‰\n",
        "# å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šæ¥ä½¿ç”¨\n",
        "\n",
        "# from google.colab import files\n",
        "# import zipfile\n",
        "# import shutil\n",
        "# \n",
        "# print('ğŸ“¤ è¯·é€‰æ‹©VEC_mig_caching.zipæ–‡ä»¶ä¸Šä¼ ...')\n",
        "# uploaded = files.upload()\n",
        "# \n",
        "# zip_name = list(uploaded.keys())[0]\n",
        "# with zipfile.ZipFile(zip_name, 'r') as z:\n",
        "#     z.extractall('/content')\n",
        "# \n",
        "# project_dir = '/content/VEC_mig_caching'\n",
        "# if not os.path.exists(project_dir):\n",
        "#     for item in os.listdir('/content'):\n",
        "#         if 'VEC' in item and os.path.isdir(f'/content/{item}'):\n",
        "#             shutil.move(f'/content/{item}', project_dir)\n",
        "#             break\n",
        "# \n",
        "# os.chdir(project_dir)\n",
        "# print(f'âœ… é¡¹ç›®ç›®å½•: {os.getcwd()}')\n",
        "# !ls -la | head -15"
    ]
})

# å•å…ƒæ ¼4: å®‰è£…ä¾èµ–
notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {"id": "install_deps"},
    "outputs": [],
    "source": [
        "# å®‰è£…ä¾èµ–\n",
        "!pip install flask-socketio pyyaml -q\n",
        "\n",
        "# åˆ›å»ºç›®å½•\n",
        "!mkdir -p results/td3_strategy_suite academic_figures logs\n",
        "\n",
        "# éªŒè¯æ–‡ä»¶\n",
        "print('âœ… ä¾èµ–å®‰è£…å®Œæˆ\\n')\n",
        "print('ğŸ“‚ å…³é”®æ–‡ä»¶æ£€æŸ¥:')\n",
        "files_check = [\n",
        "    'experiments/td3_strategy_suite/run_bandwidth_cost_comparison.py',\n",
        "    'requirements.txt',\n",
        "    'config/system_config.py'\n",
        "]\n",
        "for f in files_check:\n",
        "    print(f\"{'âœ…' if os.path.exists(f) else 'âŒ'} {f}\")"
    ]
})

# å•å…ƒæ ¼5: è¿è¡Œå®éªŒ
notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {"id": "run_experiment"},
    "outputs": [],
    "source": [
        "# ğŸš€ è¿è¡ŒRSUè®¡ç®—èµ„æºå¯¹æ¯”å®éªŒï¼ˆ1500è½®ï¼‰\n",
        "!python experiments/td3_strategy_suite/run_bandwidth_cost_comparison.py \\\n",
        "    --experiment-types rsu_compute \\\n",
        "    --rsu-compute-levels default \\\n",
        "    --episodes 1500 \\\n",
        "    --seed 42"
    ]
})

# å•å…ƒæ ¼6: å¿«é€ŸéªŒè¯æ¨¡å¼ï¼ˆæ³¨é‡Šæ‰ï¼‰
notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {"id": "fast_mode"},
    "outputs": [],
    "source": [
        "# ğŸ’¡ å¿«é€ŸéªŒè¯æ¨¡å¼ï¼ˆ500è½®ï¼Œä»…ç”¨äºæµ‹è¯•ï¼‰\n",
        "# !python experiments/td3_strategy_suite/run_bandwidth_cost_comparison.py \\\n",
        "#     --experiment-types rsu_compute \\\n",
        "#     --rsu-compute-levels default \\\n",
        "#     --episodes 500 \\\n",
        "#     --seed 42"
    ]
})

# å•å…ƒæ ¼7: æŸ¥çœ‹ç»“æœ
notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {"id": "view_results"},
    "outputs": [],
    "source": [
        "# æŸ¥çœ‹ç»“æœæ–‡ä»¶\n",
        "print('ğŸ“ å®éªŒç»“æœ:')\n",
        "!ls -lh results/td3_strategy_suite/ | grep rsu_compute\n",
        "\n",
        "print('\\nğŸ“Š ç”Ÿæˆå›¾è¡¨:')\n",
        "!ls -lh academic_figures/ | tail -10\n",
        "\n",
        "# æ˜¾ç¤ºå›¾è¡¨\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "figures = sorted(glob.glob('academic_figures/*rsu_compute*.png'))\n",
        "if figures:\n",
        "    print(f'\\næ‰¾åˆ° {len(figures)} å¼ å›¾è¡¨')\n",
        "    for fig in figures[-3:]:\n",
        "        print(f'\\nğŸ“ˆ {os.path.basename(fig)}')\n",
        "        display(Image(filename=fig))\n",
        "else:\n",
        "    print('âš ï¸ æœªæ‰¾åˆ°å›¾è¡¨')"
    ]
})

# å•å…ƒæ ¼8: æ˜¾ç¤ºæŒ‡æ ‡æ‘˜è¦
notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {"id": "show_metrics"},
    "outputs": [],
    "source": [
        "# æ˜¾ç¤ºå…³é”®æŒ‡æ ‡\n",
        "import json\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "summaries = sorted(glob.glob('results/td3_strategy_suite/*summary*.json'))\n",
        "if summaries:\n",
        "    with open(summaries[-1], 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    if 'rsu_compute' in data:\n",
        "        print('ğŸ¯ RSUè®¡ç®—èµ„æºå¯¹æ¯”ç»“æœ\\n' + '='*80)\n",
        "        for level, strategies in data['rsu_compute'].items():\n",
        "            print(f'\\nğŸ“Œ {level}\\n' + '-'*80)\n",
        "            rows = []\n",
        "            for strat, metrics in strategies.items():\n",
        "                rows.append({\n",
        "                    'ç­–ç•¥': strat,\n",
        "                    'æ—¶å»¶(s)': f\"{metrics.get('avg_delay', 0):.4f}\",\n",
        "                    'èƒ½è€—(J)': f\"{metrics.get('avg_energy_consumption', 0):.2f}\",\n",
        "                    'ååé‡': f\"{metrics.get('avg_throughput_mbps', 0):.2f}\",\n",
        "                    'RSUåˆ©ç”¨ç‡': f\"{metrics.get('avg_rsu_utilization', 0):.2%}\"\n",
        "                })\n",
        "            print(pd.DataFrame(rows).to_string(index=False))\n",
        "    else:\n",
        "        print('âš ï¸ æœªæ‰¾åˆ°RSUå®éªŒæ•°æ®')\n",
        "else:\n",
        "    print('âš ï¸ æœªæ‰¾åˆ°æ‘˜è¦æ–‡ä»¶')"
    ]
})

# å•å…ƒæ ¼9: ä¿å­˜ç»“æœ
notebook["cells"].append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {"id": "save_results"},
    "outputs": [],
    "source": [
        "# æ‰“åŒ…å¹¶ä¿å­˜ç»“æœ\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "result_zip = f'rsu_results_{timestamp}'\n",
        "figure_zip = f'rsu_figures_{timestamp}'\n",
        "\n",
        "!zip -r {result_zip}.zip results/td3_strategy_suite/\n",
        "!zip -r {figure_zip}.zip academic_figures/\n",
        "\n",
        "print(f'âœ… å·²æ‰“åŒ…:')\n",
        "print(f'   {result_zip}.zip')\n",
        "print(f'   {figure_zip}.zip')\n",
        "\n",
        "# ä¿å­˜åˆ°Drive\n",
        "if os.path.exists('/content/drive/MyDrive/VEC_results'):\n",
        "    !cp {result_zip}.zip /content/drive/MyDrive/VEC_results/\n",
        "    !cp {figure_zip}.zip /content/drive/MyDrive/VEC_results/\n",
        "    print('\\nğŸ“¤ å·²ä¿å­˜åˆ°Google Drive')\n",
        "\n",
        "# ä¸‹è½½åˆ°æœ¬åœ°\n",
        "print('\\nğŸ“¥ å¼€å§‹ä¸‹è½½åˆ°æœ¬åœ°...')\n",
        "files.download(f'{result_zip}.zip')\n",
        "files.download(f'{figure_zip}.zip')"
    ]
})

# ä¿å­˜ç¬”è®°æœ¬
output_path = os.path.join(os.path.dirname(__file__), 'VEC_RSU_Compute_Experiment.ipynb')
with open(output_path, 'w', encoding='utf-8') as f:
    json.dump(notebook, f, ensure_ascii=False, indent=2)

print(f"âœ… Colabç¬”è®°æœ¬å·²ç”Ÿæˆ: {output_path}")
