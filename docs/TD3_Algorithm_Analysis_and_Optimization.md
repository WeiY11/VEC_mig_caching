# TD3ç®—æ³•å®ç°åˆ†æä¸ä¼˜åŒ–æ–¹æ¡ˆ

## é—®é¢˜è¯Šæ–­æ€»ç»“

ç»è¿‡å¯¹æ‚¨çš„TD3ç®—æ³•å®ç°çš„å…¨é¢åˆ†æï¼Œæˆ‘å‘ç°äº†ä»¥ä¸‹å…³é”®é—®é¢˜ï¼š

### 1. çŠ¶æ€ç©ºé—´è®¾è®¡é—®é¢˜ âš ï¸ **ä¸¥é‡**

**é—®é¢˜æè¿°ï¼š**
- çŠ¶æ€å‘é‡æ„å»ºè¿‡äºç®€åŒ–ï¼Œå¤§éƒ¨åˆ†çŠ¶æ€ä½¿ç”¨éšæœºæ•°å¡«å……
- çŠ¶æ€ç»´åº¦å›ºå®šä¸º60ï¼Œä½†å®é™…æœ‰æ•ˆä¿¡æ¯åªæœ‰5ç»´
- ç¼ºä¹ä¸è®ºæ–‡æè¿°çš„VECç³»ç»ŸçŠ¶æ€çš„å¯¹åº”å…³ç³»

**ä»£ç ä½ç½®ï¼š** `single_agent/td3.py:452-467`
```python
def get_state_vector(self, node_states: Dict, system_metrics: Dict) -> np.ndarray:
    # åŸºç¡€ç³»ç»ŸçŠ¶æ€
    base_state = np.array([
        system_metrics.get('avg_task_delay', 0.0) / 1.0,
        system_metrics.get('total_energy_consumption', 0.0) / 1000.0,
        system_metrics.get('data_loss_rate', 0.0),
        system_metrics.get('cache_hit_rate', 0.0),
        system_metrics.get('migration_success_rate', 0.0),
    ])
    
    # âŒ é—®é¢˜ï¼šå¤§éƒ¨åˆ†çŠ¶æ€ä½¿ç”¨éšæœºæ•°å¡«å……
    node_states_flat = np.random.randn(self.state_dim - len(base_state))
    
    return np.concatenate([base_state, node_states_flat])
```

### 2. åŠ¨ä½œç©ºé—´ä¸ç¯å¢ƒäº¤äº’é—®é¢˜ âš ï¸ **ä¸¥é‡**

**é—®é¢˜æè¿°ï¼š**
- åŠ¨ä½œåˆ†è§£è¿‡äºç®€åŒ–ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“å›ºå®š10ä¸ªåŠ¨ä½œç»´åº¦
- åŠ¨ä½œä¸å®é™…VECç³»ç»Ÿå†³ç­–å˜é‡ç¼ºä¹æ˜ç¡®æ˜ å°„
- ç¯å¢ƒstepå‡½æ•°ä¸­åŠ¨ä½œæœªè¢«å®é™…ä½¿ç”¨

**ä»£ç ä½ç½®ï¼š** `single_agent/td3.py:468-479`
```python
def decompose_action(self, action: np.ndarray) -> Dict[str, np.ndarray]:
    """å°†å…¨å±€åŠ¨ä½œåˆ†è§£ä¸ºå„èŠ‚ç‚¹åŠ¨ä½œ"""
    actions = {}
    start_idx = 0
    
    # âŒ é—®é¢˜ï¼šåŠ¨ä½œç»´åº¦å›ºå®šï¼Œç¼ºä¹å®é™…æ„ä¹‰
    for agent_type in ['vehicle_agent', 'rsu_agent', 'uav_agent']:
        end_idx = start_idx + 10  # æ¯ä¸ªæ™ºèƒ½ä½“10ä¸ªåŠ¨ä½œç»´åº¦
        actions[agent_type] = action[start_idx:end_idx]
        start_idx = end_idx
    
    return actions
```

### 3. å¥–åŠ±å‡½æ•°è®¾è®¡é—®é¢˜ âš ï¸ **ä¸­ç­‰**

**é—®é¢˜æè¿°ï¼š**
- å¥–åŠ±æƒé‡ä¸å¹³è¡¡ï¼ˆdelay=0.4, energy=0.3, loss=0.3ï¼‰
- å½’ä¸€åŒ–å› å­å¯èƒ½å¯¼è‡´å¥–åŠ±å°ºåº¦é—®é¢˜
- ç¼ºä¹å¯¹è®ºæ–‡ä¸­å¤šç›®æ ‡ä¼˜åŒ–çš„å‡†ç¡®å»ºæ¨¡

**ä»£ç ä½ç½®ï¼š** `single_agent/td3.py:486-513`

### 4. ç¯å¢ƒä»¿çœŸé—®é¢˜ âš ï¸ **ä¸¥é‡**

**é—®é¢˜æè¿°ï¼š**
- stepå‡½æ•°ä¸­åŠ¨ä½œå‚æ•°æœªè¢«ä½¿ç”¨
- ä»¿çœŸå™¨è¿è¡Œä¸æ™ºèƒ½ä½“å†³ç­–è„±èŠ‚
- ç¼ºä¹çœŸå®çš„VECç³»ç»ŸåŠ¨æ€

**ä»£ç ä½ç½®ï¼š** `train_single_agent.py:127-157`

### 5. ç½‘ç»œæ¶æ„é…ç½®é—®é¢˜ âš ï¸ **ä¸­ç­‰**

**é—®é¢˜æè¿°ï¼š**
- éšè—å±‚ç»´åº¦é…ç½®ä¸ä¸€è‡´ï¼ˆTD3Config=400 vs å®é™…ä½¿ç”¨256ï¼‰
- å­¦ä¹ ç‡è®¾ç½®å¯èƒ½è¿‡é«˜
- æ‰¹æ¬¡å¤§å°ä¸ç¼“å†²åŒºå¤§å°æ¯”ä¾‹ä¸å½“

## ä¼˜åŒ–æ–¹æ¡ˆ

### æ–¹æ¡ˆ1ï¼šçŠ¶æ€ç©ºé—´é‡æ„ ğŸ”§

**ç›®æ ‡ï¼š** æ„å»ºç¬¦åˆè®ºæ–‡æè¿°çš„VECç³»ç»ŸçŠ¶æ€è¡¨ç¤º

**å®ç°æ­¥éª¤ï¼š**

1. **å®šä¹‰å®Œæ•´çš„çŠ¶æ€å‘é‡**
```python
def get_state_vector(self, node_states: Dict, system_metrics: Dict) -> np.ndarray:
    """æ„å»ºç¬¦åˆè®ºæ–‡çš„VECç³»ç»ŸçŠ¶æ€å‘é‡"""
    state_components = []
    
    # 1. è½¦è¾†çŠ¶æ€ (12è½¦è¾† Ã— 5ç»´ = 60ç»´)
    for vehicle in self.vehicles:
        vehicle_state = [
            vehicle.position.x / 2000.0,  # å½’ä¸€åŒ–ä½ç½®
            vehicle.position.y / 2000.0,
            vehicle.velocity.x / 30.0,    # å½’ä¸€åŒ–é€Ÿåº¦
            vehicle.velocity.y / 30.0,
            vehicle.queue_utilization,    # é˜Ÿåˆ—åˆ©ç”¨ç‡
        ]
        state_components.extend(vehicle_state)
    
    # 2. RSUçŠ¶æ€ (6RSU Ã— 4ç»´ = 24ç»´)
    for rsu in self.rsus:
        rsu_state = [
            rsu.cpu_utilization,         # CPUåˆ©ç”¨ç‡
            rsu.queue_utilization,       # é˜Ÿåˆ—åˆ©ç”¨ç‡
            rsu.cache_utilization,       # ç¼“å­˜åˆ©ç”¨ç‡
            rsu.energy_consumption / 1000.0,  # å½’ä¸€åŒ–èƒ½è€—
        ]
        state_components.extend(rsu_state)
    
    # 3. UAVçŠ¶æ€ (2UAV Ã— 4ç»´ = 8ç»´)
    for uav in self.uavs:
        uav_state = [
            uav.cpu_utilization,
            uav.queue_utilization,
            uav.battery_level,           # ç”µæ± ç”µé‡
            uav.energy_consumption / 100.0,
        ]
        state_components.extend(uav_state)
    
    # 4. å…¨å±€ç³»ç»ŸçŠ¶æ€ (8ç»´)
    global_state = [
        system_metrics.get('avg_task_delay', 0.0) / 2.0,
        system_metrics.get('total_energy_consumption', 0.0) / 5000.0,
        system_metrics.get('data_loss_rate', 0.0),
        system_metrics.get('task_completion_rate', 0.0),
        system_metrics.get('cache_hit_rate', 0.0),
        system_metrics.get('migration_success_rate', 0.0),
        system_metrics.get('network_utilization', 0.0),
        system_metrics.get('load_balance_index', 0.0),
    ]
    state_components.extend(global_state)
    
    return np.array(state_components, dtype=np.float32)
```

### æ–¹æ¡ˆ2ï¼šåŠ¨ä½œç©ºé—´é‡æ–°è®¾è®¡ ğŸ”§

**ç›®æ ‡ï¼š** å»ºç«‹åŠ¨ä½œä¸VECå†³ç­–å˜é‡çš„æ˜ç¡®æ˜ å°„

**å®ç°æ­¥éª¤ï¼š**

1. **å®šä¹‰åŠ¨ä½œç»´åº¦æ˜ å°„**
```python
class VECActionSpace:
    """VECç³»ç»ŸåŠ¨ä½œç©ºé—´å®šä¹‰"""
    
    def __init__(self):
        # åŠ¨ä½œç»´åº¦å®šä¹‰
        self.vehicle_actions = 5    # æœ¬åœ°å¤„ç†æ¯”ä¾‹ã€å¸è½½ç›®æ ‡é€‰æ‹©ç­‰
        self.rsu_actions = 8        # è®¡ç®—èµ„æºåˆ†é…ã€ç¼“å­˜ç­–ç•¥ã€è¿ç§»å†³ç­–ç­‰
        self.uav_actions = 6        # è®¡ç®—èµ„æºåˆ†é…ã€ç§»åŠ¨ç­–ç•¥ç­‰
        
        self.total_dim = (
            12 * self.vehicle_actions +  # 12è¾†è½¦
            6 * self.rsu_actions +       # 6ä¸ªRSU
            2 * self.uav_actions         # 2ä¸ªUAV
        )  # æ€»è®¡ï¼š60 + 48 + 12 = 120ç»´
    
    def decompose_action(self, action: np.ndarray) -> Dict:
        """å°†å…¨å±€åŠ¨ä½œåˆ†è§£ä¸ºå…·ä½“å†³ç­–"""
        actions = {}
        idx = 0
        
        # è½¦è¾†åŠ¨ä½œ
        for i in range(12):
            vehicle_action = action[idx:idx+self.vehicle_actions]
            actions[f'vehicle_{i}'] = {
                'local_processing_ratio': np.clip(vehicle_action[0], 0, 1),
                'offload_target_rsu': np.argmax(vehicle_action[1:4]),  # é€‰æ‹©RSU
                'offload_target_uav': np.argmax(vehicle_action[4:5]),  # é€‰æ‹©UAV
            }
            idx += self.vehicle_actions
        
        # RSUåŠ¨ä½œ
        for i in range(6):
            rsu_action = action[idx:idx+self.rsu_actions]
            actions[f'rsu_{i}'] = {
                'cpu_allocation': np.clip(rsu_action[0], 0, 1),
                'cache_policy': np.argmax(rsu_action[1:4]),  # LRU/LFU/FIFO
                'migration_threshold': np.clip(rsu_action[4], 0.5, 0.9),
                'bandwidth_allocation': np.clip(rsu_action[5:8], 0, 1),
            }
            idx += self.rsu_actions
        
        # UAVåŠ¨ä½œ
        for i in range(2):
            uav_action = action[idx:idx+self.uav_actions]
            actions[f'uav_{i}'] = {
                'cpu_allocation': np.clip(uav_action[0], 0, 1),
                'power_management': np.clip(uav_action[1], 0, 1),
                'service_priority': np.clip(uav_action[2:6], 0, 1),
            }
            idx += self.uav_actions
        
        return actions
```

### æ–¹æ¡ˆ3ï¼šå¥–åŠ±å‡½æ•°ä¼˜åŒ– ğŸ”§

**ç›®æ ‡ï¼š** å®ç°ä¸è®ºæ–‡ç›®æ ‡å‡½æ•°ä¸€è‡´çš„å¥–åŠ±è®¾è®¡

**å®ç°æ­¥éª¤ï¼š**

1. **é‡æ–°è®¾è®¡å¥–åŠ±å‡½æ•°**
```python
def calculate_reward(self, system_metrics: Dict, prev_metrics: Dict = None) -> float:
    """
    ä¼˜åŒ–çš„å¥–åŠ±å‡½æ•° - ä¸¥æ ¼å¯¹åº”è®ºæ–‡ç›®æ ‡å‡½æ•°
    è®ºæ–‡ç›®æ ‡: min(Ï‰_T * delay + Ï‰_E * energy + Ï‰_D * data_loss)
    """
    # æƒé‡é…ç½®ï¼ˆå¯è°ƒï¼‰
    w_T = 0.5  # æ—¶å»¶æƒé‡
    w_E = 0.3  # èƒ½è€—æƒé‡  
    w_D = 0.2  # æ•°æ®ä¸¢å¤±æƒé‡
    
    # æŒ‡æ ‡æå–ä¸å½’ä¸€åŒ–
    current_delay = system_metrics.get('avg_task_delay', 0.0)
    current_energy = system_metrics.get('total_energy_consumption', 0.0)
    current_loss = system_metrics.get('data_loss_rate', 0.0)
    
    # æ”¹è¿›çš„å½’ä¸€åŒ–æ–¹æ³•
    normalized_delay = np.tanh(current_delay / 2.0)      # 2ç§’ä¸ºå‚è€ƒ
    normalized_energy = np.tanh(current_energy / 2000.0) # 2000Wä¸ºå‚è€ƒ
    normalized_loss = np.clip(current_loss, 0, 1)        # å·²ç»æ˜¯æ¯”ä¾‹
    
    # åŸºç¡€æˆæœ¬è®¡ç®—
    cost = w_T * normalized_delay + w_E * normalized_energy + w_D * normalized_loss
    base_reward = -cost
    
    # æ€§èƒ½æ”¹è¿›å¥–åŠ±ï¼ˆç›¸å¯¹äºä¸Šä¸€æ­¥ï¼‰
    improvement_reward = 0.0
    if prev_metrics is not None:
        prev_delay = prev_metrics.get('avg_task_delay', current_delay)
        prev_energy = prev_metrics.get('total_energy_consumption', current_energy)
        prev_loss = prev_metrics.get('data_loss_rate', current_loss)
        
        delay_improvement = (prev_delay - current_delay) / max(prev_delay, 0.1)
        energy_improvement = (prev_energy - current_energy) / max(prev_energy, 1.0)
        loss_improvement = (prev_loss - current_loss) / max(prev_loss, 0.01)
        
        improvement_reward = 0.1 * (delay_improvement + energy_improvement + loss_improvement)
    
    # ç³»ç»Ÿç¨³å®šæ€§å¥–åŠ±
    stability_reward = 0.0
    completion_rate = system_metrics.get('task_completion_rate', 0.0)
    cache_hit_rate = system_metrics.get('cache_hit_rate', 0.0)
    
    if completion_rate > 0.8:
        stability_reward += 0.05
    if cache_hit_rate > 0.6:
        stability_reward += 0.03
    
    total_reward = base_reward + improvement_reward + stability_reward
    
    # å¥–åŠ±è£å‰ªï¼Œé¿å…æå€¼
    return np.clip(total_reward, -2.0, 1.0)
```

### æ–¹æ¡ˆ4ï¼šç¯å¢ƒäº¤äº’ä¿®å¤ ğŸ”§

**ç›®æ ‡ï¼š** å»ºç«‹æ™ºèƒ½ä½“åŠ¨ä½œä¸ç¯å¢ƒçŠ¶æ€çš„çœŸå®äº¤äº’

**å®ç°æ­¥éª¤ï¼š**

1. **ä¿®å¤stepå‡½æ•°**
```python
def step(self, action, state) -> Tuple[np.ndarray, float, bool, Dict]:
    """æ‰§è¡Œä¸€æ­¥ä»¿çœŸ - ä¿®å¤ç‰ˆæœ¬"""
    # 1. è§£æåŠ¨ä½œ
    action_space = VECActionSpace()
    parsed_actions = action_space.decompose_action(action)
    
    # 2. åº”ç”¨åŠ¨ä½œåˆ°ä»¿çœŸå™¨
    self._apply_actions_to_simulator(parsed_actions)
    
    # 3. æ‰§è¡Œä»¿çœŸæ­¥éª¤
    step_stats = self.simulator.run_simulation_step(0)
    
    # 4. æ”¶é›†æ–°çŠ¶æ€
    node_states = self._collect_node_states()
    system_metrics = self._calculate_system_metrics(step_stats)
    
    # 5. è®¡ç®—å¥–åŠ±
    reward = self.agent_env.calculate_reward(system_metrics, self.prev_metrics)
    self.prev_metrics = system_metrics.copy()
    
    # 6. è·å–ä¸‹ä¸€çŠ¶æ€
    next_state = self.agent_env.get_state_vector(node_states, system_metrics)
    
    # 7. åˆ¤æ–­ç»“æŸæ¡ä»¶
    done = self._check_episode_termination(system_metrics)
    
    info = {
        'step_stats': step_stats,
        'system_metrics': system_metrics,
        'parsed_actions': parsed_actions
    }
    
    return next_state, reward, done, info

def _apply_actions_to_simulator(self, actions: Dict):
    """å°†æ™ºèƒ½ä½“åŠ¨ä½œåº”ç”¨åˆ°ä»¿çœŸå™¨"""
    # åº”ç”¨è½¦è¾†åŠ¨ä½œ
    for i, vehicle in enumerate(self.simulator.vehicles):
        vehicle_action = actions.get(f'vehicle_{i}', {})
        vehicle.set_local_processing_ratio(
            vehicle_action.get('local_processing_ratio', 0.5)
        )
        vehicle.set_offload_preferences(
            rsu_target=vehicle_action.get('offload_target_rsu', 0),
            uav_target=vehicle_action.get('offload_target_uav', 0)
        )
    
    # åº”ç”¨RSUåŠ¨ä½œ
    for i, rsu in enumerate(self.simulator.rsus):
        rsu_action = actions.get(f'rsu_{i}', {})
        rsu.set_cpu_allocation(rsu_action.get('cpu_allocation', 1.0))
        rsu.set_cache_policy(rsu_action.get('cache_policy', 0))
        rsu.set_migration_threshold(rsu_action.get('migration_threshold', 0.8))
    
    # åº”ç”¨UAVåŠ¨ä½œ
    for i, uav in enumerate(self.simulator.uavs):
        uav_action = actions.get(f'uav_{i}', {})
        uav.set_cpu_allocation(uav_action.get('cpu_allocation', 1.0))
        uav.set_power_management(uav_action.get('power_management', 1.0))
```

### æ–¹æ¡ˆ5ï¼šè¶…å‚æ•°ä¼˜åŒ– ğŸ”§

**ç›®æ ‡ï¼š** è°ƒæ•´ç½‘ç»œæ¶æ„å’Œè®­ç»ƒå‚æ•°

**å®ç°æ­¥éª¤ï¼š**

1. **ä¼˜åŒ–TD3é…ç½®**
```python
@dataclass
class OptimizedTD3Config:
    """ä¼˜åŒ–çš„TD3é…ç½®"""
    # ç½‘ç»œç»“æ„
    hidden_dim: int = 512        # å¢åŠ ç½‘ç»œå®¹é‡
    actor_lr: float = 3e-5       # é™ä½å­¦ä¹ ç‡
    critic_lr: float = 1e-4      # é™ä½å­¦ä¹ ç‡
    
    # è®­ç»ƒå‚æ•°
    batch_size: int = 128        # é€‚ä¸­çš„æ‰¹æ¬¡å¤§å°
    buffer_size: int = 200000    # å¢åŠ ç¼“å†²åŒº
    tau: float = 0.005           # æ¢å¤æ ‡å‡†è½¯æ›´æ–°
    gamma: float = 0.99          # æ ‡å‡†æŠ˜æ‰£å› å­
    
    # TD3ç‰¹æœ‰å‚æ•°
    policy_delay: int = 2        # æ ‡å‡†å»¶è¿Ÿ
    target_noise: float = 0.2    # å¢åŠ ç›®æ ‡å™ªå£°
    noise_clip: float = 0.5      # æ ‡å‡†å™ªå£°è£å‰ª
    
    # æ¢ç´¢å‚æ•°
    exploration_noise: float = 0.3   # å¢åŠ åˆå§‹æ¢ç´¢
    noise_decay: float = 0.9999      # ç¼“æ…¢è¡°å‡
    min_noise: float = 0.02          # ä¿æŒæœ€å°æ¢ç´¢
    
    # è®­ç»ƒæ§åˆ¶
    warmup_steps: int = 10000        # å¢åŠ é¢„çƒ­æ­¥æ•°
    update_freq: int = 1             # æ¯æ­¥æ›´æ–°
```

## å®æ–½å»ºè®®

### é˜¶æ®µ1ï¼šæ ¸å¿ƒé—®é¢˜ä¿®å¤ï¼ˆä¼˜å…ˆçº§ï¼šé«˜ï¼‰
1. å®æ–½çŠ¶æ€ç©ºé—´é‡æ„ï¼ˆæ–¹æ¡ˆ1ï¼‰
2. ä¿®å¤ç¯å¢ƒäº¤äº’é—®é¢˜ï¼ˆæ–¹æ¡ˆ4ï¼‰
3. é‡æ–°è®¾è®¡åŠ¨ä½œç©ºé—´ï¼ˆæ–¹æ¡ˆ2ï¼‰

### é˜¶æ®µ2ï¼šæ€§èƒ½ä¼˜åŒ–ï¼ˆä¼˜å…ˆçº§ï¼šä¸­ï¼‰
1. ä¼˜åŒ–å¥–åŠ±å‡½æ•°ï¼ˆæ–¹æ¡ˆ3ï¼‰
2. è°ƒæ•´è¶…å‚æ•°é…ç½®ï¼ˆæ–¹æ¡ˆ5ï¼‰
3. å¢åŠ è®­ç»ƒç›‘æ§å’Œè°ƒè¯•

### é˜¶æ®µ3ï¼šé«˜çº§ä¼˜åŒ–ï¼ˆä¼˜å…ˆçº§ï¼šä½ï¼‰
1. å®æ–½è¯¾ç¨‹å­¦ä¹ 
2. æ·»åŠ ç»éªŒå›æ”¾ä¼˜å…ˆçº§
3. é›†æˆå¤šæ™ºèƒ½ä½“åä½œæœºåˆ¶

## é¢„æœŸæ•ˆæœ

å®æ–½è¿™äº›ä¼˜åŒ–åï¼Œæ‚¨åº”è¯¥èƒ½çœ‹åˆ°ï¼š

1. **è®­ç»ƒç¨³å®šæ€§æå‡**ï¼šå¥–åŠ±æ›²çº¿æ›´åŠ å¹³æ»‘ï¼Œæ”¶æ•›æ›´å¿«
2. **æ€§èƒ½æŒ‡æ ‡æ”¹å–„**ï¼šä»»åŠ¡å®Œæˆç‡ã€ç¼“å­˜å‘½ä¸­ç‡ã€èƒ½è€—æ•ˆç‡æ˜¾è‘—æå‡
3. **ç®—æ³•æ”¶æ•›æ€§**ï¼šåœ¨200-400ä¸ªepisodeå†…è¾¾åˆ°ç¨³å®šæ€§èƒ½
4. **ç³»ç»Ÿä¸€è‡´æ€§**ï¼šå®ç°ä¸è®ºæ–‡æè¿°çš„VECç³»ç»Ÿæ¨¡å‹ä¸€è‡´

å»ºè®®æ‚¨ä¼˜å…ˆå®æ–½é˜¶æ®µ1çš„ä¿®å¤ï¼Œè¿™äº›æ˜¯å¯¼è‡´å½“å‰è®­ç»ƒæ•ˆæœä¸ä½³çš„æ ¹æœ¬åŸå› ã€‚