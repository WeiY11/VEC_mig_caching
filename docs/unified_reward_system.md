# ç»Ÿä¸€å¥–åŠ±å‡½æ•°ç³»ç»Ÿè®¾è®¡æ–‡æ¡£

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£æè¿°äº† VEC ç³»ç»Ÿä¸­**ç»Ÿä¸€å¥–åŠ±è®¡ç®—å™¨**çš„è®¾è®¡ä¸å®ç°ï¼Œè§£å†³äº†ä¹‹å‰å¤šä¸ªå¥–åŠ±è®¡ç®—å™¨å¹¶å­˜å¯¼è‡´çš„ä¸ä¸€è‡´é—®é¢˜ã€‚

## ğŸ¯ æ ¸å¿ƒè®¾è®¡åŸåˆ™

### 1. **ç®€åŒ–ä¼˜åŒ–ç›®æ ‡**
- **ä¸»ç›®æ ‡**ï¼šæœ€å°åŒ–æ—¶å»¶å’Œèƒ½è€—çš„åŠ æƒå’Œ
- **æ•°å­¦è¡¨è¾¾**ï¼š`minimize Î±Â·Delay + Î²Â·Energy`
- **é»˜è®¤æƒé‡**ï¼š`Î±=2.0, Î²=1.2`

### 2. **ç§»é™¤æ•°æ®ä¸¢å¤±é‡æŒ‡æ ‡**
**åŸå› åˆ†æï¼š**
- æ•°æ®ä¸¢å¤±æœ¬è´¨ä¸Šæ˜¯**æ—¶å»¶çš„è¡ç”ŸæŒ‡æ ‡**ï¼ˆä»»åŠ¡è¶…æ—¶â†’è¢«ä¸¢å¼ƒâ†’æ•°æ®ä¸¢å¤±ï¼‰
- ä¹‹å‰æƒé‡é…ç½®ï¼šdelay(2.0) >> energy(1.2) >> loss(0.1)
- è¿‡å¤šæŒ‡æ ‡å¯èƒ½å¯¼è‡´ä¼˜åŒ–ç›®æ ‡å†²çª

**æ›¿ä»£æ–¹æ¡ˆï¼š**
- é€šè¿‡ `dropped_tasks` æƒ©ç½šç›´æ¥ä¿è¯å®Œæˆç‡
- ä¼˜åŒ–æ—¶å»¶è‡ªç„¶ä¼šå‡å°‘æ•°æ®ä¸¢å¤±

### 3. **ç®—æ³•ä¸€è‡´æ€§ä¸é€‚é…æ€§**
- **é€šç”¨ç‰ˆæœ¬**ï¼ˆDDPG, TD3, PPO, DQNï¼‰ï¼šçº¯æˆæœ¬æœ€å°åŒ–
- **SACä¸“ç”¨ç‰ˆæœ¬**ï¼šè€ƒè™‘æœ€å¤§ç†µæ¡†æ¶ï¼Œä¿ç•™æ­£å‘æ¿€åŠ±æœºåˆ¶

## ğŸ“Š å¥–åŠ±å‡½æ•°è®¾è®¡

### æ ¸å¿ƒå…¬å¼

```python
# 1. å½’ä¸€åŒ–
norm_delay = avg_delay / delay_normalizer
norm_energy = total_energy / energy_normalizer

# 2. åŸºç¡€æˆæœ¬ï¼ˆåŒç›®æ ‡åŠ æƒå’Œï¼‰
base_cost = weight_delay * norm_delay + weight_energy * norm_energy

# 3. ä¸¢å¼ƒä»»åŠ¡æƒ©ç½šï¼ˆä¿è¯å®Œæˆç‡ï¼‰
dropped_penalty = penalty_weight * dropped_tasks

# 4. è‡ªé€‚åº”é˜ˆå€¼æƒ©ç½šï¼ˆé˜²æ­¢æç«¯æƒ…å†µï¼‰
threshold_penalty = delay_threshold_penalty + energy_threshold_penalty

# 5. æ€»æˆæœ¬
total_cost = base_cost + dropped_penalty + threshold_penalty

# 6. æœ€ç»ˆå¥–åŠ±
reward = -total_cost  # é€šç”¨ç‰ˆæœ¬
reward = bonus - total_cost  # SACç‰ˆæœ¬ï¼ˆbonuså¯èƒ½ä¸ºæ­£ï¼‰
```

### å‚æ•°é…ç½®

| å‚æ•° | é€šç”¨ç®—æ³• | SACç®—æ³• | è¯´æ˜ |
|------|---------|---------|------|
| **æ—¶å»¶å½’ä¸€åŒ–** | 1.0 | 0.3 | SACæ›´æ•æ„Ÿ |
| **èƒ½è€—å½’ä¸€åŒ–** | 1000.0 | 1500.0 | SACæ›´æ•æ„Ÿ |
| **å¥–åŠ±èŒƒå›´** | [-20.0, -0.01] | [-15.0, 3.0] | SACå…è®¸æ­£å€¼ |
| **æ—¶å»¶æƒé‡** | 2.0 | 2.0 | ä¸€è‡´ |
| **èƒ½è€—æƒé‡** | 1.2 | 1.2 | ä¸€è‡´ |
| **ä¸¢å¼ƒæƒ©ç½š** | 0.02 | 0.02 | ä¸€è‡´ |

## ğŸ”„ ç®—æ³•è¿ç§»å¯¹ç…§è¡¨

### ä¹‹å‰çš„å¥–åŠ±è®¡ç®—å™¨

| ç®—æ³• | æ—§å¥–åŠ±è®¡ç®—å™¨ | ç‰¹ç‚¹ |
|------|-------------|------|
| TD3 | `enhanced_reward_calculator` | å¤æ‚çš„å­ç³»ç»Ÿå¥–åŠ± |
| DDPG | `enhanced_reward_calculator` | å¤æ‚çš„å­ç³»ç»Ÿå¥–åŠ± |
| SAC | `sac_reward_calculator` | SACä¸“ç”¨ç‰ˆæœ¬ |
| PPO | `simple_reward_calculator` | ç®€åŒ–ç‰ˆæœ¬ |
| DQN | `simple_reward_calculator` | ç®€åŒ–ç‰ˆæœ¬ |

### ç°åœ¨çš„ç»Ÿä¸€ç³»ç»Ÿ

| ç®—æ³• | æ–°å¥–åŠ±è®¡ç®—å™¨ | è°ƒç”¨æ–¹å¼ |
|------|-------------|---------|
| **æ‰€æœ‰ç®—æ³•** | `unified_reward_calculator` | ç»Ÿä¸€æ¥å£ |
| TD3/DDPG/PPO/DQN | `algorithm="general"` | é€šç”¨ç‰ˆæœ¬ |
| SAC | `algorithm="sac"` | SACä¸“ç”¨ç‰ˆæœ¬ |

## ğŸ’» ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ä½¿ç”¨

```python
from utils.unified_reward_calculator import calculate_unified_reward

# ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡
system_metrics = {
    'avg_task_delay': 0.2,              # å¹³å‡æ—¶å»¶ï¼ˆç§’ï¼‰
    'total_energy_consumption': 1000.0,  # æ€»èƒ½è€—ï¼ˆç„¦è€³ï¼‰
    'dropped_tasks': 0,                  # ä¸¢å¼ƒä»»åŠ¡æ•°
    'task_completion_rate': 0.98         # ä»»åŠ¡å®Œæˆç‡
}

# é€šç”¨ç®—æ³•ï¼ˆTD3, DDPG, PPO, DQNï¼‰
reward_general = calculate_unified_reward(system_metrics, algorithm="general")

# SACç®—æ³•
reward_sac = calculate_unified_reward(system_metrics, algorithm="sac")
```

### å‘åå…¼å®¹æ¥å£

```python
# è¿™äº›æ—§æ¥å£ä»ç„¶å¯ç”¨ï¼ˆå†…éƒ¨è°ƒç”¨ç»Ÿä¸€å¥–åŠ±è®¡ç®—å™¨ï¼‰
from utils.unified_reward_calculator import (
    calculate_enhanced_reward,  # æ›¿ä»£æ—§çš„enhanced_reward_calculator
    calculate_sac_reward,        # æ›¿ä»£æ—§çš„sac_reward_calculator
    calculate_simple_reward      # æ›¿ä»£æ—§çš„simple_reward_calculator
)

reward = calculate_enhanced_reward(system_metrics)  # ç­‰ä»·äº algorithm="general"
```

### è·å–å¥–åŠ±åˆ†è§£æŠ¥å‘Š

```python
from utils.unified_reward_calculator import get_reward_breakdown

print(get_reward_breakdown(system_metrics, algorithm="general"))
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
å¥–åŠ±åˆ†è§£æŠ¥å‘Š (GENERAL):
â”œâ”€â”€ æ€»å¥–åŠ±: -1.600
â”œâ”€â”€ æ ¸å¿ƒæŒ‡æ ‡:
â”‚   â”œâ”€â”€ æ—¶å»¶: 0.200s (å½’ä¸€åŒ–: 0.200)
â”‚   â”œâ”€â”€ èƒ½è€—: 1000.0J (å½’ä¸€åŒ–: 1.000)
â”‚   â””â”€â”€ å®Œæˆç‡: 98.0%
â”œâ”€â”€ æˆæœ¬è´¡çŒ®:
â”‚   â”œâ”€â”€ æ—¶å»¶æˆæœ¬: 0.400
â”‚   â”œâ”€â”€ èƒ½è€—æˆæœ¬: 1.200
â”‚   â””â”€â”€ ä¸¢å¼ƒæƒ©ç½š: 0.000 (0ä¸ªä»»åŠ¡)
â””â”€â”€ ä¼˜åŒ–æ–¹å‘: æœ€å°åŒ–æˆæœ¬
```

## ğŸ“ˆ æµ‹è¯•ç»“æœ

### åœºæ™¯1: æ­£å¸¸æ€§èƒ½
- **æŒ‡æ ‡**ï¼šæ—¶å»¶0.2s, èƒ½è€—1000J
- **é€šç”¨ç®—æ³•å¥–åŠ±**ï¼š-1.600
- **SACç®—æ³•å¥–åŠ±**ï¼š-1.683

### åœºæ™¯2: ä¼˜ç§€æ€§èƒ½
- **æŒ‡æ ‡**ï¼šæ—¶å»¶0.15s, èƒ½è€—800J
- **é€šç”¨ç®—æ³•å¥–åŠ±**ï¼š-1.260
- **SACç®—æ³•å¥–åŠ±**ï¼š-0.890 âœ¨ï¼ˆåŒ…å«bonusï¼‰

### åœºæ™¯3: è¾ƒå·®æ€§èƒ½
- **æŒ‡æ ‡**ï¼šæ—¶å»¶0.35s, èƒ½è€—3500J, 5ä¸ªä¸¢å¼ƒä»»åŠ¡
- **é€šç”¨ç®—æ³•å¥–åŠ±**ï¼š-5.583
- **SACç®—æ³•å¥–åŠ±**ï¼š-7.533

### å¥–åŠ±è¶‹åŠ¿éªŒè¯
```
ä¼˜ç§€ > æ­£å¸¸ > è¾ƒå·®: 0.15s < 0.20s < 0.35s âœ“
```

## ğŸ”§ ç®—æ³•ä»£ç ä¿®æ”¹

æ‰€æœ‰ç®—æ³•çš„ `calculate_reward` æ–¹æ³•å·²ç»Ÿä¸€ä¸ºï¼š

```python
def calculate_reward(self, system_metrics: Dict, 
                   cache_metrics: Optional[Dict] = None,
                   migration_metrics: Optional[Dict] = None) -> float:
    """ä½¿ç”¨ç»Ÿä¸€å¥–åŠ±è®¡ç®—å™¨"""
    from utils.unified_reward_calculator import calculate_unified_reward
    
    # é€šç”¨ç®—æ³•ç”¨ "general"ï¼ŒSACç”¨ "sac"
    return calculate_unified_reward(
        system_metrics, 
        cache_metrics, 
        migration_metrics, 
        algorithm="general"  # æˆ– "sac"
    )
```

## ğŸ“ æ–‡ä»¶æ¸…ç†

### å·²å¤‡ä»½çš„æ—§æ–‡ä»¶
- `utils/enhanced_reward_calculator.py.backup`
- `utils/sac_reward_calculator.py.backup`
- `utils/simple_reward_calculator.py.backup`

### æ–°å¢æ–‡ä»¶
- `utils/unified_reward_calculator.py` - **ç»Ÿä¸€å¥–åŠ±è®¡ç®—å™¨**
- `test_unified_reward.py` - æµ‹è¯•è„šæœ¬

## âœ… ä¼˜åŠ¿æ€»ç»“

### 1. **ç®€åŒ–ä¸èšç„¦**
- ä»3ä¸ªæŒ‡æ ‡ï¼ˆæ—¶å»¶+èƒ½è€—+æ•°æ®ä¸¢å¤±ï¼‰ç®€åŒ–ä¸º2ä¸ªæ ¸å¿ƒç›®æ ‡
- ç§»é™¤å†—ä½™çš„å­ç³»ç»Ÿå¥–åŠ±ï¼ˆç¼“å­˜ã€è¿ç§»ï¼‰ï¼Œèšç„¦ä¸»è¦ä¼˜åŒ–ç›®æ ‡

### 2. **ä¸€è‡´æ€§ä¿è¯**
- æ‰€æœ‰ç®—æ³•å…±äº«æ ¸å¿ƒå¥–åŠ±é€»è¾‘
- å‡å°‘ç»´æŠ¤æˆæœ¬å’Œæ½œåœ¨çš„ä¸ä¸€è‡´é—®é¢˜

### 3. **ç®—æ³•é€‚é…æ€§**
- SACä¿ç•™ä¸“é—¨è°ƒæ•´ä»¥é€‚åº”æœ€å¤§ç†µæ¡†æ¶
- å…¶ä»–ç®—æ³•ä½¿ç”¨ç»Ÿä¸€çš„æˆæœ¬æœ€å°åŒ–é€»è¾‘

### 4. **å‘åå…¼å®¹**
- ä¿ç•™æ‰€æœ‰æ—§æ¥å£ï¼Œç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹
- å¹³æ»‘è¿‡æ¸¡ï¼Œæ— ç ´åæ€§å˜æ›´

## ğŸš€ å¿«é€Ÿå¼€å§‹

### è¿è¡Œæµ‹è¯•
```bash
python test_unified_reward.py
```

### è®­ç»ƒç®—æ³•ï¼ˆä½¿ç”¨æ–°å¥–åŠ±å‡½æ•°ï¼‰
```bash
# TD3ç®—æ³•
python train_single_agent.py --algorithm TD3 --episodes 200

# SACç®—æ³•
python train_single_agent.py --algorithm SAC --episodes 200

# æ‰€æœ‰ç®—æ³•å¯¹æ¯”
python train_single_agent.py --compare --episodes 200
```

## ğŸ“š ç›¸å…³æ–‡æ¡£
- é…ç½®æ–‡ä»¶ï¼š`config/system_config.py` (å¥–åŠ±æƒé‡å®šä¹‰)
- ç®—æ³•å®ç°ï¼š`single_agent/*.py` (å„ç®—æ³•ä½¿ç”¨ç»Ÿä¸€å¥–åŠ±)
- è®­ç»ƒè„šæœ¬ï¼š`train_single_agent.py` (ä¸»è®­ç»ƒé€»è¾‘)

---

**æœ€åæ›´æ–°**ï¼š2025-10-02  
**ç»´æŠ¤è€…**ï¼šVECç³»ç»Ÿå¼€å‘å›¢é˜Ÿ

