"""
ç²¾ç®€ä¼˜åŒ–TD3 - ä»…åŒ…å«æœ€æœ‰æ•ˆçš„ä¸¤ä¸ªä¼˜åŒ–
Queue-aware Replay + GNN Attention

ä¸“ä¸ºVECåœºæ™¯ä¼˜åŒ–ï¼š
- é˜Ÿåˆ—æ„ŸçŸ¥å›æ”¾ï¼šå¿«é€Ÿå­¦ä¹ é«˜è´Ÿè½½åœºæ™¯
- GNNæ³¨æ„åŠ›ï¼šå¤§å¹…æå‡ç¼“å­˜å‘½ä¸­ç‡ï¼ˆ0.2%â†’24%ï¼‰

ä½œè€…ï¼šVEC_mig_caching Team
"""

from typing import Optional, Dict, Union, Any
import numpy as np

from .enhanced_td3_agent import EnhancedTD3Agent
from .enhanced_td3_config import EnhancedTD3Config


def create_optimized_config() -> EnhancedTD3Config:
    """åˆ›å»ºç²¾ç®€ä¼˜åŒ–é…ç½® - âœ¨ ä½¿ç”¨æœ€æ–°GATä¼˜åŒ–"""
    return EnhancedTD3Config(
        # âœ… æ ¸å¿ƒä¼˜åŒ–1ï¼šé˜Ÿåˆ—æ„ŸçŸ¥å›æ”¾
        use_queue_aware_replay=True,
        queue_priority_weight=0.5,  # ğŸ”§ æé«˜é˜Ÿåˆ—æƒé‡ 0.6 â†’ 0.5
        queue_occ_coef=0.5,
        packet_loss_coef=0.3,
        migration_cong_coef=0.2,
        queue_metrics_ema_decay=0.8,
        
        # âœ… æ ¸å¿ƒä¼˜åŒ–2ï¼šGNNæ³¨æ„åŠ›ï¼ˆæœ€æ–°ä¼˜åŒ–ï¼‰
        use_gat_router=True,
        num_attention_heads=6,  # ğŸ”§ å¢åŠ æ³¨æ„åŠ›å¤´æ•° 4 â†’ 6
        gat_hidden_dim=192,  # ğŸ”§ å¢å¤§éšè—å±‚ 128 â†’ 192
        gat_dropout=0.15,  # ğŸ”§ å¢åŠ dropout 0.1 â†’ 0.15
        
        # âŒ ç¦ç”¨å…¶ä»–ä¼˜åŒ–
        use_distributional_critic=False,
        use_entropy_reg=False,
        use_model_based_rollout=False,
        
        # ğŸ”§ åŸºç¡€å‚æ•°ä¼˜åŒ–
        hidden_dim=512,
        batch_size=640,  # ğŸ”§ å¢å¤§batch size 384 â†’ 640
        buffer_size=100000,
        
        # ğŸ”§ å­¦ä¹ ç‡ä¼˜åŒ–
        actor_lr=1.5e-4,  # ğŸ”§ è°ƒä½å­¦ä¹ ç‡ 2e-4 â†’ 1.5e-4
        critic_lr=2.5e-4,  # ğŸ”§ è°ƒä½å­¦ä¹ ç‡ 3e-4 â†’ 2.5e-4
        
        # ğŸ”§ æ¢ç´¢ç­–ç•¥ä¼˜åŒ–
        exploration_noise=0.20,  # ğŸ”§ æé«˜åˆå§‹å™ªå£° 0.15 â†’ 0.20
        noise_decay=0.9985,  # ğŸ”§ æ›´æ¸©å’Œçš„è¡°å‡ 0.9992 â†’ 0.9985
        min_noise=0.08,  # ğŸ”§ æé«˜æœ€å°å™ªå£° 0.05 â†’ 0.08
    )


class OptimizedTD3Wrapper:
    """
    ç²¾ç®€ä¼˜åŒ–TD3åŒ…è£…å™¨
    
    åªåŒ…å«æœ€æœ‰æ•ˆçš„ä¸¤ä¸ªä¼˜åŒ–ï¼š
    1. Queue-aware Replay - æå‡è®­ç»ƒæ•ˆç‡5å€
    2. GNN Attention - ç¼“å­˜å‘½ä¸­ç‡æå‡120å€
    """
    
    def __init__(
        self,
        num_vehicles: int = 12,
        num_rsus: int = 4,
        num_uavs: int = 2,
        use_central_resource: bool = True,
    ):
        self.num_vehicles = num_vehicles
        self.num_rsus = num_rsus
        self.num_uavs = num_uavs
        self.use_central_resource = use_central_resource
        
        # åˆ›å»ºä¼˜åŒ–é…ç½®
        config = create_optimized_config()
        
        # è®¡ç®—ç»´åº¦
        vehicle_state_dim = num_vehicles * 5  # è½¦è¾†ä¿æŒ5ç»´
        rsu_state_dim = num_rsus * 6  # ğŸ”§ RSUå¢åŠ åˆ°6ç»´ï¼ˆ+cpu_frequencyï¼‰
        uav_state_dim = num_uavs * 6  # ğŸ”§ UAVå¢åŠ åˆ°6ç»´ï¼ˆ+cpu_frequencyï¼‰
        global_state_dim = 8
        base_state_dim = vehicle_state_dim + rsu_state_dim + uav_state_dim + global_state_dim
        
        if use_central_resource:
            self.central_state_dim = 16
            # ğŸ”§ P0ä¿®å¤ï¼šæ­£ç¡®è®¡ç®—state_dimï¼ŒåŠ ä¸Šcentral_state_dim
            self.state_dim = base_state_dim + self.central_state_dim
        else:
            self.central_state_dim = 0
            self.state_dim = base_state_dim
        
        self.base_action_dim = 3 + num_rsus + num_uavs + 10
        
        if use_central_resource:
            self.central_resource_action_dim = num_vehicles + num_vehicles + num_rsus + num_uavs
            self.action_dim = self.base_action_dim + self.central_resource_action_dim
        else:
            self.central_resource_action_dim = 0
            self.action_dim = self.base_action_dim
        
        # åˆ›å»ºä¼˜åŒ–TD3æ™ºèƒ½ä½“
        self.agent = EnhancedTD3Agent(
            state_dim=self.state_dim,
            action_dim=self.action_dim,
            config=config,
            num_vehicles=num_vehicles,
            num_rsus=num_rsus,
            num_uavs=num_uavs,
            global_dim=global_state_dim,
            central_state_dim=self.central_state_dim,
        )
        
        print("[OptimizedTD3] init done")
        print(f"  topology: vehicles={num_vehicles}, rsus={num_rsus}, uavs={num_uavs}")
        print(f"  state_dim: {self.state_dim}")
        print(f"  action_dim: {self.action_dim}")
        print("  optimizations: Queue-aware Replay + GNN Attention")
        
        # ???????/??????????????
        self._last_queue_metrics = {
            'queue_occupancy': 0.0,
            'packet_loss': 0.0,
            'migration_congestion': 0.0,
        }
        self._queue_pressure_ema: Optional[float] = None
    
    def select_action(self, state: np.ndarray, training: bool = True) -> np.ndarray:
        return self.agent.select_action(state, training=training)
    
    def store_experience(
        self,
        state: np.ndarray,
        action: np.ndarray,
        reward: float,
        next_state: np.ndarray,
        done: bool,
        queue_metrics: Optional[dict] = None,
    ):
        self.agent.store_experience(state, action, reward, next_state, done, queue_metrics)
    
    def update(self) -> dict:
        return self.agent.update()
    
    def save_model(self, filepath: str) -> str:
        return self.agent.save_model(filepath)
    
    def save_models(self, filepath: str) -> str:
        return self.save_model(filepath)
    
    def load_model(self, filepath: str):
        self.agent.load_model(filepath)
    
    def load_models(self, filepath: str):
        self.load_model(filepath)
    
    def _extract_central_state(self, resource_state: Dict):
        """ä»resource_stateæå–ä¸­å¤®èµ„æºçŠ¶æ€"""
        central_state = []
        
        try:
            # å¸¦å®½åˆ†é…ç»Ÿè®¡
            bandwidth_alloc = resource_state.get('bandwidth_allocation', [])
            if isinstance(bandwidth_alloc, (list, np.ndarray)) and len(bandwidth_alloc) > 0:
                bw_array = np.array(bandwidth_alloc, dtype=np.float32)
                bw_array = np.nan_to_num(bw_array, nan=0.0)
                central_state.extend([
                    float(np.mean(bw_array)),
                    float(np.max(bw_array)),
                    float(np.min(bw_array)),
                    float(np.std(bw_array))
                ])
            else:
                central_state.extend([1.0/self.num_vehicles] * 4)
            
            # è½¦è¾†è®¡ç®—èµ„æº
            vehicle_compute = resource_state.get('vehicle_compute_allocation', [])
            if isinstance(vehicle_compute, (list, np.ndarray)) and len(vehicle_compute) > 0:
                vc_array = np.array(vehicle_compute, dtype=np.float32)
                vc_array = np.nan_to_num(vc_array, nan=0.0)
                central_state.extend([
                    float(np.mean(vc_array)),
                    float(np.max(vc_array)),
                    float(np.min(vc_array)),
                    float(np.std(vc_array))
                ])
            else:
                central_state.extend([1.0/self.num_vehicles] * 4)
            
            # RSUè®¡ç®—èµ„æº
            rsu_compute = resource_state.get('rsu_compute_allocation', [])
            if isinstance(rsu_compute, (list, np.ndarray)) and len(rsu_compute) >= self.num_rsus:
                rc_array = np.array(rsu_compute[:self.num_rsus], dtype=np.float32)
                rc_array = np.nan_to_num(rc_array, nan=1.0/self.num_rsus)
                central_state.extend([float(v) for v in rc_array])
            else:
                central_state.extend([1.0/self.num_rsus] * self.num_rsus)
            
            # UAVè®¡ç®—èµ„æº
            uav_compute = resource_state.get('uav_compute_allocation', [])
            if isinstance(uav_compute, (list, np.ndarray)) and len(uav_compute) >= self.num_uavs:
                uc_array = np.array(uav_compute[:self.num_uavs], dtype=np.float32)
                uc_array = np.nan_to_num(uc_array, nan=1.0/self.num_uavs)
                central_state.extend([float(v) for v in uc_array])
            else:
                central_state.extend([1.0/self.num_uavs] * self.num_uavs)
            
            while len(central_state) < 16:
                central_state.append(0.0)
            
            central_state = central_state[:16]
            
        except Exception as e:
            print(f"âš ï¸ ä¸­å¤®èµ„æºçŠ¶æ€æå–å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            central_state = [
                1.0/self.num_vehicles, 1.0/self.num_vehicles, 1.0/self.num_vehicles, 0.0,
                1.0/self.num_vehicles, 1.0/self.num_vehicles, 1.0/self.num_vehicles, 0.0,
                1.0/self.num_rsus, 1.0/self.num_rsus, 1.0/self.num_rsus, 1.0/self.num_rsus,
                1.0/self.num_uavs, 1.0/self.num_uavs, 0.0, 0.0
            ]
        
        central_state = [float(v) if np.isfinite(v) else 0.0 for v in central_state]
        return central_state
    
    def get_state_vector(
        self,
        node_states: Dict,
        system_metrics: Dict,
        resource_state: Optional[Dict] = None,
    ) -> np.ndarray:
        """æ„å»ºçŠ¶æ€å‘é‡"""
        state_components = []
        
        # èŠ‚ç‚¹çŠ¶æ€
        for i in range(self.num_vehicles):
            vehicle_key = f'vehicle_{i}'
            if vehicle_key in node_states:
                vehicle_state = node_states[vehicle_key][:5]  # è½¦è¾†ä¿æŒ5ç»´
                valid_state = [float(v) if np.isfinite(v) else 0.5 for v in vehicle_state]
                state_components.extend(valid_state)
            else:
                state_components.extend([0.5, 0.5, 0.0, 0.0, 0.0])
        
        for i in range(self.num_rsus):
            rsu_key = f'rsu_{i}'
            if rsu_key in node_states:
                rsu_state = node_states[rsu_key][:6]  # ğŸ”§ RSUç°åœ¨6ç»´ï¼ˆåŒ…æ‹¬cpu_frequencyï¼‰
                valid_state = [float(v) if np.isfinite(v) else 0.5 for v in rsu_state]
                state_components.extend(valid_state)
            else:
                state_components.extend([0.5, 0.5, 0.0, 0.0, 0.0, 0.625])  # é»˜è®¤cpu_freq=12.5/20=0.625
        
        for i in range(self.num_uavs):
            uav_key = f'uav_{i}'
            if uav_key in node_states:
                uav_state = node_states[uav_key][:6]  # ğŸ”§ UAVç°åœ¨6ç»´ï¼ˆåŒ…æ‹¬cpu_frequencyï¼‰
                valid_state = [float(v) if np.isfinite(v) else 0.5 for v in uav_state]
                state_components.extend(valid_state)
            else:
                state_components.extend([0.5, 0.5, 0.5, 0.0, 0.0, 0.25])  # é»˜è®¤cpu_freq=5.0/20=0.25
        
        # å…¨å±€çŠ¶æ€
        global_state = [
            float(system_metrics.get('avg_task_delay', 0.0) / 1.0),
            float(system_metrics.get('total_energy_consumption', 0.0) / 1000.0),
            float(system_metrics.get('task_completion_rate', 0.95)),
            float(system_metrics.get('cache_hit_rate', 0.85)),
            float(system_metrics.get('queue_overload_flag', 0.0)),
            float(system_metrics.get('rsu_offload_ratio', 0.5)),
            float(system_metrics.get('uav_offload_ratio', 0.2)),
            float(system_metrics.get('local_offload_ratio', 0.3)),
        ]
        global_state = [float(v) if np.isfinite(v) else 0.0 for v in global_state]
        state_components.extend(global_state)
        
        # ä¸­å¤®èµ„æºçŠ¶æ€
        if self.central_state_dim > 0 and resource_state is not None:
            central_state_vector = self._extract_central_state(resource_state)
            state_components.extend(central_state_vector)
        
        state_vector = np.array(state_components, dtype=np.float32)
        
        if np.any(np.isnan(state_vector)) or np.any(np.isinf(state_vector)):
            state_vector = np.nan_to_num(state_vector, nan=0.5, posinf=1.0, neginf=0.0)
        
        if state_vector.size < self.state_dim:
            padding_needed = self.state_dim - state_vector.size
            state_vector = np.pad(state_vector, (0, padding_needed), mode='constant', constant_values=0.5)
        elif state_vector.size > self.state_dim:
            state_vector = state_vector[:self.state_dim]
        
        return state_vector
    
    def calculate_reward(
        self,
        system_metrics: Dict,
        cache_metrics: Optional[Dict] = None,
        migration_metrics: Optional[Dict] = None
    ) -> float:
        """è®¡ç®—å¥–åŠ±"""
        from utils.unified_reward_calculator import calculate_unified_reward
        return calculate_unified_reward(system_metrics, cache_metrics, migration_metrics, algorithm="general")
    
    def get_actions(self, state: np.ndarray, training: bool = True) -> Dict:
        """è·å–åŠ¨ä½œ"""
        global_action = self.agent.select_action(state, training)
        actions = self.decompose_action(global_action)
        return actions
    
    def decompose_action(self, action: np.ndarray) -> Dict:
        """åˆ†è§£åŠ¨ä½œ"""
        actions = {}
        idx = 0
        
        base_segment = action[:self.base_action_dim]
        
        offload_preference = base_segment[:3]
        idx = 3
        
        rsu_selection = base_segment[idx:idx + self.num_rsus]
        idx += self.num_rsus
        
        uav_selection = base_segment[idx:idx + self.num_uavs]
        idx += self.num_uavs
        
        control_params = base_segment[idx:idx + 10]
        
        actions['vehicle_agent'] = action.copy()
        actions['rsu_agent'] = rsu_selection
        actions['uav_agent'] = uav_selection
        actions['control_params'] = control_params
        
        return actions

    # ================== è®­ç»ƒæ¥å£ & é˜Ÿåˆ—ä¿¡å· ================== #
    def update_queue_metrics(self, step_stats: Dict[str, Any]) -> None:
        """ä»stepç»Ÿè®¡ä¸­æå–é˜Ÿåˆ—/ä¸¢åŒ…ä¿¡å·ï¼Œé©±åŠ¨Queue-aware Replayã€‚"""
        try:
            # ğŸ”§ P1ä¿®å¤ï¼šæ”¹è¿›é˜Ÿåˆ—æŒ‡æ ‡æå–ï¼Œåˆ†èŠ‚ç‚¹ç±»å‹æå–
            # 1. è½¦è¾†çº§åˆ«é˜Ÿåˆ—å‹åŠ›
            vehicle_queue_pressure = []
            queue_rho_by_node = step_stats.get('queue_rho_by_node', {})
            if isinstance(queue_rho_by_node, dict):
                for node_key, rho_value in queue_rho_by_node.items():
                    if node_key.startswith('vehicle_'):
                        try:
                            vehicle_queue_pressure.append(float(rho_value))
                        except (TypeError, ValueError):
                            pass
            
            # 2. ç»¼åˆé˜Ÿåˆ—å‹åŠ›æŒ‡æ ‡
            queue_rho_max = float(step_stats.get('queue_rho_max', 0.0) or 0.0)
            queue_overload_flag = 1.0 if step_stats.get('queue_overload_flag', False) else 0.0
            
            # 3. è®¡ç®—å¹³å‡è½¦è¾†é˜Ÿåˆ—å‹åŠ›
            avg_vehicle_pressure = float(np.mean(vehicle_queue_pressure)) if vehicle_queue_pressure else 0.0
            
            # 4. ç»¼åˆé˜Ÿåˆ—å‹åŠ›ï¼šæœ€å¤§å€¼ + è½¦è¾†å¹³å‡ + è¿‡è½½æ ‡å¿—
            queue_occ = float(max(
                queue_rho_max,
                avg_vehicle_pressure,
                queue_overload_flag
            ))
            
            # 5. ä¸¢åŒ…ç‡æŒ‡æ ‡
            packet_loss = float(
                step_stats.get('data_loss_ratio_bytes', step_stats.get('packet_loss', 0.0)) or 0.0
            )
            
            # 6. è¿ç§»æ‹¥å¡æŒ‡æ ‡
            migration_cong = float(
                max(
                    step_stats.get('cache_eviction_rate', 0.0) or 0.0,
                    step_stats.get('migration_queue_pressure', 0.0) or 0.0,
                )
            )
        except Exception:
            queue_occ, packet_loss, migration_cong = 0.0, 0.0, 0.0
        
        queue_occ = float(np.clip(queue_occ, 0.0, 1.0))
        packet_loss = float(np.clip(packet_loss, 0.0, 1.0))
        migration_cong = float(np.clip(migration_cong, 0.0, 1.0))
        
        # å¹³æ»‘é˜Ÿåˆ—å‹åŠ›ï¼Œé¿å…æŠ–åŠ¨
        if self._queue_pressure_ema is None:
            self._queue_pressure_ema = queue_occ
        else:
            self._queue_pressure_ema = 0.8 * self._queue_pressure_ema + 0.2 * queue_occ
        queue_occ = float(np.clip(self._queue_pressure_ema, 0.0, 1.0))
        
        self._last_queue_metrics = {
            'queue_occupancy': queue_occ,
            'packet_loss': packet_loss,
            'migration_congestion': migration_cong,
        }

    def update_priority_signal(self, queue_pressure: Union[float, int]) -> None:
        """å…¼å®¹ä¸Šå±‚çš„é˜Ÿåˆ—å‹åŠ›æ¥å£ï¼Œç›´æ¥è½¬æˆé˜Ÿåˆ—å ç”¨ç‡ä¿¡å·ã€‚"""
        try:
            qp = float(queue_pressure)
        except Exception:
            qp = 0.0
        qp = float(np.clip(qp, 0.0, 1.0))
        self.update_queue_metrics({'queue_rho_max': qp})

    def train_step(
        self,
        state: np.ndarray,
        action: Union[np.ndarray, float, int],
        reward: float,
        next_state: np.ndarray,
        done: bool,
    ) -> Dict[str, Any]:
        """å•æ­¥è®­ç»ƒï¼šå†™å…¥ç»éªŒ + æ›´æ–°ç½‘ç»œ"""
        action_arr = np.asarray(action, dtype=np.float32)
        if action_arr.ndim > 1:
            action_arr = action_arr.flatten()
        
        # ä½¿ç”¨æœ€æ–°çš„é˜Ÿåˆ—æŒ‡æ ‡é©±åŠ¨ä¼˜å…ˆçº§é‡‡æ ·
        self.store_experience(state, action_arr, reward, next_state, done, self._last_queue_metrics)
        training_info = self.update()
        return training_info


# åˆ«å
OptimizedTD3Environment = OptimizedTD3Wrapper
