"""
ç²¾ç®€ä¼˜åŒ–TD3 - ä»…åŒ…å«æœ€æœ‰æ•ˆçš„ä¸¤ä¸ªä¼˜åŒ–
Queue-aware Replay + GNN Attention

ä¸“ä¸ºVECåœºæ™¯ä¼˜åŒ–ï¼š
- é˜Ÿåˆ—æ„ŸçŸ¥å›æ”¾ï¼šå¿«é€Ÿå­¦ä¹ é«˜è´Ÿè½½åœºæ™¯
- GNNæ³¨æ„åŠ›ï¼šå¤§å¹…æå‡ç¼“å­˜å‘½ä¸­ç‡ï¼ˆ0.2%â†’24%ï¼‰

ä½œè€…ï¼šVEC_mig_caching Team
"""

from typing import Optional, Dict, Union, Any
import numpy as np
from scipy.special import softmax

from .enhanced_td3_agent import EnhancedTD3Agent
from .enhanced_td3_config import EnhancedTD3Config
from .common_state_action import (
    UnifiedStateActionSpace,
    ACTION_DIM_OFFLOAD_PREF,
    ACTION_DIM_CONTROL_PARAMS,
    CENTRAL_VEHICLE_GROUPS,
    CENTRAL_RSU_AGGREGATE,
    CENTRAL_UAV_AGGREGATE,
    STATE_DIM_PER_VEHICLE,
    STATE_DIM_PER_RSU,
    STATE_DIM_PER_UAV,
    STATE_DIM_GLOBAL,
    STATE_DIM_CENTRAL,
)


def create_optimized_config() -> EnhancedTD3Config:
    """åˆ›å»ºç²¾ç®€ä¼˜åŒ–é…ç½® - âœ¨ ä½¿ç”¨æœ€æ–°GATä¼˜åŒ–
    
    ğŸ”§ 2024-12-02 v3ä¿®å¤ï¼šå¢å¼ºæ¢ç´¢+å­¦ä¹ ç‡ä¼˜åŒ–
    æ ¸å¿ƒä¿®å¤ï¼š
    1. å¢åŠ åˆå§‹æ¢ç´¢å™ªå£° 0.15 â†’ 0.25 (æ›´å¼ºçš„åˆå§‹æ¢ç´¢)
    2. åŠ å¿«å™ªå£°è¡°å‡ 0.9995 â†’ 0.999 (æ›´å¿«æ”¶æ•›)
    3. æé«˜Criticå­¦ä¹ ç‡ 3e-4 â†’ 5e-4 (åŠ å¿«å€¼å‡½æ•°å­¦ä¹ )
    4. å¢åŠ æ¢¯åº¦æ›´æ–°æ¬¡æ•°
    """
    return EnhancedTD3Config(
        # âœ… æ ¸å¿ƒä¼˜åŒ–1ï¼šé˜Ÿåˆ—æ„ŸçŸ¥å›æ”¾
        use_queue_aware_replay=True,
        queue_priority_weight=0.2,
        queue_occ_coef=0.5,
        packet_loss_coef=0.3,
        migration_cong_coef=0.2,
        queue_metrics_ema_decay=0.8,
        
        # âœ… æ ¸å¿ƒä¼˜åŒ–2ï¼šGNNæ³¨æ„åŠ›
        use_gat_router=True,
        num_attention_heads=6,
        gat_hidden_dim=192,
        gat_dropout=0.15,

        # âŒ ç¦ç”¨å…¶ä»–ä¼˜åŒ–
        use_distributional_critic=False,
        use_entropy_reg=False,
        use_model_based_rollout=False,

        # ğŸ”§ åŸºç¡€å‚æ•°ä¼˜åŒ–
        hidden_dim=384,
        batch_size=512,
        buffer_size=100000,
        warmup_steps=3000,    # ğŸ”§ 5000 â†’ 3000 (æ›´å¿«å¼€å§‹å­¦ä¹ )

        # ğŸ”§ å­¦ä¹ ç‡ä¼˜åŒ– - åŠ å¿«Criticå­¦ä¹ 
        actor_lr=1e-4,
        critic_lr=5e-4,       # ğŸ”§ 3e-4 â†’ 5e-4 (åŠ å¿«Qç½‘ç»œå­¦ä¹ )

        # ğŸ”§ æ¢ç´¢å™ªå£°ä¼˜åŒ– - æ›´å¼ºçš„åˆå§‹æ¢ç´¢ï¼Œæ›´å¿«çš„è¡°å‡
        exploration_noise=0.25,   # ğŸ”§ 0.15 â†’ 0.25 (æ›´å¼ºçš„åˆå§‹æ¢ç´¢)
        noise_decay=0.999,        # ğŸ”§ 0.9995 â†’ 0.999 (æ›´å¿«è¡°å‡)
        min_noise=0.03,           # ğŸ”§ 0.02 â†’ 0.03 (ä¿æŒæœ€ä½æ¢ç´¢)
        target_noise=0.05,        # ğŸ”§ 0.03 â†’ 0.05 (é€‚å½“çš„ç›®æ ‡å™ªå£°)
        noise_clip=0.15,          # ğŸ”§ 0.1 â†’ 0.15 (å¢å¤§è£å‰ªèŒƒå›´)

        # ğŸ”§ å¥–åŠ±å½’ä¸€åŒ–
        reward_norm_beta=0.995,
        reward_norm_clip=5.0,
    )


class OptimizedTD3Wrapper:
    """
    ç²¾ç®€ä¼˜åŒ–TD3åŒ…è£…å™¨
    
    åªåŒ…å«æœ€æœ‰æ•ˆçš„ä¸¤ä¸ªä¼˜åŒ–ï¼š
    1. Queue-aware Replay - æå‡è®­ç»ƒæ•ˆç‡5å€
    2. GNN Attention - ç¼“å­˜å‘½ä¸­ç‡æå‡120å€
    """
    
    def __init__(
        self,
        num_vehicles: int = 12,
        num_rsus: int = 4,
        num_uavs: int = 2,
        use_central_resource: bool = True,
        simulation_only: bool = False,
    ):
        self.num_vehicles = num_vehicles
        self.num_rsus = num_rsus
        self.num_uavs = num_uavs
        self.use_central_resource = use_central_resource
        self.simulation_only = simulation_only
        
        # åˆ›å»ºä¼˜åŒ–é…ç½®
        config = create_optimized_config()
        
        # è®¡ç®—ç»´åº¦ - ä½¿ç”¨ç»Ÿä¸€å¸¸é‡
        vehicle_state_dim = num_vehicles * STATE_DIM_PER_VEHICLE  # è½¦è¾†ä¿æŒ5ç»´
        rsu_state_dim = num_rsus * STATE_DIM_PER_RSU  # RSUç»Ÿä¸€ä¸º5ç»´
        uav_state_dim = num_uavs * STATE_DIM_PER_UAV  # UAVç»Ÿä¸€ä¸º5ç»´
        global_state_dim = STATE_DIM_GLOBAL
        base_state_dim = vehicle_state_dim + rsu_state_dim + uav_state_dim + global_state_dim
        
        if use_central_resource:
            self.central_state_dim = STATE_DIM_CENTRAL
            self.state_dim = base_state_dim + self.central_state_dim
        else:
            self.central_state_dim = 0
            self.state_dim = base_state_dim
        
        # åŠ¨ä½œç©ºé—´é…ç½® - ä½¿ç”¨ç»Ÿä¸€å¸¸é‡
        import os
        self.simplified_action = os.environ.get('SIMPLIFIED_ACTION', '0').strip() in {'1', 'true', 'True'}
        if self.simplified_action:
            self.base_action_dim = 8  # ç®€åŒ–ç‰ˆï¼šåªä¿ç•™æ ¸å¿ƒæ§åˆ¶
            print("[OptimizedTD3] ğŸ”§ ç®€åŒ–åŠ¨ä½œç©ºé—´å·²å¯ç”¨ (8ç»´åŸºç¡€åŠ¨ä½œ)")
        else:
            # åŸå§‹ç‰ˆï¼šä½¿ç”¨ç»Ÿä¸€è®¡ç®—å‡½æ•°
            self.base_action_dim = UnifiedStateActionSpace.calculate_action_dim(num_rsus, num_uavs, include_central=False)
        
        if use_central_resource:
            # ä¸­å¤®èµ„æºåˆ†é…æ¨¡å¼
            self.aggregated_central = os.environ.get('AGGREGATED_CENTRAL', '1').strip() in {'1', 'true', 'True'}
            
            if self.aggregated_central:
                # èšåˆæ¨¡å¼ï¼šä½¿ç”¨ç»Ÿä¸€å¸¸é‡
                self.num_vehicle_groups = CENTRAL_VEHICLE_GROUPS
                self.central_resource_action_dim = CENTRAL_VEHICLE_GROUPS + CENTRAL_RSU_AGGREGATE + CENTRAL_UAV_AGGREGATE
                print(f"[OptimizedTD3] ğŸ”§ èšåˆä¸­å¤®èµ„æºæ¨¡å¼ ({self.central_resource_action_dim}ç»´)")
            else:
                # åŸå§‹æ¨¡å¼
                self.num_vehicle_groups = num_vehicles
                self.central_resource_action_dim = num_vehicles + num_vehicles + num_rsus + num_uavs
            
            self.action_dim = self.base_action_dim + self.central_resource_action_dim
        else:
            self.central_resource_action_dim = 0
            self.aggregated_central = False
            self.num_vehicle_groups = num_vehicles
            self.action_dim = self.base_action_dim
        
        # å¦‚æœåªæ˜¯ä»¿çœŸè¿›ç¨‹ï¼Œè·³è¿‡åŠ è½½æ²‰é‡çš„ç¥ç»ç½‘ç»œ
        if simulation_only:
            self.agent = None
            print("[OptimizedTD3] Simulation-only mode initialized (No Agent Loaded)")
            return

        # åˆ›å»ºä¼˜åŒ–TD3æ™ºèƒ½ä½“
        self.agent = EnhancedTD3Agent(
            state_dim=self.state_dim,
            action_dim=self.action_dim,
            config=config,
            num_vehicles=num_vehicles,
            num_rsus=num_rsus,
            num_uavs=num_uavs,
            global_dim=global_state_dim,
            central_state_dim=self.central_state_dim,
        )
        
        print("[OptimizedTD3] init done")
        print(f"  topology: vehicles={num_vehicles}, rsus={num_rsus}, uavs={num_uavs}")
        print(f"  state_dim: {self.state_dim}")
        print(f"  action_dim: {self.action_dim}")
        print("  optimizations: Queue-aware Replay + GNN Attention")
        
        # ???????/??????????????
        self._last_queue_metrics = {
            'queue_occupancy': 0.0,
            'packet_loss': 0.0,
            'migration_congestion': 0.0,
        }
        self._queue_pressure_ema: Optional[float] = None
    
    def select_action(self, state: np.ndarray, training: bool = True) -> np.ndarray:
        if self.agent is None:
            # Simulation-only mode: return random action or zeros
            # This shouldn't be called in worker process usually, as actions come from main process
            return np.zeros(self.action_dim, dtype=np.float32)
        return self.agent.select_action(state, training=training)
    
    def store_experience(
        self,
        state: np.ndarray,
        action: np.ndarray,
        reward: float,
        next_state: np.ndarray,
        done: bool,
        queue_metrics: Optional[dict] = None,
    ):
        self.agent.store_experience(state, action, reward, next_state, done, queue_metrics)
    
    def update(self) -> dict:
        return self.agent.update()
    
    def save_model(self, filepath: str) -> str:
        return self.agent.save_model(filepath)
    
    def save_models(self, filepath: str) -> str:
        return self.save_model(filepath)
    
    def load_model(self, filepath: str):
        self.agent.load_model(filepath)
    
    def load_models(self, filepath: str):
        self.load_model(filepath)
    
    def _extract_central_state(self, resource_state: Dict):
        """ä»resource_stateæå–ä¸­å¤®èµ„æºçŠ¶æ€"""
        central_state = []
        
        try:
            # å¸¦å®½åˆ†é…ç»Ÿè®¡
            bandwidth_alloc = resource_state.get('bandwidth_allocation', [])
            if isinstance(bandwidth_alloc, (list, np.ndarray)) and len(bandwidth_alloc) > 0:
                bw_array = np.array(bandwidth_alloc, dtype=np.float32)
                bw_array = np.nan_to_num(bw_array, nan=0.0)
                central_state.extend([
                    float(np.mean(bw_array)),
                    float(np.max(bw_array)),
                    float(np.min(bw_array)),
                    float(np.std(bw_array))
                ])
            else:
                central_state.extend([1.0/self.num_vehicles] * 4)
            
            # è½¦è¾†è®¡ç®—èµ„æº
            vehicle_compute = resource_state.get('vehicle_compute_allocation', [])
            if isinstance(vehicle_compute, (list, np.ndarray)) and len(vehicle_compute) > 0:
                vc_array = np.array(vehicle_compute, dtype=np.float32)
                vc_array = np.nan_to_num(vc_array, nan=0.0)
                central_state.extend([
                    float(np.mean(vc_array)),
                    float(np.max(vc_array)),
                    float(np.min(vc_array)),
                    float(np.std(vc_array))
                ])
            else:
                central_state.extend([1.0/self.num_vehicles] * 4)
            
            # RSUè®¡ç®—èµ„æº
            rsu_compute = resource_state.get('rsu_compute_allocation', [])
            if isinstance(rsu_compute, (list, np.ndarray)) and len(rsu_compute) >= self.num_rsus:
                rc_array = np.array(rsu_compute[:self.num_rsus], dtype=np.float32)
                rc_array = np.nan_to_num(rc_array, nan=1.0/self.num_rsus)
                central_state.extend([float(v) for v in rc_array])
            else:
                central_state.extend([1.0/self.num_rsus] * self.num_rsus)
            
            # UAVè®¡ç®—èµ„æº
            uav_compute = resource_state.get('uav_compute_allocation', [])
            if isinstance(uav_compute, (list, np.ndarray)) and len(uav_compute) >= self.num_uavs:
                uc_array = np.array(uav_compute[:self.num_uavs], dtype=np.float32)
                uc_array = np.nan_to_num(uc_array, nan=1.0/self.num_uavs)
                central_state.extend([float(v) for v in uc_array])
            else:
                central_state.extend([1.0/self.num_uavs] * self.num_uavs)
            
            while len(central_state) < 16:
                central_state.append(0.0)
            
            central_state = central_state[:16]
            
        except Exception as e:
            print(f"âš ï¸ ä¸­å¤®èµ„æºçŠ¶æ€æå–å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            central_state = [
                1.0/self.num_vehicles, 1.0/self.num_vehicles, 1.0/self.num_vehicles, 0.0,
                1.0/self.num_vehicles, 1.0/self.num_vehicles, 1.0/self.num_vehicles, 0.0,
                1.0/self.num_rsus, 1.0/self.num_rsus, 1.0/self.num_rsus, 1.0/self.num_rsus,
                1.0/self.num_uavs, 1.0/self.num_uavs, 0.0, 0.0
            ]
        
        central_state = [float(v) if np.isfinite(v) else 0.0 for v in central_state]
        return central_state
    
    def get_state_vector(
        self,
        node_states: Dict,
        system_metrics: Dict,
        resource_state: Optional[Dict] = None,
    ) -> np.ndarray:
        """æ„å»ºçŠ¶æ€å‘é‡"""
        state_components = []
        
        # èŠ‚ç‚¹çŠ¶æ€
        for i in range(self.num_vehicles):
            vehicle_key = f'vehicle_{i}'
            if vehicle_key in node_states:
                vehicle_state = node_states[vehicle_key][:5]  # è½¦è¾†ä¿æŒ5ç»´
                valid_state = [float(v) if np.isfinite(v) else 0.5 for v in vehicle_state]
                state_components.extend(valid_state)
            else:
                state_components.extend([0.5, 0.5, 0.0, 0.0, 0.0])
        
        for i in range(self.num_rsus):
            rsu_key = f'rsu_{i}'
            if rsu_key in node_states:
                rsu_state = node_states[rsu_key][:5]  # ğŸ”§ ä¿®å¤2ï¼šRSUç»Ÿä¸€ä¸º5ç»´
                valid_state = [float(v) if np.isfinite(v) else 0.5 for v in rsu_state]
                state_components.extend(valid_state)
            else:
                state_components.extend([0.5, 0.5, 0.0, 0.0, 0.0])  # é»˜è®¤5ç»´
        
        for i in range(self.num_uavs):
            uav_key = f'uav_{i}'
            if uav_key in node_states:
                uav_state = node_states[uav_key][:5]  # ğŸ”§ ä¿®å¤2ï¼šUAVç»Ÿä¸€ä¸º5ç»´
                valid_state = [float(v) if np.isfinite(v) else 0.5 for v in uav_state]
                state_components.extend(valid_state)
            else:
                state_components.extend([0.5, 0.5, 0.5, 0.0, 0.0])  # é»˜è®¤5ç»´ï¼ˆé«˜åº¦ç»´åº¦å·²åŒ…å«ï¼‰
        
        # å…¨å±€çŠ¶æ€
        # ğŸ”§ P0ä¿®å¤ï¼šå½’ä¸€åŒ–å› å­å¿…é¡»ä¸UnifiedRewardCalculatorä¸¥æ ¼å¯¹é½
        # ä»é…ç½®è¯»å–ç›®æ ‡å€¼ï¼Œç¡®ä¿çŠ¶æ€å½’ä¸€åŒ–ä¸å¥–åŠ±è®¡ç®—ä½¿ç”¨ç›¸åŒåŸºå‡†
        # ğŸ”§ 2024-12-02 ä¿®å¤ï¼šé»˜è®¤å€¼å¯¹é½å®é™…ç³»ç»Ÿæ€§èƒ½
        from config import config
        latency_target = float(getattr(config.rl, 'latency_target', 1.5))     # ğŸ”§ 0.4 â†’ 1.5 (å¯¹é½å®é™…å»¶è¿Ÿ)
        energy_target = float(getattr(config.rl, 'energy_target', 1000.0))    # ğŸ”§ 3500 â†’ 1000 (å¯¹é½å®é™…èƒ½è€—)
        
        global_state = [
            float(system_metrics.get('avg_task_delay', 0.0) / max(latency_target, 1e-6)),
            float(system_metrics.get('total_energy_consumption', 0.0) / max(energy_target, 1e-6)),
            float(system_metrics.get('task_completion_rate', 0.95)),
            float(system_metrics.get('cache_hit_rate', 0.85)),
            float(system_metrics.get('queue_overload_flag', 0.0)),
            float(system_metrics.get('rsu_offload_ratio', 0.5)),
            float(system_metrics.get('uav_offload_ratio', 0.2)),
            float(system_metrics.get('local_offload_ratio', 0.3)),
        ]
        global_state = [float(v) if np.isfinite(v) else 0.0 for v in global_state]
        state_components.extend(global_state)
        
        # ä¸­å¤®èµ„æºçŠ¶æ€
        if self.central_state_dim > 0 and resource_state is not None:
            central_state_vector = self._extract_central_state(resource_state)
            state_components.extend(central_state_vector)
        
        state_vector = np.array(state_components, dtype=np.float32)
        
        if np.any(np.isnan(state_vector)) or np.any(np.isinf(state_vector)):
            state_vector = np.nan_to_num(state_vector, nan=0.5, posinf=1.0, neginf=0.0)
        
        if state_vector.size < self.state_dim:
            padding_needed = self.state_dim - state_vector.size
            state_vector = np.pad(state_vector, (0, padding_needed), mode='constant', constant_values=0.5)
        elif state_vector.size > self.state_dim:
            state_vector = state_vector[:self.state_dim]
            
        return state_vector
    
    def calculate_reward(
        self,
        system_metrics: Dict,
        cache_metrics: Optional[Dict] = None,
        migration_metrics: Optional[Dict] = None
    ) -> tuple[float, Dict[str, float]]:
        """
        è®¡ç®—å¥–åŠ±å¹¶è¿”å›ç»„ä»¶å­—å…¸
        
        ä½¿ç”¨ç»Ÿä¸€å¥–åŠ±è®¡ç®—å™¨ç¡®ä¿ä¸€è‡´æ€§ã€‚
        å½’ä¸€åŒ–åŸºå‡†è‡ªåŠ¨ä¸çŠ¶æ€å½’ä¸€åŒ–å¯¹é½ï¼ˆé€šè¿‡config.rl.latency_targetå’Œenergy_targetï¼‰ã€‚
        
        Returns:
            tuple: (reward, reward_components)
        """
        from utils.unified_reward_calculator import _general_reward_calculator
        return _general_reward_calculator.calculate_reward(system_metrics, cache_metrics, migration_metrics)
    
    def get_actions(self, state: np.ndarray, training: bool = True) -> Dict:
        """è·å–åŠ¨ä½œ"""
        global_action = self.agent.select_action(state, training)
        actions = self.decompose_action(global_action)
        return actions
    
    def decompose_action(self, action: np.ndarray) -> Dict:
        """åˆ†è§£åŠ¨ä½œ"""
        actions = {}
        
        # 1. åŸºç¡€åŠ¨ä½œ (Offload + RSU/UAV Selection + Control Params)
        base_segment = action[:self.base_action_dim]
        
        # ğŸ”§ ç®€åŒ–åŠ¨ä½œå¤„ç†ï¼š8ç»´ â†’ å±•å¼€ä¸ºå®Œæ•´æ ¼å¼
        if self.simplified_action:
            # ç®€åŒ–åŠ¨ä½œç»“æ„ (8ç»´):
            # [0:3] å¸è½½åå¥½ (local, rsu, uav)
            # [3]   RSUèšåˆæƒé‡ (å¹¿æ’­åˆ°æ‰€æœ‰RSU)
            # [4]   UAVèšåˆæƒé‡ (å¹¿æ’­åˆ°æ‰€æœ‰UAV)
            # [5:8] æ ¸å¿ƒæ§åˆ¶å‚æ•° (ç¼“å­˜æ¿€è¿›åº¦, è¿ç§»å€¾å‘, è´Ÿè½½å‡è¡¡)
            offload_preference = base_segment[:3]
            rsu_aggregate = float(base_segment[3]) if len(base_segment) > 3 else 0.0
            uav_aggregate = float(base_segment[4]) if len(base_segment) > 4 else 0.0
            core_control = base_segment[5:8] if len(base_segment) > 5 else np.zeros(3)
            
            # å¹¿æ’­åˆ°æ‰€æœ‰RSU/UAV
            rsu_selection = np.full(self.num_rsus, rsu_aggregate, dtype=np.float32)
            uav_selection = np.full(self.num_uavs, uav_aggregate, dtype=np.float32)
            # æ‰©å±•æ ¸å¿ƒæ§åˆ¶åˆ°10ç»´
            control_params = np.zeros(10, dtype=np.float32)
            control_params[:len(core_control)] = core_control
        else:
            # åŸå§‹åŠ¨ä½œå¤„ç† (19ç»´)
            offload_preference = base_segment[:3]
            idx = 3
            rsu_selection = base_segment[idx:idx + self.num_rsus]
            idx += self.num_rsus
            uav_selection = base_segment[idx:idx + self.num_uavs]
            idx += self.num_uavs
            control_params = base_segment[idx:idx + 10]
        
        actions['vehicle_agent'] = action.copy() # ä¿ç•™åŸå§‹å®Œæ•´åŠ¨ä½œä¾›å‚è€ƒ
        actions['offload_preference'] = {
            'local': float(offload_preference[0]),
            'rsu': float(offload_preference[1]),
            'uav': float(offload_preference[2])
        }
        actions['rsu_agent'] = rsu_selection
        actions['uav_agent'] = uav_selection
        actions['control_params'] = control_params
        
        # 2. ğŸ”§ ä¿®å¤ï¼šæå–ä¸­å¤®èµ„æºåŠ¨ä½œ (Central Resource Allocation)
        if self.use_central_resource:
            # actionçš„ååŠéƒ¨åˆ†æ˜¯ä¸­å¤®èµ„æºåŠ¨ä½œ
            central_segment = action[self.base_action_dim:]
            
            expected_len = self.central_resource_action_dim
            if len(central_segment) >= expected_len:
                
                if self.aggregated_central:
                    # ğŸ”§ èšåˆæ¨¡å¼ï¼š7ç»´ â†’ å±•å¼€ä¸ºå®Œæ•´èµ„æºåˆ†é…
                    # [0:4] 4ç»„è½¦è¾†èµ„æºåˆ†é…
                    # [4:6] 2ä¸ªRSUèšåˆæƒé‡
                    # [6]   1ä¸ªUAVèšåˆæƒé‡
                    c_idx = 0
                    group_weights = central_segment[c_idx:c_idx + self.num_vehicle_groups]  # 4ç»´
                    c_idx += self.num_vehicle_groups
                    rsu_weights = central_segment[c_idx:c_idx + 2]  # 2ç»´
                    c_idx += 2
                    uav_weight = float(central_segment[c_idx]) if c_idx < len(central_segment) else 0.0  # 1ç»´
                    
                    # å°†ç»„æƒé‡å¹¿æ’­åˆ°æ¯è¾†è½¦ (4ç»„ â†’ 12è½¦)
                    vehicles_per_group = self.num_vehicles // self.num_vehicle_groups
                    bw_alloc = np.zeros(self.num_vehicles, dtype=np.float32)
                    comp_alloc = np.zeros(self.num_vehicles, dtype=np.float32)
                    for g in range(self.num_vehicle_groups):
                        start_v = g * vehicles_per_group
                        end_v = min(start_v + vehicles_per_group, self.num_vehicles)
                        group_w = float(group_weights[g]) if g < len(group_weights) else 0.0
                        bw_alloc[start_v:end_v] = group_w
                        comp_alloc[start_v:end_v] = group_w  # å¸¦å®½å’Œè®¡ç®—å…±äº«æƒé‡
                    
                    # å°†RSUæƒé‡å¹¿æ’­ (2 â†’ 4 RSUs)
                    rsu_alloc = np.zeros(self.num_rsus, dtype=np.float32)
                    rsus_per_group = max(1, self.num_rsus // 2)
                    for r in range(self.num_rsus):
                        group_idx = min(r // rsus_per_group, 1)
                        rsu_alloc[r] = float(rsu_weights[group_idx]) if group_idx < len(rsu_weights) else 0.0
                    
                    # UAVç»Ÿä¸€æƒé‡
                    uav_alloc = np.full(self.num_uavs, uav_weight, dtype=np.float32)
                    
                else:
                    # åŸå§‹æ¨¡å¼ï¼š30ç»´å®Œæ•´åˆ†é…
                    c_idx = 0
                    bw_alloc = central_segment[c_idx:c_idx + self.num_vehicles]
                    c_idx += self.num_vehicles
                    comp_alloc = central_segment[c_idx:c_idx + self.num_vehicles]
                    c_idx += self.num_vehicles
                    rsu_alloc = central_segment[c_idx:c_idx + self.num_rsus]
                    c_idx += self.num_rsus
                    uav_alloc = central_segment[c_idx:c_idx + self.num_uavs]
                
                actions['central_resource'] = {
                    'bandwidth_weights': softmax(bw_alloc),
                    'compute_weights': softmax(comp_alloc),
                    'rsu_reservation': softmax(rsu_alloc),
                    'uav_reservation': softmax(uav_alloc)
                }
            else:
                print(f"âš ï¸ åŠ¨ä½œç»´åº¦è­¦å‘Š: Central segment len {len(central_segment)} < expected {expected_len}")
                actions['central_resource'] = None
        
        return actions

    # ================== è®­ç»ƒæ¥å£ & é˜Ÿåˆ—ä¿¡å· ================== #
    def update_queue_metrics(self, step_stats: Dict[str, Any]) -> None:
        """ä»stepç»Ÿè®¡ä¸­æå–é˜Ÿåˆ—/ä¸¢åŒ…ä¿¡å·ï¼Œé©±åŠ¨Queue-aware Replayã€‚"""
        try:
            # ğŸ”§ P1ä¿®å¤ï¼šæ”¹è¿›é˜Ÿåˆ—æŒ‡æ ‡æå–ï¼Œåˆ†èŠ‚ç‚¹ç±»å‹æå–
            # 1. è½¦è¾†çº§åˆ«é˜Ÿåˆ—å‹åŠ›
            vehicle_queue_pressure = []
            queue_rho_by_node = step_stats.get('queue_rho_by_node', {})
            if isinstance(queue_rho_by_node, dict):
                for node_key, rho_value in queue_rho_by_node.items():
                    if node_key.startswith('vehicle_'):
                        try:
                            vehicle_queue_pressure.append(float(rho_value))
                        except (TypeError, ValueError):
                            pass
            
            # 2. ç»¼åˆé˜Ÿåˆ—å‹åŠ›æŒ‡æ ‡
            queue_rho_max = float(step_stats.get('queue_rho_max', 0.0) or 0.0)
            queue_overload_flag = 1.0 if step_stats.get('queue_overload_flag', False) else 0.0
            
            # 3. è®¡ç®—å¹³å‡è½¦è¾†é˜Ÿåˆ—å‹åŠ›
            avg_vehicle_pressure = float(np.mean(vehicle_queue_pressure)) if vehicle_queue_pressure else 0.0
            
            # 4. ç»¼åˆé˜Ÿåˆ—å‹åŠ›ï¼šæœ€å¤§å€¼ + è½¦è¾†å¹³å‡ + è¿‡è½½æ ‡å¿—
            queue_occ = float(max(
                queue_rho_max,
                avg_vehicle_pressure,
                queue_overload_flag
            ))
            
            # 5. ä¸¢åŒ…ç‡æŒ‡æ ‡
            packet_loss = float(
                step_stats.get('data_loss_ratio_bytes', step_stats.get('packet_loss', 0.0)) or 0.0
            )
            
            # 6. è¿ç§»æ‹¥å¡æŒ‡æ ‡
            migration_cong = float(
                max(
                    step_stats.get('cache_eviction_rate', 0.0) or 0.0,
                    step_stats.get('migration_queue_pressure', 0.0) or 0.0,
                )
            )
        except Exception:
            queue_occ, packet_loss, migration_cong = 0.0, 0.0, 0.0
        
        queue_occ = float(np.clip(queue_occ, 0.0, 1.0))
        packet_loss = float(np.clip(packet_loss, 0.0, 1.0))
        migration_cong = float(np.clip(migration_cong, 0.0, 1.0))
        
        # å¹³æ»‘é˜Ÿåˆ—å‹åŠ›ï¼Œé¿å…æŠ–åŠ¨
        if self._queue_pressure_ema is None:
            self._queue_pressure_ema = queue_occ
        else:
            self._queue_pressure_ema = 0.8 * self._queue_pressure_ema + 0.2 * queue_occ
        queue_occ = float(np.clip(self._queue_pressure_ema, 0.0, 1.0))
        
        self._last_queue_metrics = {
            'queue_occupancy': queue_occ,
            'packet_loss': packet_loss,
            'migration_congestion': migration_cong,
        }

    def update_priority_signal(self, queue_pressure: Union[float, int]) -> None:
        """å…¼å®¹ä¸Šå±‚çš„é˜Ÿåˆ—å‹åŠ›æ¥å£ï¼Œç›´æ¥è½¬æˆé˜Ÿåˆ—å ç”¨ç‡ä¿¡å·ã€‚"""
        try:
            qp = float(queue_pressure)
        except Exception:
            qp = 0.0
        qp = float(np.clip(qp, 0.0, 1.0))
        self.update_queue_metrics({'queue_rho_max': qp})

    def train_step(
        self,
        state: np.ndarray,
        action: Union[np.ndarray, float, int],
        reward: float,
        next_state: np.ndarray,
        done: bool,
    ) -> Dict[str, Any]:
        """å•æ­¥è®­ç»ƒï¼šå†™å…¥ç»éªŒ + æ›´æ–°ç½‘ç»œ"""
        action_arr = np.asarray(action, dtype=np.float32)
        if action_arr.ndim > 1:
            action_arr = action_arr.flatten()
        
        # ä½¿ç”¨æœ€æ–°çš„é˜Ÿåˆ—æŒ‡æ ‡é©±åŠ¨ä¼˜å…ˆçº§é‡‡æ ·
        self.store_experience(state, action_arr, reward, next_state, done, self._last_queue_metrics)
        training_info = self.update()
        return training_info


# åˆ«å
OptimizedTD3Environment = OptimizedTD3Wrapper
