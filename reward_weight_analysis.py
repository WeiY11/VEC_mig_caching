#!/usr/bin/env python3
"""
ç»Ÿä¸€å¥–åŠ±è®¡ç®—å™¨æƒé‡é…ç½®æ·±åº¦åˆ†æ
åˆ†æè®­ç»ƒç»“æœ training_results_20251202_005655.json (800 episodes, ä¼˜åŒ–å)
"""

import json
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')

# è¯»å–è®­ç»ƒç»“æœ
results_file = 'D:/VEC_mig_caching/results/single_agent/optimized_td3/training_results_20251202_005655.json'
with open(results_file, 'r', encoding='utf-8') as f:
    data = json.load(f)

episode_rewards = np.array(data['episode_rewards'])

# =====================================================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šè®­ç»ƒæ•ˆæœè¯„ä¼°
# =====================================================================
print("=" * 80)
print("è®­ç»ƒç»“æœæ€»è§ˆ (800 Episodes, é˜¶æ®µ1ä¼˜åŒ–å)")
print("=" * 80)

print(f"\nã€åŸºæœ¬ç»Ÿè®¡ã€‘")
print(f"å¹³å‡å¥–åŠ±: {np.mean(episode_rewards):.4f}")
print(f"æ ‡å‡†å·®:   {np.std(episode_rewards):.4f}")
print(f"å˜å¼‚ç³»æ•°: {np.std(episode_rewards)/abs(np.mean(episode_rewards)):.4f}")
print(f"æœ€å°å€¼:   {np.min(episode_rewards):.4f}")
print(f"æœ€å¤§å€¼:   {np.max(episode_rewards):.4f}")

# é˜¶æ®µæ€§åˆ†æ
phases = {
    'P1 (0-200)': episode_rewards[:200],
    'P2 (200-400)': episode_rewards[200:400],
    'P3 (400-600)': episode_rewards[400:600],
    'P4 (600-800)': episode_rewards[600:],
}

print(f"\nã€é˜¶æ®µæ€§è¡¨ç°ã€‘")
for phase_name, phase_data in phases.items():
    mean_val = np.mean(phase_data)
    std_val = np.std(phase_data)
    print(f"{phase_name}: å‡å€¼={mean_val:.4f}, æ ‡å‡†å·®={std_val:.4f}")

improvement = np.mean(phases['P4 (600-800)']) - np.mean(phases['P1 (0-200)'])
print(f"\nå‰åæœŸæ”¹è¿›: {improvement:.4f} ({improvement/np.mean(phases['P1 (0-200)'])*100:.2f}%)")

# =====================================================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šå½“å‰æƒé‡é…ç½®
# =====================================================================
print("\n" + "=" * 80)
print("å½“å‰ç»Ÿä¸€å¥–åŠ±è®¡ç®—å™¨æƒé‡é…ç½®")
print("=" * 80)

weights_config = {
    'æ ¸å¿ƒæƒé‡': {
        'weight_delay': 0.5,
        'weight_energy': 0.3,
    },
    'æƒ©ç½šæƒé‡': {
        'penalty_dropped': 0.01,
        'weight_completion_gap': 0.1,
        'weight_loss_ratio': 0.1,
        'weight_cache_pressure': 0.1,
        'weight_queue_overload': 0.05,
        'weight_remote_reject': 0.5,
        'weight_cache': 0.4,
        'weight_migration': 0.1,
        'weight_local_penalty': 0.0,
    },
    'å¥–åŠ±æƒé‡': {
        'weight_offload_bonus': 0.1,
        'weight_cache_bonus': 0.5,
        'weight_joint': 0.05,
    },
    'ç›®æ ‡å€¼': {
        'latency_target': 0.4,  # seconds
        'energy_target': 3500.0,  # Joules
        'latency_tolerance': 1.0,
        'energy_tolerance': 5000.0,
    }
}

print("\nã€æ ¸å¿ƒæƒé‡ã€‘(Delay + Energy)")
for k, v in weights_config['æ ¸å¿ƒæƒé‡'].items():
    print(f"  {k:25s} = {v:.2f}")

print("\nã€æƒ©ç½šæƒé‡ã€‘")
for k, v in weights_config['æƒ©ç½šæƒé‡'].items():
    print(f"  {k:30s} = {v:.2f}")

print("\nã€å¥–åŠ±æƒé‡ã€‘(Bonus)")
for k, v in weights_config['å¥–åŠ±æƒé‡'].items():
    print(f"  {k:30s} = {v:.2f}")

print("\nã€ç›®æ ‡å€¼ä¸å½’ä¸€åŒ–ã€‘")
for k, v in weights_config['ç›®æ ‡å€¼'].items():
    print(f"  {k:30s} = {v:.2f}")

# =====================================================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šæƒé‡é…ç½®é—®é¢˜è¯Šæ–­
# =====================================================================
print("\n" + "=" * 80)
print("æƒé‡é…ç½®é—®é¢˜è¯Šæ–­")
print("=" * 80)

# è®¡ç®—æƒé‡æ¯”ä¾‹
delay_weight = 0.5
energy_weight = 0.3
core_weight_ratio = delay_weight / energy_weight if energy_weight > 0 else float('inf')

print(f"\nã€é—®é¢˜1: æ ¸å¿ƒæƒé‡æ¯”ä¾‹åˆ†æã€‘")
print(f"å»¶è¿Ÿæƒé‡ / èƒ½è€—æƒé‡ = {delay_weight} / {energy_weight} = {core_weight_ratio:.2f}")
print(f"å½“å‰é…ç½®: Delayå æ ¸å¿ƒæƒé‡çš„ {delay_weight/(delay_weight+energy_weight)*100:.1f}%")
print(f"            Energyå æ ¸å¿ƒæƒé‡çš„ {energy_weight/(delay_weight+energy_weight)*100:.1f}%")
print(f"\nâœ… è¯„ä¼°: æ¯”ä¾‹åŸºæœ¬åˆç†")
print(f"   - VECç³»ç»Ÿé€šå¸¸ä¼˜å…ˆå»¶è¿Ÿ (å®æ—¶æ€§è¦æ±‚)")
print(f"   - æ¯”ä¾‹1.67:1åœ¨åˆç†èŒƒå›´å†…")
print(f"   - ä½†è€ƒè™‘åˆ°èƒ½è€—ç›®æ ‡3500J vs å»¶è¿Ÿç›®æ ‡0.4sçš„å½’ä¸€åŒ–å°ºåº¦å·®å¼‚")
print(f"     å®é™…æƒé‡å¯èƒ½éœ€è¦å¾®è°ƒ")

# è¾…åŠ©æƒé‡æ€»å’Œ
penalty_weights = {
    'dropped': 0.01,
    'completion_gap': 0.1,
    'loss_ratio': 0.1,
    'cache_pressure': 0.1,
    'queue_overload': 0.05,
    'remote_reject': 0.5,
    'cache': 0.4,
    'migration': 0.1,
    'local_penalty': 0.0,
}

bonus_weights = {
    'offload_bonus': 0.1,
    'cache_bonus': 0.5,
    'joint': 0.05,
}

total_penalty = sum(penalty_weights.values())
total_bonus = sum(bonus_weights.values())
total_core = delay_weight + energy_weight

print(f"\nã€é—®é¢˜2: è¾…åŠ©é¡¹ä¸æ ¸å¿ƒæƒé‡å¹³è¡¡ã€‘")
print(f"æ ¸å¿ƒæƒé‡æ€»å’Œ:   {total_core:.2f} (delay + energy)")
print(f"æƒ©ç½šæƒé‡æ€»å’Œ:   {total_penalty:.2f}")
print(f"å¥–åŠ±æƒé‡æ€»å’Œ:   {total_bonus:.2f}")
print(f"è¾…åŠ©é¡¹å‡€å½±å“:   {total_penalty - total_bonus:.2f}")
print(f"\nâš ï¸  æ½œåœ¨é—®é¢˜:")
print(f"   - æƒ©ç½šæƒé‡æ€»å’Œ {total_penalty:.2f} > æ ¸å¿ƒæƒé‡ {total_core:.2f}")
print(f"   - è¾…åŠ©é¡¹å¯èƒ½æ©ç›–æ ¸å¿ƒä¼˜åŒ–ç›®æ ‡")
print(f"   - remote_rejectæƒé‡0.5è¿‡é«˜ (=æ ¸å¿ƒå»¶è¿Ÿæƒé‡)")
print(f"   - cacheç›¸å…³æƒé‡ç´¯è®¡è¾¾0.9 (0.4 cache + 0.5 bonus)")

# å¼‚å¸¸å€¼åˆ†æ
outliers = episode_rewards[episode_rewards < -3.0]
print(f"\nã€é—®é¢˜3: å¥–åŠ±åˆ†å¸ƒä¸å¼‚å¸¸å€¼ã€‘")
print(f"å¼‚å¸¸ä½å¥–åŠ±(<-3.0)æ•°é‡: {len(outliers)} ({len(outliers)/len(episode_rewards)*100:.2f}%)")
print(f"å¼‚å¸¸å€¼å‡å€¼: {np.mean(outliers):.4f}")
print(f"æœ€ä½å€¼: {np.min(episode_rewards):.4f}")
print(f"\nâš ï¸  æ½œåœ¨åŸå› :")
print(f"   - reward_clip_range = (-50.0, 0.0) èŒƒå›´è¿‡å®½")
print(f"   - å®é™…å¥–åŠ±99%åœ¨[-3, -1]ï¼Œè£å‰ªæ— ä½œç”¨")
print(f"   - æç«¯æƒ…å†µä¸‹æƒ©ç½šé¡¹ç´¯ç§¯è¿‡é‡")

# =====================================================================
# ç¬¬å››éƒ¨åˆ†ï¼šå…·ä½“æƒé‡é—®é¢˜è¯†åˆ«
# =====================================================================
print("\n" + "=" * 80)
print("å…·ä½“æƒé‡é…ç½®é—®é¢˜")
print("=" * 80)

print("\nã€âŒ é—®é¢˜æƒé‡æ¸…å•ã€‘")
print("\n1. remote_rejectæƒé‡ = 0.5")
print("   é—®é¢˜: ä¸æ ¸å¿ƒå»¶è¿Ÿæƒé‡ç›¸å½“ï¼Œè¿‡åº¦æƒ©ç½šè¾¹ç¼˜æ‹’ç»")
print("   å½±å“: å¯èƒ½å¯¼è‡´æ™ºèƒ½ä½“è¿‡åº¦è§„é¿UAV/RSUå¸è½½")
print("   å»ºè®®: é™ä½è‡³ 0.1-0.2")

print("\n2. cacheç›¸å…³æƒé‡è¿‡é«˜")
print("   - weight_cache = 0.4 (missæƒ©ç½š)")
print("   - weight_cache_bonus = 0.5 (hitå¥–åŠ±)")
print("   - ç´¯è®¡å½±å“: 0.9 (è¶…è¿‡æ ¸å¿ƒæƒé‡0.8)")
print("   é—®é¢˜: ç¼“å­˜æˆä¸ºä¸»å¯¼ä¼˜åŒ–ç›®æ ‡ï¼Œåç¦»å»¶è¿Ÿ/èƒ½è€—æ ¸å¿ƒ")
print("   å»ºè®®: cache=0.2, cache_bonus=0.3")

print("\n3. å½’ä¸€åŒ–å°ºåº¦ä¸åŒ¹é…")
print("   - latency_target = 0.4s")
print("   - energy_target = 3500J")
print("   - å½’ä¸€åŒ–åå»¶è¿Ÿ/èƒ½è€—å°ºåº¦ç›¸å·®8750å€")
print("   é—®é¢˜: å³ä½¿æƒé‡æ¯”1.67:1ï¼Œå®é™…å½±å“ä»ä¸¥é‡å¤±è¡¡")
print("   å»ºè®®: è°ƒæ•´å½’ä¸€åŒ–å› å­æˆ–æƒé‡ä»¥åŒ¹é…çœŸå®å½±å“")

print("\n4. completion_gapæƒé‡è¿‡é«˜")
print("   - weight_completion_gap = 0.1")
print("   - é…åˆcompletion_target = 0.88")
print("   é—®é¢˜: åœ¨é«˜è´Ÿè½½ä¸‹è¿‡åº¦æƒ©ç½šï¼Œç³»ç»Ÿéš¾è¾¾88%")
print("   å»ºè®®: é™ä½è‡³ 0.05 æˆ–è°ƒä½targetè‡³0.85")

print("\n5. æƒ©ç½šé¡¹è¿‡å¤šå¯¼è‡´ç´¯ç§¯æ•ˆåº”")
print("   - 9ä¸ªç‹¬ç«‹æƒ©ç½šé¡¹ (dropped, gap, loss, pressure, queue, reject, cache, migration, local)")
print("   - æç«¯æƒ…å†µä¸‹å¯ç´¯ç§¯è‡³ >3.0 æˆæœ¬")
print("   é—®é¢˜: å¯¼è‡´-5.0å¼‚å¸¸ä½å¥–åŠ±")
print("   å»ºè®®: ç®€åŒ–æƒ©ç½šé¡¹ï¼Œåˆå¹¶ç›¸å…³æŒ‡æ ‡")

# =====================================================================
# ç¬¬äº”éƒ¨åˆ†ï¼šä¼˜åŒ–å»ºè®®
# =====================================================================
print("\n" + "=" * 80)
print("æƒé‡ä¼˜åŒ–å»ºè®®æ–¹æ¡ˆ")
print("=" * 80)

print("\nã€æ–¹æ¡ˆA: æ¸è¿›å¼è°ƒæ•´ã€‘(æ¨è)")
print("\né˜¶æ®µ1: é™ä½è¾…åŠ©æƒé‡")
print("```python")
print("# config/system_config.py RLConfig")
print("self.reward_weight_delay = 0.5          # ä¿æŒä¸å˜")
print("self.reward_weight_energy = 0.3         # ä¿æŒä¸å˜")
print("self.reward_penalty_dropped = 0.01      # ä¿æŒä¸å˜")
print("")
print("# é™ä½è¾…åŠ©é¡¹æƒé‡")
print("self.reward_weight_remote_reject = 0.15  # 0.5 â†’ 0.15 (é™ä½70%)")
print("self.reward_weight_cache = 0.2           # 0.4 â†’ 0.2 (é™ä½50%)")
print("self.reward_weight_cache_bonus = 0.3     # 0.5 â†’ 0.3 (é™ä½40%)")
print("self.reward_weight_completion_gap = 0.05 # 0.1 â†’ 0.05 (é™ä½50%)")
print("```")
print("\né¢„æœŸæ•ˆæœ:")
print("  - æ ¸å¿ƒæƒé‡å æ¯”æå‡è‡³ 50%+ (å½“å‰çº¦36%)")
print("  - è¾…åŠ©é¡¹æ€»æƒé‡é™è‡³ <0.8")
print("  - å‡å°‘å¼‚å¸¸ä½å¥–åŠ±é¢‘ç‡")

print("\né˜¶æ®µ2: æ”¶ç´§å¥–åŠ±è£å‰ªèŒƒå›´")
print("```python")
print("# utils/unified_reward_calculator.py")
print("self.reward_clip_range = (-10.0, 0.0)  # (-50.0, 0.0) â†’ (-10.0, 0.0)")
print("```")
print("\né¢„æœŸæ•ˆæœ:")
print("  - é™åˆ¶æç«¯æƒ©ç½š")
print("  - Qå€¼ä¼°è®¡æ›´ç¨³å®š")

print("\né˜¶æ®µ3: è°ƒæ•´å½’ä¸€åŒ–ç›®æ ‡ (å¦‚é˜¶æ®µ1+2æ•ˆæœä¸ä½³)")
print("```python")
print("# config/system_config.py RLConfig")
print("self.latency_target = 0.5      # 0.4 â†’ 0.5 (æ”¾å®½ç›®æ ‡)")
print("self.energy_target = 4000.0    # 3500 â†’ 4000 (æ”¾å®½ç›®æ ‡)")
print("```")

print("\nã€æ–¹æ¡ˆB: æ¿€è¿›å¼é‡æ„ã€‘")
print("\næ ¸å¿ƒæ€æƒ³: åªä¿ç•™æ ¸å¿ƒæƒé‡+å…³é”®æƒ©ç½š")
print("```python")
print("# æ ¸å¿ƒæƒé‡")
print("self.reward_weight_delay = 0.6          # æå‡")
print("self.reward_weight_energy = 0.4         # æå‡")
print("")
print("# å…³é”®æƒ©ç½š")
print("self.reward_penalty_dropped = 0.02      # ä¿ç•™")
print("self.reward_weight_completion_gap = 0.05")
print("")
print("# ç¦ç”¨æ¬¡è¦é¡¹")
print("self.reward_weight_cache = 0.0          # ç¦ç”¨")
print("self.reward_weight_cache_bonus = 0.0    # ç¦ç”¨")
print("self.reward_weight_remote_reject = 0.0  # ç¦ç”¨")
print("self.reward_weight_cache_pressure = 0.0 # ç¦ç”¨")
print("# ... å…¶ä»–è¾…åŠ©é¡¹å…¨éƒ¨è®¾ä¸º0")
print("```")
print("\né£é™©: å¯èƒ½ä¸¢å¤±éƒ¨åˆ†ä¼˜åŒ–ç»†èŠ‚ï¼Œä½†æ”¶æ•›æ›´å¿«")

# =====================================================================
# ç¬¬å…­éƒ¨åˆ†ï¼šç»“è®º
# =====================================================================
print("\n" + "=" * 80)
print("è¯Šæ–­ç»“è®º")
print("=" * 80)

print("\nã€è®­ç»ƒæœªæ”¶æ•›çš„ä¸»è¦åŸå› åˆ†æã€‘")
print("\nåŸºäº800è½®è®­ç»ƒæ•°æ® (ä¼˜åŒ–å):")
print(f"  - å¹³å‡å¥–åŠ±: {np.mean(episode_rewards):.4f}")
print(f"  - å‰åæœŸæ”¹è¿›: {improvement:.4f} ({improvement/np.mean(phases['P1 (0-200)'])*100:.2f}%)")
print(f"  - å˜å¼‚ç³»æ•°: {np.std(episode_rewards)/abs(np.mean(episode_rewards)):.4f}")

print("\nâœ… é˜¶æ®µ1ä¼˜åŒ– (æ¢ç´¢å™ªå£°é™ä½) å·²ç”Ÿæ•ˆ:")
print(f"  - å‰åæœŸæœ‰è½»å¾®æ”¹è¿› (çº¦3%)")
print(f"  - å˜å¼‚ç³»æ•°ä»é«˜ (0.30)")
print(f"  - è¯´æ˜å™ªå£°ä¸æ˜¯å”¯ä¸€é—®é¢˜")

print("\nâŒ æƒé‡é…ç½®æ˜¯é‡è¦çš„æ¬¡è¦åŸå› :")
print("  1. è¾…åŠ©æƒé‡è¿‡é«˜ï¼Œæ©ç›–æ ¸å¿ƒä¼˜åŒ–ç›®æ ‡")
print("  2. remote_rejectå’Œcacheæƒé‡ä¸¥é‡å¤±è¡¡")
print("  3. æƒ©ç½šé¡¹è¿‡å¤šï¼Œæç«¯æƒ…å†µç´¯ç§¯è¿‡é‡")
print("  4. å½’ä¸€åŒ–å°ºåº¦ä¸åŒ¹é…ï¼Œå®é™…æƒé‡åç¦»è®¾è®¡")

print("\nğŸ¯ ä¼˜å…ˆçº§æ’åº:")
print("  ã€P1ã€‘é™ä½remote_rejectæƒé‡ (0.5 â†’ 0.15)")
print("  ã€P2ã€‘é™ä½cacheç›¸å…³æƒé‡ (0.4â†’0.2, 0.5â†’0.3)")
print("  ã€P3ã€‘æ”¶ç´§å¥–åŠ±è£å‰ªèŒƒå›´ (-50â†’-10)")
print("  ã€P4ã€‘è°ƒæ•´å­¦ä¹ ç‡å’Œæ‰¹é‡å¤§å° (å¦‚è®¡åˆ’çš„é˜¶æ®µ2)")

print("\nğŸ“Š é¢„æœŸæ”¹è¿›:")
print("  å¦‚æœåŒæ—¶åº”ç”¨æƒé‡ä¼˜åŒ–+é˜¶æ®µ2(å­¦ä¹ ç‡):")
print("  - å‰åæœŸæ”¹è¿›å¯è¾¾ 10-15%")
print("  - å˜å¼‚ç³»æ•°é™è‡³ 0.20-0.25")
print("  - æœ€ç»ˆå¥–åŠ±æ”¶æ•›è‡³ -1.2 åˆ° -1.0")

print("\n" + "=" * 80)
