#!/usr/bin/env python3
"""
CAMTD3 ä»»åŠ¡æ•°æ®å¤§å°å¯¹æ¯”å®éªŒï¼ˆå…­ç­–ç•¥ç‰ˆæœ¬ï¼‰
==========================================

ã€åŠŸèƒ½ã€‘
è¯„ä¼°ä¸åŒä»»åŠ¡æ•°æ®å¤§å°å¯¹ç³»ç»Ÿæ€§èƒ½çš„å½±å“ï¼Œå¯¹æ¯”å…­ç§ç­–ç•¥åœ¨ä¸åŒæ•°æ®è´Ÿè½½ä¸‹çš„è¡¨ç°ã€‚
é€šè¿‡æ‰«æä¸åŒçš„ä»»åŠ¡æ•°æ®å¤§å°èŒƒå›´ï¼Œåˆ†æï¼š
- æ•°æ®ä¼ è¾“å¼€é”€å¦‚ä½•å½±å“ç³»ç»Ÿæˆæœ¬
- å„ç­–ç•¥å¯¹æ•°æ®å¤§å°å˜åŒ–çš„é€‚åº”èƒ½åŠ›
- å¤§æ•°æ®ä»»åŠ¡ä¸‹çš„å†³ç­–ä¼˜åŒ–

ã€è®ºæ–‡å¯¹åº”ã€‘
- å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆParameter Sensitivity Analysisï¼‰
- æ•°æ®å¯†é›†å‹åœºæ™¯ä¸‹çš„æ€§èƒ½è¯„ä¼°
- éªŒè¯CAMTD3åœ¨ä¸åŒä»»åŠ¡è´Ÿè½½ä¸‹çš„é²æ£’æ€§

ã€å®éªŒè®¾è®¡ã€‘
æ‰«æå‚æ•°: task_data_size (ä»»åŠ¡æ•°æ®å¤§å° KB)
- å°ä»»åŠ¡: 50-150 KBï¼ˆè½»é‡çº§ä»»åŠ¡ï¼‰
- ä¸­å°ä»»åŠ¡: 100-300 KBï¼ˆå¸¸è§„ä»»åŠ¡ï¼‰
- ä¸­ç­‰ä»»åŠ¡: 200-500 KBï¼ˆæ ‡å‡†é…ç½®ï¼‰
- ä¸­å¤§ä»»åŠ¡: 300-800 KBï¼ˆæ•°æ®å¯†é›†å‹ï¼‰
- å¤§ä»»åŠ¡: 500-1000 KBï¼ˆé‡è´Ÿè½½åœºæ™¯ï¼‰

å›ºå®šå‚æ•°:
- è½¦è¾†æ•°: 12
- RSUæ•°: 4
- UAVæ•°: 2
- è®­ç»ƒè½®æ•°: å¯é…ç½®ï¼ˆé»˜è®¤500ï¼‰

ã€æ ¸å¿ƒæŒ‡æ ‡ã€‘
- å¹³å‡æ€»æˆæœ¬ï¼ˆæ—¶å»¶+èƒ½è€—ï¼‰
- å¹³å‡æ—¶å»¶ï¼ˆæ•°æ®å¤§å°å½±å“ä¼ è¾“æ—¶é—´ï¼‰
- å¹³å‡èƒ½è€—ï¼ˆæ•°æ®å¤§å°å½±å“ä¼ è¾“èƒ½è€—ï¼‰
- å½’ä¸€åŒ–æˆæœ¬ï¼ˆä¾¿äºå¯¹æ¯”ï¼‰

ã€ä½¿ç”¨ç¤ºä¾‹ã€‘
```bash
# âœ… é»˜è®¤é™é»˜è¿è¡Œï¼ˆæ— éœ€æ‰‹åŠ¨äº¤äº’ï¼Œæ¨èï¼‰
# å¿«é€Ÿæµ‹è¯•ï¼ˆ100è½®ï¼‰
python experiments/camtd3_strategy_suite/run_data_size_comparison.py \\
    --episodes 100 --suite-id datasize_quick

# å®Œæ•´å®éªŒï¼ˆ500è½®ï¼‰- è‡ªåŠ¨ä¿å­˜æŠ¥å‘Šï¼Œæ— äººå€¼å®ˆè¿è¡Œ
python experiments/camtd3_strategy_suite/run_data_size_comparison.py \\
    --episodes 500 --seed 42 --suite-id datasize_paper

# è‡ªå®šä¹‰æ•°æ®å¤§å°é…ç½®ï¼ˆæ ¼å¼ï¼šmin,max; ...ï¼‰
python experiments/camtd3_strategy_suite/run_data_size_comparison.py \\
    --data-sizes "100,200;200,400;400,800" --episodes 300

# ğŸ’¡ å¦‚éœ€äº¤äº’å¼ç¡®è®¤ä¿å­˜æŠ¥å‘Šï¼Œæ·»åŠ  --interactive å‚æ•°
python experiments/camtd3_strategy_suite/run_data_size_comparison.py \\
    --episodes 500 --interactive
```

ã€é¢„è®¡è¿è¡Œæ—¶é—´ã€‘
- å¿«é€Ÿæµ‹è¯•ï¼ˆ100è½® Ã— 5é…ç½® Ã— 6ç­–ç•¥ï¼‰ï¼šçº¦1.5-2.5å°æ—¶
- å®Œæ•´å®éªŒï¼ˆ500è½® Ã— 5é…ç½® Ã— 6ç­–ç•¥ï¼‰ï¼šçº¦6-9å°æ—¶

ã€è¾“å‡ºå›¾è¡¨ã€‘
- data_size_vs_cost.png: æ•°æ®å¤§å° vs å¹³å‡æˆæœ¬
- data_size_vs_delay.png: æ•°æ®å¤§å° vs å¹³å‡æ—¶å»¶
- data_size_vs_energy.png: æ•°æ®å¤§å° vs å¹³å‡èƒ½è€—
- data_size_vs_normalized_cost.png: æ•°æ®å¤§å° vs å½’ä¸€åŒ–æˆæœ¬
"""

from __future__ import annotations

import argparse
import json
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Tuple

import matplotlib.pyplot as plt

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).resolve().parents[2]
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from experiments.camtd3_strategy_suite.strategy_runner import (
    STRATEGY_KEYS,
    enrich_with_normalized_costs,
    run_strategy_suite,
    strategy_label,
)

DEFAULT_EPISODES = 500
DEFAULT_SEED = 42

DEFAULT_DATA_SIZE_CONFIGS: List[Tuple[int, int, str]] = [
    (50, 150, "Small (50-150KB)"),
    (100, 300, "Medium-Small (100-300KB)"),
    (200, 500, "Medium (200-500KB)"),
    (300, 800, "Medium-Large (300-800KB)"),
    (500, 1000, "Large (500-1000KB)"),
]


def parse_data_sizes(value: str) -> List[Tuple[int, int, str]]:
    """
    è§£ææ•°æ®å¤§å°é…ç½®å­—ç¬¦ä¸²
    
    ã€åŠŸèƒ½ã€‘
    å°†å‘½ä»¤è¡Œè¾“å…¥çš„æ•°æ®å¤§å°å­—ç¬¦ä¸²è§£æä¸º(min, max, label)å…ƒç»„åˆ—è¡¨
    
    ã€å‚æ•°ã€‘
    value: str - æ•°æ®å¤§å°å­—ç¬¦ä¸²ï¼Œæ ¼å¼ä¸º "100,200;200,400" æˆ– "default"
    
    ã€è¿”å›å€¼ã€‘
    List[Tuple[int, int, str]] - (æœ€å°å€¼, æœ€å¤§å€¼, æ ‡ç­¾)å…ƒç»„åˆ—è¡¨
    
    ã€ç¤ºä¾‹ã€‘
    "100,300;500,800" -> [(100, 300, "100-300KB"), (500, 800, "500-800KB")]
    """
    if not value or value.strip().lower() == "default":
        return [tuple(cfg) for cfg in DEFAULT_DATA_SIZE_CONFIGS]
    
    configs: List[Tuple[int, int, str]] = []
    for item in value.split(";"):
        parts = item.strip().split(",")
        if len(parts) != 2:
            raise ValueError(f"Invalid data size format: {item}. Expected 'min,max'")
        min_kb, max_kb = int(parts[0]), int(parts[1])
        label = f"{min_kb}-{max_kb}KB"
        configs.append((min_kb, max_kb, label))
    return configs


def run_single_config(
    min_kb: int,
    max_kb: int,
    label: str,
    episodes: int,
    seed: int,
    silent: bool,
    suite_path: Path,
) -> Dict[str, Any]:
    """
    è¿è¡Œå•ä¸ªæ•°æ®å¤§å°é…ç½®çš„å®éªŒ
    
    ã€åŠŸèƒ½ã€‘
    å¯¹æŒ‡å®šçš„æ•°æ®å¤§å°èŒƒå›´ï¼Œè®­ç»ƒå¹¶è¯„ä¼°å…­ç§ç­–ç•¥çš„æ€§èƒ½
    
    ã€å‚æ•°ã€‘
    min_kb: int - æœ€å°ä»»åŠ¡æ•°æ®å¤§å°ï¼ˆKBï¼‰
    max_kb: int - æœ€å¤§ä»»åŠ¡æ•°æ®å¤§å°ï¼ˆKBï¼‰
    label: str - é…ç½®æ ‡ç­¾ï¼ˆç”¨äºå±•ç¤ºï¼‰
    episodes: int - è®­ç»ƒè½®æ•°
    seed: int - éšæœºç§å­
    silent: bool - æ˜¯å¦é™é»˜æ¨¡å¼
    suite_path: Path - è¾“å‡ºç›®å½•è·¯å¾„
    
    ã€è¿”å›å€¼ã€‘
    Dict[str, Any] - åŒ…å«æ‰€æœ‰ç­–ç•¥æ€§èƒ½æŒ‡æ ‡çš„å­—å…¸
    
    ã€å®éªŒæµç¨‹ã€‘
    1. é…ç½®ä»»åŠ¡æ•°æ®å¤§å°å‚æ•°
    2. å›ºå®šç½‘ç»œæ‹“æ‰‘ï¼ˆ12è½¦è¾†+4RSU+2UAVï¼‰
    3. è®­ç»ƒå…­ç§ç­–ç•¥
    4. ä¿å­˜æ¯ä¸ªç­–ç•¥çš„è¯¦ç»†ç»“æœ
    5. è¿”å›æ±‡æ€»æŒ‡æ ‡
    """
    print(f"\n{'='*60}")
    print(f"Running data size configuration: {label}")
    print(f"{'='*60}")

    override_scenario = {
        "num_vehicles": 12,
        "num_rsus": 4,
        "num_uavs": 2,
        "task_data_size_min_kb": min_kb,
        "task_data_size_max_kb": max_kb,
        "override_topology": True,
    }

    config_dir = suite_path / f"{min_kb}_{max_kb}"
    config_dir.mkdir(parents=True, exist_ok=True)

    strategies_raw = run_strategy_suite(
        override_scenario=override_scenario,
        episodes=episodes,
        seed=seed,
        silent=silent,
    )
    strategies = enrich_with_normalized_costs(strategies_raw)

    for strat_key, metrics in strategies.items():
        detail_path = config_dir / f"{strat_key}.json"
        detail_path.write_text(
            json.dumps(
                {
                    "strategy": strat_key,
                    "strategy_label": strategy_label(strat_key),
                    "min_kb": min_kb,
                    "max_kb": max_kb,
                    **metrics,
                },
                indent=2,
                ensure_ascii=False,
            ),
            encoding="utf-8",
        )

    for strat_key in STRATEGY_KEYS:
        metrics = strategies[strat_key]
        print(
            f"  - {strategy_label(strat_key)}: "
            f"Cost={metrics['raw_cost']:.4f} Delay={metrics['avg_delay']:.4f}s "
            f"Energy={metrics['avg_energy']:.2f}J"
        )

    return {
        "label": label,
        "min_kb": min_kb,
        "max_kb": max_kb,
        "avg_kb": (min_kb + max_kb) / 2.0,
        "strategies": strategies,
        "episodes": episodes,
        "seed": seed,
    }


def plot_results(results: List[Dict[str, Any]], suite_path: Path) -> None:
    avg_sizes = [r["avg_kb"] for r in results]

    def make_chart(metric: str, ylabel: str, filename: str) -> None:
        plt.figure(figsize=(10, 6))
        for strat_key in STRATEGY_KEYS:
            values = [r["strategies"][strat_key][metric] for r in results]
            plt.plot(
                avg_sizes,
                values,
                marker="o",
                linewidth=2,
                label=strategy_label(strat_key),
            )
        plt.xlabel("Average Task Data Size (KB)")
        plt.ylabel(ylabel)
        plt.title(f"Impact of Data Size on {ylabel}")
        plt.grid(alpha=0.3)
        plt.legend()
        plt.tight_layout()
        plt.savefig(suite_path / filename, dpi=300, bbox_inches="tight")
        plt.close()

    make_chart("raw_cost", "Average Cost", "data_size_vs_cost.png")
    make_chart("avg_delay", "Average Delay (s)", "data_size_vs_delay.png")
    make_chart("avg_energy", "Average Energy (J)", "data_size_vs_energy.png")
    make_chart("normalized_cost", "Normalized Cost", "data_size_vs_normalized_cost.png")

    print("\nCharts saved:")
    for name in [
        "data_size_vs_cost.png",
        "data_size_vs_delay.png",
        "data_size_vs_energy.png",
        "data_size_vs_normalized_cost.png",
    ]:
        print(f"  - {suite_path / name}")


def main() -> None:
    parser = argparse.ArgumentParser(description="Evaluate strategy performance across different task data sizes.")
    parser.add_argument("--data-sizes", type=str, default="default", help="Ranges in 'min,max;...' format or 'default'.")
    parser.add_argument("--episodes", type=int, help="Training episodes per configuration (default 500).")
    parser.add_argument("--seed", type=int, help="Random seed (default 42).")
    parser.add_argument(
        "--suite-id",
        type=str,
        default=f"data_size_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
        help="Suite identifier.",
    )
    parser.add_argument("--output-root", type=str, default="results/parameter_sensitivity", help="Output root directory.")
    parser.add_argument("--silent", action="store_true", default=True, help="Run training in silent mode (default: True for batch experiments).")
    parser.add_argument("--interactive", action="store_true", help="Enable interactive mode (overrides silent).")
    args = parser.parse_args()
    
    # å¦‚æœæŒ‡å®šäº† --interactiveï¼Œåˆ™ç¦ç”¨é™é»˜æ¨¡å¼
    if args.interactive:
        args.silent = False

    data_size_configs = parse_data_sizes(args.data_sizes)
    episodes = args.episodes or DEFAULT_EPISODES
    seed = args.seed if args.seed is not None else DEFAULT_SEED

    suite_path = Path(args.output_root) / args.suite_id
    suite_path.mkdir(parents=True, exist_ok=True)

    results: List[Dict[str, Any]] = []
    for min_kb, max_kb, label in data_size_configs:
        entry = run_single_config(
            min_kb=min_kb,
            max_kb=max_kb,
            label=label,
            episodes=episodes,
            seed=seed,
            silent=args.silent,
            suite_path=suite_path,
        )
        results.append(entry)

    summary = {
        "experiment_type": "data_size_sensitivity",
        "suite_id": args.suite_id,
        "created_at": datetime.now().isoformat(),
        "num_configs": len(results),
        "episodes_per_config": episodes,
        "seed": seed,
        "results": results,
    }
    summary_path = suite_path / "summary.json"
    summary_path.write_text(json.dumps(summary, indent=2, ensure_ascii=False), encoding="utf-8")

    plot_results(results, suite_path)

    print(f"\nData Size Sensitivity Analysis Completed")
    print(f"Suite ID: {args.suite_id}")
    print(f"Configurations tested: {len(results)}")
    print(f"{'Data Size':<18}", end="")
    for strat_key in STRATEGY_KEYS:
        print(f"{strategy_label(strat_key):>18}", end="")
    print()
    print("-" * (18 + 18 * len(STRATEGY_KEYS)))
    for record in results:
        print(f"{record['label']:<18}", end="")
        for strat_key in STRATEGY_KEYS:
            print(f"{record['strategies'][strat_key]['raw_cost']:<18.4f}", end="")
        print()
    print(f"\nSummary saved to: {summary_path}")


if __name__ == "__main__":
    main()
