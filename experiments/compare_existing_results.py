#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯¹æ¯”å·²æœ‰çš„è®­ç»ƒç»“æœå¹¶ç”Ÿæˆå›¾è¡¨
"""

import os
import sys
import json
import numpy as np
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥å¯è§†åŒ–æ¨¡å—
from experiments.visualize_weight_comparison import (
    plot_cost_comparison,
    plot_cost_curves,
    plot_reward_curves,
    plot_radar_comparison,
    plot_metrics_comparison,
    plot_convergence_comparison,
    plot_pareto_frontier
)


def load_and_process_results(json_files):
    """åŠ è½½å¹¶å¤„ç†å¤šä¸ªè®­ç»ƒç»“æœJSONæ–‡ä»¶"""
    
    results = []
    
    print(f"\n{'='*70}")
    print(f"åŠ è½½ {len(json_files)} ä¸ªè®­ç»ƒç»“æœæ–‡ä»¶...")
    print(f"{'='*70}\n")
    
    for i, json_file in enumerate(json_files, 1):
        print(f"[{i}/{len(json_files)}] è¯»å–: {os.path.basename(json_file)}")
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æå–é…ç½®ä¿¡æ¯
            config_info = data.get('config', {})
            experiment_name = data.get('experiment_name', f'config_{i}')
            
            # æå–æƒé‡é…ç½®
            weights = {
                'reward_weight_delay': config_info.get('reward_weight_delay', 2.0),
                'reward_weight_energy': config_info.get('reward_weight_energy', 1.2),
                'reward_weight_cache': config_info.get('reward_weight_cache', 0.15),
                'reward_penalty_dropped': config_info.get('reward_penalty_dropped', 0.05),
                'energy_target': config_info.get('energy_target', 1200.0),
                'latency_target': config_info.get('latency_target', 0.40),
            }
            
            # æå–æŒ‡æ ‡æ•°æ®
            metrics = data.get('episode_metrics', {})
            
            # è®¡ç®—å100è½®å¹³å‡æŒ‡æ ‡
            last_100 = min(100, len(metrics.get('total_energy', [])))
            
            if last_100 > 0:
                avg_energy = np.mean(metrics['total_energy'][-last_100:])
                avg_delay = np.mean(metrics['avg_delay'][-last_100:])
                avg_cache_hit = np.mean(metrics['cache_hit_rate'][-last_100:])
                avg_completion = np.mean(metrics['task_completion_rate'][-last_100:])
                
                result = {
                    'name': experiment_name,
                    'file': os.path.basename(json_file),
                    'data': data,
                    'metrics': metrics,
                    'weights': weights,
                    'avg_energy': avg_energy,
                    'avg_delay': avg_delay,
                    'avg_cache_hit': avg_cache_hit,
                    'avg_completion': avg_completion,
                }
                
                results.append(result)
                
                print(f"  âœ“ {experiment_name}")
                print(f"    èƒ½è€—: {avg_energy:.1f}J, æ—¶å»¶: {avg_delay:.4f}s, "
                      f"ç¼“å­˜: {avg_cache_hit:.2%}, å®Œæˆç‡: {avg_completion:.2%}")
            else:
                print(f"  âœ— æ•°æ®ä¸è¶³")
                
        except Exception as e:
            print(f"  âœ— è¯»å–å¤±è´¥: {e}")
    
    print(f"\næˆåŠŸåŠ è½½ {len(results)} ä¸ªç»“æœ\n")
    
    return results


def generate_all_charts(results, output_dir):
    """ç”Ÿæˆæ‰€æœ‰å¯¹æ¯”å›¾è¡¨"""
    
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"\n{'='*70}")
    print("ç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
    print(f"{'='*70}\n")
    
    try:
        # 1. æˆæœ¬å¯¹æ¯”å›¾
        print("  [1/7] ç”Ÿæˆæˆæœ¬å¯¹æ¯”å›¾...")
        plot_cost_comparison(results, os.path.join(output_dir, "cost_comparison.png"))
        
        # 2. æˆæœ¬æ›²çº¿å¯¹æ¯”
        print("  [2/7] ç”Ÿæˆæˆæœ¬æ›²çº¿å¯¹æ¯”å›¾...")
        plot_cost_curves(results, os.path.join(output_dir, "cost_curves.png"))
        
        # 3. å¥–åŠ±æ›²çº¿å¯¹æ¯”
        print("  [3/7] ç”Ÿæˆå¥–åŠ±æ›²çº¿å¯¹æ¯”å›¾...")
        plot_reward_curves(results, os.path.join(output_dir, "reward_curves.png"))
        
        # 4. é›·è¾¾å›¾
        print("  [4/7] ç”Ÿæˆç»¼åˆæ€§èƒ½é›·è¾¾å›¾...")
        plot_radar_comparison(results, os.path.join(output_dir, "radar_comparison.png"))
        
        # 5. è¯¦ç»†æŒ‡æ ‡å¯¹æ¯”
        print("  [5/7] ç”Ÿæˆè¯¦ç»†æŒ‡æ ‡å¯¹æ¯”å›¾...")
        plot_metrics_comparison(results, os.path.join(output_dir, "metrics_comparison.png"))
        
        # 6. æ”¶æ•›æ›²çº¿
        print("  [6/7] ç”Ÿæˆæ”¶æ•›æ›²çº¿å¯¹æ¯”å›¾...")
        plot_convergence_comparison(results, os.path.join(output_dir, "convergence_comparison.png"))
        
        # 7. Paretoå‰æ²¿
        print("  [7/7] ç”ŸæˆParetoå‰æ²¿åˆ†æå›¾...")
        plot_pareto_frontier(results, os.path.join(output_dir, "pareto_frontier.png"))
        
        print(f"\nâœ… æ‰€æœ‰å›¾è¡¨å·²ä¿å­˜åˆ°: {output_dir}/")
        print("\nç”Ÿæˆçš„å›¾è¡¨åˆ—è¡¨:")
        print("  1. cost_comparison.png   - æˆæœ¬å¯¹æ¯”ï¼ˆæŸ±çŠ¶å›¾+å †å å›¾ï¼‰â­")
        print("  2. cost_curves.png       - æˆæœ¬æ›²çº¿ï¼ˆè®­ç»ƒè¿‡ç¨‹ï¼‰â­")
        print("  3. reward_curves.png     - å¥–åŠ±æ›²çº¿ï¼ˆè®­ç»ƒè¿‡ç¨‹ï¼‰â­")
        print("  4. radar_comparison.png  - ç»¼åˆæ€§èƒ½é›·è¾¾å›¾")
        print("  5. metrics_comparison.png - 6æŒ‡æ ‡è¯¦ç»†å¯¹æ¯”")
        print("  6. convergence_comparison.png - 4ç»´æ”¶æ•›æ›²çº¿")
        print("  7. pareto_frontier.png   - æ—¶å»¶-èƒ½è€—Paretoå‰æ²¿")
        
    except Exception as e:
        print(f"\nâŒ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def print_summary(results):
    """æ‰“å°ç»“æœæ‘˜è¦"""
    
    print(f"\n{'='*70}")
    print("å®éªŒç»“æœæ‘˜è¦")
    print(f"{'='*70}\n")
    
    # æŒ‰æˆæœ¬æ’åºï¼ˆè®¡ç®—æ€»æˆæœ¬ï¼‰
    for result in results:
        weights = result['weights']
        w_delay = weights['reward_weight_delay']
        w_energy = weights['reward_weight_energy']
        w_cache = weights['reward_weight_cache']
        target_delay = weights['latency_target']
        target_energy = weights['energy_target']
        
        norm_delay = result['avg_delay'] / target_delay
        norm_energy = result['avg_energy'] / target_energy
        cache_miss = 1 - result['avg_cache_hit']
        
        total_cost = w_delay * norm_delay + w_energy * norm_energy + w_cache * cache_miss
        result['total_cost'] = total_cost
    
    # æŒ‰æˆæœ¬æ’åº
    sorted_results = sorted(results, key=lambda x: x['total_cost'])
    
    print(f"{'é…ç½®åç§°':30s} | {'æ€»æˆæœ¬':>8s} | {'èƒ½è€—(J)':>10s} | {'æ—¶å»¶(s)':>8s} | {'ç¼“å­˜ç‡':>8s} | {'å®Œæˆç‡':>8s}")
    print("-"*90)
    
    for i, result in enumerate(sorted_results, 1):
        marker = "ğŸ†" if i == 1 else f"{i:2d}"
        print(f"{marker} {result['name']:27s} | {result['total_cost']:8.2f} | "
              f"{result['avg_energy']:10.1f} | {result['avg_delay']:8.4f} | "
              f"{result['avg_cache_hit']:7.2%} | {result['avg_completion']:7.2%}")
    
    print(f"\næœ€ä¼˜é…ç½®: {sorted_results[0]['name']} (æ€»æˆæœ¬: {sorted_results[0]['total_cost']:.2f})")


def main():
    # 14ä¸ªè®­ç»ƒç»“æœæ–‡ä»¶
    json_files = [
        r"D:\VEC_mig_caching\results\single_agent\td3\æƒé‡å¯¹æ¯”å®éªŒ\training_results_20251102_201444.json",
        r"D:\VEC_mig_caching\results\single_agent\td3\æƒé‡å¯¹æ¯”å®éªŒ\training_results_20251102_193909.json",
        r"D:\VEC_mig_caching\results\single_agent\td3\æƒé‡å¯¹æ¯”å®éªŒ\training_results_20251102_190111.json",
        r"D:\VEC_mig_caching\results\single_agent\td3\æƒé‡å¯¹æ¯”å®éªŒ\training_results_20251102_182026.json",
        r"D:\VEC_mig_caching\results\single_agent\td3\æƒé‡å¯¹æ¯”å®éªŒ\training_results_20251102_174023.json",
        r"D:\VEC_mig_caching\results\single_agent\td3\æƒé‡å¯¹æ¯”å®éªŒ\training_results_20251102_170758.json",
        r"D:\VEC_mig_caching\results\single_agent\td3\æƒé‡å¯¹æ¯”å®éªŒ\training_results_20251102_163726.json",
        r"D:\VEC_mig_caching\results\single_agent\td3\æƒé‡å¯¹æ¯”å®éªŒ\training_results_20251102_160246.json",
        r"D:\VEC_mig_caching\results\single_agent\td3\æƒé‡å¯¹æ¯”å®éªŒ\training_results_20251102_153226.json",
        r"D:\VEC_mig_caching\results\single_agent\td3\æƒé‡å¯¹æ¯”å®éªŒ\training_results_20251102_143208.json",
        r"D:\VEC_mig_caching\results\single_agent\td3\æƒé‡å¯¹æ¯”å®éªŒ\training_results_20251102_150158.json",
        r"D:\VEC_mig_caching\results\single_agent\td3\æƒé‡å¯¹æ¯”å®éªŒ\training_results_20251102_140220.json",
        r"D:\VEC_mig_caching\results\single_agent\td3\æƒé‡å¯¹æ¯”å®éªŒ\training_results_20251102_133219.json",
        r"D:\VEC_mig_caching\results\single_agent\td3\æƒé‡å¯¹æ¯”å®éªŒ\training_results_20251102_130212.json",
    ]
    
    # åŠ è½½ç»“æœ
    results = load_and_process_results(json_files)
    
    if not results:
        print("âŒ æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•ç»“æœ")
        return
    
    # æ‰“å°æ‘˜è¦
    print_summary(results)
    
    # ç”Ÿæˆå›¾è¡¨
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = f"results/weight_comparison/comparison_{timestamp}"
    
    generate_all_charts(results, output_dir)
    
    print(f"\n{'='*70}")
    print("ğŸ‰ å¯¹æ¯”åˆ†æå®Œæˆï¼")
    print(f"{'='*70}")
    print(f"\næŸ¥çœ‹ç»“æœ:")
    print(f"  ğŸ“Š å›¾è¡¨ç›®å½•: {output_dir}/")
    print(f"  ğŸ† æœ€ä¼˜é…ç½®: {sorted(results, key=lambda x: x['total_cost'])[0]['name']}")
    print()


if __name__ == "__main__":
    main()

