#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¥–åŠ±æƒé‡å¯¹æ¯”å®éªŒè„šæœ¬

åŠŸèƒ½ï¼š
1. å®šä¹‰å¤šç»„æƒé‡é…ç½®æ–¹æ¡ˆ
2. è‡ªåŠ¨è¿è¡Œå¿«é€Ÿè¯„ä¼°å®éªŒ
3. ç”Ÿæˆè¯¦ç»†å¯¹æ¯”æŠ¥å‘Š
4. å¯è§†åŒ–ä¸åŒæƒé‡çš„æ•ˆæœ
# æ­¥éª¤1: å¿«é€ŸéªŒè¯ï¼ˆ5åˆ†é’Ÿï¼‰
python experiments/weight_comparison.py --mode full --config balanced --episodes 10

# æ­¥éª¤2: å¦‚æœæˆåŠŸï¼Œè¿è¡Œå®Œæ•´ç‰ˆï¼ˆ2-3å°æ—¶ï¼‰
python experiments/weight_comparison.py --mode full --config balanced --episodes 500

# æ­¥éª¤3: è¿è¡ŒTop 3é…ç½®ï¼ˆ6-9å°æ—¶ï¼‰
experiments\run_top3_configs.bat

# æ­¥éª¤4: ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
python experiments/visualize_weight_comparison.py

# æ­¥éª¤5: æŸ¥çœ‹åˆ†ææŠ¥å‘Š
python experiments/weight_comparison.py --mode analyze

ä½¿ç”¨æ–¹æ³•ï¼š
  python experiments/weight_comparison.py --mode quick  # å¿«é€Ÿè¯„ä¼°ï¼ˆ100è½®ï¼‰
  python experiments/weight_comparison.py --mode full   # å®Œæ•´å®éªŒï¼ˆ500è½®ï¼‰
  python experiments/weight_comparison.py --mode generate  # ä»…ç”Ÿæˆé…ç½®æ–‡ä»¶
"""

import os
import sys
import json
import argparse
import subprocess
from datetime import datetime
from typing import Dict, List, Any
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import config


class WeightConfiguration:
    """æƒé‡é…ç½®ç±»"""
    
    def __init__(self, name: str, description: str, weights: Dict[str, float]):
        self.name = name
        self.description = description
        self.weights = weights
    
    def to_dict(self):
        return {
            "name": self.name,
            "description": self.description,
            "weights": self.weights
        }


# ========== å®šä¹‰æƒé‡é…ç½®æ–¹æ¡ˆ ==========

WEIGHT_CONFIGS = [
    # 1. å½“å‰é…ç½®ï¼ˆåŸºçº¿ï¼‰
    WeightConfiguration(
        name="current",
        description="å½“å‰é…ç½® - èƒ½è€—ä¸»å¯¼ï¼ˆèƒ½è€—å½’ä¸€åŒ–å€¼å¤§ï¼‰",
        weights={
            "reward_weight_delay": 2.0,
            "reward_weight_energy": 1.2,
            "reward_weight_cache": 0.15,
            "reward_penalty_dropped": 0.05,
            "energy_target": 1200.0,
            "latency_target": 0.40,
        }
    ),
    
    # 2. æ—¶å»¶ä¼˜å…ˆé…ç½®
    WeightConfiguration(
        name="delay_priority",
        description="æ—¶å»¶ä¼˜å…ˆ - æ—¶å»¶æƒé‡åŠ å€",
        weights={
            "reward_weight_delay": 3.0,  # å¢åŠ æ—¶å»¶æƒé‡
            "reward_weight_energy": 1.0,  # é™ä½èƒ½è€—æƒé‡
            "reward_weight_cache": 0.15,
            "reward_penalty_dropped": 0.05,
            "energy_target": 1200.0,
            "latency_target": 0.40,
        }
    ),
    
    # 3. èƒ½è€—ä¼˜å…ˆé…ç½®
    WeightConfiguration(
        name="energy_priority",
        description="èƒ½è€—ä¼˜å…ˆ - èƒ½è€—æƒé‡åŠ å€",
        weights={
            "reward_weight_delay": 1.5,  # é™ä½æ—¶å»¶æƒé‡
            "reward_weight_energy": 2.0,  # å¢åŠ èƒ½è€—æƒé‡
            "reward_weight_cache": 0.15,
            "reward_penalty_dropped": 0.05,
            "energy_target": 1200.0,
            "latency_target": 0.40,
        }
    ),
    
    # 4. å¹³è¡¡é…ç½®ï¼ˆæ—¶å»¶èƒ½è€—ç­‰æƒé‡ï¼‰
    WeightConfiguration(
        name="balanced",
        description="å¹³è¡¡é…ç½® - æ—¶å»¶èƒ½è€—å½’ä¸€åŒ–åç­‰æƒé‡",
        weights={
            "reward_weight_delay": 2.0,
            "reward_weight_energy": 1.2,
            "reward_weight_cache": 0.15,
            "reward_penalty_dropped": 0.05,
            "energy_target": 3500.0,  # è°ƒæ•´èƒ½è€—ç›®æ ‡ä½¿å½’ä¸€åŒ–å€¼æ¥è¿‘æ—¶å»¶
            "latency_target": 0.40,
        }
    ),
    
    # 5. ç¼“å­˜å¢å¼ºé…ç½®
    WeightConfiguration(
        name="cache_enhanced",
        description="ç¼“å­˜å¢å¼º - æé«˜ç¼“å­˜æƒé‡",
        weights={
            "reward_weight_delay": 2.0,
            "reward_weight_energy": 1.2,
            "reward_weight_cache": 0.35,  # ç¼“å­˜æƒé‡æé«˜
            "reward_penalty_dropped": 0.05,
            "energy_target": 1200.0,
            "latency_target": 0.40,
        }
    ),
    
    # 6. é«˜å¯é æ€§é…ç½®
    WeightConfiguration(
        name="high_reliability",
        description="é«˜å¯é æ€§ - å¼ºè°ƒä»»åŠ¡å®Œæˆç‡",
        weights={
            "reward_weight_delay": 2.0,
            "reward_weight_energy": 1.2,
            "reward_weight_cache": 0.15,
            "reward_penalty_dropped": 0.10,  # å¤§å¹…å¢åŠ ä¸¢å¼ƒæƒ©ç½š
            "energy_target": 1200.0,
            "latency_target": 0.40,
        }
    ),
    
    # 7. æ¿€è¿›é…ç½®ï¼ˆé«˜æƒé‡ï¼ŒæŒ‘æˆ˜æé™ï¼‰
    WeightConfiguration(
        name="aggressive",
        description="æ¿€è¿›é…ç½® - åŒæ—¶ä¼˜åŒ–æ‰€æœ‰ç›®æ ‡",
        weights={
            "reward_weight_delay": 3.0,
            "reward_weight_energy": 2.0,
            "reward_weight_cache": 0.25,
            "reward_penalty_dropped": 0.08,
            "energy_target": 1200.0,
            "latency_target": 0.35,  # æ›´ä¸¥æ ¼çš„æ—¶å»¶ç›®æ ‡
        }
    ),
    
    # 8. ä¿å®ˆé…ç½®ï¼ˆä½æƒé‡ï¼Œç¨³å®šæ”¶æ•›ï¼‰
    WeightConfiguration(
        name="conservative",
        description="ä¿å®ˆé…ç½® - å¹³æ»‘æƒé‡ï¼Œæ˜“äºæ”¶æ•›",
        weights={
            "reward_weight_delay": 1.5,
            "reward_weight_energy": 1.0,
            "reward_weight_cache": 0.10,
            "reward_penalty_dropped": 0.03,
            "energy_target": 1200.0,
            "latency_target": 0.40,
        }
    ),
    
    # 9. æ—¶å»¶èƒ½è€—å¹³è¡¡v2ï¼ˆè°ƒæ•´å½’ä¸€åŒ–ç›®æ ‡ï¼‰
    WeightConfiguration(
        name="balanced_v2",
        description="å¹³è¡¡v2 - é€šè¿‡ç›®æ ‡å€¼å¹³è¡¡æ—¶å»¶èƒ½è€—æƒé‡",
        weights={
            "reward_weight_delay": 2.0,
            "reward_weight_energy": 1.2,
            "reward_weight_cache": 0.15,
            "reward_penalty_dropped": 0.05,
            "energy_target": 2000.0,  # ä¸­é—´å€¼
            "latency_target": 0.40,
        }
    ),
    
    # 10. ç¼“å­˜æ¿€è¿›é…ç½®
    WeightConfiguration(
        name="cache_aggressive",
        description="ç¼“å­˜æ¿€è¿› - å¤§å¹…æé«˜ç¼“å­˜æƒé‡",
        weights={
            "reward_weight_delay": 2.0,
            "reward_weight_energy": 1.2,
            "reward_weight_cache": 0.50,  # éå¸¸é«˜çš„ç¼“å­˜æƒé‡
            "reward_penalty_dropped": 0.05,
            "energy_target": 1200.0,
            "latency_target": 0.40,
        }
    ),
    
    # 11. æœ€å°æˆæœ¬é…ç½®
    WeightConfiguration(
        name="min_cost",
        description="æœ€å°æˆæœ¬ - å¹³è¡¡æƒé‡+åˆç†ç›®æ ‡",
        weights={
            "reward_weight_delay": 1.8,
            "reward_weight_energy": 1.5,
            "reward_weight_cache": 0.12,
            "reward_penalty_dropped": 0.04,
            "energy_target": 2500.0,
            "latency_target": 0.38,
        }
    ),
    
    # 12. ä¸¥æ ¼æ—¶å»¶é…ç½®
    WeightConfiguration(
        name="strict_latency",
        description="ä¸¥æ ¼æ—¶å»¶ - æ›´ä¸¥æ ¼çš„æ—¶å»¶ç›®æ ‡",
        weights={
            "reward_weight_delay": 3.5,
            "reward_weight_energy": 1.0,
            "reward_weight_cache": 0.15,
            "reward_penalty_dropped": 0.05,
            "energy_target": 1200.0,
            "latency_target": 0.35,  # æ›´ä¸¥æ ¼çš„æ—¶å»¶ç›®æ ‡
        }
    ),
    
    # 13. èŠ‚èƒ½ä¼˜å…ˆv2
    WeightConfiguration(
        name="energy_saver",
        description="èŠ‚èƒ½ä¼˜å…ˆv2 - æä½èƒ½è€—ç›®æ ‡",
        weights={
            "reward_weight_delay": 1.5,
            "reward_weight_energy": 2.5,
            "reward_weight_cache": 0.15,
            "reward_penalty_dropped": 0.05,
            "energy_target": 800.0,  # æä½èƒ½è€—ç›®æ ‡
            "latency_target": 0.40,
        }
    ),
    
    # 14. ç»¼åˆæœ€ä¼˜ï¼ˆåŸºäºå‰æœŸåˆ†æï¼‰
    WeightConfiguration(
        name="comprehensive",
        description="ç»¼åˆæœ€ä¼˜ - åŸºäºç»éªŒçš„ç»¼åˆé…ç½®",
        weights={
            "reward_weight_delay": 2.2,
            "reward_weight_energy": 1.5,
            "reward_weight_cache": 0.20,
            "reward_penalty_dropped": 0.06,
            "energy_target": 1800.0,
            "latency_target": 0.38,
        }
    ),
]


def generate_config_files(output_dir: str = "experiments/weight_configs"):
    """ç”Ÿæˆæ‰€æœ‰æƒé‡é…ç½®æ–‡ä»¶"""
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"\n{'='*70}")
    print(f"ç”Ÿæˆæƒé‡é…ç½®æ–‡ä»¶...")
    print(f"{'='*70}\n")
    
    config_files = []
    for cfg in WEIGHT_CONFIGS:
        filename = f"{cfg.name}_weights.json"
        filepath = os.path.join(output_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(cfg.to_dict(), f, indent=2, ensure_ascii=False)
        
        config_files.append(filepath)
        print(f"[OK] {cfg.name:20s} - {cfg.description}")
    
    print(f"\né…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ°: {output_dir}/")
    return config_files


def run_single_experiment(config_name: str, config_weights: Dict, 
                         episodes: int = 100, output_dir: str = None):
    """è¿è¡Œå•ä¸ªæƒé‡é…ç½®å®éªŒ"""
    
    if output_dir is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = f"results/weight_comparison/{config_name}_{timestamp}"
    
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¿å­˜é…ç½®
    config_file = os.path.join(output_dir, "weights_config.json")
    with open(config_file, 'w') as f:
        json.dump(config_weights, f, indent=2)
    
    print(f"\n{'='*70}")
    print(f"è¿è¡Œå®éªŒ: {config_name}")
    print(f"é…ç½®: {config_weights}")
    print(f"è®­ç»ƒè½®æ•°: {episodes}")
    print(f"{'='*70}\n")
    
    # æ„å»ºå‘½ä»¤è¡Œå‚æ•°
    cmd = [
        sys.executable,
        "train_single_agent.py",
        "--algorithm", "TD3",
        "--episodes", str(episodes),
        "--num-vehicles", "12",
        "--silent-mode",  # ğŸ”§ é™é»˜æ¨¡å¼ï¼Œé¿å…äº¤äº’å¼è¾“å…¥å¡ä½
    ]
    
    # è®¾ç½®ç¯å¢ƒå˜é‡ä¼ é€’æƒé‡é…ç½®
    env = os.environ.copy()
    env['WEIGHT_CONFIG'] = json.dumps(config_weights)
    env['EXPERIMENT_NAME'] = config_name
    
    try:
        # è¿è¡Œè®­ç»ƒ
        result = subprocess.run(
            cmd,
            env=env,
            capture_output=False,
            text=True,
            cwd=os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        )
        
        if result.returncode == 0:
            print(f"\n[OK] Experiment {config_name} completed!")
            return True
        else:
            print(f"\n[FAIL] Experiment {config_name} failed!")
            return False
            
    except Exception as e:
        print(f"\n[ERROR] Experiment {config_name} error: {e}")
        return False


def create_batch_script(episodes: int = 500, output_file: str = None):
    """åˆ›å»ºæ‰¹å¤„ç†è„šæœ¬ï¼Œç”¨äºä¾æ¬¡è¿è¡Œæ‰€æœ‰é…ç½®"""
    
    if output_file is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"experiments/run_weight_comparison_{timestamp}.bat"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("@echo off\n")
        f.write("REM æƒé‡å¯¹æ¯”å®éªŒæ‰¹å¤„ç†è„šæœ¬\n")
        f.write(f"REM ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("REM æ¯ä¸ªé…ç½®è®­ç»ƒ {} è½®\n\n".format(episodes))
        
        for i, cfg in enumerate(WEIGHT_CONFIGS, 1):
            f.write(f"echo.\n")
            f.write(f"echo ============================================================\n")
            f.write(f"echo å®éªŒ {i}/{len(WEIGHT_CONFIGS)}: {cfg.name}\n")
            f.write(f"echo {cfg.description}\n")
            f.write(f"echo ============================================================\n")
            f.write(f"echo.\n\n")
            
            # è®¾ç½®ç¯å¢ƒå˜é‡
            for key, value in cfg.weights.items():
                f.write(f"set WEIGHT_{key.upper()}={value}\n")
            
            f.write(f"set EXPERIMENT_NAME={cfg.name}\n\n")
            
            # è¿è¡Œè®­ç»ƒï¼ˆæ·»åŠ  --silent-mode é¿å…äº¤äº’å¼è¾“å…¥ï¼‰
            f.write(f"python train_single_agent.py --algorithm TD3 --episodes {episodes} --num-vehicles 12 --silent-mode\n\n")
            
            f.write(f"if errorlevel 1 (\n")
            f.write(f"    echo å®éªŒ {cfg.name} å¤±è´¥ï¼\n")
            f.write(f"    pause\n")
            f.write(f"    exit /b 1\n")
            f.write(f")\n\n")
        
        f.write("echo.\n")
        f.write("echo æ‰€æœ‰å®éªŒå®Œæˆï¼\n")
        f.write("echo.\n")
        f.write("pause\n")
    
    print(f"\næ‰¹å¤„ç†è„šæœ¬å·²ç”Ÿæˆ: {output_file}")
    print(f"è¿è¡Œæ–¹å¼: {output_file}")
    return output_file


def analyze_results(results_dir: str = "results/weight_comparison"):
    """åˆ†ææ‰€æœ‰å®éªŒç»“æœå¹¶ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
    
    if not os.path.exists(results_dir):
        print(f"ç»“æœç›®å½•ä¸å­˜åœ¨: {results_dir}")
        return
    
    print(f"\n{'='*70}")
    print(f"åˆ†ææƒé‡å¯¹æ¯”å®éªŒç»“æœ...")
    print(f"{'='*70}\n")
    
    results = []
    
    # æ‰«ææ‰€æœ‰å®éªŒç»“æœ
    for config_name in os.listdir(results_dir):
        config_path = os.path.join(results_dir, config_name)
        if not os.path.isdir(config_path):
            continue
        
        # æŸ¥æ‰¾è®­ç»ƒç»“æœæ–‡ä»¶
        result_files = [f for f in os.listdir(config_path) if f.startswith('training_results') and f.endswith('.json')]
        
        if not result_files:
            print(f"[WARN] No result file found: {config_name}")
            continue
        
        # è¯»å–æœ€æ–°ç»“æœ
        result_file = sorted(result_files)[-1]
        result_path = os.path.join(config_path, result_file)
        
        try:
            with open(result_path, 'r') as f:
                data = json.load(f)
            
            metrics = data.get('episode_metrics', {})
            
            # æå–å100è½®å¹³å‡æŒ‡æ ‡
            last_100 = min(100, len(metrics.get('total_energy', [])))
            
            if last_100 == 0:
                continue
            
            result = {
                'config_name': config_name,
                'avg_energy': np.mean(metrics['total_energy'][-last_100:]),
                'avg_cache_hit': np.mean(metrics['cache_hit_rate'][-last_100:]),
                'avg_completion': np.mean(metrics['task_completion_rate'][-last_100:]),
                'avg_delay': np.mean(metrics['avg_delay'][-last_100:]),
                'avg_loss': np.mean(metrics['data_loss_ratio_bytes'][-last_100:]),
                'std_energy': np.std(metrics['total_energy'][-last_100:]),
                'std_cache_hit': np.std(metrics['cache_hit_rate'][-last_100:]),
            }
            
            results.append(result)
            
        except Exception as e:
            print(f"[ERROR] Failed to read {config_name}: {e}")
    
    if not results:
        print("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å®éªŒç»“æœ")
        return
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    print("\n" + "="*70)
    print("æƒé‡é…ç½®å¯¹æ¯”ç»“æœ")
    print("="*70)
    print(f"{'é…ç½®åç§°':20s} | {'èƒ½è€—(J)':>10s} | {'ç¼“å­˜ç‡':>8s} | {'å®Œæˆç‡':>8s} | {'æ—¶å»¶(s)':>8s} | {'ä¸¢å¤±ç‡':>8s}")
    print("-"*70)
    
    for r in sorted(results, key=lambda x: x['avg_completion'], reverse=True):
        print(f"{r['config_name']:20s} | {r['avg_energy']:10.1f} | {r['avg_cache_hit']:7.1%} | {r['avg_completion']:7.1%} | {r['avg_delay']:8.4f} | {r['avg_loss']:7.1%}")
    
    # æ‰¾å‡ºæœ€ä½³é…ç½®
    print("\n" + "="*70)
    print("æœ€ä½³é…ç½®æ¨è")
    print("="*70)
    
    best_completion = max(results, key=lambda x: x['avg_completion'])
    best_cache = max(results, key=lambda x: x['avg_cache_hit'])
    best_energy = min(results, key=lambda x: x['avg_energy'])
    best_delay = min(results, key=lambda x: x['avg_delay'])
    
    print(f"æœ€é«˜å®Œæˆç‡: {best_completion['config_name']} ({best_completion['avg_completion']:.2%})")
    print(f"æœ€é«˜ç¼“å­˜å‘½ä¸­ç‡: {best_cache['config_name']} ({best_cache['avg_cache_hit']:.2%})")
    print(f"æœ€ä½èƒ½è€—: {best_energy['config_name']} ({best_energy['avg_energy']:.1f}J)")
    print(f"æœ€ä½æ—¶å»¶: {best_delay['config_name']} ({best_delay['avg_delay']:.4f}s)")
    
    # è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆå½’ä¸€åŒ–ååŠ æƒå¹³å‡ï¼‰
    print("\n" + "="*70)
    print("ç»¼åˆè¯„åˆ†ï¼ˆå½’ä¸€åŒ–åŠ æƒå¹³å‡ï¼‰")
    print("="*70)
    
    # å½’ä¸€åŒ–å„æŒ‡æ ‡
    max_completion = max(r['avg_completion'] for r in results)
    max_cache = max(r['avg_cache_hit'] for r in results)
    min_energy = min(r['avg_energy'] for r in results)
    max_energy = max(r['avg_energy'] for r in results)
    min_delay = min(r['avg_delay'] for r in results)
    max_delay = max(r['avg_delay'] for r in results)
    
    for r in results:
        # å½’ä¸€åŒ–å¾—åˆ†ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
        score_completion = r['avg_completion'] / max_completion if max_completion > 0 else 0
        score_cache = r['avg_cache_hit'] / max_cache if max_cache > 0 else 0
        score_energy = 1 - (r['avg_energy'] - min_energy) / (max_energy - min_energy) if max_energy > min_energy else 1
        score_delay = 1 - (r['avg_delay'] - min_delay) / (max_delay - min_delay) if max_delay > min_delay else 1
        
        # ç»¼åˆå¾—åˆ†ï¼ˆæƒé‡ï¼šå®Œæˆç‡30%ï¼Œç¼“å­˜20%ï¼Œèƒ½è€—25%ï¼Œæ—¶å»¶25%ï¼‰
        r['ç»¼åˆå¾—åˆ†'] = 0.30 * score_completion + 0.20 * score_cache + 0.25 * score_energy + 0.25 * score_delay
    
    for r in sorted(results, key=lambda x: x['ç»¼åˆå¾—åˆ†'], reverse=True):
        print(f"{r['config_name']:20s} | ç»¼åˆå¾—åˆ†: {r['ç»¼åˆå¾—åˆ†']:.3f}")
    
    # ä¿å­˜å¯¹æ¯”ç»“æœ
    comparison_file = os.path.join(results_dir, f"comparison_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
    with open(comparison_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nå¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {comparison_file}")


def main():
    parser = argparse.ArgumentParser(description="æƒé‡å¯¹æ¯”å®éªŒå·¥å…·")
    parser.add_argument("--mode", type=str, default="generate",
                       choices=["quick", "full", "generate", "analyze"],
                       help="è¿è¡Œæ¨¡å¼: quick(å¿«é€Ÿ100è½®), full(å®Œæ•´500è½®), generate(ä»…ç”Ÿæˆé…ç½®), analyze(åˆ†æç»“æœ)")
    parser.add_argument("--config", type=str, default=None,
                       help="æŒ‡å®šå•ä¸ªé…ç½®è¿è¡Œ")
    parser.add_argument("--episodes", type=int, default=None,
                       help="è®­ç»ƒè½®æ•°ï¼ˆè¦†ç›–æ¨¡å¼é»˜è®¤å€¼ï¼‰")
    
    args = parser.parse_args()
    
    if args.mode == "generate":
        # ç”Ÿæˆé…ç½®æ–‡ä»¶
        generate_config_files()
        
        # ç”Ÿæˆæ‰¹å¤„ç†è„šæœ¬
        episodes = args.episodes if args.episodes else 500
        create_batch_script(episodes=episodes)
        
        print("\n" + "="*70)
        print("ä¸‹ä¸€æ­¥:")
        print("="*70)
        print("1. æ£€æŸ¥ç”Ÿæˆçš„é…ç½®æ–‡ä»¶: experiments/weight_configs/")
        print("2. è¿è¡Œæ‰¹å¤„ç†è„šæœ¬: experiments/run_weight_comparison_*.bat")
        print("3. æˆ–æ‰‹åŠ¨è¿è¡Œå•ä¸ªé…ç½®ï¼ˆä¿®æ”¹config/system_config.pyä¸­çš„æƒé‡ï¼‰")
        print("4. å®éªŒå®Œæˆåè¿è¡Œ: python experiments/weight_comparison.py --mode analyze")
        
    elif args.mode == "analyze":
        # åˆ†æç»“æœ
        analyze_results()
        
    elif args.mode in ["quick", "full"]:
        # è¿è¡Œå®éªŒ
        episodes = args.episodes if args.episodes else (100 if args.mode == "quick" else 500)
        
        if args.config:
            # è¿è¡ŒæŒ‡å®šé…ç½®
            cfg = next((c for c in WEIGHT_CONFIGS if c.name == args.config), None)
            if cfg:
                run_single_experiment(cfg.name, cfg.weights, episodes)
            else:
                print(f"é”™è¯¯: æœªæ‰¾åˆ°é…ç½® '{args.config}'")
                print(f"å¯ç”¨é…ç½®: {', '.join(c.name for c in WEIGHT_CONFIGS)}")
        else:
            # è¿è¡Œæ‰€æœ‰é…ç½®
            print(f"\n{'='*70}")
            print(f"å¼€å§‹æƒé‡å¯¹æ¯”å®éªŒ - {args.mode.upper()} æ¨¡å¼")
            print(f"å…± {len(WEIGHT_CONFIGS)} ä¸ªé…ç½®ï¼Œæ¯ä¸ªé…ç½®è®­ç»ƒ {episodes} è½®")
            print(f"{'='*70}\n")
            
            for i, cfg in enumerate(WEIGHT_CONFIGS, 1):
                print(f"\n[{i}/{len(WEIGHT_CONFIGS)}] è¿è¡Œé…ç½®: {cfg.name}")
                run_single_experiment(cfg.name, cfg.weights, episodes)
            
            print(f"\n{'='*70}")
            print("æ‰€æœ‰å®éªŒå®Œæˆï¼")
            print(f"{'='*70}\n")
            
            # è‡ªåŠ¨åˆ†æç»“æœ
            analyze_results()
            
            # ğŸ¨ è‡ªåŠ¨ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
            print(f"\n{'='*70}")
            print("å¼€å§‹ç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
            print(f"{'='*70}\n")
            
            try:
                viz_script = os.path.join(os.path.dirname(__file__), "visualize_weight_comparison.py")
                subprocess.run([sys.executable, viz_script], check=True)
                print("\nâœ… å¯¹æ¯”å›¾è¡¨ç”Ÿæˆå®Œæˆï¼")
            except Exception as e:
                print(f"\nâš ï¸ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
                print("å¯æ‰‹åŠ¨è¿è¡Œ: python experiments/visualize_weight_comparison.py")


if __name__ == "__main__":
    main()

