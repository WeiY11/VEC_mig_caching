#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TD3ç»¼åˆå¯¹æ¯”è¯•éªŒæ¡†æ¶
ä¸ºCAM-TD3ç®—æ³•è®¾è®¡çš„å®Œæ•´å®éªŒæ–¹æ¡ˆï¼Œç¬¦åˆé¡¶çº§ä¼šè®®/æœŸåˆŠæ ‡å‡†

å®éªŒç»´åº¦ï¼š
1. ç®—æ³•å¯¹æ¯”ï¼ˆBaseline Comparisonï¼‰ï¼šä¸DRLã€å¯å‘å¼ã€å…ƒå¯å‘å¼ç®—æ³•å¯¹æ¯”
2. æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰ï¼šéªŒè¯å„æ¨¡å—æœ‰æ•ˆæ€§
3. å‚æ•°æ•æ„Ÿæ€§ï¼ˆParameter Sensitivityï¼‰ï¼šåˆ†æå…³é”®å‚æ•°å½±å“
4. é²æ£’æ€§æµ‹è¯•ï¼ˆRobustness Testï¼‰ï¼šæç«¯åœºæ™¯ä¸‹çš„æ€§èƒ½
5. æ”¶æ•›æ€§åˆ†æï¼ˆConvergence Analysisï¼‰ï¼šè®­ç»ƒç¨³å®šæ€§è¯„ä¼°
6. å¯æ‰©å±•æ€§æµ‹è¯•ï¼ˆScalability Testï¼‰ï¼šå¤§è§„æ¨¡åœºæ™¯æ€§èƒ½

è®ºæ–‡å¯¹åº”ï¼š
- ç®—æ³•å¯¹æ¯” â†’ Section 5.1: Performance Comparison
- æ¶ˆèå®éªŒ â†’ Section 5.2: Ablation Study
- å‚æ•°æ•æ„Ÿæ€§ â†’ Section 5.3: Parameter Analysis
- é²æ£’æ€§æµ‹è¯• â†’ Section 5.4: Robustness Evaluation
- æ”¶æ•›æ€§åˆ†æ â†’ Section 5.5: Convergence Study
- å¯æ‰©å±•æ€§ â†’ Section 5.6: Scalability Analysis

ç”¨é€”ï¼š
- æœŸåˆŠ/ä¼šè®®çº§çš„å®Œæ•´å®éªŒå¥—ä»¶ï¼ŒåŒ…æ‹¬ï¼šç®—æ³•å¯¹æ¯”ã€æ¶ˆèã€å‚æ•°æ•æ„Ÿæ€§ã€é²æ£’æ€§ã€æ”¶æ•›æ€§ã€å¯æ‰©å±•æ€§ã€‚
- è‡ªåŠ¨ç»„ç»‡å¹¶ä¿å­˜ç»“æœï¼Œäº§å‡ºè®ºæ–‡å¯ç”¨çš„æ•°æ®ä¸æ‘˜è¦ã€‚

è¿è¡Œå‘½ä»¤ï¼š
- å®Œæ•´å¥—ä»¶ï¼ˆå¿«é€Ÿï¼‰:   python run_td3_comparison.py --mode quick --dimension all
- å®Œæ•´å¥—ä»¶ï¼ˆæ ‡å‡†ï¼‰:   python run_td3_comparison.py --mode standard --dimension all
- ä»…æŸä¸€ç»´åº¦:         python run_td3_comparison.py --mode standard --dimension ablation|sensitivity|robustness|convergence|scalability
"""

import os
import json
import time
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field, asdict

# ============================================================
# å®éªŒé…ç½®æ•°æ®ç±»
# ============================================================

@dataclass
class TD3ExperimentConfig:
    """TD3å®éªŒé…ç½®"""
    name: str
    description: str
    episodes: int = 200
    seeds: List[int] = field(default_factory=lambda: [42, 2025, 3407])
    num_vehicles: int = 12
    num_rsus: int = 4
    num_uavs: int = 2
    max_steps: int = 200
    
    # æ¶ˆèæ§åˆ¶
    enable_cache: bool = True
    enable_migration: bool = True
    enable_collaborative_cache: bool = True
    enable_priority: bool = True
    
    # åœºæ™¯é…ç½®
    bandwidth: float = 20.0  # MHz
    task_arrival_rate: float = 0.5  # tasks/step
    task_size_range: Tuple[float, float] = (1.0, 5.0)  # MB
    
    # å…¶ä»–å‚æ•°
    extra_params: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self):
        return asdict(self)


@dataclass
class ExperimentResult:
    """å®éªŒç»“æœ"""
    config_name: str
    algorithm: str
    seeds: List[int]
    episodes: int
    
    # æ€§èƒ½æŒ‡æ ‡ï¼ˆå‡å€¼ Â± æ ‡å‡†å·®ï¼‰
    avg_reward: Tuple[float, float]  # (mean, std)
    avg_delay: Tuple[float, float]
    avg_energy: Tuple[float, float]
    task_completion_rate: Tuple[float, float]
    cache_hit_rate: Tuple[float, float]
    migration_success_rate: Tuple[float, float]
    
    # é¢å¤–ç»Ÿè®¡
    convergence_episode: Optional[int] = None
    training_time_hours: Optional[float] = None
    
    def to_dict(self):
        return asdict(self)


# ============================================================
# å®éªŒå¥—ä»¶å®šä¹‰
# ============================================================

class TD3ComprehensiveComparison:
    """TD3ç»¼åˆå¯¹æ¯”å®éªŒæ‰§è¡Œå™¨"""
    
    def __init__(self, output_dir: str = "results/td3_comprehensive"):
        self.output_dir = Path(output_dir)
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.experiment_dir = self.output_dir / self.timestamp
        self.experiment_dir.mkdir(parents=True, exist_ok=True)
        
        self.results: Dict[str, Dict[str, Any]] = {}
        
    # ========================================================
    # ç»´åº¦1: ç®—æ³•å¯¹æ¯”å®éªŒ
    # ========================================================
    
    def define_algorithm_comparison(self) -> List[Dict[str, Any]]:
        """
        å®šä¹‰ç®—æ³•å¯¹æ¯”å®éªŒ
        
        å¯¹æ¯”ç»„ï¼š
        1. DRLç®—æ³•ç»„ï¼šTD3, DDPG, SAC, PPO, DQN
        2. å¯å‘å¼ç®—æ³•ç»„ï¼šRandom, Greedy, RoundRobin, LoadBalanced, NearestNode, LocalFirst
        3. å…ƒå¯å‘å¼ç®—æ³•ç»„ï¼šGA, PSO, SimulatedAnnealing
        
        è¯„ä¼°æŒ‡æ ‡ï¼š
        - æ—¶å»¶ï¼ˆä¸»è¦ï¼‰ã€èƒ½è€—ï¼ˆä¸»è¦ï¼‰
        - ä»»åŠ¡å®Œæˆç‡ã€ç¼“å­˜å‘½ä¸­ç‡ã€è¿ç§»æˆåŠŸç‡
        """
        algorithms = []
        
        # ===== DRLç®—æ³•ç»„ =====
        drl_algorithms = ["TD3", "DDPG", "SAC", "PPO", "DQN"]
        for alg in drl_algorithms:
            algorithms.append({
                "name": alg,
                "label": f"CAM-{alg}" if alg == "TD3" else alg,
                "category": "drl",
                "episodes": 800,  # å……åˆ†è®­ç»ƒ
                "seeds": [42, 2025, 3407],  # 3ä¸ªéšæœºç§å­
                "params": {}
            })
        
        # ===== å¯å‘å¼ç®—æ³•ç»„ =====
        heuristic_algorithms = [
            ("Random", "éšæœºé€‰æ‹©"),
            ("Greedy", "è´ªå¿ƒæœ€å°è´Ÿè½½"),
            ("RoundRobin", "è½®è¯¢åˆ†é…"),
            ("LoadBalanced", "è´Ÿè½½å‡è¡¡"),
            ("NearestNode", "æœ€è¿‘èŠ‚ç‚¹"),
            ("LocalFirst", "æœ¬åœ°ä¼˜å…ˆ")
        ]
        for alg_name, desc in heuristic_algorithms:
            algorithms.append({
                "name": alg_name,
                "label": alg_name,
                "category": "heuristic",
                "episodes": 200,  # å¯å‘å¼ç®—æ³•ä¸éœ€è¦è®­ç»ƒï¼Œä½†éœ€è¦è¯„ä¼°
                "seeds": [42, 2025, 3407],
                "params": {},
                "description": desc
            })
        
        # ===== å…ƒå¯å‘å¼ç®—æ³•ç»„ =====
        meta_algorithms = [
            ("GA", "é—ä¼ ç®—æ³•", {"population_size": 50, "generations": 100}),
            ("PSO", "ç²’å­ç¾¤ç®—æ³•", {"swarm_size": 40, "iterations": 100}),
            ("SimulatedAnnealing", "æ¨¡æ‹Ÿé€€ç«", {"initial_temp": 1000, "cooling_rate": 0.95})
        ]
        for alg_name, desc, params in meta_algorithms:
            algorithms.append({
                "name": alg_name,
                "label": alg_name,
                "category": "meta",
                "episodes": 200,
                "seeds": [42, 2025, 3407],
                "params": params,
                "description": desc
            })
        
        return algorithms
    
    # ========================================================
    # ç»´åº¦2: æ¶ˆèå®éªŒ
    # ========================================================
    
    def define_ablation_study(self) -> List[TD3ExperimentConfig]:
        """
        å®šä¹‰æ¶ˆèå®éªŒé…ç½®
        
        ç›®çš„ï¼šéªŒè¯æ¯ä¸ªæ¨¡å—å¯¹ç³»ç»Ÿæ€§èƒ½çš„è´¡çŒ®
        
        é…ç½®ç»„ï¼š
        1. Full-System: å®Œæ•´ç³»ç»Ÿï¼ˆCAM-TD3ï¼‰- åŸºå‡†
        2. No-Cache: ç¦ç”¨è¾¹ç¼˜ç¼“å­˜æ¨¡å—
        3. No-Migration: ç¦ç”¨ä»»åŠ¡è¿ç§»æ¨¡å—
        4. No-Collaborative-Cache: ç¦ç”¨åä½œç¼“å­˜ï¼ˆRSUé—´ï¼‰
        5. No-Priority: ç¦ç”¨ä¼˜å…ˆçº§é˜Ÿåˆ—
        6. Basic-TD3: åŸºç¡€TD3ï¼ˆæ— ç¼“å­˜ã€æ— è¿ç§»ï¼‰
        7. Minimal-System: æœ€å°ç³»ç»Ÿï¼ˆæ‰€æœ‰ä¼˜åŒ–æ¨¡å—ç¦ç”¨ï¼‰
        """
        configs = []
        
        # 1. å®Œæ•´ç³»ç»Ÿï¼ˆåŸºå‡†ï¼‰
        configs.append(TD3ExperimentConfig(
            name="Full-System",
            description="å®Œæ•´CAM-TD3ç³»ç»Ÿï¼ˆæ‰€æœ‰æ¨¡å—å¯ç”¨ï¼‰",
            episodes=800,
            seeds=[42, 2025, 3407, 12345, 67890],  # 5ä¸ªç§å­ï¼Œæ›´å¯é 
            enable_cache=True,
            enable_migration=True,
            enable_collaborative_cache=True,
            enable_priority=True
        ))
        
        # 2. æ— ç¼“å­˜
        configs.append(TD3ExperimentConfig(
            name="No-Cache",
            description="ç¦ç”¨è¾¹ç¼˜ç¼“å­˜æ¨¡å—ï¼ˆéªŒè¯ç¼“å­˜æœ‰æ•ˆæ€§ï¼‰",
            episodes=800,
            seeds=[42, 2025, 3407, 12345, 67890],
            enable_cache=False,
            enable_migration=True,
            enable_collaborative_cache=False,  # ç¼“å­˜ç¦ç”¨ï¼Œåä½œç¼“å­˜ä¹Ÿæ— æ•ˆ
            enable_priority=True
        ))
        
        # 3. æ— è¿ç§»
        configs.append(TD3ExperimentConfig(
            name="No-Migration",
            description="ç¦ç”¨ä»»åŠ¡è¿ç§»æ¨¡å—ï¼ˆéªŒè¯è¿ç§»æœ‰æ•ˆæ€§ï¼‰",
            episodes=800,
            seeds=[42, 2025, 3407, 12345, 67890],
            enable_cache=True,
            enable_migration=False,
            enable_collaborative_cache=True,
            enable_priority=True
        ))
        
        # 4. æ— åä½œç¼“å­˜
        configs.append(TD3ExperimentConfig(
            name="No-Collaborative-Cache",
            description="ç¦ç”¨RSUé—´åä½œç¼“å­˜ï¼ˆéªŒè¯åä½œæœ‰æ•ˆæ€§ï¼‰",
            episodes=800,
            seeds=[42, 2025, 3407, 12345, 67890],
            enable_cache=True,
            enable_migration=True,
            enable_collaborative_cache=False,
            enable_priority=True
        ))
        
        # 5. æ— ä¼˜å…ˆçº§é˜Ÿåˆ—
        configs.append(TD3ExperimentConfig(
            name="No-Priority",
            description="ç¦ç”¨ä»»åŠ¡ä¼˜å…ˆçº§é˜Ÿåˆ—ï¼ˆFIFOé˜Ÿåˆ—ï¼‰",
            episodes=800,
            seeds=[42, 2025, 3407, 12345, 67890],
            enable_cache=True,
            enable_migration=True,
            enable_collaborative_cache=True,
            enable_priority=False
        ))
        
        # 6. åŸºç¡€TD3ï¼ˆæ— ç¼“å­˜ã€æ— è¿ç§»ï¼‰
        configs.append(TD3ExperimentConfig(
            name="Basic-TD3",
            description="åŸºç¡€TD3ï¼ˆä»…å¸è½½å†³ç­–ï¼Œæ— ç¼“å­˜è¿ç§»ï¼‰",
            episodes=800,
            seeds=[42, 2025, 3407, 12345, 67890],
            enable_cache=False,
            enable_migration=False,
            enable_collaborative_cache=False,
            enable_priority=True
        ))
        
        # 7. æœ€å°ç³»ç»Ÿ
        configs.append(TD3ExperimentConfig(
            name="Minimal-System",
            description="æœ€å°ç³»ç»Ÿï¼ˆæ‰€æœ‰ä¼˜åŒ–æ¨¡å—ç¦ç”¨ï¼‰",
            episodes=800,
            seeds=[42, 2025, 3407, 12345, 67890],
            enable_cache=False,
            enable_migration=False,
            enable_collaborative_cache=False,
            enable_priority=False
        ))
        
        return configs
    
    # ========================================================
    # ç»´åº¦3: å‚æ•°æ•æ„Ÿæ€§åˆ†æ
    # ========================================================
    
    def define_parameter_sensitivity(self) -> Dict[str, List[TD3ExperimentConfig]]:
        """
        å®šä¹‰å‚æ•°æ•æ„Ÿæ€§åˆ†æå®éªŒ
        
        ç›®çš„ï¼šåˆ†æå…³é”®å‚æ•°å¯¹ç³»ç»Ÿæ€§èƒ½çš„å½±å“
        
        å‚æ•°ç»´åº¦ï¼š
        1. è½¦è¾†è§„æ¨¡ (num_vehicles): 4, 8, 12, 16, 20, 24, 30
        2. RSUå¯†åº¦ (num_rsus): 2, 4, 6, 8, 10
        3. UAVæ•°é‡ (num_uavs): 0, 1, 2, 3, 4
        4. å¸¦å®½æ°´å¹³ (bandwidth): 10, 15, 20, 25, 30 MHz
        5. ä»»åŠ¡åˆ°è¾¾ç‡ (task_arrival_rate): 0.2, 0.4, 0.6, 0.8, 1.0
        6. ä»»åŠ¡è§„æ¨¡ (task_size): å°(0.5-2MB), ä¸­(1-5MB), å¤§(3-10MB)
        """
        sensitivity_experiments = {}
        
        # ===== 1. è½¦è¾†è§„æ¨¡æ•æ„Ÿæ€§ =====
        vehicle_counts = [4, 8, 12, 16, 20, 24, 30]
        sensitivity_experiments["vehicle_scaling"] = []
        for num_vehicles in vehicle_counts:
            sensitivity_experiments["vehicle_scaling"].append(TD3ExperimentConfig(
                name=f"TD3_vehicles_{num_vehicles}",
                description=f"è½¦è¾†æ•°é‡: {num_vehicles}",
                episodes=400,  # å‚æ•°åˆ†æå¯ä»¥é€‚å½“å‡å°‘è½®æ¬¡
                seeds=[42, 2025, 3407],
                num_vehicles=num_vehicles,
                num_rsus=4,
                num_uavs=2
            ))
        
        # ===== 2. RSUå¯†åº¦æ•æ„Ÿæ€§ =====
        rsu_counts = [2, 4, 6, 8, 10]
        sensitivity_experiments["rsu_density"] = []
        for num_rsus in rsu_counts:
            sensitivity_experiments["rsu_density"].append(TD3ExperimentConfig(
                name=f"TD3_rsus_{num_rsus}",
                description=f"RSUæ•°é‡: {num_rsus}",
                episodes=400,
                seeds=[42, 2025, 3407],
                num_vehicles=12,
                num_rsus=num_rsus,
                num_uavs=2
            ))
        
        # ===== 3. UAVæ•°é‡æ•æ„Ÿæ€§ =====
        uav_counts = [0, 1, 2, 3, 4]
        sensitivity_experiments["uav_count"] = []
        for num_uavs in uav_counts:
            sensitivity_experiments["uav_count"].append(TD3ExperimentConfig(
                name=f"TD3_uavs_{num_uavs}",
                description=f"UAVæ•°é‡: {num_uavs}",
                episodes=400,
                seeds=[42, 2025, 3407],
                num_vehicles=12,
                num_rsus=4,
                num_uavs=num_uavs
            ))
        
        # ===== 4. å¸¦å®½æ°´å¹³æ•æ„Ÿæ€§ =====
        bandwidth_levels = [10, 15, 20, 25, 30]  # MHz
        sensitivity_experiments["bandwidth"] = []
        for bw in bandwidth_levels:
            sensitivity_experiments["bandwidth"].append(TD3ExperimentConfig(
                name=f"TD3_bw_{bw}MHz",
                description=f"å¸¦å®½: {bw} MHz",
                episodes=400,
                seeds=[42, 2025, 3407],
                num_vehicles=12,
                num_rsus=4,
                num_uavs=2,
                bandwidth=float(bw)
            ))
        
        # ===== 5. ä»»åŠ¡åˆ°è¾¾ç‡æ•æ„Ÿæ€§ =====
        arrival_rates = [0.2, 0.4, 0.6, 0.8, 1.0]
        sensitivity_experiments["task_arrival_rate"] = []
        for rate in arrival_rates:
            sensitivity_experiments["task_arrival_rate"].append(TD3ExperimentConfig(
                name=f"TD3_arrival_{rate:.1f}",
                description=f"ä»»åŠ¡åˆ°è¾¾ç‡: {rate} tasks/step",
                episodes=400,
                seeds=[42, 2025, 3407],
                num_vehicles=12,
                task_arrival_rate=rate
            ))
        
        # ===== 6. ä»»åŠ¡è§„æ¨¡æ•æ„Ÿæ€§ =====
        task_sizes = [
            ("small", (0.5, 2.0), "å°ä»»åŠ¡(0.5-2MB)"),
            ("medium", (1.0, 5.0), "ä¸­ä»»åŠ¡(1-5MB)"),
            ("large", (3.0, 10.0), "å¤§ä»»åŠ¡(3-10MB)")
        ]
        sensitivity_experiments["task_size"] = []
        for size_name, size_range, desc in task_sizes:
            sensitivity_experiments["task_size"].append(TD3ExperimentConfig(
                name=f"TD3_tasksize_{size_name}",
                description=desc,
                episodes=400,
                seeds=[42, 2025, 3407],
                num_vehicles=12,
                task_size_range=size_range
            ))
        
        return sensitivity_experiments
    
    # ========================================================
    # ç»´åº¦4: é²æ£’æ€§æµ‹è¯•
    # ========================================================
    
    def define_robustness_tests(self) -> List[TD3ExperimentConfig]:
        """
        å®šä¹‰é²æ£’æ€§æµ‹è¯•å®éªŒ
        
        ç›®çš„ï¼šéªŒè¯ç®—æ³•åœ¨æç«¯/å¼‚å¸¸åœºæ™¯ä¸‹çš„è¡¨ç°
        
        åœºæ™¯ï¼š
        1. æç«¯é«˜è´Ÿè½½ï¼šè½¦è¾†30è¾† + é«˜ä»»åŠ¡åˆ°è¾¾ç‡
        2. æç«¯ä½å¸¦å®½ï¼šå¸¦å®½5MHzï¼ˆæ‹¥å¡åœºæ™¯ï¼‰
        3. é«˜ç§»åŠ¨æ€§ï¼šè½¦è¾†é«˜é€Ÿç§»åŠ¨ï¼ˆé¢‘ç¹åˆ‡æ¢è¿æ¥ï¼‰
        4. RSUå¤±æ•ˆï¼šéƒ¨åˆ†RSUéšæœºå¤±æ•ˆ
        5. åŠ¨æ€æ‹“æ‰‘ï¼šæ‹“æ‰‘ç»“æ„åŠ¨æ€å˜åŒ–
        6. çªå‘æµé‡ï¼šä»»åŠ¡çªå‘åˆ°è¾¾
        """
        configs = []
        
        # 1. æç«¯é«˜è´Ÿè½½
        configs.append(TD3ExperimentConfig(
            name="Extreme-High-Load",
            description="æç«¯é«˜è´Ÿè½½åœºæ™¯ï¼ˆ30è½¦è¾†+é«˜ä»»åŠ¡ç‡ï¼‰",
            episodes=500,
            seeds=[42, 2025, 3407],
            num_vehicles=30,
            num_rsus=6,
            num_uavs=3,
            task_arrival_rate=1.2,
            extra_params={"scenario": "high_load"}
        ))
        
        # 2. æç«¯ä½å¸¦å®½
        configs.append(TD3ExperimentConfig(
            name="Extreme-Low-Bandwidth",
            description="æç«¯ä½å¸¦å®½åœºæ™¯ï¼ˆ5MHzæ‹¥å¡ï¼‰",
            episodes=500,
            seeds=[42, 2025, 3407],
            num_vehicles=16,
            num_rsus=4,
            num_uavs=2,
            bandwidth=5.0,
            extra_params={"scenario": "low_bandwidth"}
        ))
        
        # 3. é«˜ç§»åŠ¨æ€§
        configs.append(TD3ExperimentConfig(
            name="High-Mobility",
            description="é«˜ç§»åŠ¨æ€§åœºæ™¯ï¼ˆè½¦è¾†é«˜é€Ÿ120km/h+ï¼‰",
            episodes=500,
            seeds=[42, 2025, 3407],
            num_vehicles=12,
            num_rsus=6,  # éœ€è¦æ›´å¤šRSUè¦†ç›–
            num_uavs=2,
            extra_params={
                "scenario": "high_mobility",
                "vehicle_speed_range": (80, 140)  # km/h
            }
        ))
        
        # 4. RSUå¤±æ•ˆ
        configs.append(TD3ExperimentConfig(
            name="RSU-Failure",
            description="RSUå¤±æ•ˆåœºæ™¯ï¼ˆéšæœºRSUå¤±æ•ˆ30%æ¦‚ç‡ï¼‰",
            episodes=500,
            seeds=[42, 2025, 3407],
            num_vehicles=12,
            num_rsus=6,
            num_uavs=2,
            extra_params={
                "scenario": "rsu_failure",
                "failure_probability": 0.3
            }
        ))
        
        # 5. åŠ¨æ€æ‹“æ‰‘
        configs.append(TD3ExperimentConfig(
            name="Dynamic-Topology",
            description="åŠ¨æ€æ‹“æ‰‘åœºæ™¯ï¼ˆè½¦è¾†è¿›å‡ºã€èŠ‚ç‚¹å˜åŒ–ï¼‰",
            episodes=500,
            seeds=[42, 2025, 3407],
            num_vehicles=12,
            num_rsus=4,
            num_uavs=2,
            extra_params={
                "scenario": "dynamic_topology",
                "vehicle_join_leave": True
            }
        ))
        
        # 6. çªå‘æµé‡
        configs.append(TD3ExperimentConfig(
            name="Bursty-Traffic",
            description="çªå‘æµé‡åœºæ™¯ï¼ˆä»»åŠ¡çªå‘åˆ°è¾¾ï¼‰",
            episodes=500,
            seeds=[42, 2025, 3407],
            num_vehicles=12,
            num_rsus=4,
            num_uavs=2,
            extra_params={
                "scenario": "bursty_traffic",
                "burst_interval": 50,  # æ¯50æ­¥çªå‘ä¸€æ¬¡
                "burst_size": 20  # çªå‘20ä¸ªä»»åŠ¡
            }
        ))
        
        return configs
    
    # ========================================================
    # ç»´åº¦5: æ”¶æ•›æ€§åˆ†æ
    # ========================================================
    
    def define_convergence_analysis(self) -> List[TD3ExperimentConfig]:
        """
        å®šä¹‰æ”¶æ•›æ€§åˆ†æå®éªŒ
        
        ç›®çš„ï¼šåˆ†æTD3ç®—æ³•çš„æ”¶æ•›é€Ÿåº¦å’Œç¨³å®šæ€§
        
        å®éªŒï¼š
        1. å¤šéšæœºç§å­å®éªŒï¼ˆ10ä¸ªç§å­ï¼‰ï¼šè¯„ä¼°æ”¶æ•›ä¸€è‡´æ€§
        2. é•¿æœŸè®­ç»ƒå®éªŒï¼ˆ1500è½®ï¼‰ï¼šè§‚å¯Ÿé•¿æœŸç¨³å®šæ€§
        3. ä¸åŒå­¦ä¹ ç‡å®éªŒï¼šåˆ†æå­¦ä¹ ç‡å¯¹æ”¶æ•›çš„å½±å“
        """
        configs = []
        
        # 1. å¤šéšæœºç§å­ï¼ˆ10ä¸ªï¼‰
        configs.append(TD3ExperimentConfig(
            name="Convergence-MultiSeed",
            description="å¤šéšæœºç§å­æ”¶æ•›æ€§åˆ†æï¼ˆ10ç§å­ï¼‰",
            episodes=800,
            seeds=[42, 2025, 3407, 12345, 67890, 11111, 22222, 33333, 44444, 55555],
            num_vehicles=12,
            num_rsus=4,
            num_uavs=2
        ))
        
        # 2. é•¿æœŸè®­ç»ƒ
        configs.append(TD3ExperimentConfig(
            name="Convergence-Long-Term",
            description="é•¿æœŸè®­ç»ƒæ”¶æ•›æ€§åˆ†æï¼ˆ1500è½®ï¼‰",
            episodes=1500,
            seeds=[42, 2025, 3407],
            num_vehicles=12,
            num_rsus=4,
            num_uavs=2
        ))
        
        # 3. ä¸åŒå­¦ä¹ ç‡
        learning_rates = [1e-4, 3e-4, 5e-4, 1e-3]
        for lr in learning_rates:
            configs.append(TD3ExperimentConfig(
                name=f"Convergence-LR-{lr:.0e}",
                description=f"å­¦ä¹ ç‡{lr}çš„æ”¶æ•›æ€§",
                episodes=800,
                seeds=[42, 2025, 3407],
                num_vehicles=12,
                num_rsus=4,
                num_uavs=2,
                extra_params={"learning_rate": lr}
            ))
        
        return configs
    
    # ========================================================
    # ç»´åº¦6: å¯æ‰©å±•æ€§æµ‹è¯•
    # ========================================================
    
    def define_scalability_tests(self) -> List[TD3ExperimentConfig]:
        """
        å®šä¹‰å¯æ‰©å±•æ€§æµ‹è¯•å®éªŒ
        
        ç›®çš„ï¼šéªŒè¯ç®—æ³•åœ¨å¤§è§„æ¨¡åœºæ™¯ä¸‹çš„æ€§èƒ½
        
        è§„æ¨¡ï¼š
        1. å°è§„æ¨¡ï¼š5è½¦ + 2RSU + 1UAV
        2. ä¸­è§„æ¨¡ï¼š12è½¦ + 4RSU + 2UAVï¼ˆæ ‡å‡†ï¼‰
        3. å¤§è§„æ¨¡ï¼š30è½¦ + 8RSU + 4UAV
        4. è¶…å¤§è§„æ¨¡ï¼š50è½¦ + 12RSU + 6UAV
        5. æé™è§„æ¨¡ï¼š100è½¦ + 20RSU + 10UAV
        """
        scales = [
            ("Small", 5, 2, 1, "å°è§„æ¨¡"),
            ("Medium", 12, 4, 2, "ä¸­è§„æ¨¡ï¼ˆæ ‡å‡†ï¼‰"),
            ("Large", 30, 8, 4, "å¤§è§„æ¨¡"),
            ("XLarge", 50, 12, 6, "è¶…å¤§è§„æ¨¡"),
            ("XXLarge", 100, 20, 10, "æé™è§„æ¨¡")
        ]
        
        configs = []
        for scale_name, num_v, num_r, num_u, desc in scales:
            configs.append(TD3ExperimentConfig(
                name=f"Scalability-{scale_name}",
                description=f"{desc}: {num_v}è½¦+{num_r}RSU+{num_u}UAV",
                episodes=500 if num_v <= 30 else 300,  # å¤§è§„æ¨¡å‡å°‘è½®æ¬¡
                seeds=[42, 2025, 3407],
                num_vehicles=num_v,
                num_rsus=num_r,
                num_uavs=num_u
            ))
        
        return configs
    
    # ========================================================
    # å®éªŒæ‰§è¡Œæ ¸å¿ƒ
    # ========================================================
    
    def run_experiment(self, config: TD3ExperimentConfig, algorithm: str = "TD3") -> Dict[str, Any]:
        """
        è¿è¡Œå•ä¸ªå®éªŒé…ç½®
        
        å‚æ•°ï¼š
            config: å®éªŒé…ç½®
            algorithm: ç®—æ³•åç§°
        
        è¿”å›ï¼š
            å®éªŒç»“æœå­—å…¸
        """
        from train_single_agent import train_single_algorithm
        
        print(f"\n{'='*80}")
        print(f"å®éªŒ: {config.name}")
        print(f"æè¿°: {config.description}")
        print(f"ç®—æ³•: {algorithm}")
        print(f"è½®æ¬¡: {config.episodes}")
        print(f"ç§å­: {config.seeds}")
        print(f"{'='*80}\n")
        
        # å‡†å¤‡åœºæ™¯è¦†ç›–é…ç½®
        scenario_overrides = {
            "num_vehicles": config.num_vehicles,
            "num_rsus": config.num_rsus,
            "num_uavs": config.num_uavs,
            "max_steps_per_episode": config.max_steps,
            "override_topology": True
        }
        
        # æ·»åŠ é¢å¤–å‚æ•°
        if config.bandwidth != 20.0:
            scenario_overrides["bandwidth"] = config.bandwidth
        
        scenario_overrides.update(config.extra_params)
        
        # å¤šç§å­å®éªŒ
        seed_results = []
        for seed in config.seeds:
            print(f"  â†’ è¿è¡Œç§å­: {seed}")
            start_time = time.time()
            
            # è®¾ç½®éšæœºç§å­
            import random
            random.seed(seed)
            np.random.seed(seed)
            try:
                import torch
                torch.manual_seed(seed)
            except ImportError:
                pass
            
            # è¿è¡Œè®­ç»ƒ
            result = train_single_algorithm(
                algorithm,
                num_episodes=config.episodes,
                silent_mode=True,
                override_scenario=scenario_overrides,
                use_enhanced_cache=config.enable_cache,
                disable_migration=(not config.enable_migration)
            )
            
            elapsed_time = time.time() - start_time
            
            # æå–æŒ‡æ ‡ï¼ˆå20%ç¨³å®šæœŸï¼‰
            stable_start = int(config.episodes * 0.8)
            episode_rewards = result.get("episode_rewards", [])
            episode_metrics = result.get("episode_metrics", {})
            
            seed_result = {
                "seed": seed,
                "training_time_hours": elapsed_time / 3600.0,
                "avg_reward": np.mean(episode_rewards[stable_start:]) if episode_rewards else 0,
                "avg_delay": np.mean(episode_metrics.get("avg_delay", [])[stable_start:]) if episode_metrics.get("avg_delay") else 0,
                "avg_energy": np.mean(episode_metrics.get("total_energy", [])[stable_start:]) if episode_metrics.get("total_energy") else 0,
                "task_completion_rate": np.mean(episode_metrics.get("task_completion_rate", [])[stable_start:]) if episode_metrics.get("task_completion_rate") else 0,
                "cache_hit_rate": np.mean(episode_metrics.get("cache_hit_rate", [])[stable_start:]) if episode_metrics.get("cache_hit_rate") else 0,
                "migration_success_rate": np.mean(episode_metrics.get("migration_success_rate", [])[stable_start:]) if episode_metrics.get("migration_success_rate") else 0,
            }
            
            seed_results.append(seed_result)
            print(f"     å®Œæˆ - å¥–åŠ±: {seed_result['avg_reward']:.3f}, æ—¶å»¶: {seed_result['avg_delay']:.3f}s")
        
        # èšåˆå¤šç§å­ç»“æœ
        aggregated = self._aggregate_seed_results(seed_results)
        aggregated["config"] = config.to_dict()
        aggregated["algorithm"] = algorithm
        
        # ä¿å­˜ç»“æœ
        result_file = self.experiment_dir / f"{config.name}.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(aggregated, f, indent=2, ensure_ascii=False)
        
        print(f"âœ“ ç»“æœå·²ä¿å­˜: {result_file}")
        
        return aggregated
    
    def _aggregate_seed_results(self, seed_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """èšåˆå¤šä¸ªç§å­çš„å®éªŒç»“æœ"""
        metrics = ["avg_reward", "avg_delay", "avg_energy", "task_completion_rate", 
                   "cache_hit_rate", "migration_success_rate", "training_time_hours"]
        
        aggregated = {
            "num_seeds": len(seed_results),
            "seeds": [r["seed"] for r in seed_results]
        }
        
        for metric in metrics:
            values = [r[metric] for r in seed_results if r.get(metric) is not None]
            if values:
                aggregated[metric] = {
                    "mean": float(np.mean(values)),
                    "std": float(np.std(values)),
                    "min": float(np.min(values)),
                    "max": float(np.max(values)),
                    "values": values
                }
            else:
                aggregated[metric] = None
        
        return aggregated
    
    # ========================================================
    # å®Œæ•´å®éªŒå¥—ä»¶è¿è¡Œ
    # ========================================================
    
    def run_full_suite(self, mode: str = "quick"):
        """
        è¿è¡Œå®Œæ•´å®éªŒå¥—ä»¶
        
        å‚æ•°ï¼š
            mode: å®éªŒæ¨¡å¼
                - "quick": å¿«é€Ÿæµ‹è¯•ï¼ˆå‡å°‘è½®æ¬¡å’Œç§å­ï¼‰
                - "standard": æ ‡å‡†å®éªŒï¼ˆè®ºæ–‡æ ‡å‡†é…ç½®ï¼‰
                - "extensive": æ‰©å±•å®éªŒï¼ˆæœ€å…¨é¢ï¼‰
        """
        print("\n" + "="*80)
        print("ğŸ”¬ TD3ç»¼åˆå¯¹æ¯”å®éªŒå¥—ä»¶")
        print("="*80)
        print(f"æ¨¡å¼: {mode.upper()}")
        print(f"è¾“å‡ºç›®å½•: {self.experiment_dir}")
        print("="*80 + "\n")
        
        # æ ¹æ®æ¨¡å¼è°ƒæ•´å‚æ•°
        if mode == "quick":
            episode_factor = 0.25
            seed_count = 1
        elif mode == "standard":
            episode_factor = 1.0
            seed_count = 3
        else:  # extensive
            episode_factor = 1.5
            seed_count = 5
        
        # ä¿å­˜å®éªŒé…ç½®
        suite_config = {
            "mode": mode,
            "timestamp": self.timestamp,
            "episode_factor": episode_factor,
            "seed_count": seed_count
        }
        
        config_file = self.experiment_dir / "suite_config.json"
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(suite_config, f, indent=2)
        
        # 1. ç®—æ³•å¯¹æ¯”
        print("\n" + "="*80)
        print("ğŸ“Š ç»´åº¦1: ç®—æ³•å¯¹æ¯”å®éªŒ")
        print("="*80)
        # ï¼ˆè¿™é‡Œå¯ä»¥è°ƒç”¨ç®—æ³•å¯¹æ¯”æ‰§è¡Œï¼‰
        
        # 2. æ¶ˆèå®éªŒ
        print("\n" + "="*80)
        print("ğŸ” ç»´åº¦2: æ¶ˆèå®éªŒ")
        print("="*80)
        ablation_configs = self.define_ablation_study()
        for config in ablation_configs:
            # æ ¹æ®æ¨¡å¼è°ƒæ•´
            config.episodes = int(config.episodes * episode_factor)
            config.seeds = config.seeds[:seed_count]
            
            result = self.run_experiment(config, algorithm="TD3")
            self.results[f"ablation_{config.name}"] = result
        
        # 3. å‚æ•°æ•æ„Ÿæ€§ï¼ˆé€‰æ‹©éƒ¨åˆ†ç»´åº¦ï¼‰
        print("\n" + "="*80)
        print("ğŸ“ˆ ç»´åº¦3: å‚æ•°æ•æ„Ÿæ€§åˆ†æ")
        print("="*80)
        sensitivity_experiments = self.define_parameter_sensitivity()
        
        # é€‰æ‹©å…³é”®ç»´åº¦ï¼ˆè½¦è¾†è§„æ¨¡ + å¸¦å®½ï¼‰
        for dim_name in ["vehicle_scaling", "bandwidth"]:
            print(f"\nâ†’ å‚æ•°ç»´åº¦: {dim_name}")
            for config in sensitivity_experiments[dim_name]:
                config.episodes = int(config.episodes * episode_factor)
                config.seeds = config.seeds[:seed_count]
                
                result = self.run_experiment(config, algorithm="TD3")
                self.results[f"sensitivity_{config.name}"] = result
        
        # 4. é²æ£’æ€§æµ‹è¯•ï¼ˆé€‰æ‹©2ä¸ªåœºæ™¯ï¼‰
        print("\n" + "="*80)
        print("ğŸ›¡ï¸ ç»´åº¦4: é²æ£’æ€§æµ‹è¯•")
        print("="*80)
        robustness_configs = self.define_robustness_tests()
        for config in robustness_configs[:2]:  # å…ˆè¿è¡Œå‰2ä¸ª
            config.episodes = int(config.episodes * episode_factor)
            config.seeds = config.seeds[:seed_count]
            
            result = self.run_experiment(config, algorithm="TD3")
            self.results[f"robustness_{config.name}"] = result
        
        # 5. æ”¶æ•›æ€§åˆ†æ
        if mode in ["standard", "extensive"]:
            print("\n" + "="*80)
            print("ğŸ“‰ ç»´åº¦5: æ”¶æ•›æ€§åˆ†æ")
            print("="*80)
            convergence_configs = self.define_convergence_analysis()
            for config in convergence_configs[:1]:  # å¤šç§å­å®éªŒ
                result = self.run_experiment(config, algorithm="TD3")
                self.results[f"convergence_{config.name}"] = result
        
        # 6. å¯æ‰©å±•æ€§æµ‹è¯•
        if mode == "extensive":
            print("\n" + "="*80)
            print("ğŸ“ ç»´åº¦6: å¯æ‰©å±•æ€§æµ‹è¯•")
            print("="*80)
            scalability_configs = self.define_scalability_tests()
            for config in scalability_configs:
                result = self.run_experiment(config, algorithm="TD3")
                self.results[f"scalability_{config.name}"] = result
        
        # ä¿å­˜æ€»ç»“
        self._save_summary()
        
        print("\n" + "="*80)
        print("âœ… TD3ç»¼åˆå¯¹æ¯”å®éªŒå¥—ä»¶å®Œæˆï¼")
        print(f"ç»“æœä¿å­˜åœ¨: {self.experiment_dir}")
        print("="*80 + "\n")
    
    def _save_summary(self):
        """ä¿å­˜å®éªŒæ€»ç»“"""
        summary = {
            "timestamp": self.timestamp,
            "total_experiments": len(self.results),
            "results_overview": {}
        }
        
        for exp_name, result in self.results.items():
            summary["results_overview"][exp_name] = {
                "avg_reward": result.get("avg_reward", {}).get("mean"),
                "avg_delay": result.get("avg_delay", {}).get("mean"),
                "avg_energy": result.get("avg_energy", {}).get("mean"),
                "task_completion_rate": result.get("task_completion_rate", {}).get("mean")
            }
        
        summary_file = self.experiment_dir / "experiment_summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ“ å®éªŒæ€»ç»“å·²ä¿å­˜: {summary_file}")


# ============================================================
# å‘½ä»¤è¡Œå…¥å£
# ============================================================

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="TD3ç»¼åˆå¯¹æ¯”å®éªŒæ¡†æ¶")
    parser.add_argument("--mode", type=str, default="quick",
                       choices=["quick", "standard", "extensive"],
                       help="å®éªŒæ¨¡å¼ï¼šquick(å¿«é€Ÿæµ‹è¯•), standard(æ ‡å‡†), extensive(æ‰©å±•)")
    parser.add_argument("--dimension", type=str, default="all",
                       choices=["all", "algorithm", "ablation", "sensitivity", 
                               "robustness", "convergence", "scalability"],
                       help="å®éªŒç»´åº¦é€‰æ‹©")
    parser.add_argument("--output-dir", type=str, default="results/td3_comprehensive",
                       help="è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    # åˆ›å»ºå®éªŒæ‰§è¡Œå™¨
    runner = TD3ComprehensiveComparison(output_dir=args.output_dir)
    
    # è¿è¡Œå®éªŒ
    if args.dimension == "all":
        runner.run_full_suite(mode=args.mode)
    else:
        # å•ç‹¬è¿è¡ŒæŸä¸ªç»´åº¦
        print(f"è¿è¡Œå•ä¸ªç»´åº¦: {args.dimension}")
        # TODO: å®ç°å•ç‹¬ç»´åº¦è¿è¡Œ
    
    print("\nğŸ‰ å®éªŒå®Œæˆï¼")


if __name__ == "__main__":
    main()

