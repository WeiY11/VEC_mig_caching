#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TD3 å¤šè½¦è¾†æ•°é‡çµæ•åº¦å®éªŒè„šæœ¬

ç¤ºä¾‹ç”¨æ³•ï¼š
    python experiments/run_td3_vehicle_sweep.py --vehicles 8 12 16 --episodes 200
    python experiments/run_td3_vehicle_sweep.py --vehicle-range 8 16 4 --episodes 150

è„šæœ¬ä¼šé’ˆå¯¹ä¸åŒè½¦è¾†æ•°é‡è¿è¡Œ TD3 è®­ç»ƒï¼Œ
é€šè¿‡ç¯å¢ƒå˜é‡ `TRAINING_SCENARIO_OVERRIDES` è¦†ç›–ä»¿çœŸå™¨é…ç½®ï¼Œ
å¹¶å°†å…³é”®ç»“æœæ±‡æ€»ä¿å­˜ã€‚
"""

from __future__ import annotations

import argparse
import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
parent_dir = Path(__file__).parent.parent
if str(parent_dir) not in sys.path:
    sys.path.insert(0, str(parent_dir))

from train_single_agent import _apply_global_seed_from_env, train_single_algorithm
from utils.vehicle_sweep_html_generator import VehicleSweepHTMLGenerator
import matplotlib
matplotlib.use('Agg')  # å¿…é¡»åœ¨å¯¼å…¥pyplotä¹‹å‰è®¾ç½®
import matplotlib.pyplot as plt
import numpy as np
import base64
from io import BytesIO


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="è¿è¡ŒTD3ä¸åŒè½¦è¾†æ•°é‡å®éªŒ")
    parser.add_argument(
        "--vehicles",
        type=int,
        nargs="*",
        help="æ˜¾å¼æŒ‡å®šè½¦è¾†æ•°é‡åˆ—è¡¨ (ä¼˜å…ˆçº§é«˜äº --vehicle-range)",
    )
    parser.add_argument(
        "--vehicle-range",
        type=int,
        nargs=3,
        metavar=("START", "END", "STEP"),
        help="ä½¿ç”¨èŒƒå›´ç”Ÿæˆè½¦è¾†æ•°é‡ (å«èµ·å§‹, ä¸å«ç»ˆæ­¢)",
    )
    parser.add_argument(
        "--episodes",
        type=int,
        default=200,
        help="æ¯ä¸ªè½¦è¾†è®¾ç½®çš„è®­ç»ƒè½®æ¬¡ (é»˜è®¤: 200)",
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=42,
        help="å®éªŒç»Ÿä¸€éšæœºç§å­ (é»˜è®¤: 42)",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=Path("results/experiments/td3_vehicle_sweep"),
        help="å®éªŒç»“æœè¾“å‡ºç›®å½• (é»˜è®¤: results/experiments/td3_vehicle_sweep)",
    )
    parser.add_argument(
        "--eval-interval",
        type=int,
        default=None,
        help="è¯„ä¼°é—´éš” (é€ä¼ ç»™train_single_algorithm)",
    )
    parser.add_argument(
        "--save-interval",
        type=int,
        default=None,
        help="ä¿å­˜é—´éš” (é€ä¼ ç»™train_single_algorithm)",
    )
    parser.add_argument(
        "--generate-charts",
        action="store_true",
        default=True,
        help="è‡ªåŠ¨ç”Ÿæˆå¯¹æ¯”å›¾è¡¨ (é»˜è®¤: True)",
    )
    parser.add_argument(
        "--no-charts",
        action="store_true",
        help="ç¦ç”¨å›¾è¡¨ç”Ÿæˆ",
    )
    parser.add_argument(
        "--generate-html",
        action="store_true",
        default=True,
        help="ç”ŸæˆHTMLæŠ¥å‘Š (é»˜è®¤: True)",
    )
    parser.add_argument(
        "--no-html",
        action="store_true",
        help="ç¦ç”¨HTMLæŠ¥å‘Šç”Ÿæˆ",
    )
    return parser.parse_args()


def _create_empty_result(num_vehicles: int, episodes: int) -> Dict:
    """
    åˆ›å»ºç©ºçš„è®­ç»ƒç»“æœï¼ˆç”¨äºå¤±è´¥æƒ…å†µï¼‰
    
    Args:
        num_vehicles: è½¦è¾†æ•°é‡
        episodes: é¢„æœŸçš„è®­ç»ƒè½®æ¬¡
        
    Returns:
        ç©ºçš„ç»“æœå­—å…¸
    """
    return {
        'algorithm': 'TD3',
        'network_topology': {
            'num_vehicles': num_vehicles,
            'num_rsus': 4,
            'num_uavs': 2,
        },
        'state_dim': 'N/A',
        'training_config': {
            'num_episodes': episodes,
            'training_time_hours': 0.0
        },
        'episode_rewards': [],
        'episode_metrics': {},
        'final_performance': {
            'avg_step_reward': -999.0,  # æ˜æ˜¾çš„å¤±è´¥æ ‡è®°
            'avg_delay': 999.0,
            'avg_completion': 0.0
        }
    }


def _build_vehicle_list(args: argparse.Namespace) -> List[int]:
    """
    æ„å»ºè½¦è¾†æ•°é‡åˆ—è¡¨
    
    Args:
        args: å‘½ä»¤è¡Œå‚æ•°
        
    Returns:
        è½¦è¾†æ•°é‡åˆ—è¡¨
    """
    if args.vehicles:
        return args.vehicles
    if args.vehicle_range:
        start, end, step = args.vehicle_range
        if step <= 0:
            raise ValueError("vehicle-range çš„æ­¥é•¿å¿…é¡»ä¸ºæ­£æ•°")
        return list(range(start, end, step))
    
    # ğŸ”§ ä¼˜åŒ–ï¼šä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤è½¦è¾†æ•°é‡ä½œä¸ºåŸºå‡†
    from config import config
    default_vehicles = config.num_vehicles
    return [default_vehicles // 2, default_vehicles, default_vehicles + 4]  # ä¾‹å¦‚ï¼š[6, 12, 16]


def _run_single_setting(num_vehicles: int, seed: int, episodes: int, eval_interval: int | None, save_interval: int | None) -> Dict:
    """
    è¿è¡Œå•ä¸ªè½¦è¾†é…ç½®çš„è®­ç»ƒ
    
    Args:
        num_vehicles: è½¦è¾†æ•°é‡
        seed: éšæœºç§å­
        episodes: è®­ç»ƒè½®æ¬¡
        eval_interval: è¯„ä¼°é—´éš”
        save_interval: ä¿å­˜é—´éš”
        
    Returns:
        è®­ç»ƒç»“æœå­—å…¸
    """
    # è®¾ç½®éšæœºç§å­
    os.environ['RANDOM_SEED'] = str(seed)
    _apply_global_seed_from_env()
    
    # æ„å»ºåœºæ™¯è¦†ç›–é…ç½®
    overrides = {
        "num_vehicles": num_vehicles,
        "override_topology": True
    }
    
    try:
        # ğŸ”§ ä¼˜åŒ–ï¼šç›´æ¥é€šè¿‡override_scenarioå‚æ•°ä¼ é€’ï¼Œæ— éœ€ç¯å¢ƒå˜é‡
        result = train_single_algorithm(
            "TD3",
            num_episodes=episodes,
            eval_interval=eval_interval,
            save_interval=save_interval,
            silent_mode=True,  # å¯ç”¨é™é»˜æ¨¡å¼ï¼Œé¿å…ç”¨æˆ·äº¤äº’é˜»å¡æ‰¹é‡å®éªŒ
            override_scenario=overrides
        )
        
        # éªŒè¯ç»“æœå®Œæ•´æ€§
        if not result or 'final_performance' not in result:
            print(f"âš ï¸  è®­ç»ƒç»“æœä¸å®Œæ•´ (vehicles={num_vehicles})")
            return _create_empty_result(num_vehicles, episodes)
            
        return result
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥ (vehicles={num_vehicles}): {e}")
        import traceback
        traceback.print_exc()
        return _create_empty_result(num_vehicles, episodes)
    finally:
        # æ¸…ç†ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœæœ‰è®¾ç½®çš„è¯ï¼‰
        os.environ.pop('TRAINING_SCENARIO_OVERRIDES', None)


def _extract_summary(num_vehicles: int, run_result: Dict) -> Dict:
    """
    æå–è®­ç»ƒç»“æœæ‘˜è¦
    
    Args:
        num_vehicles: è½¦è¾†æ•°é‡
        run_result: è®­ç»ƒç»“æœå­—å…¸
        
    Returns:
        æ‘˜è¦å­—å…¸
    """
    final_perf = run_result.get("final_performance", {})
    training_cfg = run_result.get("training_config", {})
    
    # ğŸ”§ ä¼˜åŒ–ï¼šè·å–å®é™…çŠ¶æ€ç»´åº¦ï¼Œæ”¯æŒå¤šç§æ ¼å¼
    state_dim = run_result.get("state_dim", "N/A")
    if state_dim == "N/A" and "network_topology" in run_result:
        # å°è¯•è®¡ç®—çŠ¶æ€ç»´åº¦
        topo = run_result["network_topology"]
        num_v = topo.get("num_vehicles", num_vehicles)
        num_r = topo.get("num_rsus", 4)
        num_u = topo.get("num_uavs", 2)
        # ä½¿ç”¨ç»Ÿä¸€çš„çŠ¶æ€ç»´åº¦è®¡ç®—å…¬å¼
        state_dim = num_v * 5 + num_r * 5 + num_u * 5 + 8
    
    # ä¿å­˜å®Œæ•´çš„episodeæ•°æ®ç”¨äºå›¾è¡¨ç”Ÿæˆ
    episode_rewards = run_result.get("episode_rewards", [])
    episode_metrics = run_result.get("episode_metrics", {})
    
    # ğŸ”§ ä¼˜åŒ–ï¼šç¡®ä¿avg_step_rewardå­˜åœ¨ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ç»“æœï¼‰
    avg_step_reward = final_perf.get("avg_step_reward")
    if avg_step_reward is None:
        # å°è¯•ä»avg_rewardè·å–ï¼ˆæ—§ç‰ˆæœ¬ï¼‰
        avg_step_reward = final_perf.get("avg_reward", 0.0)
    
    return {
        "num_vehicles": num_vehicles,
        "state_dim": state_dim,
        "episodes": training_cfg.get("num_episodes", 0),
        "training_time_hours": training_cfg.get("training_time_hours", 0.0),
        "avg_step_reward": avg_step_reward,
        "avg_delay": final_perf.get("avg_delay", 0.0),
        "avg_completion": final_perf.get("avg_completion", 0.0),
        # ä¿å­˜æ—¶é—´åºåˆ—æ•°æ®
        "episode_rewards": episode_rewards,
        "episode_metrics": episode_metrics,
    }


def _save_results(output_dir: Path, summaries: List[Dict]) -> None:
    output_dir.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    summary_path = output_dir / f"td3_vehicle_sweep_summary_{timestamp}.json"
    with summary_path.open("w", encoding="utf-8") as fp:
        json.dump(summaries, fp, indent=2, ensure_ascii=False)

    md_path = output_dir / f"td3_vehicle_sweep_summary_{timestamp}.md"
    with md_path.open("w", encoding="utf-8") as fp:
        fp.write("# TD3 ä¸åŒè½¦è¾†æ•°é‡å®éªŒç»“æœ\n\n")
        fp.write("| Vehicles | State Dim | Episodes | Training Hours | Avg Step Reward | Avg Delay (s) | Completion Rate |\n")
        fp.write("| -------- | --------- | -------- | --------------- | ---------------- | ------------- | ---------------- |\n")
        for item in summaries:
            fp.write(
                f"| {item['num_vehicles']} | {item['state_dim']} | {item['episodes']} | {item['training_time_hours']:.3f} |"
                f" {item['avg_step_reward']:.4f} | {item['avg_delay']:.4f} | {item['avg_completion']:.2%} |\n"
            )

    print(f"[OK] Results saved: {summary_path}")
    print(f"[OK] Markdown report: {md_path}")


def _generate_comparison_charts(output_dir: Path, summaries: List[Dict], timestamp: str) -> None:
    """
    ç”Ÿæˆè½¦è¾†æ•°é‡å¯¹æ¯”å›¾è¡¨
    """
    print("\n" + "=" * 80)
    print("[Chart Generation] Generating comparison charts...")
    print("=" * 80 + "\n")
    
    # è®¾ç½®å­¦æœ¯é£æ ¼
    plt.style.use('seaborn-v0_8-paper')
    plt.rcParams['font.size'] = 10
    plt.rcParams['figure.dpi'] = 300
    
    # æå–æ•°æ®
    vehicles = [s['num_vehicles'] for s in summaries]
    avg_delays = [s['avg_delay'] for s in summaries]
    avg_completions = [s['avg_completion'] for s in summaries]
    avg_step_rewards = [s['avg_step_reward'] for s in summaries]
    training_times = [s['training_time_hours'] for s in summaries]
    
    # åˆ›å»º4Ã—2å¸ƒå±€çš„ç»¼åˆå¯¹æ¯”å›¾
    fig = plt.figure(figsize=(16, 12))
    
    # 1. å¹³å‡æ—¶å»¶ vs è½¦è¾†æ•°
    ax1 = plt.subplot(2, 3, 1)
    ax1.plot(vehicles, avg_delays, 'o-', color='#D55E00', linewidth=2.5, markersize=8)
    ax1.set_xlabel('Number of Vehicles')
    ax1.set_ylabel('Average Delay (s)')
    ax1.set_title('(a) Average Delay vs Vehicle Count')
    ax1.grid(True, alpha=0.3, linestyle='--')
    for i, (x, y) in enumerate(zip(vehicles, avg_delays)):
        ax1.text(x, y, f'{y:.3f}', ha='center', va='bottom', fontsize=8)
    
    # 2. ä»»åŠ¡å®Œæˆç‡ vs è½¦è¾†æ•°
    ax2 = plt.subplot(2, 3, 2)
    ax2.plot(vehicles, [c*100 for c in avg_completions], 'o-', color='#029E73', linewidth=2.5, markersize=8)
    ax2.set_xlabel('Number of Vehicles')
    ax2.set_ylabel('Task Completion Rate (%)')
    ax2.set_title('(b) Completion Rate vs Vehicle Count')
    ax2.grid(True, alpha=0.3, linestyle='--')
    for i, (x, y) in enumerate(zip(vehicles, avg_completions)):
        ax2.text(x, y*100, f'{y*100:.1f}%', ha='center', va='bottom', fontsize=8)
    
    # 3. å¹³å‡æ¯æ­¥å¥–åŠ± vs è½¦è¾†æ•°
    ax3 = plt.subplot(2, 3, 3)
    ax3.plot(vehicles, avg_step_rewards, 'o-', color='#0173B2', linewidth=2.5, markersize=8)
    ax3.set_xlabel('Number of Vehicles')
    ax3.set_ylabel('Average Step Reward')
    ax3.set_title('(c) Reward vs Vehicle Count')
    ax3.grid(True, alpha=0.3, linestyle='--')
    for i, (x, y) in enumerate(zip(vehicles, avg_step_rewards)):
        ax3.text(x, y, f'{y:.3f}', ha='center', va='bottom', fontsize=8)
    
    # 4. è®­ç»ƒæ—¶é—´ vs è½¦è¾†æ•°
    ax4 = plt.subplot(2, 3, 4)
    ax4.plot(vehicles, training_times, 'o-', color='#CC78BC', linewidth=2.5, markersize=8)
    ax4.set_xlabel('Number of Vehicles')
    ax4.set_ylabel('Training Time (hours)')
    ax4.set_title('(d) Training Time vs Vehicle Count')
    ax4.grid(True, alpha=0.3, linestyle='--')
    for i, (x, y) in enumerate(zip(vehicles, training_times)):
        ax4.text(x, y, f'{y:.2f}h', ha='center', va='bottom', fontsize=8)
    
    # 5. æ”¶æ•›æ€§å¯¹æ¯”ï¼ˆå¦‚æœæœ‰episodeæ•°æ®ï¼‰
    ax5 = plt.subplot(2, 3, 5)
    has_episode_data = all('episode_rewards' in s and s['episode_rewards'] for s in summaries)
    if has_episode_data:
        colors = ['#0173B2', '#DE8F05', '#029E73', '#D55E00', '#CC78BC', '#CA9161']
        for i, summary in enumerate(summaries):
            rewards = summary['episode_rewards']
            if len(rewards) > 0:
                # ç§»åŠ¨å¹³å‡
                window = min(20, len(rewards) // 5) if len(rewards) >= 5 else 1
                if window > 1:
                    moving_avg = np.convolve(rewards, np.ones(window)/window, mode='valid')
                    episodes = range(window, len(rewards) + 1)
                else:
                    moving_avg = rewards
                    episodes = range(1, len(rewards) + 1)
                
                label = f'{summary["num_vehicles"]} vehicles'
                ax5.plot(episodes, moving_avg, label=label, 
                        color=colors[i % len(colors)], linewidth=2, alpha=0.8)
        
        ax5.set_xlabel('Episode')
        ax5.set_ylabel('Average Step Reward')
        ax5.set_title('(e) Convergence Comparison')
        ax5.legend(loc='best', frameon=True, fancybox=False, edgecolor='black')
        ax5.grid(True, alpha=0.3, linestyle='--')
    else:
        ax5.text(0.5, 0.5, 'No episode data available', 
                ha='center', va='center', transform=ax5.transAxes)
        ax5.set_title('(e) Convergence Comparison')
    
    # 6. ç»¼åˆæ€§èƒ½é›·è¾¾å›¾
    ax6 = plt.subplot(2, 3, 6, projection='polar')
    
    # å½’ä¸€åŒ–æŒ‡æ ‡åˆ°[0, 1]
    def normalize(data):
        min_val, max_val = min(data), max(data)
        if max_val == min_val:
            return [0.5] * len(data)
        return [(x - min_val) / (max_val - min_val) for x in data]
    
    # æ—¶å»¶å½’ä¸€åŒ–ï¼ˆè¶Šå°è¶Šå¥½ï¼Œæ‰€ä»¥å–åï¼‰
    norm_delays = [1 - x for x in normalize(avg_delays)]
    norm_completions = normalize(avg_completions)
    # å¥–åŠ±å½’ä¸€åŒ–ï¼ˆè´Ÿå€¼ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†ï¼‰
    if all(r < 0 for r in avg_step_rewards):
        # éƒ½æ˜¯è´Ÿå€¼ï¼Œè¶Šå¤§ï¼ˆæ¥è¿‘0ï¼‰è¶Šå¥½
        norm_rewards = normalize(avg_step_rewards)
    else:
        norm_rewards = normalize(avg_step_rewards)
    
    # é€‰æ‹©ä¸­é—´çš„é…ç½®ä½œä¸ºç¤ºä¾‹
    mid_idx = len(summaries) // 2
    radar_data = [norm_completions[mid_idx], norm_delays[mid_idx], norm_rewards[mid_idx]]
    
    metrics = ['Completion\nRate', 'Low\nDelay', 'Reward']
    angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()
    radar_data += radar_data[:1]  # é—­åˆ
    angles += angles[:1]
    
    ax6.plot(angles, radar_data, 'o-', linewidth=2, color='#0173B2')
    ax6.fill(angles, radar_data, alpha=0.25, color='#0173B2')
    ax6.set_xticks(angles[:-1])
    ax6.set_xticklabels(metrics)
    ax6.set_ylim(0, 1)
    ax6.set_title(f'(f) Performance Radar\n({vehicles[mid_idx]} vehicles)', y=1.08)
    ax6.grid(True)
    
    plt.suptitle('TD3 Vehicle Count Sensitivity Analysis', fontsize=14, fontweight='bold', y=0.98)
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    chart_path = output_dir / f"vehicle_sweep_comparison_{timestamp}.png"
    plt.savefig(chart_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"[OK] Comparison chart saved: {chart_path}")
    
    # ç”Ÿæˆå•ç‹¬çš„è¯¦ç»†å›¾è¡¨
    _generate_detailed_charts(output_dir, summaries, timestamp)
    
    print("\n" + "=" * 80)
    print("[SUCCESS] All charts generated!")
    print("=" * 80 + "\n")


def _generate_detailed_charts(output_dir: Path, summaries: List[Dict], timestamp: str) -> None:
    """
    ç”Ÿæˆæ›´è¯¦ç»†çš„å•ç‹¬å›¾è¡¨
    """
    vehicles = [s['num_vehicles'] for s in summaries]
    
    # 1. æŸ±çŠ¶å›¾å¯¹æ¯” - å…³é”®æŒ‡æ ‡
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
    
    # æ—¶å»¶å’Œå®Œæˆç‡
    x = np.arange(len(vehicles))
    width = 0.35
    
    delays = [s['avg_delay'] for s in summaries]
    completions = [s['avg_completion'] * 100 for s in summaries]
    
    ax1.bar(x, delays, width, label='Avg Delay (s)', color='#D55E00', alpha=0.8, edgecolor='black')
    ax1.set_xlabel('Number of Vehicles')
    ax1.set_ylabel('Average Delay (s)')
    ax1.set_title('Average Delay Comparison')
    ax1.set_xticks(x)
    ax1.set_xticklabels(vehicles)
    ax1.grid(True, alpha=0.3, axis='y', linestyle='--')
    
    # æ·»åŠ æ•°å€¼æ ‡æ³¨
    for i, v in enumerate(delays):
        ax1.text(i, v, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')
    
    ax2.bar(x, completions, width, label='Completion Rate (%)', color='#029E73', alpha=0.8, edgecolor='black')
    ax2.set_xlabel('Number of Vehicles')
    ax2.set_ylabel('Task Completion Rate (%)')
    ax2.set_title('Task Completion Rate Comparison')
    ax2.set_xticks(x)
    ax2.set_xticklabels(vehicles)
    ax2.grid(True, alpha=0.3, axis='y', linestyle='--')
    
    # æ·»åŠ æ•°å€¼æ ‡æ³¨
    for i, v in enumerate(completions):
        ax2.text(i, v, f'{v:.1f}%', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    chart_path = output_dir / f"vehicle_sweep_bar_comparison_{timestamp}.png"
    plt.savefig(chart_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"[OK] Bar chart saved: {chart_path}")


def main() -> None:
    args = parse_args()
    vehicle_list = _build_vehicle_list(args)
    
    # å¤„ç†å›¾è¡¨ç”Ÿæˆæ ‡å¿—
    generate_charts = args.generate_charts and not args.no_charts
    generate_html = args.generate_html and not args.no_html

    print("=" * 80)
    print("[TD3 Vehicle Sweep Experiment]")
    print(f"Vehicle counts: {vehicle_list}")
    print(f"Random seed: {args.seed}")
    print(f"Episodes per run: {args.episodes}")
    print(f"Generate charts: {generate_charts}")
    print(f"Generate HTML report: {generate_html}")
    print("=" * 80)

    summaries: List[Dict] = []
    for num_vehicles in vehicle_list:
        print("-" * 60)
        print(f"[Running] num_vehicles = {num_vehicles}")
        result = _run_single_setting(num_vehicles, args.seed, args.episodes, args.eval_interval, args.save_interval)
        summary = _extract_summary(num_vehicles, result)
        summaries.append(summary)
        print(
            f"[OK] num_vehicles={num_vehicles} completed: "
            f"Delay={summary['avg_delay']:.4f}s, Completion={summary['avg_completion']:.2%}"
        )

    # ğŸ”§ ç»Ÿä¸€æ—¶é—´æˆ³ï¼ˆç¡®ä¿æ–‡ä»¶åä¸€è‡´ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ä¿å­˜ç»“æœ
    _save_results(args.output_dir, summaries)
    
    # å®šä¹‰å›¾è¡¨è·¯å¾„
    chart1_path = args.output_dir / f"vehicle_sweep_comparison_{timestamp}.png"
    chart2_path = args.output_dir / f"vehicle_sweep_bar_comparison_{timestamp}.png"
    
    # ğŸ†• ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
    if generate_charts:
        try:
            _generate_comparison_charts(args.output_dir, summaries, timestamp)
        except Exception as e:
            print(f"[WARNING] Failed to generate charts: {e}")
            print("Results are still saved successfully.")
    
    # ğŸ†• ç”Ÿæˆå¢å¼ºç‰ˆHTMLæŠ¥å‘Šï¼ˆåœ¨å›¾è¡¨ç”Ÿæˆä¹‹åï¼‰
    if generate_html:
        try:
            print("\n" + "=" * 80)
            print("[HTML Report] Generating enhanced HTML report...")
            print("=" * 80 + "\n")
            
            # ä½¿ç”¨å¢å¼ºç‰ˆHTMLç”Ÿæˆå™¨
            generator = VehicleSweepHTMLGenerator()
            html_content = generator.generate_enhanced_report(summaries, timestamp, chart1_path, chart2_path)
            
            html_path = args.output_dir / f"vehicle_sweep_report_{timestamp}.html"
            if generator.save_report(html_content, html_path):
                print(f"[OK] HTML report saved: {html_path}")
                
                # è‡ªåŠ¨æ‰“å¼€HTMLæŠ¥å‘Š
                import webbrowser
                abs_path = html_path.resolve()
                webbrowser.open(f'file://{abs_path}')
                print(f"[OK] HTML report opened in browser")
                
                print("\n" + "=" * 80)
                print("[SUCCESS] Enhanced HTML report generated!")
                print("=" * 80 + "\n")
        except Exception as e:
            print(f"[WARNING] Failed to generate HTML report: {e}")
            print("Results and charts are still saved successfully.")
    
    print("=" * 80)
    print("[SUCCESS] Vehicle sweep experiment completed!")
    print(f"Output directory: {args.output_dir.resolve()}")
    print("=" * 80)


if __name__ == "__main__":
    main()


