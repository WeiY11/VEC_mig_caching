#!/usr/bin/env python3
"""
TD3 ååŒç¼“å­˜å®¹é‡å¯¹æ¯”å®éªŒ
=============================

ç ”ç©¶ç›®æ ‡
--------
- æ‰«æååŒç¼“å­˜å®¹é‡ï¼ˆRSU/UAV å…±äº«ç¼“å­˜ï¼‰å¯¹å…­ç±»ç­–ç•¥æ€§èƒ½çš„å½±å“
- å…³æ³¨ç¼“å­˜å‘½ä¸­ç‡ã€ç¼“å­˜åˆ©ç”¨ç‡ã€æ•°æ®ä¸¢å¤±æ¯”ä¾‹ç­‰æŒ‡æ ‡çš„å˜åŒ–è¶‹åŠ¿
- ä¸ºè®ºæ–‡å›¾è¡¨æˆ–æŠ¥å‘Šæä¾›å¯å¤ç°çš„çµæ•åº¦åˆ†æè„šæœ¬
"""

from __future__ import annotations

import argparse
import json
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List

import matplotlib.pyplot as plt

# ========== æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„ ==========
script_dir = Path(__file__).resolve().parent
project_root = script_dir.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from experiments.td3_strategy_suite.strategy_runner import (
    evaluate_configs,
    strategy_label,
    tail_mean,
)
from experiments.td3_strategy_suite.visualization_utils import (
    add_line_charts,
    print_chart_summary,
)
from experiments.td3_strategy_suite.suite_cli import (
    add_common_experiment_args,
    format_strategy_list,
    resolve_common_args,
    resolve_strategy_keys,
    suite_path as build_suite_path,
    get_default_scenario_overrides,
    validate_td3_episodes,
)

DEFAULT_EPISODES = 1500  # TD3 æ”¶æ•›æ¨èè½®æ¬¡
DEFAULT_EPISODES_FAST = 500  # å¿«é€ŸéªŒè¯æ¨¡å¼
DEFAULT_EPISODES_HEURISTIC = 300  # å¯å‘å¼ç­–ç•¥æ”¶æ•›æ‰€éœ€è½®æ¬¡
DEFAULT_SEED = 42
DEFAULT_CACHE_LEVELS_MB = [256, 512, 768, 1024, 1536]  # MB (æå°/å°/ä¸­/å¤§/æå¤§)


def parse_cache_levels(value: str) -> List[float]:
    if not value or value.strip().lower() == "default":
        return list(DEFAULT_CACHE_LEVELS_MB)
    parsed: List[float] = []
    for item in value.split(","):
        item = item.strip()
        if not item:
            continue
        parsed.append(float(item))
    if not parsed:
        raise ValueError("Cache capacity list cannot be empty.")
    return parsed


def cache_metrics_hook(
    strategy_key: str,
    metrics: Dict[str, float],
    config: Dict[str, object],
    episode_metrics: Dict[str, List[float]],
) -> None:
    hit_rate = tail_mean(episode_metrics.get("cache_hit_rate", []))
    utilization = tail_mean(episode_metrics.get("cache_utilization", []))
    eviction_rate = tail_mean(episode_metrics.get("cache_eviction_rate", []))
    loss_ratio = tail_mean(episode_metrics.get("data_loss_ratio_bytes", []))

    metrics["cache_hit_rate"] = max(hit_rate, 0.0)
    metrics["cache_utilization"] = max(utilization, 0.0)
    metrics["cache_eviction_rate"] = max(eviction_rate, 0.0)
    metrics["data_loss_ratio"] = max(loss_ratio, 0.0)


def plot_results(results: List[Dict[str, object]], suite_dir: Path, strategy_keys: List[str]) -> None:
    capacities = [float(record["cache_capacity_mb"]) for record in results]

    def make_chart(metric: str, ylabel: str, filename: str) -> None:
        plt.figure(figsize=(10, 6))
        for strat_key in strategy_keys:
            values = [record["strategies"][strat_key][metric] for record in results]
            plt.plot(capacities, values, marker="o", linewidth=2, label=strategy_label(strat_key))
        plt.xlabel("Collaborative Cache Capacity (MB)")
        plt.ylabel(ylabel)
        plt.title(f"Impact of Cache Capacity on {ylabel}")
        plt.grid(alpha=0.3)
        plt.legend()
        plt.tight_layout()
        plt.savefig(suite_dir / filename, dpi=300, bbox_inches="tight")
        plt.close()

    make_chart("raw_cost", "Average Cost", "cache_capacity_vs_cost.png")
    make_chart("cache_hit_rate", "Cache Hit Rate", "cache_capacity_vs_hit_rate.png")
    make_chart("cache_utilization", "Cache Utilization", "cache_capacity_vs_utilization.png")
    make_chart("data_loss_ratio", "Data Loss Ratio", "cache_capacity_vs_loss_ratio.png")

    print("\nCharts saved:")
    for name in [
        "cache_capacity_vs_cost.png",
        "cache_capacity_vs_hit_rate.png",
        "cache_capacity_vs_utilization.png",
        "cache_capacity_vs_loss_ratio.png",
    ]:
        print(f"  - {suite_dir / name}")


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Evaluate TD3 strategy performance under different collaborative cache capacities."
    )
    parser.add_argument(
        "--cache-levels",
        type=str,
        default="default",
        help="Comma-separated cache capacity values (MB) or 'default'.",
    )
    add_common_experiment_args(
        parser,
        default_suite_prefix="cache_capacity",
        default_output_root="results/parameter_sensitivity",
        default_episodes=DEFAULT_EPISODES,
        default_seed=DEFAULT_SEED,
        allow_strategies=True,
    )

    args = parser.parse_args()
    # å¿«é€Ÿæ¨¡å¼å¯é™ä½è½®æ¬¡/é…ç½®ï¼Œç”¨äºè°ƒè¯•
    if args.fast_mode:
        print("\n" + "=" * 80)
        print("ğŸš€ å¿«é€ŸéªŒè¯æ¨¡å¼å·²å¯ç”¨ï¼š")
        print(f"  è®­ç»ƒè½®æ¬¡: {DEFAULT_EPISODES} -> {DEFAULT_EPISODES_FAST}")
        print(f"  é…ç½®ç‚¹  : {len(DEFAULT_CACHE_LEVELS_MB)} -> 3 (min/median/max)")
        print("=" * 80 + "\n")
        default_episodes_to_use = DEFAULT_EPISODES_FAST
    else:
        default_episodes_to_use = DEFAULT_EPISODES

    common = resolve_common_args(
        args,
        default_suite_prefix="cache_capacity",
        default_output_root="results/parameter_sensitivity",
        default_episodes=default_episodes_to_use,
        default_seed=DEFAULT_SEED,
        allow_strategies=True,
    )
    strategy_keys = resolve_strategy_keys(common.strategies)

    cache_levels = parse_cache_levels(args.cache_levels)
    if args.fast_mode and cache_levels == DEFAULT_CACHE_LEVELS_MB:
        midpoint = cache_levels[len(cache_levels) // 2]
        cache_levels = [cache_levels[0], midpoint, cache_levels[-1]]
    configs: List[Dict[str, object]] = []
    for capacity_mb in cache_levels:
        overrides = get_default_scenario_overrides(
            cache_capacity=float(capacity_mb),
        )
        configs.append(
            {
                "key": f"{int(capacity_mb)}mb",
                "label": f"{int(capacity_mb)} MB",
                "overrides": overrides,
                "cache_capacity_mb": float(capacity_mb),
            }
        )

    # ğŸ¯ éªŒè¯TD3è®­ç»ƒè½®æ¬¡
    validate_td3_episodes(common.episodes, strategy_keys)

    # ğŸ¯ å¯å‘å¼ç­–ç•¥ç¼©çŸ­è½®æ¬¡ï¼ˆä¿æŒå…¬å¹³åŒæ—¶èŠ‚çœæ—¶é—´ï¼‰
    heuristic_strategies = {"local-only", "remote-only", "offloading-only", "resource-only", "random", "round-robin"}
    strategy_episode_overrides: Dict[str, int] = {}
    if common.optimize_heuristic:
        for key in strategy_keys:
            if key in heuristic_strategies:
                strategy_episode_overrides[key] = DEFAULT_EPISODES_HEURISTIC
        if strategy_episode_overrides:
            print("\nğŸ¯ å¯å‘å¼ç­–ç•¥ä¼˜åŒ–å·²å¯ç”¨ï¼š")
            print(f"  - å¯å‘å¼ç­–ç•¥è½®æ¬¡: {DEFAULT_EPISODES_HEURISTIC}")
            print(f"  - TD3 ç­–ç•¥è½®æ¬¡ : {common.episodes}")

    total_runs = len(configs) * len(strategy_keys)
    print(f"\nå³å°†è¿è¡Œ {len(configs)} ä¸ªé…ç½® Ã— {len(strategy_keys)} ç­–ç•¥ = {total_runs} æ¬¡è®­ç»ƒ")
    
    suite_dir = build_suite_path(common)
    results = evaluate_configs(
        configs=configs,
        episodes=common.episodes,
        seed=common.seed,
        silent=common.silent,
        suite_path=suite_dir,
        strategies=strategy_keys,
        per_strategy_hook=cache_metrics_hook,
        central_resource=common.central_resource,
        strategy_episode_overrides=strategy_episode_overrides or None,
    )

    summary = {
        "experiment_type": "cache_capacity_sensitivity",
        "suite_id": common.suite_id,
        "created_at": datetime.now().isoformat(),
        "num_configs": len(results),
        "episodes_per_config": common.episodes,
        "seed": common.seed,
        "strategy_keys": strategy_keys,
        "cache_levels_mb": cache_levels,
        "results": results,
    }
    summary_path = suite_dir / "summary.json"
    summary_path.write_text(json.dumps(summary, indent=2, ensure_ascii=False), encoding="utf-8")

    plot_results(results, suite_dir, strategy_keys)

    print("\nCache Capacity Sensitivity Analysis Completed")
    print(f"Suite ID             : {common.suite_id}")
    print(f"Strategies           : {format_strategy_list(common.strategies)}")
    print(f"Configurations tested: {len(results)}")
    print(f"{'Capacity (MB)':<16}", end="")
    for strat_key in strategy_keys:
        print(f"{strategy_label(strat_key):>18}", end="")
    print()
    print("-" * (16 + 18 * len(strategy_keys)))
    for record in results:
        print(f"{record['cache_capacity_mb']:<16.0f}", end="")
        for strat_key in strategy_keys:
            print(f"{record['strategies'][strat_key]['raw_cost']:<18.4f}", end="")
        print()
    print(f"\nSummary saved to: {summary_path}")


if __name__ == "__main__":
    main()
