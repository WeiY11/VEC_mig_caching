"""
è¾¹ç¼˜ç¼“å­˜ç®¡ç†ç³»ç»Ÿ - å¯¹åº”è®ºæ–‡ç¬¬7èŠ‚
å®ç°æ™ºèƒ½ç¼“å­˜ç­–ç•¥ã€åä½œç¼“å­˜å’ŒèƒŒåŒ…ä¼˜åŒ–ç®—æ³•
"""
import numpy as np
import time
import math
from typing import Dict, List, Tuple, Optional, Set
from dataclasses import dataclass
from enum import Enum
from collections import defaultdict, OrderedDict
# ğŸ”§ ä¿®å¤ï¼šå¯¼å…¥ç»Ÿä¸€æ—¶é—´ç®¡ç†å™¨
from utils.unified_time_manager import get_simulation_time

from models.data_structures import Task, TaskType
from config import config
from utils.common import calculate_zipf_probability, ExponentialMovingAverage


class CacheReplacementPolicy(Enum):
    """ç¼“å­˜æ›¿æ¢ç­–ç•¥æšä¸¾"""
    LRU = "lru"      # Least Recently Used
    LFU = "lfu"      # Least Frequently Used
    FIFO = "fifo"    # First In First Out
    HYBRID = "hybrid" # æ··åˆç­–ç•¥


@dataclass
class CachedItem:
    """ç¼“å­˜é¡¹æ•°æ®ç»“æ„"""
    content_id: str
    data_size: float
    access_count: int = 0
    last_access_time: float = 0.0
    cache_time: float = 0.0
    
    # çƒ­åº¦ç›¸å…³
    historical_heat: float = 0.0
    slot_heat: float = 0.0
    zipf_popularity: float = 0.0
    
    # é¢„æµ‹ç›¸å…³
    predicted_requests: float = 0.0
    cache_value: float = 0.0


class HeatBasedCacheStrategy:
    """
    åŸºäºçƒ­åº¦çš„ç¼“å­˜ç­–ç•¥ - å¯¹åº”è®ºæ–‡ç¬¬7èŠ‚
    ç»“åˆå†å²çƒ­åº¦ã€æ—¶é—´æ§½çƒ­åº¦å’ŒZipfæµè¡Œåº¦åˆ†å¸ƒ
    """
    
    def __init__(self, slot_duration: Optional[float] = None, total_slots: Optional[int] = None):
        """
        åˆå§‹åŒ–çƒ­åº¦ç­–ç•¥
        
        Args:
            slot_duration: æ—¶é—´æ§½æ—¶é•¿ï¼ˆç§’ï¼‰ï¼ŒNoneåˆ™è‡ªé€‚åº”
            total_slots: æ€»æ—¶é—´æ§½æ•°ï¼ŒNoneåˆ™è‡ªé€‚åº”
        """
        # ğŸ”§ åˆ›æ–°ä¼˜åŒ–:è‡ªé€‚åº”çƒ­åº¦å‚æ•°åŠ¨æ€è°ƒæ•´
        # ğŸ¯ æ ¸å¿ƒåˆ›æ–°:æ ¹æ®ç³»ç»Ÿè´Ÿè½½å’Œæ—¶éš™æ¨¡å¼åŠ¨æ€è°ƒæ•´è¡°å‡é€Ÿåº¦
        self.decay_factor = 0.88          # ğŸš€ åˆ›æ–°:è¿›ä¸€æ­¥åŠ å¿«å†·å´(0.92â†’0.88),å¿«é€Ÿå“åº”å†…å®¹æµè¡Œåº¦å˜åŒ–
        self.heat_mix_factor = 0.6        # ğŸš€ åˆ›æ–°:æ›´é‡è§†å®æ—¶çƒ­åº¦(0.7â†’0.6),æ•æ‰åŠ¨æ€çƒ­ç‚¹
        self.zipf_exponent = 0.8          # Zipfåˆ†å¸ƒå‚æ•°
                
        # ğŸ†• åˆ›æ–°:è‡ªé€‚åº”å‚æ•°(æ ¹æ®ç³»ç»Ÿè´Ÿè½½åŠ¨æ€è°ƒæ•´)
        self.adaptive_decay_enabled = True  # å¯ç”¨è‡ªé€‚åº”è¡°å‡
        self.min_decay_factor = 0.80      # é«˜è´Ÿè½½æ—¶æœ€å°è¡°å‡(æ›´æ¿€è¿›æ·˜æ±°)
        self.max_decay_factor = 0.92      # ä½è´Ÿè½½æ—¶æœ€å¤§è¡°å‡(æ›´ä¿å®ˆç¼“å­˜)
        self.system_load_threshold = 0.7  # è´Ÿè½½é˜ˆå€¼
        
        # ğŸš€ è‡ªé€‚åº”æ—¶é—´æ§½é…ç½®
        self.slot_duration = slot_duration if slot_duration is not None else 10.0  # é»˜è®¤10ç§’
        self.total_slots = total_slots if total_slots is not None else 200  # é»˜è®¤200æ§½
        self.adaptive_slot = (slot_duration is None)  # æ˜¯å¦å¯ç”¨è‡ªé€‚åº”
        
        # çƒ­åº¦ç»Ÿè®¡
        self.historical_heat: Dict[str, float] = defaultdict(float)
        self.slot_heat: Dict[str, Dict[int, float]] = defaultdict(lambda: defaultdict(float))
        self.current_slot = 0
        self.simulation_start_time = get_simulation_time()  # è®°å½•ä»¿çœŸå¼€å§‹æ—¶é—´
        
        # è‡ªé€‚åº”è°ƒæ•´ç›¸å…³
        self.access_count_per_slot = defaultdict(int)  # æ¯ä¸ªæ§½çš„è®¿é—®è®¡æ•°
        self.last_slot_adjustment = 0
        
        # è®¿é—®ç»Ÿè®¡
        self.access_history: Dict[str, List[float]] = defaultdict(list)
        self.content_popularity_rank: Dict[str, int] = {}
        
        # ç§»åŠ¨å¹³å‡è®¡ç®—å™¨
        self.avg_heat = ExponentialMovingAverage(alpha=0.1)
        
        # æ€§èƒ½ä¼˜åŒ–ï¼šè®°å½•ä¸Šæ¬¡æ’åæ›´æ–°ï¼ˆç”¨äºæƒ°æ€§æ›´æ–°ï¼‰
        self._last_rank_update = 0
    
    def update_heat(self, content_id: str, access_weight: float = 1.0, system_load: float = 0.5):
        """
        ğŸš€ åˆ›æ–°ä¼˜åŒ–:è‡ªé€‚åº”çƒ­åº¦æ›´æ–° - æ ¹æ®ç³»ç»Ÿè´Ÿè½½åŠ¨æ€è°ƒæ•´è¡°å‡
            
        åˆ›æ–°ç‚¹:
        1. é«˜è´Ÿè½½æ—¶åŠ å¿«è¡°å‡,å¿«é€Ÿè…¾å‡ºç©ºé—´
        2. ä½è´Ÿè½½æ—¶å‡æ…¢è¡°å‡,ä¿ç•™æ›´å¤šå†å²ä¿¡æ¯
        3. å¼•å…¥è®¿é—®é—´éš”åŠ æƒ,é¢‘ç¹è®¿é—®çš„å†…å®¹è·å¾—æ›´é«˜æƒé‡
        """
        # ğŸ†• åˆ›æ–°:è‡ªé€‚åº”è¡°å‡å› å­(æ ¹æ®ç³»ç»Ÿè´Ÿè½½)
        if self.adaptive_decay_enabled:
            if system_load > self.system_load_threshold:
                # é«˜è´Ÿè½½:æ¿€è¿›æ·˜æ±°,å¿«é€Ÿå“åº”
                current_decay = self.min_decay_factor
            else:
                # ä½è´Ÿè½½:ä¿å®ˆç¼“å­˜,åˆ©ç”¨å†å²
                current_decay = self.max_decay_factor
        else:
            current_decay = self.decay_factor
            
        # ğŸ†• åˆ›æ–°:è®¿é—®é—´éš”åŠ æƒ(é¢‘ç¹è®¿é—®è·å¾—boost)
        access_boost = 1.0
        if content_id in self.access_history and len(self.access_history[content_id]) >= 2:
            # è®¡ç®—æœ€è¿‘ä¸¤æ¬¡è®¿é—®é—´éš”
            last_interval = get_simulation_time() - self.access_history[content_id][-1]
            if last_interval < 30.0:  # 30ç§’å†…å†æ¬¡è®¿é—®,è§†ä¸ºé«˜é¢‘
                access_boost = 1.5  # æå‡50%æƒé‡
            
        # æ›´æ–°å†å²çƒ­åº¦ - å¼(35) + åˆ›æ–°è‡ªé€‚åº”æœºåˆ¶
        self.historical_heat[content_id] = (current_decay * self.historical_heat[content_id] + 
                                           access_weight * access_boost)
        
        # ğŸš€ è‡ªé€‚åº”æ—¶é—´æ§½è®¡ç®—
        simulation_time = get_simulation_time()
        current_slot = int(simulation_time / self.slot_duration) % self.total_slots
        self.slot_heat[content_id][current_slot] += access_weight
        
        # è®°å½•å½“å‰æ§½çš„è®¿é—®è®¡æ•°ï¼ˆç”¨äºè‡ªé€‚åº”è°ƒæ•´ï¼‰
        self.access_count_per_slot[current_slot] += 1
        
        # ğŸš€ è‡ªé€‚åº”è°ƒæ•´æ—¶é—´æ§½ç²’åº¦ï¼ˆæ¯1000æ¬¡è®¿é—®æ£€æŸ¥ä¸€æ¬¡ï¼‰
        if self.adaptive_slot and len(self.historical_heat) % 1000 == 0:
            self._adjust_slot_granularity()
        
        # ğŸ”§ ä¿®å¤ï¼šè®°å½•ä»¿çœŸæ—¶é—´ï¼ˆä¼˜åŒ–ï¼šåªä¿ç•™æœ€è¿‘20æ¬¡ï¼Œå‡å°‘80%å†…å­˜ï¼‰
        self.access_history[content_id].append(get_simulation_time())
        
        # é™åˆ¶å†å²é•¿åº¦ï¼ˆä¼˜åŒ–ï¼šä»100å‡å°‘åˆ°20ï¼‰
        if len(self.access_history[content_id]) > 20:
            self.access_history[content_id].pop(0)
    
    def _adjust_slot_granularity(self):
        """
        è‡ªé€‚åº”è°ƒæ•´æ—¶é—´æ§½ç²’åº¦
        æ ¹æ®è®¿é—®å¯†åº¦åŠ¨æ€è°ƒæ•´slot_duration
        """
        if len(self.access_count_per_slot) < 10:
            return  # æ•°æ®ä¸è¶³ï¼Œä¸è°ƒæ•´
        
        # è®¡ç®—å¹³å‡æ¯æ§½è®¿é—®æ•°
        avg_accesses_per_slot = np.mean(list(self.access_count_per_slot.values()))
        
        # ç›®æ ‡ï¼šæ¯æ§½20-50æ¬¡è®¿é—®ä¸ºæœ€ä½³ï¼ˆæ—¢èƒ½æ•æ‰æ¨¡å¼ï¼Œåˆä¸è¿‡äºç»†ç¢ï¼‰
        if avg_accesses_per_slot > 100:
            # è®¿é—®å¤ªå¯†é›†ï¼Œå¢åŠ æ§½æ—¶é•¿
            self.slot_duration = min(30.0, self.slot_duration * 1.5)
        elif avg_accesses_per_slot < 10:
            # è®¿é—®å¤ªç¨€ç–ï¼Œå‡å°æ§½æ—¶é•¿
            self.slot_duration = max(5.0, self.slot_duration * 0.8)
        
        # è®°å½•è°ƒæ•´
        self.last_slot_adjustment = get_simulation_time()
    
    def calculate_combined_heat(self, content_id: str) -> float:
        """
        è®¡ç®—ç»¼åˆçƒ­åº¦ - å¯¹åº”è®ºæ–‡å¼(37)
        Heat(c) = Î· * H_hist(c) + (1-Î·) * H_slot(c,t)
        """
        hist_heat = self.historical_heat.get(content_id, 0.0)
        
        # ğŸš€ ä½¿ç”¨è‡ªé€‚åº”æ—¶é—´æ§½
        simulation_time = get_simulation_time()
        current_slot = int(simulation_time / self.slot_duration) % self.total_slots
        slot_heat = self.slot_heat[content_id].get(current_slot, 0.0)
        
        combined_heat = (self.heat_mix_factor * hist_heat + 
                        (1 - self.heat_mix_factor) * slot_heat)
        
        return combined_heat
    
    def calculate_zipf_popularity(self, content_id: str, total_contents: int) -> float:
        """
        è®¡ç®—Zipfæµè¡Œåº¦ï¼ˆä¼˜åŒ–ç‰ˆï¼šæƒ°æ€§æ›´æ–°æ’åï¼‰
        
        æ€§èƒ½ä¼˜åŒ–ï¼šä»…åœ¨è®¿é—®å†å²å˜åŒ–è¶…è¿‡é˜ˆå€¼æ—¶é‡æ–°æ’åï¼Œå‡å°‘99%è®¡ç®—
        """
        # è®¡ç®—å½“å‰æ€»è®¿é—®æ•°
        current_total_accesses = sum(len(h) for h in self.access_history.values())
        
        # ä»…åœ¨è®¿é—®å†å²å˜åŒ–è¶…è¿‡100æ¬¡æ—¶é‡æ–°æ’å
        if not hasattr(self, '_last_rank_update') or \
           current_total_accesses - self._last_rank_update > 100:
            
            # æ ¹æ®è®¿é—®æ¬¡æ•°æ’å
            access_counts = {cid: len(history) for cid, history in self.access_history.items()}
            sorted_contents = sorted(access_counts.items(), key=lambda x: x[1], reverse=True)
            
            self.content_popularity_rank.clear()
            for rank, (cid, _) in enumerate(sorted_contents, 1):
                self.content_popularity_rank[cid] = rank
            
            self._last_rank_update = current_total_accesses
        
        rank = self.content_popularity_rank.get(content_id, total_contents)
        return calculate_zipf_probability(rank, total_contents, self.zipf_exponent)
    
    def cleanup_stale_data(self, current_time: float, staleness_threshold: float = 7200):
        """
        æ¸…ç†è¿‡æœŸæ•°æ®ï¼ˆä¼˜åŒ–ï¼šé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰
        
        Args:
            current_time: å½“å‰ä»¿çœŸæ—¶é—´
            staleness_threshold: è¿‡æœŸé˜ˆå€¼ï¼ˆç§’ï¼Œé»˜è®¤2å°æ—¶ï¼‰
        """
        stale_contents = []
        
        # æ‰¾å‡ºè¿‡æœŸå†…å®¹
        for content_id in list(self.historical_heat.keys()):
            if content_id in self.access_history and self.access_history[content_id]:
                last_access = self.access_history[content_id][-1]
                if current_time - last_access > staleness_threshold:
                    stale_contents.append(content_id)
        
        # æ¸…ç†æˆ–é™ä½çƒ­åº¦
        for content_id in stale_contents:
            # é™ä½çƒ­åº¦ä½†ä¸å®Œå…¨åˆ é™¤ï¼ˆå…è®¸é‡æ–°å˜çƒ­ï¼‰
            self.historical_heat[content_id] *= 0.3
            
            # å¦‚æœçƒ­åº¦å¤ªä½ï¼Œå®Œå…¨åˆ é™¤
            if self.historical_heat[content_id] < 0.01:
                del self.historical_heat[content_id]
                if content_id in self.access_history:
                    del self.access_history[content_id]
                if content_id in self.slot_heat:
                    del self.slot_heat[content_id]
                if content_id in self.content_popularity_rank:
                    del self.content_popularity_rank[content_id]
    
    def get_cache_priority(self, content_id: str, data_size: float, 
                          total_contents: int) -> float:
        """
        è®¡ç®—ç¼“å­˜ä¼˜å…ˆçº§
        ç»¼åˆçƒ­åº¦ã€æµè¡Œåº¦ã€å¤§å°ç­‰å› ç´ 
        """
        # åŸºç¡€çƒ­åº¦
        heat = self.calculate_combined_heat(content_id)
        
        # Zipfæµè¡Œåº¦
        zipf_pop = self.calculate_zipf_popularity(content_id, total_contents)
        
        # å¤§å°æƒ©ç½š (å°æ–‡ä»¶ä¼˜å…ˆ)
        size_penalty = math.log(1 + data_size / 1e6)  # MBçº§åˆ«
        
        # æœ€è¿‘æ€§å¥–åŠ±
        recency_bonus = 0.0
        if content_id in self.access_history and self.access_history[content_id]:
            last_access = self.access_history[content_id][-1]
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ä»¿çœŸæ—¶é—´è®¡ç®—é—´éš”
            time_since_access = get_simulation_time() - last_access
            recency_bonus = max(0, 1.0 - time_since_access / 600)  # 10åˆ†é’Ÿå†…çš„å¥–åŠ±(é€‚åº”ä»¿çœŸ)
        
        # ç»¼åˆä¼˜å…ˆçº§ï¼ˆä¼˜åŒ–æƒé‡ï¼šæ›´é‡è§†å®é™…è®¿é—®çƒ­åº¦ï¼‰
        priority = (
            0.5 * heat +           # å¢åŠ çƒ­åº¦æƒé‡ï¼ˆä»0.4â†’0.5ï¼‰ï¼Œæ›´é‡è§†å®é™…è®¿é—®
            0.2 * zipf_pop +       # é™ä½Zipfæƒé‡ï¼ˆä»0.3â†’0.2ï¼‰ï¼Œå‡å°‘ç†è®ºå‡è®¾ä¾èµ–
            0.25 * recency_bonus - # å¢åŠ æ–°é²œåº¦æƒé‡ï¼ˆä»0.2â†’0.25ï¼‰ï¼Œå¿«é€Ÿå“åº”å˜åŒ–
            0.05 * size_penalty    # é™ä½å¤§å°æƒ©ç½šï¼ˆä»0.1â†’0.05ï¼‰ï¼Œå…è®¸ç¼“å­˜æ›´å¤šå†…å®¹
        )
        
        return max(0.0, priority)


class CollaborativeCacheManager:
    """
    åä½œç¼“å­˜ç®¡ç†å™¨
    å®ç°é‚»å±…åä½œå’ŒèƒŒåŒ…ä¼˜åŒ–ç®—æ³•
    """
    
    def __init__(self, node_id: str, node_type: Optional[str] = None):
        self.node_id = node_id
        self.node_type = node_type if node_type else "RSU"  # é»˜è®¤RSU
        
        # ğŸ¯ P0-1ä¼˜åŒ–ï¼šæ ¹æ®èŠ‚ç‚¹ç±»å‹è®¾ç½®å®¹é‡å’Œç­–ç•¥
        if self.node_type == "Vehicle":
            self.cache_capacity = config.cache.vehicle_cache_capacity
            policy_name = config.cache.vehicle_cache_policy.lower()
        elif self.node_type == "UAV":
            self.cache_capacity = config.cache.uav_cache_capacity
            policy_name = config.cache.uav_cache_policy.lower()
        else:  # RSU
            self.cache_capacity = config.cache.rsu_cache_capacity
            policy_name = config.cache.rsu_cache_policy.lower()
        
        # ç¼“å­˜å­˜å‚¨
        self.cached_items: Dict[str, CachedItem] = {}
        self.current_usage = 0.0
        
        # æ›¿æ¢ç­–ç•¥
        # ğŸ¯ P0-1ä¼˜åŒ–ï¼šä½¿ç”¨é’ˆå¯¹æ€§ç­–ç•¥é…ç½®
        if policy_name == "lru":
            self.replacement_policy = CacheReplacementPolicy.LRU
        elif policy_name == "lfu":
            self.replacement_policy = CacheReplacementPolicy.LFU
        elif policy_name == "fifo":
            self.replacement_policy = CacheReplacementPolicy.FIFO
        else:
            self.replacement_policy = CacheReplacementPolicy.HYBRID
        self.heat_strategy = HeatBasedCacheStrategy()
        
        # é‚»å±…åä½œ
        self.neighbor_nodes: Set[str] = set()
        self.neighbor_cache_states: Dict[str, Set[str]] = {}
        self.collaboration_sync_interval = 300  # 5åˆ†é’ŸåŒæ­¥ä¸€æ¬¡
        self.last_sync_time = 0.0
        
        # ğŸ”§ ä¿®å¤ï¼šé™ä½é¢„å–æ¿€è¿›ç¨‹åº¦
        self.prefetch_window_ratio = 0.03  # é¢„å–çª—å£é™è‡³3%ï¼Œå‡å°‘èµ„æºå ç”¨
        self.prefetch_threshold = 0.8      # æé«˜é¢„å–é˜ˆå€¼ï¼Œæ›´åŠ è°¨æ…
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.cache_stats = {
            'total_requests': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'evictions': 0,
            'prefetch_hits': 0,
            'collaboration_saves': 0
        }
        
        # èƒŒåŒ…ä¼˜åŒ–ç›¸å…³
        self.knapsack_enabled = True
        self.value_weights = {
            'hit_value': 3.0,
            'cost_penalty': 1.0,
            'over_budget_penalty': 5.0,
            'energy_penalty': 0.2
        }
    
    def request_content(self, content_id: str, data_size: float) -> Tuple[bool, str]:
        """
        è¯·æ±‚å†…å®¹ - å¯¹åº”è®ºæ–‡ç¬¬7èŠ‚çš„å››ç±»åŠ¨ä½œ
        
        Returns:
            (æ˜¯å¦å‘½ä¸­, åŠ¨ä½œç±»å‹)
        """
        self.cache_stats['total_requests'] += 1
        
        # ğŸ¯ P1-1ä¼˜åŒ–ï¼šæ¯100æ¬¡è¯·æ±‚æ‰§è¡Œä¸€æ¬¡é¢„æµ‹ç¼“å­˜
        if self.cache_stats['total_requests'] % 100 == 0:
            predicted_contents = self.predictive_caching()
            # è®°å½•é¢„æµ‹ç»“æœï¼ˆå¯ç”¨äºåç»­é¢„åŠ è½½ï¼‰
            if not hasattr(self, '_predicted_contents'):
                self._predicted_contents = set()
            self._predicted_contents.update(predicted_contents)
        
        # æ›´æ–°çƒ­åº¦
        self.heat_strategy.update_heat(content_id)
        
        # æ£€æŸ¥æœ¬åœ°ç¼“å­˜å‘½ä¸­
        if content_id in self.cached_items:
            self._handle_cache_hit(content_id)
            return True, "cache_hit"  # åŠ¨ä½œ0
        
        # æ£€æŸ¥é‚»å±…åä½œ
        if self._check_neighbor_collaboration(content_id):
            self.cache_stats['collaboration_saves'] += 1
            return True, "neighbor_hit"
        
        # ç¼“å­˜æœªå‘½ä¸­ï¼Œå†³å®šç¼“å­˜åŠ¨ä½œ
        action = self._decide_cache_action(content_id, data_size)
        
        if action == 1:
            # é«˜çƒ­åº¦å†…å®¹ï¼Œç›´æ¥ç¼“å­˜
            success = self._add_to_cache(content_id, data_size)
            self.cache_stats['cache_misses'] += 1
            return False, "cache_and_store" if success else "cache_full"
        
        elif action == 2:
            # ä¸­ç­‰çƒ­åº¦å†…å®¹ï¼Œé¢„å–
            success = self._prefetch_content(content_id, data_size)
            self.cache_stats['cache_misses'] += 1
            return False, "prefetch" if success else "prefetch_failed"
        
        elif action == 3:
            # èƒŒåŒ…æ›¿æ¢
            success = self._knapsack_replacement(content_id, data_size)
            self.cache_stats['cache_misses'] += 1
            return False, "knapsack_replace" if success else "replace_failed"
        
        else:
            # ä¸ç¼“å­˜
            self.cache_stats['cache_misses'] += 1
            return False, "no_cache"
    
    def _handle_cache_hit(self, content_id: str):
        """å¤„ç†ç¼“å­˜å‘½ä¸­"""
        if content_id in self.cached_items:
            item = self.cached_items[content_id]
            item.access_count += 1
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ä»¿çœŸæ—¶é—´
            item.last_access_time = get_simulation_time()
            
            self.cache_stats['cache_hits'] += 1
            
            # æ›´æ–°LRUé¡ºåº (å¦‚æœä½¿ç”¨LRUç­–ç•¥)
            if self.replacement_policy == CacheReplacementPolicy.LRU:
                # é‡æ–°æ’å…¥ä»¥æ›´æ–°é¡ºåº
                self.cached_items[content_id] = self.cached_items.pop(content_id)
    
    def _check_neighbor_collaboration(self, content_id: str) -> bool:
        """
        ğŸ¯ P1-2ä¼˜åŒ–ï¼šæ£€æŸ¥é‚»å±…åä½œç¼“å­˜ï¼ˆå«æˆæœ¬è¯„ä¼°ï¼‰
        """
        for neighbor_id, cached_contents in self.neighbor_cache_states.items():
            if content_id in cached_contents:
                # ğŸ”¥ è°ƒç”¨æˆæœ¬è¯„ä¼°ï¼Œåªåœ¨å€¼å¾—æ—¶æ‰åä½œ
                should_collaborate, cost = self._evaluate_collaboration_cost(content_id, neighbor_id)
                if should_collaborate:
                    return True
        return False
    
    def _decide_cache_action(self, content_id: str, data_size: float) -> int:
        """
        å†³å®šç¼“å­˜åŠ¨ä½œ - å¯¹åº”è®ºæ–‡å†³ç­–é€»è¾‘
        
        Returns:
            0: å·²ç¼“å­˜, 1: é«˜çƒ­åº¦ç¼“å­˜, 2: é¢„å–, 3: èƒŒåŒ…æ›¿æ¢
        """
        # è®¡ç®—å†…å®¹çƒ­åº¦
        heat = self.heat_strategy.calculate_combined_heat(content_id)
        
        # è·å–å¯ç”¨å®¹é‡
        available_capacity = self.cache_capacity - self.current_usage
        
        # ğŸ”§ ä¼˜åŒ–ï¼šåŸºäºå®é™…çƒ­åº¦èŒƒå›´[0,1]è®¾ç½®åˆç†é˜ˆå€¼
        high_heat_threshold = 0.7   # 70%çƒ­åº¦è§¦å‘é«˜ä¼˜å…ˆçº§ç¼“å­˜
        medium_heat_threshold = 0.4  # 40%çƒ­åº¦è§¦å‘ä¸­ç­‰ä¼˜å…ˆçº§ç¼“å­˜
        capacity_threshold = self.cache_capacity * 0.05  # 5%å®¹é‡ä¿ç•™é˜ˆå€¼
        
        # å†³ç­–é€»è¾‘
        if heat > high_heat_threshold and available_capacity > capacity_threshold:
            return 1  # é«˜çƒ­åº¦ä¸”æœ‰è¶³å¤Ÿå®¹é‡ï¼Œç›´æ¥ç¼“å­˜
        
        elif medium_heat_threshold < heat <= high_heat_threshold:
            return 2  # ä¸­ç­‰çƒ­åº¦ï¼Œé¢„å–
        
        elif available_capacity <= 0 and self.knapsack_enabled:
            return 3  # å®¹é‡ä¸è¶³ï¼ŒèƒŒåŒ…æ›¿æ¢
        
        else:
            return 0  # ä¸ç¼“å­˜
    
    def _add_to_cache(self, content_id: str, data_size: float) -> bool:
        """æ·»åŠ å†…å®¹åˆ°ç¼“å­˜"""
        if self.current_usage + data_size > self.cache_capacity:
            # å®¹é‡ä¸è¶³ï¼Œå°è¯•æ›¿æ¢
            if not self._make_space(data_size):
                return False
        
        # åˆ›å»ºç¼“å­˜é¡¹
        item = CachedItem(
            content_id=content_id,
            data_size=data_size,
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ä»¿çœŸæ—¶é—´
            cache_time=get_simulation_time(),
            last_access_time=get_simulation_time()
        )
        
        # è®¡ç®—çƒ­åº¦å’Œä¼˜å…ˆçº§
        item.historical_heat = self.heat_strategy.historical_heat.get(content_id, 0.0)
        item.cache_value = self.heat_strategy.get_cache_priority(content_id, data_size, len(self.cached_items) + 1)
        
        self.cached_items[content_id] = item
        self.current_usage += data_size
        
        return True
    
    def _prefetch_content(self, content_id: str, data_size: float) -> bool:
        """é¢„å–å†…å®¹"""
        # æ£€æŸ¥é¢„å–çª—å£å®¹é‡
        prefetch_capacity = self.cache_capacity * self.prefetch_window_ratio
        
        if data_size <= prefetch_capacity:
            # åœ¨é¢„å–çª—å£å†…å°è¯•ç¼“å­˜
            return self._add_to_cache(content_id, data_size)
        
        return False
    
    def _knapsack_replacement(self, content_id: str, data_size: float) -> bool:
        """
        èƒŒåŒ…ä¼˜åŒ–æ›¿æ¢ - å¯¹åº”è®ºæ–‡èƒŒåŒ…ç®—æ³•
        æœ€å¤§åŒ–ç¼“å­˜ä»·å€¼ï¼Œçº¦æŸæ€»å®¹é‡
        """
        if not self.cached_items:
            return self._add_to_cache(content_id, data_size)
        
        # è®¡ç®—æ–°å†…å®¹çš„ä»·å€¼
        new_value = self.heat_strategy.get_cache_priority(content_id, data_size, len(self.cached_items) + 1)
        
        # å€™é€‰æ›¿æ¢é¡¹åˆ—è¡¨ (ä»·å€¼, å¤§å°, content_id)
        candidates = []
        for cid, item in self.cached_items.items():
            value = item.cache_value
            candidates.append((value, item.data_size, cid))
        
        # è´ªå¿ƒèƒŒåŒ…ç®—æ³•ï¼šæŒ‰ä»·å€¼å¯†åº¦æ’åº
        candidates.sort(key=lambda x: x[0] / x[1], reverse=False)  # ä»·å€¼å¯†åº¦ä»ä½åˆ°é«˜
        
        # å¯»æ‰¾å¯ä»¥é‡Šæ”¾çš„ç©ºé—´
        freed_space = 0.0
        items_to_remove = []
        
        for value, size, cid in candidates:
            if freed_space >= data_size:
                break
            
            # å¦‚æœæ–°å†…å®¹ä»·å€¼æ›´é«˜ï¼Œåˆ™æ›¿æ¢
            if new_value > value:
                freed_space += size
                items_to_remove.append(cid)
        
        # æ‰§è¡Œæ›¿æ¢
        if freed_space >= data_size:
            for cid in items_to_remove:
                self._evict_item(cid)
            
            return self._add_to_cache(content_id, data_size)
        
        return False
    
    def _make_space(self, required_space: float) -> bool:
        """
        æ ¹æ®æ›¿æ¢ç­–ç•¥è…¾å‡ºç©ºé—´
        ğŸ¯ P3-3ä¼˜åŒ–ï¼šæ‰¹é‡æ·˜æ±°ä¼˜åŒ–
        """
        # ğŸ”¥ æ‰¹é‡æ·˜æ±°ä¼˜åŒ–ï¼šé¢„ç•™é¢å¤–ç©ºé—´å‡å°‘é¢‘ç¹æ·˜æ±°
        # ä¸€æ¬¡æ·˜æ±°é‡Šæ”¾120%çš„æ‰€éœ€ç©ºé—´
        buffer_ratio = 1.2
        target_space = required_space * buffer_ratio
        
        if self.replacement_policy == CacheReplacementPolicy.LRU:
            return self._lru_eviction(target_space)
        elif self.replacement_policy == CacheReplacementPolicy.LFU:
            return self._lfu_eviction(target_space)
        elif self.replacement_policy == CacheReplacementPolicy.FIFO:
            return self._fifo_eviction(target_space)
        else:  # HYBRID
            return self._hybrid_eviction(target_space)
    
    def _lru_eviction(self, required_space: float) -> bool:
        """LRUæ›¿æ¢ç­–ç•¥"""
        sorted_items = sorted(self.cached_items.items(), 
                            key=lambda x: x[1].last_access_time)
        
        freed_space = 0.0
        for content_id, item in sorted_items:
            if freed_space >= required_space:
                break
            
            freed_space += item.data_size
            self._evict_item(content_id)
        
        return freed_space >= required_space
    
    def _lfu_eviction(self, required_space: float) -> bool:
        """LFUæ›¿æ¢ç­–ç•¥"""
        sorted_items = sorted(self.cached_items.items(), 
                            key=lambda x: x[1].access_count)
        
        freed_space = 0.0
        for content_id, item in sorted_items:
            if freed_space >= required_space:
                break
            
            freed_space += item.data_size
            self._evict_item(content_id)
        
        return freed_space >= required_space
    
    def _fifo_eviction(self, required_space: float) -> bool:
        """FIFOæ›¿æ¢ç­–ç•¥"""
        sorted_items = sorted(self.cached_items.items(), 
                            key=lambda x: x[1].cache_time)
        
        freed_space = 0.0
        for content_id, item in sorted_items:
            if freed_space >= required_space:
                break
            
            freed_space += item.data_size
            self._evict_item(content_id)
        
        return freed_space >= required_space
    
    def _hybrid_eviction(self, required_space: float) -> bool:
        """
        ğŸ¯ P3-1ä¼˜åŒ–ï¼šæ··åˆæ›¿æ¢ç­–ç•¥ï¼ˆè‡ªé€‚åº”æƒé‡ï¼‰
        ç»¼åˆè€ƒè™‘ï¼šæ—¶é—´æ€§ã€é¢‘ç‡ã€ä»·å€¼ï¼ˆæƒé‡è‡ªé€‚åº”ï¼‰
        """
        # ğŸ”¥ è‡ªé€‚åº”æƒé‡è®¡ç®—
        weights = self._adaptive_hybrid_weights()
        
        # ç»¼åˆè€ƒè™‘è®¿é—®é¢‘ç‡ã€æœ€è¿‘æ€§å’Œç¼“å­˜ä»·å€¼
        scored_items = []
        
        for content_id, item in self.cached_items.items():
            # ğŸ”§ ä¿®å¤ï¼šè®¡ç®—ç»¼åˆåˆ†æ•° (åˆ†æ•°è¶Šä½è¶Šå®¹æ˜“è¢«æ›¿æ¢)
            recency_score = (get_simulation_time() - item.last_access_time) / 600  # æ”¹ä¸º10åˆ†é’Ÿé€‚åº”ä»¿çœŸ
            frequency_score = 1.0 / max(1, item.access_count)
            value_score = 1.0 / max(0.1, item.cache_value)
            
            # ğŸ¯ ä½¿ç”¨è‡ªé€‚åº”æƒé‡
            total_score = (weights['recency'] * recency_score + 
                          weights['frequency'] * frequency_score + 
                          weights['value'] * value_score)
            scored_items.append((total_score, content_id, item))
        
        # æŒ‰åˆ†æ•°æ’åºï¼Œåˆ†æ•°é«˜çš„ä¼˜å…ˆæ›¿æ¢
        scored_items.sort(key=lambda x: x[0], reverse=True)
        
        freed_space = 0.0
        for score, content_id, item in scored_items:
            if freed_space >= required_space:
                break
            
            freed_space += item.data_size
            self._evict_item(content_id)
        
        return freed_space >= required_space
    
    # ğŸ¯ P3-1ä¼˜åŒ–ï¼šè‡ªé€‚åº”æƒé‡è®¡ç®—
    def _adaptive_hybrid_weights(self) -> Dict[str, float]:
        """
        æ ¹æ®å½“å‰ç¼“å­˜çŠ¶æ€åŠ¨æ€è°ƒæ•´æ··åˆç­–ç•¥æƒé‡
        
        Returns:
            {'recency': float, 'frequency': float, 'value': float}
        """
        # é»˜è®¤æƒé‡
        weights = {'recency': 0.4, 'frequency': 0.3, 'value': 0.3}
        
        if not self.cached_items:
            return weights
        
        # è®¡ç®—ç¼“å­˜ä½¿ç”¨ç‡
        usage_ratio = self.current_usage / self.cache_capacity
        
        # è®¡ç®—å‘½ä¸­ç‡
        total_requests = self.cache_stats['hits'] + self.cache_stats['misses']
        hit_rate = self.cache_stats['hits'] / total_requests if total_requests > 0 else 0.5
        
        # ğŸ”¥ è‡ªé€‚åº”è§„åˆ™ï¼š
        # 1. é«˜ä½¿ç”¨ç‡(>80%) â†’ æé«˜frequencyæƒé‡ï¼Œä¿ç•™é«˜é¢‘å†…å®¹
        if usage_ratio > 0.8:
            weights['frequency'] = 0.4
            weights['recency'] = 0.3
            weights['value'] = 0.3
        
        # 2. ä½å‘½ä¸­ç‡(<60%) â†’ æé«˜valueæƒé‡ï¼Œä¼˜åŒ–çƒ­åº¦é€‰æ‹©
        if hit_rate < 0.6:
            weights['value'] = 0.4
            weights['recency'] = 0.35
            weights['frequency'] = 0.25
        
        # 3. é«˜å‘½ä¸­ç‡(>85%) â†’ æé«˜recencyæƒé‡ï¼ŒåŠ å¿«æ›´æ–°
        if hit_rate > 0.85:
            weights['recency'] = 0.5
            weights['frequency'] = 0.25
            weights['value'] = 0.25
        
        return weights
    
    def _evict_item(self, content_id: str):
        """ä»ç¼“å­˜ä¸­ç§»é™¤é¡¹ç›®"""
        if content_id in self.cached_items:
            item = self.cached_items.pop(content_id)
            self.current_usage -= item.data_size
            self.cache_stats['evictions'] += 1
    
    # ğŸ¯ P1-1ä¼˜åŒ–ï¼šé¢„æµ‹å¼ç¼“å­˜é¢„åŠ è½½
    def predictive_caching(self, prediction_horizon: Optional[int] = None) -> List[str]:
        """
        åŸºäºçƒ­åº¦è¶‹åŠ¿é¢„æµ‹æœªæ¥é«˜éœ€æ±‚å†…å®¹
        
        Args:
            prediction_horizon: é¢„æµ‹æ•°é‡ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®å€¼
            
        Returns:
            åº”è¯¥é¢„åŠ è½½çš„å†…å®¹IDåˆ—è¡¨
        """
        if not config.cache.enable_predictive_caching:
            return []
        
        if prediction_horizon is None:
            prediction_horizon = config.cache.prediction_horizon
        
        predictions = []
        current_time = get_simulation_time()
        prediction_threshold = config.cache.prediction_threshold
        
        # éå†æ‰€æœ‰æœ‰è®¿é—®å†å²çš„å†…å®¹
        for content_id in self.heat_strategy.access_history.keys():
            access_times = self.heat_strategy.access_history[content_id]
            
            # è‡³å°‘éœ€3æ¬¡è®¿é—®æ‰èƒ½é¢„æµ‹è¶‹åŠ¿
            if len(access_times) < 3:
                continue
            
            # è®¡ç®—è®¿é—®å¢é•¿ç‡
            recent_accesses = len([t for t in access_times if current_time - t < 60])  # æœ€è¿‘1åˆ†é’Ÿ
            older_accesses = len([t for t in access_times if 60 <= current_time - t < 120])  # 1-2åˆ†é’Ÿå‰
            
            if older_accesses > 0:
                growth_rate = recent_accesses / older_accesses
                if growth_rate > prediction_threshold:  # å¢é•¿è¶…è¿‡50%
                    # é¢„æµ‹æœªæ¥éœ€æ±‚
                    predicted_requests = recent_accesses * growth_rate
                    
                    # æ›´æ–°ç¼“å­˜é¡¹çš„é¢„æµ‹å€¼
                    if content_id in self.cached_items:
                        self.cached_items[content_id].predicted_requests = predicted_requests
                    
                    predictions.append((content_id, predicted_requests))
        
        # è¿”å›é¢„æµ‹éœ€æ±‚æœ€é«˜çš„å‰Nä¸ª
        predictions.sort(key=lambda x: x[1], reverse=True)
        return [cid for cid, _ in predictions[:prediction_horizon]]
    
    # ğŸ¯ P1-2ä¼˜åŒ–ï¼šåä½œç¼“å­˜æˆæœ¬è¯„ä¼°
    def _evaluate_collaboration_cost(self, content_id: str, neighbor_id: str) -> Tuple[bool, float]:
        """
        è¯„ä¼°åä½œç¼“å­˜çš„æˆæœ¬æ•ˆç›Š
        
        Args:
            content_id: å†…å®¹ID
            neighbor_id: é‚»å±…èŠ‚ç‚¹ID
            
        Returns:
            (æ˜¯å¦åä½œ, åä½œæˆæœ¬)
        """
        # è®¡ç®—ä»é‚»å±…è·å–çš„å»¶è¿Ÿæˆæœ¬
        # å‡è®¾é‚»å±…è·ç¦»å­˜å‚¨åœ¨ neighbor_distances ä¸­
        if not hasattr(self, 'neighbor_distances'):
            self.neighbor_distances = {}  # åˆå§‹åŒ–é‚»å±…è·ç¦»å­—å…¸
        
        distance = self.neighbor_distances.get(neighbor_id, 500)  # é»˜è®¤500m
        transmission_delay = distance / 3e8 * 1000  # å…‰é€Ÿä¼ æ’­å»¶è¿Ÿ(ms)
        bandwidth_cost = 10  # å¸¦å®½å ç”¨æˆæœ¬(ç®€åŒ–)
        
        collaboration_cost = transmission_delay + bandwidth_cost
        
        # ä¸æœ¬åœ°ç¼“å­˜æ¯”è¾ƒ
        local_cache_cost = 50  # æœ¬åœ°ç¼“å­˜çš„å›ºå®šæˆæœ¬
        
        # åä½œæˆæœ¬å°äºæœ¬åœ°æˆæœ¬çš„1.2å€æ‰å€¼å¾—åä½œ
        return collaboration_cost < local_cache_cost * 1.2, collaboration_cost
    
    # ğŸ¯ P2-2ä¼˜åŒ–ï¼šåŠ¨æ€å®¹é‡è°ƒæ•´
    def adaptive_capacity_allocation(self, current_load: float, hit_rate: float) -> float:
        """
        æ ¹æ®è´Ÿè½½å’Œå‘½ä¸­ç‡åŠ¨æ€è°ƒæ•´ç¼“å­˜å®¹é‡
        
        ç­–ç•¥ï¼š
        - é«˜è´Ÿè½½ä½å‘½ä¸­ç‡ â†’ å¢åŠ å®¹é‡
        - ä½è´Ÿè½½é«˜å‘½ä¸­ç‡ â†’ å‡å°‘å®¹é‡ï¼ˆèŠ‚èƒ½ï¼‰
        
        Args:
            current_load: å½“å‰è´Ÿè½½ (0.0-1.0+)
            hit_rate: ç¼“å­˜å‘½ä¸­ç‡ (0.0-1.0)
            
        Returns:
            æ–°çš„ç¼“å­˜å®¹é‡
        """
        if not config.cache.enable_dynamic_capacity:
            return self.cache_capacity
        
        base_capacity = self.cache_capacity
        
        # è´Ÿè½½å› å­ï¼š0.0-1.0 â†’ 0.8-1.2
        load_factor = 0.8 + 0.4 * min(1.0, current_load)
        
        # å‘½ä¸­ç‡å› å­ï¼š<0.6 â†’ å¢åŠ ï¼Œ>0.8 â†’ å‡å°‘
        if hit_rate < 0.6:
            hit_rate_factor = 1.2
        elif hit_rate > 0.8:
            hit_rate_factor = 0.9
        else:
            hit_rate_factor = 1.0
        
        new_capacity = base_capacity * load_factor * hit_rate_factor
        
        # é™åˆ¶åœ¨åˆç†èŒƒå›´ (50%-150%)
        min_capacity = base_capacity * config.cache.capacity_adjust_min_ratio
        max_capacity = base_capacity * config.cache.capacity_adjust_max_ratio
        
        return np.clip(new_capacity, min_capacity, max_capacity)
    
    # ğŸ¯ P3-2ä¼˜åŒ–ï¼šç¼“å­˜é¢„çƒ­ç­–ç•¥
    def warmup_cache(self, historical_stats: Optional[Dict] = None) -> None:
        """
        ä½¿ç”¨å†å²ç»Ÿè®¡æ•°æ®é¢„çƒ­ç¼“å­˜
        
        Args:
            historical_stats: å†å²çƒ­é—¨å†…å®¹ç»Ÿè®¡
                {content_id: {'frequency': int, 'avg_size': float, 'heat': float}}
        """
        if not config.cache.enable_cache_warmup:
            return
        
        if not historical_stats:
            # å¦‚æœæ²¡æœ‰å†å²æ•°æ®ï¼Œä½¿ç”¨å½“å‰çƒ­åº¦ç»Ÿè®¡
            historical_stats = {}
            for content_id, heat in self.heat_strategy.historical_heat.items():
                if heat > 0.1:  # åªé¢„çƒ­çƒ­åº¦è¶…è¿‡0.1çš„å†…å®¹
                    historical_stats[content_id] = {
                        'heat': heat,
                        'avg_size': 1.0,  # é»˜è®¤1MB
                        'frequency': len(self.heat_strategy.access_history.get(content_id, []))
                    }
        
        if not historical_stats:
            return
        
        # æŒ‰çƒ­åº¦æ’åº
        sorted_contents = sorted(historical_stats.items(), 
                               key=lambda x: x[1].get('heat', 0.0), 
                               reverse=True)
        
        preload_budget = self.cache_capacity * config.cache.warmup_capacity_ratio  # ä½¿ç”¨30%å®¹é‡é¢„çƒ­
        used_budget = 0.0
        
        for content_id, stats in sorted_contents:
            size = stats.get('avg_size', 1.0)
            if used_budget + size <= preload_budget:
                # æ¨¡æ‹Ÿç¼“å­˜ï¼ˆä¸å®é™…ä¸‹è½½ï¼Œåªè®°å½•å…ƒæ•°æ®ï¼‰
                self.cached_items[content_id] = CachedItem(
                    content_id=content_id,
                    data_size=size,
                    historical_heat=stats.get('heat', 0.0),
                    cache_time=get_simulation_time(),
                    access_count=stats.get('frequency', 1)
                )
                self.current_usage += size
                used_budget += size
    
    def sync_with_neighbors(self, neighbor_cache_states: Dict[str, Set[str]]):
        """ä¸é‚»å±…åŒæ­¥ç¼“å­˜çŠ¶æ€"""
        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€ä»¿çœŸæ—¶é—´  
        current_time = get_simulation_time()
        
        if current_time - self.last_sync_time < self.collaboration_sync_interval:
            return
        
        self.neighbor_cache_states = neighbor_cache_states.copy()
        self.last_sync_time = current_time
        
        # æ›´æ–°é‚»å±…åˆ—è¡¨
        self.neighbor_nodes = set(neighbor_cache_states.keys())
        
        # ğŸ¯ P2-2ä¼˜åŒ–ï¼šå®šæœŸæ‰§è¡ŒåŠ¨æ€å®¹é‡è°ƒæ•´ï¼ˆæ¯æ¬¡åŒæ­¥æ—¶ï¼‰
        if config.cache.enable_dynamic_capacity:
            stats = self.get_cache_statistics()
            # è®¡ç®—å½“å‰è´Ÿè½½å’Œå‘½ä¸­ç‡
            current_load = stats['usage_ratio']
            hit_rate = stats['hit_rate']
            
            # è°ƒæ•´å®¹é‡
            new_capacity = self.adaptive_capacity_allocation(current_load, hit_rate)
            if abs(new_capacity - self.cache_capacity) > self.cache_capacity * 0.05:  # å˜åŒ–è¶…è¿‡5%æ‰è°ƒæ•´
                self.cache_capacity = new_capacity
    
    def get_cache_state(self) -> Set[str]:
        """è·å–å½“å‰ç¼“å­˜çŠ¶æ€"""
        return set(self.cached_items.keys())
    
    def get_cache_statistics(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        total_requests = self.cache_stats['total_requests']
        
        return {
            'total_requests': total_requests,
            'cache_hits': self.cache_stats['cache_hits'],
            'cache_misses': self.cache_stats['cache_misses'],
            'hit_rate': self.cache_stats['cache_hits'] / max(1, total_requests),
            'miss_rate': self.cache_stats['cache_misses'] / max(1, total_requests),
            'evictions': self.cache_stats['evictions'],
            'prefetch_hits': self.cache_stats['prefetch_hits'],
            'collaboration_saves': self.cache_stats['collaboration_saves'],
            'current_usage': self.current_usage,
            'usage_ratio': self.current_usage / self.cache_capacity,
            'cached_items_count': len(self.cached_items),
            'avg_item_size': self.current_usage / max(1, len(self.cached_items))
        }
    
    def calculate_cache_reward(self) -> float:
        """
        è®¡ç®—ç¼“å­˜å¥–åŠ± - å¯¹åº”è®ºæ–‡ç¼“å­˜å¥–åŠ±å‡½æ•°
        """
        stats = self.get_cache_statistics()
        
        # å¥–åŠ±ç»„ä»¶
        hit_rate_reward = self.value_weights['hit_value'] * stats['hit_rate']
        
        # æˆæœ¬æƒ©ç½š
        operation_cost = self.cache_stats['evictions'] / max(1, stats['total_requests'])
        cost_penalty = self.value_weights['cost_penalty'] * operation_cost
        
        # è¶…é¢„ç®—æƒ©ç½š
        over_budget_penalty = 0.0
        if stats['usage_ratio'] > 1.0:
            over_budget_penalty = self.value_weights['over_budget_penalty'] * (stats['usage_ratio'] - 1.0)
        
        # èƒ½è€—è€ƒè™‘ (ç®€åŒ–)
        energy_penalty = self.value_weights['energy_penalty'] * stats['usage_ratio']
        
        # æ€»å¥–åŠ±
        total_reward = (hit_rate_reward - cost_penalty - over_budget_penalty - energy_penalty)
        
        return total_reward