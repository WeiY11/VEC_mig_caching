#!/usr/bin/env python
"""
å®æ—¶ç›‘æ§è®­ç»ƒè¿›åº¦å¹¶å†™å…¥TensorBoard
"""
import json
import time
from pathlib import Path
from datetime import datetime

try:
    from torch.utils.tensorboard import SummaryWriter
except ImportError:
    print("å®‰è£…tensorboard...")
    import os
    os.system("pip install tensorboard -q")
    from torch.utils.tensorboard import SummaryWriter

def monitor_experiments():
    """ç›‘æ§å®éªŒç»“æœå¹¶å®æ—¶æ›´æ–°TensorBoard"""
    
    results_dir = Path("results/parameter_sensitivity")
    tb_dir = Path("runs/batch_experiments")
    tb_dir.mkdir(parents=True, exist_ok=True)
    
    print("=" * 60)
    print("VECæ‰¹é‡å®éªŒ - TensorBoardå®æ—¶ç›‘æ§")
    print("=" * 60)
    print(f"ç›‘æ§ç›®å½•: {results_dir}")
    print(f"TensorBoardæ—¥å¿—: {tb_dir}")
    print(f"å¯åŠ¨æ—¶é—´: {datetime.now()}")
    print()
    print("æç¤º: åœ¨AutoDLæ§åˆ¶å°ç‚¹å‡»'TensorBoard'æŒ‰é’®å³å¯æŸ¥çœ‹")
    print("      æˆ–è®¿é—®: http://localhost:6007")
    print()
    print("æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
    print("=" * 60)
    print()
    
    processed_files = set()
    writers = {}
    
    try:
        while True:
            # æ‰«ææ‰€æœ‰summaryæ–‡ä»¶
            summary_files = list(results_dir.glob("**/summary.json"))
            
            for summary_file in summary_files:
                if summary_file in processed_files:
                    continue
                
                try:
                    with open(summary_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # è·å–å®éªŒåç§°
                    exp_name = summary_file.parent.name
                    
                    # åˆ›å»ºæˆ–è·å–writer
                    if exp_name not in writers:
                        writers[exp_name] = SummaryWriter(log_dir=str(tb_dir / exp_name))
                        print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ“Š æ–°å®éªŒ: {exp_name}")
                    
                    writer = writers[exp_name]
                    
                    # å†™å…¥é…ç½®æ•°æ®
                    if 'configurations' in data:
                        configs = data['configurations']
                        print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ“ˆ {exp_name}: {len(configs)}ä¸ªé…ç½®")
                        
                        for idx, config in enumerate(configs):
                            config_name = config.get('name', f'config_{idx}')
                            metrics = config.get('metrics', {})
                            
                            # å†™å…¥æ‰€æœ‰å¯ç”¨æŒ‡æ ‡
                            for metric_name, value in metrics.items():
                                if isinstance(value, (int, float)):
                                    writer.add_scalar(
                                        f'{exp_name}/{config_name}/{metric_name}',
                                        value,
                                        idx
                                    )
                            
                            # ç‰¹åˆ«æ ‡æ³¨å½’ä¸€åŒ–æˆæœ¬
                            if 'normalized_cost' in metrics:
                                writer.add_scalar(
                                    f'Summary/normalized_cost',
                                    metrics['normalized_cost'],
                                    idx
                                )
                    
                    writer.flush()
                    processed_files.add(summary_file)
                    
                except Exception as e:
                    print(f"âš ï¸  å¤„ç† {summary_file.name} æ—¶å‡ºé”™: {e}")
            
            # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
            time.sleep(30)
            
    except KeyboardInterrupt:
        print("\n\nåœæ­¢ç›‘æ§...")
        for writer in writers.values():
            writer.close()
        print("âœ… TensorBoardæ—¥å¿—å·²ä¿å­˜")

if __name__ == "__main__":
    monitor_experiments()

