#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½ä¼˜åŒ–å·¥å…·æ¨¡å—
ä¸ºä¸åŒç®—æ³•æä¾›ä¼˜åŒ–çš„æ‰¹æ¬¡å¤§å°å’Œå†…å­˜ç®¡ç†é…ç½®
"""

import gc
import time
import psutil
import numpy as np
from typing import Dict, Any, Optional, Tuple
from functools import wraps
import logging


# ä¼˜åŒ–çš„æ‰¹æ¬¡å¤§å°é…ç½® - åŸºäºå†…å­˜ä¸­çš„æ€§èƒ½é…ç½®
OPTIMIZED_BATCH_SIZES = {
    # å¤šæ™ºèƒ½ä½“ç®—æ³•
    'MATD3': 384,
    'MADDPG': 384, 
    'MAPPO': 384,
    'QMIX': 48,
    'SAC-MA': 384,
    
    # å•æ™ºèƒ½ä½“ç®—æ³•
    'DQN': 48,
    'DDPG': 192,
    'TD3': 192,
    'SAC': 384,
    'PPO': 96
}

# å†…å­˜ç®¡ç†é…ç½®
MEMORY_CONFIG = {
    'gc_frequency': 100,      # æ¯100æ­¥æ‰§è¡Œä¸€æ¬¡åƒåœ¾å›æ”¶
    'max_memory_usage': 0.8,  # æœ€å¤§å†…å­˜ä½¿ç”¨ç‡80%
    'buffer_size_limit': 100000,  # ç»éªŒå›æ”¾ç¼“å†²åŒºå¤§å°é™åˆ¶
    'state_cache_size': 1000,  # çŠ¶æ€ç¼“å­˜å¤§å°
}

# è®¡ç®—ä¼˜åŒ–é…ç½®
COMPUTE_CONFIG = {
    'use_vectorization': True,   # ä½¿ç”¨å‘é‡åŒ–è®¡ç®—
    'batch_computation': True,   # æ‰¹é‡è®¡ç®—
    'memory_pinning': False,     # å†…å­˜å›ºå®š (GPU)
    'gradient_accumulation': 2,  # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
}


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.start_time = None
        self.memory_usage = []
        self.computation_times = []
        self.step_count = 0
        
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        self.start_time = time.time()
        self.step_count = 0
        
    def record_step(self, computation_time: float = None):
        """è®°å½•æ­¥éª¤æ€§èƒ½"""
        self.step_count += 1
        
        # è®°å½•å†…å­˜ä½¿ç”¨
        memory_percent = psutil.virtual_memory().percent
        self.memory_usage.append(memory_percent)
        
        # è®°å½•è®¡ç®—æ—¶é—´
        if computation_time is not None:
            self.computation_times.append(computation_time)
        
        # å®šæœŸæ¸…ç†å†å²è®°å½•
        if len(self.memory_usage) > 1000:
            self.memory_usage = self.memory_usage[-500:]
        if len(self.computation_times) > 1000:
            self.computation_times = self.computation_times[-500:]
    
    def get_performance_stats(self) -> Dict:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        total_time = time.time() - self.start_time if self.start_time else 0
        
        return {
            'total_steps': self.step_count,
            'total_time': total_time,
            'steps_per_second': self.step_count / max(total_time, 1e-6),
            'avg_memory_usage': np.mean(self.memory_usage) if self.memory_usage else 0,
            'max_memory_usage': max(self.memory_usage) if self.memory_usage else 0,
            'avg_computation_time': np.mean(self.computation_times) if self.computation_times else 0,
            'total_computation_time': sum(self.computation_times) if self.computation_times else 0
        }


class MemoryManager:
    """å†…å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        self.gc_counter = 0
        self.memory_threshold = MEMORY_CONFIG['max_memory_usage']
        
    def check_memory_usage(self) -> bool:
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        memory_percent = psutil.virtual_memory().percent / 100.0
        return memory_percent < self.memory_threshold
    
    def cleanup_if_needed(self, force: bool = False):
        """æ ¹æ®éœ€è¦æ¸…ç†å†…å­˜"""
        self.gc_counter += 1
        
        should_cleanup = (
            force or 
            self.gc_counter % MEMORY_CONFIG['gc_frequency'] == 0 or
            not self.check_memory_usage()
        )
        
        if should_cleanup:
            # æ‰§è¡Œåƒåœ¾å›æ”¶
            collected = gc.collect()
            
            # è®°å½•æ¸…ç†ç»“æœ
            memory_after = psutil.virtual_memory().percent
            logging.debug(f"å†…å­˜æ¸…ç†: å›æ”¶ {collected} ä¸ªå¯¹è±¡, å†…å­˜ä½¿ç”¨: {memory_after:.1f}%")
            
            return True
        
        return False
    
    def optimize_buffer_size(self, algorithm: str, current_size: int) -> int:
        """ä¼˜åŒ–ç¼“å†²åŒºå¤§å°"""
        # æ ¹æ®å†…å­˜ä½¿ç”¨æƒ…å†µåŠ¨æ€è°ƒæ•´
        memory_percent = psutil.virtual_memory().percent / 100.0
        
        if memory_percent > 0.9:
            # å†…å­˜ç´§å¼ ï¼Œå‡å°ç¼“å†²åŒº
            return min(current_size, MEMORY_CONFIG['buffer_size_limit'] // 2)
        elif memory_percent < 0.5:
            # å†…å­˜å……è¶³ï¼Œå¯ä»¥å¢å¤§ç¼“å†²åŒº
            return min(current_size * 2, MEMORY_CONFIG['buffer_size_limit'])
        else:
            # æ­£å¸¸èŒƒå›´
            return min(current_size, MEMORY_CONFIG['buffer_size_limit'])


def performance_timer(func):
    """æ€§èƒ½è®¡æ—¶è£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        
        computation_time = end_time - start_time
        
        # å¦‚æœå®ä¾‹æœ‰performance_monitorï¼Œè®°å½•æ—¶é—´
        if hasattr(args[0], 'performance_monitor'):
            args[0].performance_monitor.record_step(computation_time)
        
        return result
    return wrapper


def memory_efficient_batch_processing(data: np.ndarray, batch_size: int, 
                                     process_func: callable) -> list:
    """
    å†…å­˜é«˜æ•ˆçš„æ‰¹å¤„ç†
    
    Args:
        data: è¾“å…¥æ•°æ®
        batch_size: æ‰¹æ¬¡å¤§å°
        process_func: å¤„ç†å‡½æ•°
        
    Returns:
        å¤„ç†ç»“æœåˆ—è¡¨
    """
    results = []
    memory_manager = MemoryManager()
    
    for i in range(0, len(data), batch_size):
        batch = data[i:i + batch_size]
        
        # å¤„ç†æ‰¹æ¬¡
        batch_result = process_func(batch)
        results.append(batch_result)
        
        # å†…å­˜ç®¡ç†
        if i % (batch_size * 10) == 0:  # æ¯10ä¸ªæ‰¹æ¬¡æ£€æŸ¥ä¸€æ¬¡
            memory_manager.cleanup_if_needed()
    
    return results


def get_optimal_batch_size(algorithm: str, available_memory_gb: float = None) -> int:
    """
    è·å–ç®—æ³•çš„æœ€ä¼˜æ‰¹æ¬¡å¤§å°
    
    Args:
        algorithm: ç®—æ³•åç§°
        available_memory_gb: å¯ç”¨å†…å­˜(GB)
        
    Returns:
        æœ€ä¼˜æ‰¹æ¬¡å¤§å°
    """
    base_batch_size = OPTIMIZED_BATCH_SIZES.get(algorithm, 64)
    
    if available_memory_gb is None:
        # è‡ªåŠ¨æ£€æµ‹å¯ç”¨å†…å­˜
        memory_info = psutil.virtual_memory()
        available_memory_gb = memory_info.available / (1024**3)
    
    # æ ¹æ®å¯ç”¨å†…å­˜è°ƒæ•´æ‰¹æ¬¡å¤§å°
    if available_memory_gb < 4:
        # å†…å­˜ä¸è¶³4GBï¼Œå‡åŠ
        return base_batch_size // 2
    elif available_memory_gb < 8:
        # å†…å­˜4-8GBï¼Œä¿æŒåŸå€¼
        return base_batch_size
    else:
        # å†…å­˜å……è¶³ï¼Œå¯ä»¥é€‚å½“å¢å¤§
        return min(base_batch_size * 2, 512)  # æœ€å¤§ä¸è¶…è¿‡512


def optimize_numpy_arrays(arrays: list) -> list:
    """
    ä¼˜åŒ–numpyæ•°ç»„çš„å†…å­˜ä½¿ç”¨
    
    Args:
        arrays: numpyæ•°ç»„åˆ—è¡¨
        
    Returns:
        ä¼˜åŒ–åçš„æ•°ç»„åˆ—è¡¨
    """
    optimized = []
    
    for arr in arrays:
        if isinstance(arr, np.ndarray):
            # è½¬æ¢ä¸ºæ›´ç´§å‡‘çš„æ•°æ®ç±»å‹
            if arr.dtype == np.float64:
                # float64 -> float32 (å¦‚æœç²¾åº¦å…è®¸)
                optimized.append(arr.astype(np.float32))
            elif arr.dtype == np.int64:
                # å°è¯•æ›´å°çš„æ•´æ•°ç±»å‹
                if arr.max() < 32767 and arr.min() > -32768:
                    optimized.append(arr.astype(np.int16))
                elif arr.max() < 2147483647 and arr.min() > -2147483648:
                    optimized.append(arr.astype(np.int32))
                else:
                    optimized.append(arr)
            else:
                optimized.append(arr)
        else:
            optimized.append(arr)
    
    return optimized


def create_performance_optimized_config(algorithm: str) -> Dict[str, Any]:
    """
    åˆ›å»ºæ€§èƒ½ä¼˜åŒ–é…ç½®
    
    Args:
        algorithm: ç®—æ³•åç§°
        
    Returns:
        ä¼˜åŒ–é…ç½®å­—å…¸
    """
    return {
        'batch_size': get_optimal_batch_size(algorithm),
        'buffer_size': min(MEMORY_CONFIG['buffer_size_limit'], 
                          get_optimal_batch_size(algorithm) * 200),
        'memory_config': MEMORY_CONFIG.copy(),
        'compute_config': COMPUTE_CONFIG.copy(),
        'use_performance_monitor': True,
        'enable_memory_management': True,
    }


class OptimizedTrainingLoop:
    """ä¼˜åŒ–çš„è®­ç»ƒå¾ªç¯"""
    
    def __init__(self, algorithm: str):
        self.algorithm = algorithm
        self.config = create_performance_optimized_config(algorithm)
        self.performance_monitor = PerformanceMonitor()
        self.memory_manager = MemoryManager()
        
    @performance_timer
    def training_step(self, *args, **kwargs):
        """ä¼˜åŒ–çš„è®­ç»ƒæ­¥éª¤"""
        # å†…å­˜æ£€æŸ¥
        if not self.memory_manager.check_memory_usage():
            logging.warning(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå¼ºåˆ¶æ¸…ç†")
            self.memory_manager.cleanup_if_needed(force=True)
        
        # å®é™…è®­ç»ƒé€»è¾‘ç”±å­ç±»å®ç°
        return self._execute_training_step(*args, **kwargs)
    
    def _execute_training_step(self, *args, **kwargs):
        """å­ç±»éœ€è¦å®ç°çš„è®­ç»ƒæ­¥éª¤"""
        raise NotImplementedError
    
    def get_performance_report(self) -> str:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        stats = self.performance_monitor.get_performance_stats()
        
        return f"""
ğŸš€ æ€§èƒ½æŠ¥å‘Š - {self.algorithm}
{'=' * 40}
æ€»æ­¥æ•°: {stats['total_steps']}
æ€»æ—¶é—´: {stats['total_time']:.2f}s
æ­¥æ•°/ç§’: {stats['steps_per_second']:.2f}
å¹³å‡å†…å­˜ä½¿ç”¨: {stats['avg_memory_usage']:.1f}%
æœ€å¤§å†…å­˜ä½¿ç”¨: {stats['max_memory_usage']:.1f}%
å¹³å‡è®¡ç®—æ—¶é—´: {stats['avg_computation_time']:.4f}s
æ€»è®¡ç®—æ—¶é—´: {stats['total_computation_time']:.2f}s
"""


# å…¨å±€æ€§èƒ½ç›‘æ§å™¨
global_performance_monitor = PerformanceMonitor()


def get_system_performance_info() -> Dict:
    """è·å–ç³»ç»Ÿæ€§èƒ½ä¿¡æ¯"""
    memory = psutil.virtual_memory()
    cpu = psutil.cpu_percent(interval=1)
    
    return {
        'cpu_percent': cpu,
        'memory_total_gb': memory.total / (1024**3),
        'memory_available_gb': memory.available / (1024**3),
        'memory_percent': memory.percent,
        'recommended_batch_sizes': OPTIMIZED_BATCH_SIZES.copy()
    }