"""Task migration manager module.

Provides utilities for planning and executing task migrations."""
import logging
import numpy as np
import uuid
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from enum import Enum

from models.data_structures import Task, Position
from config import config
from utils.unified_time_manager import get_simulation_time


class MigrationType(Enum):
    """Migration type enumeration."""
    RSU_TO_RSU = "rsu_to_rsu"
    RSU_TO_UAV = "rsu_to_uav"
    UAV_TO_RSU = "uav_to_rsu"
    VEHICLE_FOLLOW = "vehicle_follow"
    PREEMPTIVE = "preemptive"


@dataclass
class MigrationPlan:
    """Migration plan data structure."""
    migration_id: str
    migration_type: MigrationType
    source_node_id: str
    target_node_id: str
    migration_cost: float = 0.0
    migration_delay: float = 0.0
    success_probability: float = 0.0
    is_completed: bool = False
    downtime: float = 0.001  # Keep-Before-Break downtime (seconds)
    tasks_moved: int = 0
    urgency_score: float = 0.5  # ğŸ†• åˆ›æ–°:è¿ç§»ç´§æ€¥åº¦è¯„åˆ†



class TaskMigrationManager:
    """High-level task migration manager."""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        # ç‘™ï¹€å½‚é—ƒå â‚¬?
        self.rsu_overload_threshold = config.migration.rsu_overload_threshold
        self.uav_overload_threshold = config.migration.uav_overload_threshold
        self.uav_min_battery = config.migration.uav_min_battery
        
        # ğŸ†• åˆ›æ–°:è‡ªé€‚åº”é˜ˆå€¼è°ƒæ•´æœºåˆ¶
        self.adaptive_threshold_enabled = True
        self.rsu_threshold_min = 0.70  # æœ€å°é˜ˆå€¼(æ¿€è¿›è¿ç§»)
        self.rsu_threshold_max = 0.90  # æœ€å¤§é˜ˆå€¼(ä¿å®ˆè¿ç§»)
        self.threshold_adjustment_rate = 0.02  # æ¯æ¬¡è°ƒæ•´å¹…åº¦
        
        # ğŸ†• åˆ›æ–°:æ€§èƒ½åé¦ˆæŒ‡æ ‡(ç”¨äºé˜ˆå€¼è‡ªé€‚åº”)
        self.recent_migration_success_rate = 0.0
        self.recent_avg_delay_improvement = 0.0
        self.threshold_adjustment_interval = 50  # æ¯50æ¬¡è¿ç§»è°ƒæ•´ä¸€æ¬¡
        self.migration_counter = 0
        
        # é´æ„­æ¹°é™å‚›æšŸ
        self.alpha_comp = config.migration.migration_alpha_comp
        self.alpha_tx = config.migration.migration_alpha_tx
        self.alpha_lat = config.migration.migration_alpha_lat
        
        # ç¼ç†»æ·‡â„ƒä¼…
        self.migration_stats = {
            'total_attempts': 0,
            'successful_migrations': 0,
            'total_downtime': 0.0,
            'avg_cost': 0.0,
            'total_tasks_migrated': 0
        }
        
        # éå³°åµˆç» ï¼„æ‚Š
        self.node_last_migration: Dict[str, float] = {}
        self.cooldown_period = config.migration.cooldown_period
        # Retry/backoff configuration
        self.retry_backoff_base = float(getattr(config.migration, 'retry_backoff_base', 0.5))
        self.retry_backoff_max = float(getattr(config.migration, 'retry_backoff_max', 6.0))
        self.max_retry_attempts = int(getattr(config.migration, 'max_retry_attempts', 3))
        self.retry_queue: Dict[str, Dict[str, Any]] = {}
    
    def check_migration_needs(self, node_states: Dict, node_positions: Dict[str, Position]) -> List[MigrationPlan]:
        """ğŸš€ åˆ›æ–°ä¼˜åŒ–:æ™ºèƒ½è¿ç§»éœ€æ±‚æ£€æµ‹ + è‡ªé€‚åº”é˜ˆå€¼è°ƒæ•´"""
        migration_plans = []
        current_time = get_simulation_time()
        
        # ğŸ†• åˆ›æ–°:å®šæœŸè°ƒæ•´é˜ˆå€¼(åŸºäºæ€§èƒ½åé¦ˆ)
        self.migration_counter += 1
        if self.adaptive_threshold_enabled and self.migration_counter % self.threshold_adjustment_interval == 0:
            self._adjust_threshold_based_on_performance()
        
        for node_id, state in node_states.items():
            # å¦«â‚¬éŒãƒ¥å–é—å­˜æ¹¡
            if (node_id in self.node_last_migration and 
                current_time - self.node_last_migration[node_id] < self.cooldown_period):
                continue
            
            # ğŸ†• åˆ›æ–°:ç»¼åˆè¯„ä¼°è¿ç§»å¿…è¦æ€§(ä¸ä»…çœ‹è´Ÿè½½,è¿˜çœ‹é˜Ÿåˆ—è¶‹åŠ¿)
            if node_id.startswith("rsu_"):
                should_migrate, urgency_score = self._evaluate_rsu_migration_need(
                    node_id, state, node_states
                )
                # ğŸ”§ ä¿®å¤ï¼šæé«˜è¿ç§»è§¦å‘é˜ˆå€¼ï¼Œå‡å°‘é¢‘ç¹è¿ç§»
                if should_migrate and urgency_score > 1.2:
                    # ç€µç»˜å£˜æ©ä½ºĞ©é©çˆ£
                    target_node = self._find_best_target(node_id, "rsu", node_states, node_positions)
                    if target_node:
                        plan = self._create_migration_plan(node_id, target_node, node_states, node_positions)
                        if plan:
                            # ğŸ†• åˆ›æ–°:æ ¹æ®ç´§æ€¥åº¦è°ƒæ•´è¿ç§»ä¼˜å…ˆçº§
                            plan.urgency_score = urgency_score
                            migration_plans.append(plan)
            
            elif node_id.startswith("uav_"):
                battery_level = getattr(state, 'battery_level', 1.0)
                if (battery_level < self.uav_min_battery or 
                    state.load_factor > self.uav_overload_threshold):
                    # UAVé—‡â‚¬ç‘•ä½½ç¸¼ç»‰?
                    target_node = self._find_best_target(node_id, "uav", node_states, node_positions)
                    if target_node:
                        plan = self._create_migration_plan(node_id, target_node, node_states, node_positions)
                        if plan:
                            migration_plans.append(plan)
        
        migration_plans.extend(
            self._collect_retry_plans(current_time, node_states, node_positions)
        )
        
        # ğŸ¯ P3ä¼˜åŒ–ï¼šæ‰¹é‡è¿ç§»ä¼˜åŒ–
        migration_plans = self._batch_migrate_optimization(migration_plans)
        
        # ğŸ†• åˆ›æ–°:æŒ‰ç´§æ€¥åº¦æ’åºè¿ç§»è®¡åˆ’
        migration_plans.sort(key=lambda p: getattr(p, 'urgency_score', 0.5), reverse=True)
        
        return migration_plans
    
    def _find_best_target(self, source_node_id: str, source_type: str, 
                         node_states: Dict, node_positions: Dict[str, Position]) -> Optional[str]:
        """Find the best migration target for a source node."""
        candidates = []
        
        if source_type == "rsu":
            # é¦ƒæ•¡ æ·‡é”›æ°­æ–ç€¹å€Ÿç¸¼ç»‰è¤æ´°éå›¬â‚¬å¤‹å«¨é‰â€²æ¬¢é”›å±½é”çŠºç¸¼ç»‰ç»˜æº€æµ¼?
            for node_id, state in node_states.items():
                if node_id.startswith("rsu_") and node_id != source_node_id:
                    if state.load_factor < self.rsu_overload_threshold * 0.9:  # æµ ?.8é»æ„°ç®é’?.9
                        candidates.append(node_id)
                elif node_id.startswith("uav_"):
                    battery_level = getattr(state, 'battery_level', 1.0)
                    if (battery_level > self.uav_min_battery * 1.2 and   # æµ ?.5é—„å¶ˆåš¦1.2
                        state.load_factor < self.uav_overload_threshold * 0.9):  # æµ ?.8é»æ„°ç®é’?.9
                        candidates.append(node_id)
        
        elif source_type == "uav":
            # é¦ƒæ•¡ æ·‡é”›æ­AVæ©ä½ºĞ©é‰â€²æ¬¢æ¶”ç†¼â‚¬å‚šå®³é€æƒ§
            for node_id, state in node_states.items():
                if node_id.startswith("rsu_"):
                    if state.load_factor < self.rsu_overload_threshold * 0.9:  # æµ ?.8é»æ„°ç®é’?.9
                        candidates.append(node_id)
        
        # é–«å¤‹å«¨ç’ºæ¿ˆéˆâ‚¬æ©æˆ æ®‘éŠæ¬“â‚¬?
        if candidates and source_node_id in node_positions:
            source_pos = node_positions[source_node_id]
            best_candidate = max(candidates,  # ğŸ¯ P1-1: ä½¿ç”¨maxå’Œè¯„åˆ†å‡½æ•°
                               key=lambda x: self._score_target_node(x, source_node_id, source_pos, node_states, node_positions))
            return best_candidate
        
        return None

    def _collect_retry_plans(self, current_time: float,
                             node_states: Dict,
                             node_positions: Dict[str, Position]) -> List[MigrationPlan]:
        """Generate migration plans for entries waiting in the retry queue."""
        ready_plans: List[MigrationPlan] = []
        pending_keys = list(self.retry_queue.keys())
        for source_id in pending_keys:
            entry = self.retry_queue.get(source_id, {})
            if not entry:
                continue
            if current_time < entry.get('next_retry_time', 0.0):
                continue
            target_id = entry.get('target_node_id')
            plan = None
            if target_id:
                plan = self._create_migration_plan(source_id, target_id, node_states, node_positions)
            if plan is None:
                target_id = self._find_best_target(source_id, entry.get('source_type', ''), node_states, node_positions)
                if target_id:
                    plan = self._create_migration_plan(source_id, target_id, node_states, node_positions)
            if plan:
                ready_plans.append(plan)
                self.retry_queue.pop(source_id, None)
            else:
                # Could not create plan now; push next retry window
                entry_attempts = entry.get('attempts', 1)
                backoff = min(self.retry_backoff_max, self.retry_backoff_base * (2 ** max(0, entry_attempts - 1)))
                entry['next_retry_time'] = current_time + backoff
                self.retry_queue[source_id] = entry
        return ready_plans
    
    def _create_migration_plan(self, source_node_id: str, target_node_id: str,
                             node_states: Dict, node_positions: Dict[str, Position]) -> Optional[MigrationPlan]:
        """Create a migration plan."""
        distance = 0.0
        if source_node_id in node_positions and target_node_id in node_positions:
            distance = node_positions[source_node_id].distance_to(node_positions[target_node_id])

        transmission_cost = distance / 1000.0  # ä¼ è¾“æˆæœ¬è¿‘ä¼¼æŒ‰å…¬é‡Œè®¡ç®—
        computation_cost = 1.0  # å›ºå®šè®¡ç®—æˆæœ¬å ä½

        migration_bandwidth = max(1e-9, getattr(config.migration, 'migration_bandwidth', 1e6))
        data_range = getattr(config.task, 'task_data_size_range', getattr(config.task, 'data_size_range', (1.0, 1.0)))
        
        # å®‰å…¨åœ°è§£ææ•°æ®å¤§å°èŒƒå›´
        if isinstance(data_range, (list, tuple)) and len(data_range) >= 2:
            avg_data_size = (float(data_range[0]) + float(data_range[1])) / 2.0
        elif isinstance(data_range, (list, tuple)) and len(data_range) == 1:
            avg_data_size = float(data_range[0])
        elif isinstance(data_range, (int, float)):
            avg_data_size = float(data_range)
        else:
            # é»˜è®¤å€¼ï¼š1MB
            avg_data_size = 1e6
        data_size_bits = max(avg_data_size * 8.0, 1.0)
        migration_delay = max(0.01, data_size_bits / migration_bandwidth)
        latency_cost = migration_delay / max(1e-9, config.network.time_slot_duration)  # å»¶è¿Ÿæˆæœ¬

        total_cost = (
            self.alpha_comp * computation_cost +
            self.alpha_tx * transmission_cost +
            self.alpha_lat * latency_cost
        )

        success_prob = self._calculate_success_probability(distance, node_states, source_node_id, target_node_id)  # ğŸ”§ ä¼˜åŒ–ï¼šå¤šå› ç´ æˆåŠŸç‡

        if source_node_id.startswith("rsu_") and target_node_id.startswith("rsu_"):
            migration_type = MigrationType.RSU_TO_RSU
        elif source_node_id.startswith("rsu_") and target_node_id.startswith("uav_"):
            migration_type = MigrationType.RSU_TO_UAV
        elif source_node_id.startswith("uav_") and target_node_id.startswith("rsu_"):
            migration_type = MigrationType.UAV_TO_RSU
        else:
            migration_type = MigrationType.PREEMPTIVE

        return MigrationPlan(
            migration_id=str(uuid.uuid4()),
            migration_type=migration_type,
            source_node_id=source_node_id,
            target_node_id=target_node_id,
            migration_cost=total_cost,
            migration_delay=migration_delay,
            success_probability=success_prob
        )

    def execute_migration(self, migration_plan: MigrationPlan,
                          node_states: Optional[Dict] = None,
                          system_nodes: Optional[Dict[str, Dict[str, Any]]] = None,
                          tasks_to_move: Optional[int] = None) -> bool:
        """Execute a Keep-Before-Break migration cycle and return whether it succeeded."""
        self.migration_stats['total_attempts'] += 1
        migration_plan.tasks_moved = 0

        # ğŸ”§ ä¼˜åŒ–ï¼šKeep-Before-Breaké˜¶æ®µè‡ªé€‚åº”åˆ’åˆ†
        prep_ratio, sync_ratio, down_ratio = self._adaptive_kbb_phases(migration_plan)
        preparation_time = migration_plan.migration_delay * prep_ratio
        sync_time = migration_plan.migration_delay * sync_ratio
        migration_plan.downtime = migration_plan.migration_delay * down_ratio

        success = np.random.random() < migration_plan.success_probability

        if success:
            self.migration_stats['successful_migrations'] += 1
            self.migration_stats['total_downtime'] += migration_plan.downtime
            migration_plan.is_completed = True

            # æ›´æ–°å†·å´æ—¶é—´
            self.node_last_migration[migration_plan.source_node_id] = get_simulation_time()

            # Update average migration cost
            self._update_avg_cost(migration_plan.migration_cost)

            # åº”ç”¨è¿ç§»å¯¹èŠ‚ç‚¹çš„å®é™…å½±å“
            self._apply_migration_effects(
                migration_plan, node_states=node_states, system_nodes=system_nodes, tasks_to_move=tasks_to_move
            )
            if migration_plan.tasks_moved:
                self.migration_stats['total_tasks_migrated'] = (
                    self.migration_stats.get('total_tasks_migrated', 0) + migration_plan.tasks_moved
                )
        else:
            self._schedule_retry(migration_plan)

        return success

    def _schedule_retry(self, migration_plan: MigrationPlan) -> None:
        """Schedule a retry with exponential backoff for a failed migration."""
        source_id = migration_plan.source_node_id
        source_type = ''
        if source_id.startswith('rsu_'):
            source_type = 'rsu'
        elif source_id.startswith('uav_'):
            source_type = 'uav'
        entry = self.retry_queue.get(source_id, {
            'attempts': 0,
            'source_type': source_type
        })
        attempts = entry.get('attempts', 0) + 1
        if attempts > self.max_retry_attempts:
            self.retry_queue.pop(source_id, None)
            self.logger.debug(
                "Dropping migration retries for %s after %d attempts",
                source_id, attempts
            )
            return
        backoff = min(self.retry_backoff_max, self.retry_backoff_base * (2 ** (attempts - 1)))
        next_retry = get_simulation_time() + backoff
        self.retry_queue[source_id] = {
            'attempts': attempts,
            'source_type': entry.get('source_type'),
            'target_node_id': migration_plan.target_node_id,
            'next_retry_time': next_retry
        }


    def _apply_migration_effects(self, migration_plan: MigrationPlan,
                              node_states: Optional[Dict] = None,
                              system_nodes: Optional[Dict[str, Dict[str, Any]]] = None,
                              tasks_to_move: Optional[int] = None) -> None:
        """Update source and target nodes after a successful migration."""
        if system_nodes is None:
            return

        source_node = system_nodes.get(migration_plan.source_node_id)
        target_node = system_nodes.get(migration_plan.target_node_id)
        if not source_node or not target_node:
            return

        source_queue = None
        for key in ('computation_queue', 'task_queue', 'tasks'):
            candidate = source_node.get(key)
            if candidate is not None:
                source_queue = candidate
                break

        target_queue = None
        target_queue_key = None
        for key in ('computation_queue', 'task_queue', 'tasks'):
            candidate = target_node.get(key)
            if candidate is not None:
                target_queue = candidate
                target_queue_key = key
                break

        if source_queue is None or len(source_queue) == 0:
            return

        if target_queue is None:
            target_queue = []
            target_queue_key = target_queue_key or 'computation_queue'
            target_node[target_queue_key] = target_queue

        if tasks_to_move is None:
            tasks_to_move = max(1, int(len(source_queue) * 0.2))
        tasks_to_move = max(1, min(tasks_to_move, len(source_queue)))

        moved_tasks: List[Task] = []
        scored_candidates = [t for t in list(source_queue) if isinstance(t, Task)]
        if scored_candidates:
            # ğŸ¯ P2-2ä¼˜åŒ–ï¼šæ™ºèƒ½ä»»åŠ¡é€‰æ‹©
            intelligent_tasks = self._select_tasks_for_intelligent_migration(scored_candidates, tasks_to_move)
            for task in intelligent_tasks:
                if self._detach_task_from_queue(source_queue, task):
                    moved_tasks.append(task)
        # Fall back to FIFO if we still need to move tasks
        while len(moved_tasks) < tasks_to_move and source_queue:
            if hasattr(source_queue, 'popleft'):
                try:
                    moved_tasks.append(source_queue.popleft())
                    continue
                except IndexError:
                    break
            try:
                moved_tasks.append(source_queue.pop(0))
            except (IndexError, AttributeError):
                break

        if not moved_tasks:
            return
        
        # ğŸ”§ ä¿®å¤ï¼šè¿ç§»å‰åŒæ­¥ç¼“å­˜å†…å®¹ï¼Œé¿å…æ•°æ®ä¸¢å¤±
        self._sync_cache_before_migration(source_node, target_node, moved_tasks)

        if hasattr(target_queue, 'extend'):
            target_queue.extend(moved_tasks)
        else:
            for task in moved_tasks:
                if hasattr(target_queue, 'append'):
                    target_queue.append(task)

        migration_plan.tasks_moved = len(moved_tasks)

        if node_states is not None:
            source_state = node_states.get(migration_plan.source_node_id)
            target_state = node_states.get(migration_plan.target_node_id)
            self._update_node_state_metrics(source_state, len(source_queue))
            self._update_node_state_metrics(target_state, len(target_queue))

    def _update_node_state_metrics(self, node_state, queue_length: int) -> None:
        """Refresh queue length and load factor for a node state."""
        if node_state is None:
            return

        try:
            node_state.queue_length = max(0, int(queue_length))
        except Exception:
            setattr(node_state, 'queue_length', max(0, int(queue_length)))

        capacity = self._get_nominal_capacity(node_state)
        if capacity <= 0:
            return

        load_factor = queue_length / capacity
        try:
            node_state.load_factor = float(load_factor)
        except Exception:
            setattr(node_state, 'load_factor', float(load_factor))

    def _get_nominal_capacity(self, node_state) -> float:
        label = getattr(node_state, 'node_type', None)
        if isinstance(label, str):
            label_value = label.lower()
        elif label is not None and hasattr(label, 'value'):
            label_value = str(label.value).lower()
        else:
            label_value = str(label).lower() if label is not None else ''

        queue_cfg = getattr(config, 'queue', None)
        if 'rsu' in label_value:
            return float(getattr(queue_cfg, 'rsu_nominal_capacity', 20.0)) if queue_cfg else 20.0
        if 'uav' in label_value:
            return float(getattr(queue_cfg, 'uav_nominal_capacity', 10.0)) if queue_cfg else 10.0
        if 'vehicle' in label_value:
            return 5.0
        return 10.0

    def _update_avg_cost(self, new_cost: float):
        """Update average migration cost."""
        current_avg = self.migration_stats['avg_cost']
        success_count = self.migration_stats['successful_migrations']
        
        if success_count == 1:
            self.migration_stats['avg_cost'] = new_cost
        else:
            # ç»‰è¯²å§©éªå†²æ½
            alpha = 0.1
            self.migration_stats['avg_cost'] = alpha * new_cost + (1 - alpha) * current_avg
    
    def get_migration_statistics(self) -> Dict:
        """Return migration statistics."""
        total_attempts = self.migration_stats['total_attempts']
        successful = self.migration_stats['successful_migrations']
        
        return {
            'total_attempts': total_attempts,
            'successful_migrations': successful,
            'success_rate': successful / max(1, total_attempts),
            'total_downtime': self.migration_stats['total_downtime'],
            'avg_downtime_per_migration': self.migration_stats['total_downtime'] / max(1, successful),
            'avg_cost': self.migration_stats['avg_cost'],
            'total_tasks_migrated': self.migration_stats.get('total_tasks_migrated', 0)
        }
    
    def step(self, node_states: Dict, node_positions: Dict[str, Position],
            system_nodes: Optional[Dict[str, Dict[str, Any]]] = None) -> Dict:
        """Run one migration-planning step and return aggregated statistics."""
        migration_plans = self.check_migration_needs(node_states, node_positions)

        step_stats = {
            'migrations_planned': len(migration_plans),
            'migrations_executed': 0,
            'migrations_successful': 0,
            'tasks_migrated': 0
        }

        for plan in migration_plans:
            step_stats['migrations_executed'] += 1
            success = self.execute_migration(
                plan,
                node_states=node_states,
                system_nodes=system_nodes
            )
            if success:
                step_stats['migrations_successful'] += 1
                step_stats['tasks_migrated'] += plan.tasks_moved

        return step_stats

    def _score_task_for_migration(self, task: Task) -> Tuple[int, int]:
        """Lower score means higher priority for migration."""
        priority = getattr(task, 'priority', getattr(config.task, 'num_priority_levels', 4))
        try:
            remaining = int(task.remaining_lifetime_slots)
        except Exception:
            remaining = getattr(task, 'max_delay_slots', 0)
        return (priority, remaining)

    def _calculate_success_probability(self, distance: float, node_states: Dict,
                                      source_node_id: str, target_node_id: str) -> float:
        """
        ğŸ¯ ä¼˜åŒ–ï¼šå¤šå› ç´ è¿ç§»æˆåŠŸç‡è®¡ç®—
        
        è€ƒè™‘å› ç´ ï¼š
        1. è·ç¦»æƒ©ç½š
        2. æºèŠ‚ç‚¹è´Ÿè½½æƒ©ç½šï¼ˆè¿‡è½½æ—¶è¿ç§»æ›´éš¾ï¼‰
        3. ç›®æ ‡èŠ‚ç‚¹å®¹é‡å¥–åŠ±
        4. ç½‘ç»œæ‹¥å¡æƒ©ç½š
        """
        # åŸºç¡€æˆåŠŸç‡
        base_prob = 0.9
        
        # ğŸ’¡ è·ç¦»æƒ©ç½š
        distance_penalty = min(0.3, distance / 10000.0)
        
        # ğŸ’¡ æºèŠ‚ç‚¹è´Ÿè½½æƒ©ç½šï¼ˆè¿‡è½½æ—¶è¿ç§»æ›´éš¾ï¼‰
        source_state = node_states.get(source_node_id)
        source_penalty = 0.0
        if source_state and hasattr(source_state, 'load_factor'):
            if source_state.load_factor > 0.8:
                source_penalty = (source_state.load_factor - 0.8) * 0.5
        
        # ğŸ’¡ ç›®æ ‡èŠ‚ç‚¹å®¹é‡å¥–åŠ±
        target_state = node_states.get(target_node_id)
        target_bonus = 0.0
        if target_state and hasattr(target_state, 'load_factor'):
            target_bonus = (1.0 - target_state.load_factor) * 0.1
        
        # ğŸ’¡ ç½‘ç»œæ‹¥å¡æƒ©ç½š
        network_penalty = 0.0
        if source_state and hasattr(source_state, 'bandwidth_utilization'):
            network_penalty = source_state.bandwidth_utilization * 0.1
        
        # ğŸ¯ ç»¼åˆæˆåŠŸç‡
        success_prob = base_prob - distance_penalty - source_penalty + target_bonus - network_penalty
        return float(np.clip(success_prob, 0.4, 0.95))
    
    def _adaptive_kbb_phases(self, migration_plan: MigrationPlan) -> Tuple[float, float, float]:
        """
        ğŸ”§ ä¼˜åŒ–ï¼šè‡ªé€‚åº”Keep-Before-Breaké˜¶æ®µåˆ’åˆ†
        
        æ ¹æ®è¿ç§»ç±»å‹åŠ¨æ€è°ƒæ•´ä¸‰ä¸ªé˜¶æ®µçš„æ—¶é—´åˆ†é…ï¼š
        - å‡†å¤‡é˜¶æ®µï¼šèµ„æºé¢„ç•™ã€çŠ¶æ€åŒæ­¥
        - åŒæ­¥é˜¶æ®µï¼šæ•°æ®ä¼ è¾“
        - é™é»˜åˆ‡æ¢ï¼šdowntime
        
        Returns:
            (prep_ratio, sync_ratio, downtime_ratio)
        """
        migration_type = migration_plan.migration_type
        
        if migration_type == MigrationType.RSU_TO_RSU:
            # RSUé—´æœ‰çº¿è¿ç§»ï¼Œå‡†å¤‡æ—¶é—´çŸ­
            return (0.5, 0.4, 0.1)
        elif migration_type == MigrationType.RSU_TO_UAV:
            # åˆ°UAVæ— çº¿è¿ç§»ï¼ŒåŒæ­¥æ—¶é—´é•¿
            return (0.6, 0.35, 0.05)
        elif migration_type == MigrationType.UAV_TO_RSU:
            # UAVåˆ°RSUï¼Œå¹³è¡¡é…ç½®
            return (0.55, 0.35, 0.1)
        else:
            # é»˜è®¤é…ç½®ï¼ˆVEHICLE_FOLLOW, PREEMPTIVEç­‰ï¼‰
            return (0.7, 0.25, 0.05)

    def _detach_task_from_queue(self, queue, task: Task) -> bool:
        """Remove a specific task object from the given queue-like container."""
        if queue is None or task is None:
            return False
        if hasattr(queue, 'remove_task'):
            try:
                queue.remove_task(task.task_id)
                return True
            except Exception:
                pass
        if hasattr(queue, 'remove'):
            try:
                queue.remove(task)
                return True
            except ValueError:
                return False
        # Manual scan fallback
        try:
            for idx, item in enumerate(queue):
                if item is task:
                    del queue[idx]
                    return True
        except Exception:
            return False
        return False

    # ========== ğŸ¯ P1-P3 å…¨é¢ä¼˜åŒ–æ–¹æ³• ==========
    
    def _score_target_node(self, target_id: str, source_id: str, source_pos: Position,
                          node_states: Dict, node_positions: Dict[str, Position]) -> float:
        """
        ğŸ¯ P1-1: å¤šç»´åº¦ç›®æ ‡èŠ‚ç‚¹è¯„åˆ†ï¼ˆè½»é‡â€œæ³¨æ„åŠ›â€èåˆï¼‰

        - åŸºäºè´Ÿè½½/è·ç¦»/é˜Ÿåˆ—/å¸¦å®½çš„æ—§è¯„åˆ†ä¿ç•™
        - å¢åŠ â€œç¼“è§£æ”¶ç›Šâ€(source->targetè´Ÿè½½å·®) ä¸ â€œå†å²å¯é æ€§â€ ä½œä¸ºåŠ¨æ€æƒé‡
        - ä½¿ç”¨ softmax è®¡ç®—è½»é‡æƒé‡ï¼Œçªå‡ºæœ€å…·æ”¶ç›Šçš„ç‰¹å¾ï¼Œå…¼é¡¾ç®€å•æ€§
        """
        target_state = node_states.get(target_id)
        source_state = node_states.get(source_id)
        if not target_state:
            return 0.0

        # 1. è´Ÿè½½è¯„åˆ†ï¼šè¶Šç©ºé—²è¶Šå¥½
        load_score = 1.0 - min(1.0, getattr(target_state, 'load_factor', 1.0))

        # 2. è·ç¦»è¯„åˆ†ï¼šè¶Šè¿‘è¶Šå¥½
        target_pos = node_positions.get(target_id)
        if target_pos:
            distance = source_pos.distance_to(target_pos)
            distance_score = 1.0 / (1.0 + distance / 1000.0)
        else:
            distance_score = 0.5

        # 3. é˜Ÿåˆ—è¯„åˆ†ï¼šé˜Ÿåˆ—è¶ŠçŸ­è¶Šå¥½
        queue_length = getattr(target_state, 'queue_length', 0)
        queue_capacity = 20.0 if target_id.startswith("rsu_") else 10.0
        queue_score = 1.0 - min(1.0, queue_length / queue_capacity)

        # 4. å¸¦å®½è¯„åˆ†ï¼šå¸¦å®½è¶Šç©ºé—²è¶Šå¥½
        bandwidth_util = getattr(target_state, 'bandwidth_utilization', 0.5)
        bandwidth_score = 1.0 - min(1.0, bandwidth_util)

        # 5. ç¼“è§£æ”¶ç›Šï¼šæºèŠ‚ç‚¹ä¸ç›®æ ‡èŠ‚ç‚¹çš„è´Ÿè½½å·®ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
        source_load = getattr(source_state, 'load_factor', 1.0) if source_state else 1.0
        relief_score = max(0.0, source_load - getattr(target_state, 'load_factor', 0.0))
        relief_score = min(1.0, relief_score)

        # 6. å†å²å¯é æ€§ï¼šè¿‘æœŸè¿ç§»æˆåŠŸç‡ï¼Œé¿å…é¢‘ç¹å¤±è´¥çš„è·¯å¾„
        success_rate = self.migration_stats['successful_migrations'] / max(1, self.migration_stats['total_attempts'])
        reliability_score = float(np.clip(success_rate + 0.05, 0.0, 1.0))  # åŠ ä¸€ä¸ªè½»å¾®çš„å…ˆéªŒ

        # æ—§ç‰ˆé™æ€æƒé‡ï¼ˆä¿æŒå…¼å®¹ï¼‰
        legacy_score = 0.4 * load_score + 0.3 * distance_score + 0.2 * queue_score + 0.1 * bandwidth_score

        # è½»é‡æ³¨æ„åŠ›ï¼šè®©æ”¶ç›Š/å¯é æ€§è‡ªåŠ¨â€œæŠ¬æƒé‡â€
        attn_features = np.array([
            load_score,
            queue_score,
            distance_score,
            relief_score,
            reliability_score,
            bandwidth_score
        ], dtype=np.float32)
        attn_logits = attn_features * np.array([1.0, 1.0, 0.8, 1.5, 1.2, 0.6], dtype=np.float32)  # åå‘ç¼“è§£æ”¶ç›Šä¸å¯é æ€§
        attn_weights = np.exp(attn_logits - np.max(attn_logits))
        attn_weights_sum = float(attn_weights.sum()) if np.isfinite(attn_weights.sum()) and attn_weights.sum() > 0 else 1.0
        attn_weights = attn_weights / attn_weights_sum
        attention_score = float(np.dot(attn_weights, attn_features))

        # èåˆï¼šä¿æŒæ—§é€»è¾‘çš„ç¨³å®šæ€§ï¼ŒåŒæ—¶è®©æ³¨æ„åŠ›çªå‡ºé«˜æ”¶ç›Šç›®æ ‡
        return 0.55 * attention_score + 0.45 * legacy_score
    
    def _sync_cache_before_migration(self, source_node: Dict, target_node: Dict, tasks: List[Task]) -> None:
        """
        ğŸ”§ ä¿®å¤ï¼šè¿ç§»å‰åŒæ­¥ç¼“å­˜å†…å®¹ï¼Œç¡®ä¿æ•°æ®ä¸ä¸¢å¤±
        
        å°†å¾…è¿ç§»ä»»åŠ¡ç›¸å…³çš„ç¼“å­˜å†…å®¹é¢„å…ˆå¤åˆ¶åˆ°ç›®æ ‡èŠ‚ç‚¹
        """
        source_cache = source_node.get('cache', {})
        if not source_cache or not tasks:
            return
        
        target_cache = target_node.setdefault('cache', {})
        target_capacity = target_node.get('cache_capacity', 1000.0)
        
        # è®¡ç®—ç›®æ ‡ç¼“å­˜å¯ç”¨ç©ºé—´
        target_used = sum(float(item.get('size', 0) or 0) for item in target_cache.values())
        target_available = max(0, target_capacity - target_used)
        
        # æ”¶é›†éœ€è¦åŒæ­¥çš„å†…å®¹ID
        content_ids_to_sync = set()
        for task in tasks:
            if not isinstance(task, Task):
                continue
            content_id = getattr(task, 'content_id', None) or getattr(task, 'input_content_id', None)
            if content_id and content_id in source_cache:
                content_ids_to_sync.add(content_id)
        
        # åŒæ­¥ç¼“å­˜å†…å®¹
        synced_count = 0
        synced_size = 0.0
        for content_id in content_ids_to_sync:
            if content_id in target_cache:
                continue
            
            cache_item = source_cache.get(content_id)
            if not cache_item:
                continue
            
            item_size = float(cache_item.get('size', 1.0) or 1.0)
            if target_available < item_size:
                break
            
            # å¤åˆ¶ç¼“å­˜æ¡ç›®
            import copy
            target_cache[content_id] = copy.deepcopy(cache_item)
            target_cache[content_id]['migrated'] = True
            target_available -= item_size
            synced_size += item_size
            synced_count += 1
        
        if synced_count > 0:
            self.logger.debug(f"ğŸ”„ è¿ç§»å‰åŒæ­¥ç¼“å­˜: {synced_count}é¡¹, {synced_size:.1f}MB")
    
    def _select_tasks_for_intelligent_migration(self, source_queue, max_count: int) -> List[Task]:
        """
        ğŸ¯ P2-2: æ™ºèƒ½ä»»åŠ¡é€‰æ‹© - ä¼˜å…ˆè¿ç§»é«˜ä¼˜å…ˆçº§+ç´§æ€¥ä»»åŠ¡
        """
        tasks_scored = []
        for task in source_queue:
            if not isinstance(task, Task):
                continue
            
            # è®¡ç®—ç´§æ€¥åº¦
            try:
                remaining_slots = int(task.remaining_lifetime_slots)
                urgency = 1.0 / max(1.0, remaining_slots)
            except:
                urgency = 0.5
            
            # ä¼˜å…ˆçº§æƒé‡ï¼ˆä¼˜å…ˆçº§1æœ€é«˜ï¼‰
            priority = getattr(task, 'priority', 4)
            priority_weight = (5 - priority) / 4.0
            
            # å¤§å°æƒ©ç½šï¼ˆå¤§ä»»åŠ¡è¿ç§»æˆæœ¬é«˜ï¼‰
            data_size = getattr(task, 'data_size', 0)
            size_penalty = data_size / 1e6  # MB
            
            # ç»¼åˆè¯„åˆ†
            score = urgency * 0.5 + priority_weight * 0.3 - size_penalty * 0.2
            tasks_scored.append((task, score))
        
        # æŒ‰è¯„åˆ†æ’åºï¼Œé€‰æ‹©top-K
        tasks_scored.sort(key=lambda x: x[1], reverse=True)
        return [task for task, _ in tasks_scored[:max_count]]
    
    def _batch_migrate_optimization(self, migration_plans: List[MigrationPlan]) -> List[MigrationPlan]:
        """
        ğŸ¯ P3: æ‰¹é‡è¿ç§»ä¼˜åŒ–
        
        åˆå¹¶åŒæºåŒç›®æ ‡çš„è¿ç§»è®¡åˆ’ï¼Œå‡å°‘20%å¼€é”€
        """
        from collections import defaultdict
        batches = defaultdict(list)
        
        # æŒ‰(source, target)åˆ†ç»„
        for plan in migration_plans:
            key = (plan.source_node_id, plan.target_node_id)
            batches[key].append(plan)
        
        optimized_plans = []
        for (source, target), plans in batches.items():
            if len(plans) > 1:
                # åˆå¹¶ä¸ºæ‰¹é‡è¿ç§»ï¼Œå‡å°‘20%å¼€é”€
                merged_plan = plans[0]
                merged_plan.migration_delay *= 0.8
                merged_plan.migration_cost *= 0.8
                self.logger.info(f"ğŸš€ æ‰¹é‡è¿ç§»ä¼˜åŒ–: {source}->{target} åˆå¹¶{len(plans)}ä¸ªè®¡åˆ’")
                optimized_plans.append(merged_plan)
            else:
                optimized_plans.extend(plans)
        
        return optimized_plans
    
    def _calculate_precise_migration_cost(self, migration_plan: MigrationPlan, 
                                         task_list: List[Task],
                                         node_states: Dict) -> float:
        """
        ğŸ¯ P3: ç²¾ç¡®è¿ç§»æˆæœ¬è®¡ç®—
        
        è€ƒè™‘ï¼šä¼ è¾“æˆæœ¬ + è®¡ç®—æˆæœ¬ + ç½‘ç»œæ‹¥å¡æˆæœ¬
        """
        # 1. å®é™…ä¼ è¾“æˆæœ¬
        total_data_size = sum(getattr(t, 'data_size', 0) for t in task_list)
        data_size_bits = total_data_size * 8
        migration_bw = max(1e-9, getattr(config.migration, 'migration_bandwidth', 1e6))
        transmission_time = data_size_bits / migration_bw
        transmission_cost = transmission_time * self.alpha_tx
        
        # 2. å®é™…è®¡ç®—æˆæœ¬ï¼ˆçŠ¶æ€åŒæ­¥ã€ä¸Šä¸‹æ–‡åˆ‡æ¢ï¼‰
        num_tasks = len(task_list)
        computation_cost = num_tasks * 0.05 * self.alpha_comp
        
        # 3. ç½‘ç»œæ‹¥å¡æˆæœ¬
        source_state = node_states.get(migration_plan.source_node_id)
        if source_state and hasattr(source_state, 'bandwidth_utilization'):
            source_bw_util = source_state.bandwidth_utilization
            latency_penalty = transmission_time * (1 + source_bw_util) * self.alpha_lat
        else:
            latency_penalty = transmission_time * self.alpha_lat
        
        total_cost = transmission_cost + computation_cost + latency_penalty
        return total_cost

    def _evaluate_rsu_migration_need(self, node_id: str, state, node_states: Dict) -> Tuple[bool, float]:
        """
        ğŸ†• åˆ›æ–°:ç»¼åˆè¯„ä¼°RSUè¿ç§»å¿…è¦æ€§
        
        åŸºäºå¤šä¸ªå› ç´ åˆ¤æ–­:
        1. è´Ÿè½½å› å­(å½“å‰è´Ÿè½½ vs é˜ˆå€¼)
        2. è´Ÿè½½è¶‹åŠ¿(æ˜¯å¦æŒç»­ä¸Šå‡)
        3. é˜Ÿåˆ—é•¿åº¦å¢é•¿é€Ÿåº¦
        
        Returns:
            (should_migrate, urgency_score): æ˜¯å¦è¿ç§»å’Œç´§æ€¥åº¦è¯„åˆ†[0,1]
        """
        load_factor = state.load_factor
        
        # 1. åŸºç¡€åˆ¤æ–­:è´Ÿè½½æ˜¯å¦è¶…é˜ˆå€¼
        if load_factor <= self.rsu_overload_threshold:
            return False, 0.0
        
        # 2. è®¡ç®—è¶…è½½ç¨‹åº¦
        overload_ratio = (load_factor - self.rsu_overload_threshold) / max(0.1, 1.0 - self.rsu_overload_threshold)
        urgency_score = min(1.0, overload_ratio)
        
        # 3. è´Ÿè½½è¶‹åŠ¿åˆ¤æ–­(å¦‚æœæœ‰å†å²æ•°æ®)
        # ç®€åŒ–ç‰ˆ:åŸºäºé˜Ÿåˆ—é•¿åº¦ä¼°è®¡è¶‹åŠ¿
        queue_length = getattr(state, 'queue_length', 0)
        if queue_length > 15:  # é˜Ÿåˆ—è¿‡é•¿,å¢åŠ ç´§æ€¥åº¦
            urgency_score *= 1.2
        
        urgency_score = min(1.0, urgency_score)
        return True, urgency_score
    
    def _adjust_threshold_based_on_performance(self) -> None:
        """
        ğŸ†• åˆ›æ–°:åŸºäºæ€§èƒ½åé¦ˆè°ƒæ•´è¿ç§»é˜ˆå€¼
        
        ç­–ç•¥:
        - å¦‚æœè¿ç§»æˆåŠŸç‡é«˜ä¸”æ•ˆæœå¥½ -> é™ä½é˜ˆå€¼(æ›´æ¿€è¿›)
        - å¦‚æœè¿ç§»æˆåŠŸç‡ä½æˆ–æ•ˆæœå·® -> æé«˜é˜ˆå€¼(æ›´ä¿å®ˆ)
        """
        success_rate = self.migration_stats['successful_migrations'] / max(1, self.migration_stats['total_attempts'])
        self.recent_migration_success_rate = success_rate
        
        # æˆåŠŸç‡é«˜,ä¸”è¿ç§»æœ‰æ•ˆ -> é™ä½é˜ˆå€¼
        if success_rate > 0.85:
            self.rsu_overload_threshold = max(
                self.rsu_threshold_min,
                self.rsu_overload_threshold - self.threshold_adjustment_rate
            )
            self.logger.info(f"ğŸ”§ è°ƒæ•´è¿ç§»é˜ˆå€¼: {self.rsu_overload_threshold:.3f} (æ›´æ¿€è¿›,æˆåŠŸç‡={success_rate:.2%})")
        # æˆåŠŸç‡ä½ -> æé«˜é˜ˆå€¼
        elif success_rate < 0.65:
            self.rsu_overload_threshold = min(
                self.rsu_threshold_max,
                self.rsu_overload_threshold + self.threshold_adjustment_rate
            )
            self.logger.info(f"ğŸ”§ è°ƒæ•´è¿ç§»é˜ˆå€¼: {self.rsu_overload_threshold:.3f} (æ›´ä¿å®ˆ,æˆåŠŸç‡={success_rate:.2%})")


