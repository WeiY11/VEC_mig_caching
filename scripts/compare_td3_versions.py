#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TD3 ç‰ˆæœ¬å¯¹æ¯”è„šæœ¬ - v2.0 vs v3.0
ç”¨äºå¯è§†åŒ–å¯¹æ¯”ä¼˜åŒ–å‰åçš„è®­ç»ƒæ•ˆæœ
"""
import json
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path
import sys

def load_results(filepath):
    """åŠ è½½è®­ç»ƒç»“æœ"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)

def moving_average(data, window=20):
    """è®¡ç®—ç§»åŠ¨å¹³å‡"""
    if len(data) < window:
        return data
    return np.convolve(data, np.ones(window)/window, mode='valid')

def calculate_variance(data, window=100):
    """è®¡ç®—æ»‘åŠ¨çª—å£æ–¹å·®"""
    variances = []
    for i in range(len(data)):
        start = max(0, i - window + 1)
        window_data = data[start:i+1]
        if len(window_data) >= 10:  # è‡³å°‘10ä¸ªæ•°æ®ç‚¹
            mean = np.mean(window_data)
            var = np.mean((np.array(window_data) - mean)**2)
            variances.append(var)
        else:
            variances.append(0)
    return variances

def compare_versions(v2_file, v3_file, output_dir="results/single_agent/td3"):
    """å¯¹æ¯”ä¸¤ä¸ªç‰ˆæœ¬çš„è®­ç»ƒç»“æœ"""
    print("ğŸ“Š åŠ è½½è®­ç»ƒæ•°æ®...")
    v2_data = load_results(v2_file)
    v3_data = load_results(v3_file)
    
    v2_episodes = v2_data['episodes']
    v3_episodes = v3_data['episodes']
    
    # æå–å…³é”®æŒ‡æ ‡
    v2_rewards = [ep['reward'] for ep in v2_episodes]
    v3_rewards = [ep['reward'] for ep in v3_episodes]
    
    v2_delays = [ep['avg_delay'] for ep in v2_episodes]
    v3_delays = [ep['avg_delay'] for ep in v3_episodes]
    
    v2_energy = [ep['avg_energy'] for ep in v2_episodes]
    v3_energy = [ep['avg_energy'] for ep in v3_episodes]
    
    v2_completion = [ep['completion_rate'] for ep in v2_episodes]
    v3_completion = [ep['completion_rate'] for ep in v3_episodes]
    
    v2_noise = [ep['training_stats']['exploration_noise'] for ep in v2_episodes]
    v3_noise = [ep['training_stats']['exploration_noise'] for ep in v3_episodes]
    
    print("ğŸ“ˆ ç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
    
    # åˆ›å»ºå¯¹æ¯”å›¾è¡¨
    fig = plt.figure(figsize=(20, 12))
    
    # 1. Rewardå¯¹æ¯”
    ax1 = plt.subplot(3, 3, 1)
    ax1.plot(v2_rewards, alpha=0.3, color='#E74C3C', linewidth=0.5)
    ax1.plot(moving_average(v2_rewards, 20), color='#E74C3C', linewidth=2, label='v2.0')
    ax1.plot(v3_rewards, alpha=0.3, color='#27AE60', linewidth=0.5)
    ax1.plot(moving_average(v3_rewards, 20), color='#27AE60', linewidth=2, label='v3.0')
    ax1.set_xlabel('Episode')
    ax1.set_ylabel('Reward')
    ax1.set_title('Reward Convergence Comparison')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. Reward Varianceå¯¹æ¯”
    ax2 = plt.subplot(3, 3, 2)
    v2_var = calculate_variance(v2_rewards, 100)
    v3_var = calculate_variance(v3_rewards, 100)
    ax2.plot(v2_var, color='#E74C3C', linewidth=2, label='v2.0')
    ax2.plot(v3_var, color='#27AE60', linewidth=2, label='v3.0')
    ax2.axhline(y=0.15, color='orange', linestyle='--', alpha=0.5, label='Target (<0.15)')
    ax2.set_xlabel('Episode')
    ax2.set_ylabel('Reward Variance')
    ax2.set_title('Stability Comparison (100-Episode Window)')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. Exploration Noiseå¯¹æ¯”
    ax3 = plt.subplot(3, 3, 3)
    ax3.plot(v2_noise, color='#E74C3C', linewidth=2, label='v2.0')
    ax3.plot(v3_noise, color='#27AE60', linewidth=2, label='v3.0')
    ax3.set_xlabel('Episode')
    ax3.set_ylabel('Exploration Noise')
    ax3.set_title('Exploration Strategy Comparison')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. æ—¶å»¶å¯¹æ¯”
    ax4 = plt.subplot(3, 3, 4)
    ax4.plot(moving_average(v2_delays, 20), color='#E74C3C', linewidth=2, label='v2.0')
    ax4.plot(moving_average(v3_delays, 20), color='#27AE60', linewidth=2, label='v3.0')
    ax4.set_xlabel('Episode')
    ax4.set_ylabel('Average Delay (s)')
    ax4.set_title('Delay Performance')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    # 5. èƒ½è€—å¯¹æ¯”
    ax5 = plt.subplot(3, 3, 5)
    ax5.plot(moving_average(v2_energy, 20), color='#E74C3C', linewidth=2, label='v2.0')
    ax5.plot(moving_average(v3_energy, 20), color='#27AE60', linewidth=2, label='v3.0')
    ax5.set_xlabel('Episode')
    ax5.set_ylabel('Average Energy (J)')
    ax5.set_title('Energy Performance')
    ax5.legend()
    ax5.grid(True, alpha=0.3)
    
    # 6. å®Œæˆç‡å¯¹æ¯”
    ax6 = plt.subplot(3, 3, 6)
    ax6.plot(moving_average(v2_completion, 20), color='#E74C3C', linewidth=2, label='v2.0')
    ax6.plot(moving_average(v3_completion, 20), color='#27AE60', linewidth=2, label='v3.0')
    ax6.set_xlabel('Episode')
    ax6.set_ylabel('Completion Rate')
    ax6.set_title('Task Completion Rate')
    ax6.legend()
    ax6.grid(True, alpha=0.3)
    
    # 7. åæœŸç¨³å®šæ€§å¯¹æ¯”ï¼ˆæœ€å200è½®ï¼‰
    ax7 = plt.subplot(3, 3, 7)
    late_v2 = v2_rewards[-200:] if len(v2_rewards) >= 200 else v2_rewards
    late_v3 = v3_rewards[-200:] if len(v3_rewards) >= 200 else v3_rewards
    ax7.boxplot([late_v2, late_v3], labels=['v2.0', 'v3.0'])
    ax7.set_ylabel('Reward')
    ax7.set_title('Late-Stage Stability (Last 200 Episodes)')
    ax7.grid(True, alpha=0.3)
    
    # 8. ç»Ÿè®¡å¯¹æ¯”è¡¨
    ax8 = plt.subplot(3, 3, 8)
    ax8.axis('off')
    
    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    v2_final_reward = np.mean(v2_rewards[-100:])
    v3_final_reward = np.mean(v3_rewards[-100:])
    v2_final_var = np.var(v2_rewards[-100:])
    v3_final_var = np.var(v3_rewards[-100:])
    v2_final_noise = v2_noise[-1]
    v3_final_noise = v3_noise[-1]
    v2_final_delay = np.mean(v2_delays[-100:])
    v3_final_delay = np.mean(v3_delays[-100:])
    
    stats_text = f"""
    ğŸ“Š æœ€ç»ˆæ€§èƒ½å¯¹æ¯” (æœ€å100è½®)
    
    æŒ‡æ ‡              v2.0        v3.0        æ”¹è¿›
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    å¹³å‡å¥–åŠ±       {v2_final_reward:7.4f}   {v3_final_reward:7.4f}   {(v3_final_reward-v2_final_reward)/abs(v2_final_reward)*100:+.1f}%
    å¥–åŠ±æ–¹å·®       {v2_final_var:7.4f}   {v3_final_var:7.4f}   {(v3_final_var-v2_final_var)/v2_final_var*100:+.1f}%
    æ¢ç´¢å™ªå£°       {v2_final_noise:7.4f}   {v3_final_noise:7.4f}   {(v3_final_noise-v2_final_noise)/v2_final_noise*100:+.1f}%
    å¹³å‡æ—¶å»¶       {v2_final_delay:7.4f}s  {v3_final_delay:7.4f}s  {(v3_final_delay-v2_final_delay)/v2_final_delay*100:+.1f}%
    
    âœ… ç¨³å®šæ€§è¯„ä¼°:
    v2.0: {"ä¼˜ç§€" if v2_final_var < 0.15 else "è‰¯å¥½" if v2_final_var < 0.25 else "éœ€æ”¹è¿›"}
    v3.0: {"ä¼˜ç§€" if v3_final_var < 0.15 else "è‰¯å¥½" if v3_final_var < 0.25 else "éœ€æ”¹è¿›"}
    """
    ax8.text(0.1, 0.5, stats_text, fontsize=10, family='monospace', 
             verticalalignment='center')
    
    # 9. æ”¶æ•›é€Ÿåº¦å¯¹æ¯”
    ax9 = plt.subplot(3, 3, 9)
    # è®¡ç®—è¾¾åˆ°ç›®æ ‡æ€§èƒ½çš„è½®æ¬¡
    target_reward = max(np.mean(v2_rewards), np.mean(v3_rewards)) * 0.9
    v2_converge = next((i for i, r in enumerate(moving_average(v2_rewards, 20)) if r >= target_reward), len(v2_rewards))
    v3_converge = next((i for i, r in enumerate(moving_average(v3_rewards, 20)) if r >= target_reward), len(v3_rewards))
    
    ax9.bar(['v2.0', 'v3.0'], [v2_converge, v3_converge], color=['#E74C3C', '#27AE60'])
    ax9.set_ylabel('Episodes to Converge')
    ax9.set_title(f'Convergence Speed (Target: {target_reward:.2f})')
    ax9.grid(True, alpha=0.3, axis='y')
    
    plt.suptitle('TD3 Version Comparison: v2.0 vs v3.0 (Optimization Validation)', 
                 fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    output_path = Path(output_dir) / 'td3_version_comparison.png'
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"âœ… å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜: {output_path}")
    
    # ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š
    report = {
        'v2.0': {
            'final_reward_mean': float(v2_final_reward),
            'final_reward_variance': float(v2_final_var),
            'final_exploration_noise': float(v2_final_noise),
            'final_delay': float(v2_final_delay),
            'convergence_episode': int(v2_converge)
        },
        'v3.0': {
            'final_reward_mean': float(v3_final_reward),
            'final_reward_variance': float(v3_final_var),
            'final_exploration_noise': float(v3_final_noise),
            'final_delay': float(v3_final_delay),
            'convergence_episode': int(v3_converge)
        },
        'improvements': {
            'reward_mean': f"{(v3_final_reward-v2_final_reward)/abs(v2_final_reward)*100:+.2f}%",
            'reward_variance': f"{(v3_final_var-v2_final_var)/v2_final_var*100:+.2f}%",
            'exploration_noise': f"{(v3_final_noise-v2_final_noise)/v2_final_noise*100:+.2f}%",
            'delay': f"{(v3_final_delay-v2_final_delay)/v2_final_delay*100:+.2f}%"
        }
    }
    
    report_path = Path(output_dir) / 'td3_version_comparison.json'
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    print(f"âœ… ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    plt.show()
    
    return report

if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("ä½¿ç”¨æ–¹æ³•: python compare_td3_versions.py <v2.0ç»“æœæ–‡ä»¶> <v3.0ç»“æœæ–‡ä»¶>")
        print("\nç¤ºä¾‹:")
        print("python scripts/compare_td3_versions.py \\")
        print("    results/single_agent/td3/training_results_v2.json \\")
        print("    results/single_agent/td3/training_results_v3.json")
        sys.exit(1)
    
    v2_file = sys.argv[1]
    v3_file = sys.argv[2]
    
    if not Path(v2_file).exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {v2_file}")
        sys.exit(1)
    
    if not Path(v3_file).exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {v3_file}")
        sys.exit(1)
    
    report = compare_versions(v2_file, v3_file)
    
    print("\n" + "="*60)
    print("ğŸ“Š ä¼˜åŒ–æ•ˆæœæ€»ç»“:")
    print("="*60)
    for key, value in report['improvements'].items():
        print(f"  {key:20s}: {value}")
    print("="*60)

