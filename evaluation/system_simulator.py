#!/usr/bin/env python3
"""
å®Œæ•´ç³»ç»Ÿä»¿çœŸå™¨

ç”¨äºæµ‹è¯•å®Œæ•´çš„è½¦è”ç½‘è¾¹ç¼˜ç¼“å­˜ç³»ç»Ÿï¼Œæä¾›é«˜ä¿çœŸçš„è½¦è¾†ã€RSUã€UAVäº¤äº’ä»¿çœŸã€‚
æ”¯æŒä»»åŠ¡ç”Ÿæˆã€å¸è½½å†³ç­–ã€ç¼“å­˜ç®¡ç†ã€è¿ç§»ç­–ç•¥ç­‰åŠŸèƒ½ã€‚

Complete system simulator for testing the full vehicular edge caching system.
Provides high-fidelity simulation of vehicle, RSU, and UAV interactions.
"""

import math
import numpy as np
import torch
import random
import os
import logging
from typing import Dict, List, Tuple, Any, Optional
import json
from datetime import datetime
from collections import deque, defaultdict

# ğŸ”‘ ä¿®å¤ï¼šå¯¼å…¥ç»Ÿä¸€æ—¶é—´ç®¡ç†å™¨
# Unified time manager for consistent simulation timing
from utils.unified_time_manager import get_simulation_time, advance_simulation_time, reset_simulation_time

# ğŸ”‘ ä¿®å¤ï¼šå¯¼å…¥realisticå†…å®¹ç”Ÿæˆå™¨
# Realistic content generator for simulating various content types
from utils.realistic_content_generator import generate_realistic_content, get_realistic_content_size
from utils.spatial_index import SpatialIndex
from decision.two_stage_planner import TwoStagePlanner, PlanEntry
from decision.strategy_coordinator import StrategyCoordinator

try:
    from communication.bandwidth_allocator import BandwidthAllocator
except ImportError:  # pragma: no cover - optional module
    BandwidthAllocator = None

class CentralResourcePool:
    """
    ä¸­å¤®èµ„æºæ± ç®¡ç†å™¨
    
    ã€åŠŸèƒ½ã€‘
    Phase 1çš„æ ¸å¿ƒç»„ä»¶ï¼šé›†ä¸­ç®¡ç†æ‰€æœ‰å¯åˆ†é…èµ„æºï¼ˆå¸¦å®½ã€è®¡ç®—èµ„æºï¼‰
    ä¾›ä¸­å¤®æ™ºèƒ½ä½“å†³ç­–ä½¿ç”¨ï¼Œå®ç°å…¨å±€èµ„æºä¼˜åŒ–
    
    ã€ç®¡ç†çš„èµ„æºã€‘
    1. æ€»å¸¦å®½ï¼š50 MHzï¼ˆä¸Šè¡Œ+ä¸‹è¡Œï¼‰
    2. æ€»RSUè®¡ç®—ï¼š60 GHzï¼ˆ4ä¸ªRSUå…±äº«ï¼‰
    3. æ€»UAVè®¡ç®—ï¼š8 GHzï¼ˆ2ä¸ªUAVå…±äº«ï¼‰
    4. æ€»æœ¬åœ°è®¡ç®—ï¼š2 GHzï¼ˆ12è½¦è¾†å…±äº«ï¼‰
    
    ã€Phase 1å†³ç­–ã€‘
    ä¸­å¤®æ™ºèƒ½ä½“ç”Ÿæˆèµ„æºåˆ†é…å‘é‡ï¼š
    - bandwidth_allocation[12]: æ¯ä¸ªè½¦è¾†çš„å¸¦å®½åˆ†é…æ¯”ä¾‹
    - rsu_compute_allocation[4]: æ¯ä¸ªRSUçš„è®¡ç®—èµ„æºåˆ†é…æ¯”ä¾‹
    - uav_compute_allocation[2]: æ¯ä¸ªUAVçš„è®¡ç®—èµ„æºåˆ†é…æ¯”ä¾‹
    - vehicle_compute_allocation[12]: æ¯ä¸ªè½¦è¾†çš„æœ¬åœ°è®¡ç®—åˆ†é…æ¯”ä¾‹
    
    ã€Phase 2æ‰§è¡Œã€‘
    æ ¹æ®åˆ†é…ç»“æœï¼Œå„èŠ‚ç‚¹æ‰§è¡Œæœ¬åœ°è°ƒåº¦
    """
    
    def __init__(self, config):
        """
        åˆå§‹åŒ–ä¸­å¤®èµ„æºæ± 
        
        Args:
            config: ç³»ç»Ÿé…ç½®å¯¹è±¡
        """
        # ğŸ¯ æ€»èµ„æºæ± ï¼ˆä»configè¯»å–ï¼‰
        self.total_bandwidth = getattr(config.network, 'bandwidth', 50e6)  # 50 MHz
        self.total_vehicle_compute = getattr(config.compute, 'total_vehicle_compute', 2e9)  # 2 GHz
        self.total_rsu_compute = getattr(config.compute, 'total_rsu_compute', 60e9)  # 60 GHz
        self.total_uav_compute = getattr(config.compute, 'total_uav_compute', 8e9)  # 8 GHz
        
        # èŠ‚ç‚¹æ•°é‡
        self.num_vehicles = getattr(config.network, 'num_vehicles', 12)
        self.num_rsus = getattr(config.network, 'num_rsus', 4)
        self.num_uavs = getattr(config.network, 'num_uavs', 2)
        
        # ğŸ”„ å½“å‰åˆ†é…çŠ¶æ€ï¼ˆåˆå§‹åŒ–ä¸ºå‡åŒ€åˆ†é…ï¼‰
        self.bandwidth_allocation = np.ones(self.num_vehicles) / self.num_vehicles  # å‡åŒ€åˆ†é…
        self.vehicle_compute_allocation = np.ones(self.num_vehicles) / self.num_vehicles
        self.rsu_compute_allocation = np.ones(self.num_rsus) / self.num_rsus
        self.uav_compute_allocation = np.ones(self.num_uavs) / self.num_uavs
        
        # ğŸ“Š èµ„æºä½¿ç”¨ç»Ÿè®¡
        self.bandwidth_usage = 0.0  # å½“å‰å¸¦å®½ä½¿ç”¨ç‡
        self.vehicle_compute_usage = np.zeros(self.num_vehicles)
        self.rsu_compute_usage = np.zeros(self.num_rsus)
        self.uav_compute_usage = np.zeros(self.num_uavs)
        
    def update_allocation(self, allocation_dict: Dict[str, np.ndarray]):
        """
        æ›´æ–°èµ„æºåˆ†é…ï¼ˆPhase 1å†³ç­–ï¼‰
        
        Args:
            allocation_dict: åŒ…å«å„èµ„æºåˆ†é…å‘é‡çš„å­—å…¸
                - 'bandwidth': [num_vehicles]
                - 'vehicle_compute': [num_vehicles]
                - 'rsu_compute': [num_rsus]
                - 'uav_compute': [num_uavs]
        """
        if 'bandwidth' in allocation_dict:
            self.bandwidth_allocation = self._normalize(allocation_dict['bandwidth'])
        if 'vehicle_compute' in allocation_dict:
            self.vehicle_compute_allocation = self._normalize(allocation_dict['vehicle_compute'])
        if 'rsu_compute' in allocation_dict:
            self.rsu_compute_allocation = self._normalize(allocation_dict['rsu_compute'])
        if 'uav_compute' in allocation_dict:
            self.uav_compute_allocation = self._normalize(allocation_dict['uav_compute'])
    
    def get_vehicle_bandwidth(self, vehicle_idx: int) -> float:
        """è·å–æŒ‡å®šè½¦è¾†çš„åˆ†é…å¸¦å®½ï¼ˆHzï¼‰"""
        return self.bandwidth_allocation[vehicle_idx] * self.total_bandwidth
    
    def get_vehicle_compute(self, vehicle_idx: int) -> float:
        """è·å–æŒ‡å®šè½¦è¾†çš„åˆ†é…è®¡ç®—èµ„æºï¼ˆHzï¼‰"""
        return self.vehicle_compute_allocation[vehicle_idx] * self.total_vehicle_compute
    
    def get_rsu_compute(self, rsu_idx: int) -> float:
        """è·å–æŒ‡å®šRSUçš„åˆ†é…è®¡ç®—èµ„æºï¼ˆHzï¼‰"""
        return self.rsu_compute_allocation[rsu_idx] * self.total_rsu_compute
    
    def get_uav_compute(self, uav_idx: int) -> float:
        """è·å–æŒ‡å®šUAVçš„åˆ†é…è®¡ç®—èµ„æºï¼ˆHzï¼‰"""
        return self.uav_compute_allocation[uav_idx] * self.total_uav_compute
    
    def update_usage_stats(self, vehicle_usage=None, rsu_usage=None, uav_usage=None):
        """æ›´æ–°èµ„æºä½¿ç”¨ç»Ÿè®¡"""
        if vehicle_usage is not None:
            self.vehicle_compute_usage = vehicle_usage
        if rsu_usage is not None:
            self.rsu_compute_usage = rsu_usage
        if uav_usage is not None:
            self.uav_compute_usage = uav_usage
    
    def get_resource_state(self) -> Dict[str, Any]:
        """
        è·å–èµ„æºæ± çŠ¶æ€ï¼ˆä¾›æ™ºèƒ½ä½“è§‚æµ‹ï¼‰
        
        Returns:
            åŒ…å«èµ„æºåˆ†é…å’Œä½¿ç”¨æƒ…å†µçš„å­—å…¸
        """
        return {
            'total_bandwidth': self.total_bandwidth,
            'total_vehicle_compute': self.total_vehicle_compute,
            'total_rsu_compute': self.total_rsu_compute,
            'total_uav_compute': self.total_uav_compute,
            'bandwidth_allocation': self.bandwidth_allocation.copy(),
            'vehicle_compute_allocation': self.vehicle_compute_allocation.copy(),
            'rsu_compute_allocation': self.rsu_compute_allocation.copy(),
            'uav_compute_allocation': self.uav_compute_allocation.copy(),
            'vehicle_compute_usage': self.vehicle_compute_usage.copy(),
            'rsu_compute_usage': self.rsu_compute_usage.copy(),
            'uav_compute_usage': self.uav_compute_usage.copy(),
            # ğŸ“Š èµ„æºåˆ©ç”¨ç‡
            'vehicle_utilization': np.mean(self.vehicle_compute_usage),
            'rsu_utilization': np.mean(self.rsu_compute_usage),
            'uav_utilization': np.mean(self.uav_compute_usage),
        }
    
    @staticmethod
    def _normalize(arr: np.ndarray) -> np.ndarray:
        """å½’ä¸€åŒ–åˆ†é…å‘é‡ï¼Œç¡®ä¿æ€»å’Œä¸º1"""
        arr = np.clip(arr, 0, 1)  # ç¡®ä¿éè´Ÿä¸”<=1
        total = np.sum(arr)
        if total > 1e-6:
            return arr / total
        else:
            # å¦‚æœå…¨ä¸º0ï¼Œè¿”å›å‡åŒ€åˆ†é…
            return np.ones_like(arr) / len(arr)


class CompleteSystemSimulator:
    """
    å®Œæ•´ç³»ç»Ÿä»¿çœŸå™¨
    
    è¯¥ç±»å®ç°äº†è½¦è”ç½‘è¾¹ç¼˜è®¡ç®—ç³»ç»Ÿçš„å®Œæ•´ä»¿çœŸï¼ŒåŒ…æ‹¬ï¼š
    - è½¦è¾†ç§»åŠ¨æ¨¡å‹ï¼ˆæ²¿ä¸»å¹²é“åŒè·¯å£åœºæ™¯ï¼‰
    - RSUå’ŒUAVéƒ¨ç½²ä¸ç®¡ç†
    - ä»»åŠ¡ç”Ÿæˆä¸åˆ†é…
    - ç¼“å­˜ç®¡ç†ä¸ååŒ
    - æ™ºèƒ½è¿ç§»ç­–ç•¥
    - æ€§èƒ½ç»Ÿè®¡ä¸ç›‘æ§
    
    Complete system simulator for vehicular edge computing.
    """
    
    def __init__(self, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–ä»¿çœŸå™¨
        
        Args:
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«ç½‘ç»œæ‹“æ‰‘ã€ä»¿çœŸå‚æ•°ç­‰
                   å¦‚æœä¸ºNoneï¼Œåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.config = config or self.get_default_config()
        self.allow_local_processing = bool(self.config.get('allow_local_processing', True))
        forced_mode = str(self.config.get('forced_offload_mode', '')).strip().lower()
        self.forced_offload_mode = forced_mode if forced_mode in {'local_only', 'remote_only'} else ''
        self.override_topology = self.config.get('override_topology', False)
        
        # ç»Ÿä¸€ç³»ç»Ÿé…ç½®å…¥å£ï¼ˆè‹¥å¯ç”¨ï¼‰
        # Try to load system-wide configuration if available
        try:
            from config import config as sys_config
            self.sys_config = sys_config
        except (ImportError, AttributeError, ModuleNotFoundError) as e:
            logging.debug(f"System config not available: {e}")
            self.sys_config = None
        
        # ç½‘ç»œæ‹“æ‰‘å‚æ•°ï¼šè½¦è¾†ã€RSUã€UAVæ•°é‡
        # Network topology parameters: number of vehicles, RSUs, and UAVs
        if self.sys_config is not None and not self.override_topology:
            self.num_vehicles = getattr(self.sys_config.network, 'num_vehicles', 12)
            self.num_rsus = getattr(self.sys_config.network, 'num_rsus', 6)
            self.num_uavs = getattr(self.sys_config.network, 'num_uavs', 2)
        else:
            self.num_vehicles = self.config.get('num_vehicles', 12)
            self.num_rsus = self.config.get('num_rsus', 4)  # ğŸ”‘ ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„é»˜è®¤å€¼
            self.num_uavs = self.config.get('num_uavs', 2)
        if self.sys_config is not None and not self.override_topology:
            default_radius = getattr(self.sys_config.network, 'coverage_radius', 300)
            default_uav_radius = getattr(self.sys_config.network, 'uav_coverage_radius', 350)
            default_uav_altitude = getattr(self.sys_config.network, 'uav_altitude', 120.0)
        else:
            default_radius = getattr(self.sys_config.network, 'coverage_radius', 300) if self.sys_config is not None else 300
            default_uav_radius = getattr(self.sys_config.network, 'uav_coverage_radius', 350) if self.sys_config is not None else 350
            default_uav_altitude = getattr(self.sys_config.network, 'uav_altitude', 120.0) if self.sys_config is not None else 120.0
        self.coverage_radius = self.config.get('coverage_radius', default_radius)
        self.uav_coverage_radius = self.config.get('uav_coverage_radius', default_uav_radius)
        self.uav_altitude = self.config.get('uav_altitude', default_uav_altitude)

        # ä»¿çœŸå‚æ•°ï¼šæ—¶é—´ã€æ—¶éš™ã€ä»»åŠ¡åˆ°è¾¾ç‡
        # Simulation parameters: time, time slot, task arrival rate
        if self.sys_config is not None and not self.config.get('override_topology', False):
            self.simulation_time = getattr(self.sys_config, 'simulation_time', 1000)
            self.time_slot = getattr(self.sys_config.network, 'time_slot_duration', 0.1)  # ğŸš€ é€‚åº”é«˜è´Ÿè½½æ—¶éš™
            self.task_arrival_rate = getattr(self.sys_config.task, 'arrival_rate', 2.5)  # ğŸš€ é«˜è´Ÿè½½åˆ°è¾¾ç‡
        else:
            self.simulation_time = self.config.get('simulation_time', 1000)
            self.time_slot = self.config.get('time_slot', 0.1)  # ğŸš€ é«˜è´Ÿè½½é»˜è®¤æ—¶éš™
            self.task_arrival_rate = self.config.get('task_arrival_rate', 2.5)  # ğŸš€ é«˜è´Ÿè½½é»˜è®¤åˆ°è¾¾ç‡
        
        # å­é…ç½®å¯¹è±¡å¼•ç”¨
        # Sub-configuration object references
        self.task_config = getattr(self.sys_config, 'task', None) if self.sys_config is not None else None
        self.service_config = getattr(self.sys_config, 'service', None) if self.sys_config is not None else None
        self.stats_config = getattr(self.sys_config, 'stats', None) if self.sys_config is not None else None
        
        # æ€§èƒ½ç»Ÿè®¡ä¸è¿è¡ŒçŠ¶æ€
        # Performance statistics and runtime state
        self.stats = self._fresh_stats_dict()
        self.queue_config = getattr(self.sys_config, 'queue', None)
        queue_cfg = self.queue_config
        self.queue_stability_threshold = float(getattr(queue_cfg, 'global_rho_threshold', 1.0)) if queue_cfg is not None else 1.0
        self.queue_warning_ratio = float(getattr(queue_cfg, 'stability_warning_ratio', 0.9)) if queue_cfg is not None else 0.9
        self.node_max_load_factor = float(getattr(queue_cfg, 'max_load_factor', 1.0)) if queue_cfg is not None else 1.0
        self.rsu_nominal_capacity = float(getattr(queue_cfg, 'rsu_nominal_capacity', 20.0)) if queue_cfg is not None else 20.0
        self.uav_nominal_capacity = float(getattr(queue_cfg, 'uav_nominal_capacity', 10.0)) if queue_cfg is not None else 10.0
        self.vehicle_nominal_capacity = float(getattr(queue_cfg, 'vehicle_nominal_capacity', 20.0)) if queue_cfg is not None else 20.0
        self.queue_overflow_margin = float(getattr(queue_cfg, 'overflow_margin', 1.2)) if queue_cfg is not None else 1.2
        self.cache_config = getattr(self.sys_config, 'cache', None)
        self.communication_config = getattr(self.sys_config, 'communication', None)
        self.cache_pressure_guard = float(getattr(self.cache_config, 'pressure_guard_ratio', 0.05)) if self.cache_config is not None else 0.05
        delay_clip_from_cfg = getattr(self.stats_config, 'delay_clip_upper', None) if self.stats_config is not None else None
        self.delay_clip_upper = float(delay_clip_from_cfg if delay_clip_from_cfg is not None else self.config.get('delay_clip_upper', 0.0) or 0.0)
        self.migration_delay_weight = float(self.config.get('migration_delay_weight', 600.0))
        self.migration_energy_weight = float(self.config.get('migration_energy_weight', 1.0))
        self._queue_overload_warning_active = False
        self._queue_warning_triggered = False
        self.active_tasks: List[Dict] = []  # æ¯é¡¹: {id, vehicle_id, arrival_time, deadline, work_remaining, node_type, node_idx}
        self.task_counter = 0
        self.current_step = 0
        self.current_time = 0.0
        # Two-stage planning toggle (env-controlled)
        self._two_stage_enabled = (os.environ.get('TWO_STAGE_MODE', '').strip() in {'1', 'true', 'True'})
        self._two_stage_planner: TwoStagePlanner | None = None
        self.spatial_index: Optional[SpatialIndex] = SpatialIndex()
        self._central_resource_enabled = os.environ.get('CENTRAL_RESOURCE', '').strip() in {'1', 'true', 'True'}
        
        # ğŸ¯ ä¸­å¤®èµ„æºæ± åˆå§‹åŒ–ï¼ˆPhase 1æ ¸å¿ƒç»„ä»¶ï¼‰
        # Central resource pool initialization (Phase 1 core component)
        if self.sys_config is not None:
            self.resource_pool = CentralResourcePool(self.sys_config)
        else:
            # å¦‚æœæ²¡æœ‰sys_configï¼Œä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»ºä¸€ä¸ªä¸´æ—¶configå¯¹è±¡
            from types import SimpleNamespace
            temp_config = SimpleNamespace(
                network=SimpleNamespace(bandwidth=50e6, num_vehicles=12, num_rsus=4, num_uavs=2),
                compute=SimpleNamespace(total_vehicle_compute=2e9, total_rsu_compute=60e9, total_uav_compute=8e9)
            )
            self.resource_pool = CentralResourcePool(temp_config)
        
        # ğŸ”§ è¯»å–èµ„æºé…ç½®å‚æ•°ï¼ˆCPUé¢‘ç‡ã€å¸¦å®½ç­‰ï¼‰
        # Read resource configuration parameters (CPU frequency, bandwidth, etc.)
        # âš ï¸ æ³¨æ„ï¼šèµ„æºç°åœ¨ä»ä¸­å¤®èµ„æºæ± åˆ†é…ï¼Œè¿™é‡Œä¿ç•™å…¼å®¹æ€§
        if self.sys_config is not None and not self.config.get('override_topology', False):
            self.rsu_cpu_freq = getattr(self.sys_config.compute, 'rsu_default_freq', 15e9)
            self.uav_cpu_freq = getattr(self.sys_config.compute, 'uav_default_freq', 4e9)
            self.vehicle_cpu_freq = getattr(self.sys_config.compute, 'vehicle_default_freq', 0.167e9)
            self.bandwidth = getattr(self.sys_config.network, 'bandwidth', 50e6)
        else:
            self.rsu_cpu_freq = self.config.get('rsu_cpu_freq', 15e9)  # Hz
            self.uav_cpu_freq = self.config.get('uav_cpu_freq', 4e9)  # Hz
            self.vehicle_cpu_freq = self.config.get('vehicle_cpu_freq', 0.167e9)  # Hz
            self.bandwidth = self.config.get('bandwidth', 50e6)  # Hz

        # åŸºå‡†é¢‘ç‡ç”¨äºè®¡ç®—capacity scaleï¼Œä¿æŒç»Ÿä¸€å‚ç…§ï¼ˆé»˜è®¤ 15/4GHzï¼‰
        self.rsu_reference_freq = float(self.config.get('rsu_reference_freq', 15e9))
        self.uav_reference_freq = float(self.config.get('uav_reference_freq', 4e9))
        
        # åˆå§‹åŒ–ç»„ä»¶ï¼ˆè½¦è¾†ã€RSUã€UAVç­‰ï¼‰
        # Initialize components (vehicles, RSUs, UAVs, etc.)
        self.initialize_components()
        self._reset_runtime_states()
        self._init_dynamic_bandwidth_support()
    
    def get_default_config(self) -> Dict:
        """
        è·å–é»˜è®¤é…ç½®å‚æ•°
        
        æä¾›ç³»ç»Ÿä»¿çœŸçš„é»˜è®¤é…ç½®ï¼ŒåŒ…æ‹¬ç½‘ç»œæ‹“æ‰‘ã€è®¡ç®—èƒ½åŠ›ã€
        å¸¦å®½ã€åŠŸç‡ç­‰å…³é”®å‚æ•°ã€‚
        
        Returns:
            åŒ…å«æ‰€æœ‰é»˜è®¤é…ç½®å‚æ•°çš„å­—å…¸
        """
        return {
            'num_vehicles': 12,
            'num_rsus': 6,
            'num_uavs': 2,
            'simulation_time': 1000,
            'time_slot': 0.1,
            'task_arrival_rate': 0.8,
            'cache_capacity': 100,
            'computation_capacity': 1000,  # MIPS
            'bandwidth': 20,  # MHz
            'transmission_power': 0.1,  # W
            'computation_power': 1.0,  # W
            'rsu_base_service': 4,
            'rsu_max_service': 9,
            'rsu_work_capacity': 2.5,
            'uav_base_service': 3,
            'uav_max_service': 6,
            'uav_work_capacity': 1.7,
            'drop_log_interval': 400,
            'task_report_interval': 100,
            'task_compute_density': 400,
        }
    
    def initialize_components(self):
        """
        åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶
        
        åˆ›å»ºå¹¶é…ç½®ç³»ç»Ÿçš„æ‰€æœ‰ç»„ä»¶ï¼ŒåŒ…æ‹¬ï¼š
        - è½¦è¾†åˆå§‹åŒ–ï¼ˆä½ç½®ã€é€Ÿåº¦ã€æ–¹å‘ç­‰ï¼‰
        - RSUèŠ‚ç‚¹éƒ¨ç½²ï¼ˆä½ç½®ã€è¦†ç›–èŒƒå›´ã€ç¼“å­˜å®¹é‡ç­‰ï¼‰
        - UAVèŠ‚ç‚¹éƒ¨ç½²ï¼ˆä½ç½®ã€è¦†ç›–èŒƒå›´ã€è®¡ç®—èƒ½åŠ›ç­‰ï¼‰
        - ä¸­å¤®RSUè°ƒåº¦å™¨åˆå§‹åŒ–
        - è¿ç§»ç®¡ç†å™¨åˆå§‹åŒ–
        
        Initialize system components including vehicles, RSUs, and UAVs.
        """
        # ğŸ›£ï¸ ä¸»å¹²é“-åŒè·¯å£åˆå§‹åŒ–
        # Main road with two intersections initialization
        # ğŸ”§ ä¿®å¤ï¼šæ ¹æ®ç”¨æˆ·æŒ‡å®šçš„åæ ‡ç³»ç»Ÿé‡æ–°è°ƒæ•´ï¼ˆUAV_0ä¸ºåŸç‚¹ï¼Œå‘å³X+ï¼Œå‘ä¸‹Y-ï¼‰
        # ç”¨æˆ·åæ ‡ï¼šUAV_0(0,0), UAV_1(0,-1030), ä½†ç³»ç»Ÿå†…éƒ¨éœ€è¦æ­£åæ ‡
        # è§£å†³æ–¹æ¡ˆï¼šå°†æ•´ä½“åœºæ™¯å‘Yè½´æ­£æ–¹å‘åç§»1545mï¼Œç¡®ä¿æ‰€æœ‰åæ ‡éƒ½ä¸ºæ­£å€¼
        # ğŸ¯ åœºæ™¯èŒƒå›´ï¼šX: [-515, 515] â†’ [0, 1030], Y: [-1545, 515] â†’ [0, 2060]
        self.offset_y = 1545.0  # Yè½´åç§»é‡ï¼Œä½¿æœ€å°åæ ‡ä¸º0
        self.offset_x = 515.0   # Xè½´åç§»é‡ï¼Œä½¿æœ€å°åæ ‡ä¸º0
        
        # è½¬æ¢åçš„åœºæ™¯èŒƒå›´
        self.scenario_width = 1030.0   # Xè½´èŒƒå›´: 0 ~ 1030m
        self.scenario_height = 2060.0  # Yè½´èŒƒå›´: 0 ~ 2060m
        
        # ä¸»å¹²é“å’Œè·¯å£ä½ç½®ï¼ˆè½¬æ¢åçš„åæ ‡ï¼‰
        self.road_center_x = 515.0  # ä¸»å¹²é“Xåæ ‡ï¼ˆ0+515ï¼‰
        self.road_width = 30.0      # é“è·¯å®½åº¦
        self.road_y = self.offset_y  # ä¸ºäº†å…¼å®¹æ—§ä»£ç ï¼Œè®¾ä¸ºä¸Šè·¯å£Yåæ ‡
        
        # ä¸¤ä¸ªåå­—è·¯å£ä½ç½®ï¼ˆè½¬æ¢åï¼‰
        intersection_0_y = 1545.0  # ä¸Šè·¯å£ï¼šåŸ(0,0) â†’ (515, 1545)
        intersection_1_y = 515.0   # ä¸‹è·¯å£ï¼šåŸ(0,-1030) â†’ (515, 515)
        
        self.intersections = {  # ä¿¡å·ç¯ç›¸ä½ å‘¨æœŸ Tï¼Œç»¿ç¯æ¯”ä¾‹ g
            'upper': {'x': self.road_center_x, 'y': intersection_0_y, 'cycle_T': 60.0, 'green_ratio': 0.5, 'phase_offset': 0.0},
            'lower': {'x': self.road_center_x, 'y': intersection_1_y, 'cycle_T': 60.0, 'green_ratio': 0.5, 'phase_offset': 15.0},
        }

        # è½¦è¾†åˆå§‹åŒ–ï¼šè½åœ¨é“è·¯ä¸Šï¼Œæ–¹å‘ä¸ºä¸œ(0)æˆ–è¥¿(pi)ï¼Œè½¦é“å†…å¾®æ‰°
        # Vehicle initialization: positioned on road, heading east (0) or west (pi), with lane perturbation
        # ğŸ”§ ä¿®å¤ï¼šæ ¹æ®æ–°åœºæ™¯èŒƒå›´è°ƒæ•´è½¦è¾†åˆå§‹åŒ–åŒºåŸŸ
        self.vehicles = []
        for i in range(self.num_vehicles):
            # éšæœºåˆ†å¸ƒåœ¨ä¸»å¹²é“å’Œä¸¤ä¸ªè·¯å£çš„æ¨ªå‘é“è·¯ä¸Š
            road_choice = np.random.rand()
            if road_choice < 0.5:  # 50%åœ¨ä¸»å¹²é“ï¼ˆçºµå‘ï¼‰
                go_north = np.random.rand() < 0.5
                x0 = self.road_center_x + np.random.uniform(-self.road_width/2, self.road_width/2)
                y0 = np.random.uniform(515.0, 1545.0)  # åœ¨ä¸¤ä¸ªè·¯å£ä¹‹é—´
                base_dir = -np.pi/2 if go_north else np.pi/2  # åŒ—æˆ–å—
            else:  # 50%åœ¨æ¨ªå‘é“è·¯
                intersection_y = intersection_0_y if np.random.rand() < 0.5 else intersection_1_y
                go_east = np.random.rand() < 0.6
                x0 = np.random.uniform(50.0, 980.0)  # æ¨ªå‘é“è·¯èŒƒå›´
                y0 = intersection_y + np.random.uniform(-self.road_width/2, self.road_width/2)
                base_dir = 0.0 if go_east else np.pi  # ä¸œæˆ–è¥¿
                    
            v0 = np.random.uniform(8.0, 15.0)  # åˆå§‹é€Ÿåº¦ 8-15 m/s (~29-54 km/hï¼Œé™ä½ç§»åŠ¨é€Ÿåº¦)
            vehicle = {
                'id': f'V_{i}',
                'position': np.array([x0, y0], dtype=float),
                'velocity': v0,
                'direction': base_dir,
                'lane_bias': 0.0,  # è½¦é“åå·®
                'tasks': [],
                'energy_consumed': 0.0,
                'device_cache': {},  # è½¦è½½ç¼“å­˜
                'device_cache_capacity': 100.0,  # è½¦è½½ç¼“å­˜å®¹é‡(MB) - 100MB
                # ğŸ¯ Phase 2æœ¬åœ°è°ƒåº¦å‚æ•°
                'cpu_freq': self.vehicle_cpu_freq,  # åˆ†é…çš„CPUé¢‘ç‡ï¼ˆHzï¼‰
                'cpu_frequency': self.vehicle_cpu_freq,  # ğŸ”§ æ–°å¢ï¼šä¸çŠ¶æ€ç¼–ç å­—æ®µåä¸€è‡´
                'allocated_bandwidth': 0.0,  # åˆ†é…çš„å¸¦å®½ï¼ˆHzï¼‰
                'task_queue_by_priority': {1: [], 2: [], 3: [], 4: []},  # æŒ‰ä¼˜å…ˆçº§åˆ†ç±»çš„ä»»åŠ¡é˜Ÿåˆ—
                'compute_usage': 0.0,  # å½“å‰è®¡ç®—ä½¿ç”¨ç‡
                'queue_length': 0,  # ğŸ”§ æ–°å¢ï¼šå½“å‰é˜Ÿåˆ—é•¿åº¦ï¼ˆç”¨äºçŠ¶æ€ç¼–ç ï¼‰
            }
            self.vehicles.append(vehicle)
        print(f"è½¦è¾†åˆå§‹åŒ–å®Œæˆï¼šä¸»å¹¹é“åŒè·¯å£åœºæ™¯ï¼Œåœºæ™¯èŒƒå›´X:[0,{self.scenario_width:.0f}] Y:[0,{self.scenario_height:.0f}]")
        
        # RSUèŠ‚ç‚¹åˆå§‹åŒ–
        # RSU node initialization
        self.rsus = []
        # ğŸ”§ ä¿®å¤ï¼šå°†ç”¨æˆ·åæ ‡è½¬æ¢ä¸ºç³»ç»Ÿå†…éƒ¨æ­£åæ ‡
        # ç”¨æˆ·åæ ‡ï¼ˆæ¨ªå‘Xï¼Œçºµå‘Yï¼‰ â†’ ç³»ç»Ÿåæ ‡ï¼ˆX+515, Y+1545ï¼‰
        # é“è·¯å¸ƒå±€ï¼šä¸¤ä¸ªåå­—è·¯å£ä¸­å¿ƒ(515,1545)å’Œ(515,515)ï¼Œæ¯ä¸ªè·¯å£å‘å››æ–¹å»¶ä¼¸515mï¼Œé“è·¯å®½30m
        if self.num_rsus <= 4:
            # ğŸ¯ ç”¨æˆ·æŒ‡å®šåæ ‡ï¼ˆæ ‡å‡†ç¬›å¡å°”åæ ‡ç³»ï¼‰â†’ è½¬æ¢åçš„ç³»ç»Ÿåæ ‡ï¼š
            # RSU_0: (100, 65) â†’ (615, 1610)
            # RSU_1: (-65, -150) â†’ (450, 1395)
            # RSU_2: (100, -750) â†’ (615, 795)
            # RSU_3: (-65, -1150) â†’ (450, 395)
            rsu_positions = [
                np.array([100.0 + self.offset_x, 65.0 + self.offset_y]),       # RSU_0: (615, 1610)
                np.array([-65.0 + self.offset_x, -150.0 + self.offset_y]),     # RSU_1: (450, 1395)
                np.array([100.0 + self.offset_x, -750.0 + self.offset_y]),     # RSU_2: (615, 795)
                np.array([-65.0 + self.offset_x, -1150.0 + self.offset_y]),    # RSU_3: (450, 395)
            ]
        else:
            # åŠ¨æ€ç”ŸæˆRSUä½ç½®ï¼Œå‡åŒ€åˆ†å¸ƒåœ¨é“è·¯äº¤å‰å£å‘¨å›´
            rsu_positions = []
            spacing = 1500.0 / (self.num_rsus - 1)  # å‡åŒ€é—´éš”
            for i in range(self.num_rsus):
                y_pos = 300.0 + i * spacing
                x_pos = 350.0 if i % 2 == 0 else 650.0  # äº¤é”™å·¦å³ï¼ˆé“è·¯å¤–ï¼‰
                rsu_positions.append(np.array([x_pos, y_pos]))
        
        # åˆ›å»ºRSUèŠ‚ç‚¹
        # Create RSU nodes with configuration
        for i in range(self.num_rsus):
            rsu = {
                'id': f'RSU_{i}',
                'position': rsu_positions[i],
                'coverage_radius': self.coverage_radius,  # è¦†ç›–åŠå¾„(m)
                'cache': {},  # ç¼“å­˜å­—å…¸
                'cache_capacity': 200.0,  # ç¼“å­˜å®¹é‡(MB) - 200MBè¾¹ç¼˜æœåŠ¡å™¨ç¼“å­˜
                'cache_capacity_bytes': (getattr(self.sys_config.cache, 'rsu_cache_capacity', 200e6) if self.sys_config is not None else 200e6),
                'cpu_freq': self.rsu_cpu_freq,  # ğŸ†• CPUé¢‘ç‡(Hz)
                'cpu_frequency': self.rsu_cpu_freq,  # ğŸ”§ æ–°å¢ï¼šä¸çŠ¶æ€ç¼–ç å­—æ®µåä¸€è‡´
                'computation_queue': [],  # è®¡ç®—ä»»åŠ¡é˜Ÿåˆ—
                'energy_consumed': 0.0,  # ç´¯è®¡èƒ½è€—(J)
                # ğŸ¯ Phase 2èµ„æºè°ƒåº¦å‚æ•°
                'allocated_compute': self.rsu_cpu_freq,  # åˆ†é…çš„è®¡ç®—èµ„æºï¼ˆHzï¼‰
                'compute_usage': 0.0,  # å½“å‰è®¡ç®—ä½¿ç”¨ç‡
                'connected_vehicles': [],  # æ¥å…¥çš„è½¦è¾†åˆ—è¡¨
                'recent_cache_hit_rate': 0.5,  # ğŸ”§ æ–°å¢ï¼šè¿‘æœŸç¼“å­˜å‘½ä¸­ç‡ï¼ˆç”¨äºçŠ¶æ€ç¼–ç ï¼‰
                'cache_hits_window': 0,  # ğŸ”§ ç»Ÿè®¡çª—å£å†…çš„ç¼“å­˜å‘½ä¸­æ¬¡æ•°
                'cache_requests_window': 0,  # ğŸ”§ ç»Ÿè®¡çª—å£å†…çš„ç¼“å­˜è¯·æ±‚æ¬¡æ•°
            }
            self.rsus.append(rsu)
        
        # UAVèŠ‚ç‚¹åˆå§‹åŒ–
        # UAV node initialization
        self.uavs = []
        # ğŸ”§ ä¿®å¤ï¼šå°†ç”¨æˆ·åæ ‡è½¬æ¢ä¸ºç³»ç»Ÿå†…éƒ¨æ­£åæ ‡
        # ç”¨æˆ·åæ ‡ï¼ˆæ¨ªå‘Xï¼Œçºµå‘Yï¼‰ â†’ ç³»ç»Ÿåæ ‡ï¼ˆX+515, Y+1545ï¼‰
        # ä¸¤ä¸ªUAVåˆ†åˆ«åœ¨åå­—è·¯å£ä¸­å¿ƒä¸Šç©ºï¼Œé—´è·1030m
        if self.num_uavs <= 2:
            # ğŸ¯ ç”¨æˆ·æŒ‡å®šåæ ‡ï¼ˆæ ‡å‡†ç¬›å¡å°”åæ ‡ç³»ï¼‰â†’ è½¬æ¢åçš„ç³»ç»Ÿåæ ‡ï¼š
            # UAV_0: (0, 0) â†’ (515, 1545) - ä¸Šè·¯å£ä¸­å¿ƒä¸Šç©º
            # UAV_1: (0, -1030) â†’ (515, 515) - ä¸‹è·¯å£ä¸­å¿ƒä¸Šç©º
            uav_positions = [
                np.array([0.0 + self.offset_x, 0.0 + self.offset_y, self.uav_altitude]),        # UAV_0: (515, 1545, alt)
                np.array([0.0 + self.offset_x, -1030.0 + self.offset_y, self.uav_altitude]),    # UAV_1: (515, 515, alt)
            ]
        else:
            # åŠ¨æ€ç”ŸæˆUAVä½ç½®ï¼Œå‡åŒ€åˆ†å¸ƒåœ¨é“è·¯ä¸Šæ–¹ï¼Œé¿å…ä¸RSUé‡å 
            uav_positions = []
            spacing = 1500.0 / (self.num_uavs - 1)  # å‡åŒ€é—´éš”
            for i in range(self.num_uavs):
                x_pos = 500.0  # ä¿æŒåœ¨ä¸»å¹²é“ä¸­å¤®
                y_pos = 300.0 + i * spacing
                uav_positions.append(np.array([x_pos, y_pos, self.uav_altitude]))
        
        # åˆ›å»ºUAVèŠ‚ç‚¹
        # Create UAV nodes with configuration
        for i in range(self.num_uavs):
            uav = {
                'id': f'UAV_{i}',
                'position': uav_positions[i],  # å›ºå®šæ‚¬åœä½ç½®
                'velocity': 0.0,  # å½“å‰é€Ÿåº¦(m/s)
                'coverage_radius': self.uav_coverage_radius,  # ğŸ”§ ä¿®å¤: ä»é…ç½®è¯»å–è¦†ç›–åŠå¾„
                'cache': {},  # ç¼“å­˜å­—å…¸
                'cache_capacity': 150.0,  # ç¼“å­˜å®¹é‡(MB) - 150MBè½»é‡çº§UAVç¼“å­˜
                'cache_capacity_bytes': (getattr(self.sys_config.cache, 'uav_cache_capacity', 150e6) if self.sys_config is not None else 150e6),
                'cpu_freq': self.uav_cpu_freq,  # ğŸ†• CPUé¢‘ç‡(Hz)
                'cpu_frequency': self.uav_cpu_freq,  # ğŸ”§ æ–°å¢ï¼šä¸çŠ¶æ€ç¼–ç å­—æ®µåä¸€è‡´
                'computation_queue': [],  # è®¡ç®—ä»»åŠ¡é˜Ÿåˆ—
                'energy_consumed': 0.0,  # ç´¯è®¡èƒ½è€—(J)
                # ğŸ¯ Phase 2èµ„æºè°ƒåº¦å‚æ•°
                'allocated_compute': self.uav_cpu_freq,  # åˆ†é…çš„è®¡ç®—èµ„æºï¼ˆHzï¼‰
                'compute_usage': 0.0,  # å½“å‰è®¡ç®—ä½¿ç”¨ç‡
                'battery_level': 1.0,  # ç”µé‡æ°´å¹³
                'connected_vehicles': [],  # æœåŠ¡çš„è½¦è¾†åˆ—è¡¨
            }
            self.uavs.append(uav)
        
        print(f"åˆ›å»ºäº† {self.num_vehicles} è½¦è¾†, {self.num_rsus} RSU, {self.num_uavs} UAV")
        
        # ğŸ¢ åˆå§‹åŒ–ä¸­å¤®RSUè°ƒåº¦å™¨(é€‰æ‹©RSU_2ä½œä¸ºä¸­å¤®è°ƒåº¦ä¸­å¿ƒ)
        # Initialize central RSU scheduler for coordinated task management
        try:
            from utils.central_rsu_scheduler import create_central_scheduler
            central_rsu_id = f"RSU_{2 if self.num_rsus > 2 else 0}"
            self.central_scheduler = create_central_scheduler(central_rsu_id)
            print(f"ä¸­å¤®RSUè°ƒåº¦å™¨å·²å¯ç”¨: {central_rsu_id}")
        except (ImportError, AttributeError, RuntimeError) as e:
            logging.warning(f"ä¸­å¤®è°ƒåº¦å™¨åŠ è½½å¤±è´¥: {e}")
            self.central_scheduler = None
        
        # æ‡’åŠ è½½è¿ç§»ç®¡ç†å™¨
        # Lazy load migration manager for task migration strategies
        try:
            from migration.migration_manager import TaskMigrationManager
            if not hasattr(self, 'migration_manager') or self.migration_manager is None:
                self.migration_manager = TaskMigrationManager()
        except (ImportError, AttributeError) as e:
            logging.debug(f"Migration manager not available: {e}")
            self.migration_manager = None

        # åˆå§‹åŒ–è‡ªé€‚åº”ç¼“å­˜æ§åˆ¶å™¨
        try:
            from utils.adaptive_control import AdaptiveCacheController
            self.adaptive_cache_controller = AdaptiveCacheController(
                cache_capacity=1000.0  # Default RSU capacity
            )
            print("è‡ªé€‚åº”ç¼“å­˜æ§åˆ¶å™¨å·²å¯ç”¨")
        except (ImportError, AttributeError, RuntimeError) as e:
            logging.warning(f"è‡ªé€‚åº”ç¼“å­˜æ§åˆ¶å™¨åŠ è½½å¤±è´¥: {e}")
            self.adaptive_cache_controller = None
        
        # ä¸€è‡´æ€§è‡ªæ£€ï¼ˆä¸å¼ºåˆ¶ç»ˆæ­¢ï¼Œä»…æç¤ºï¼‰
        # Consistency check for topology configuration
        try:
            expected_rsus, expected_uavs = 4, 2
            if self.num_rsus != expected_rsus or self.num_uavs != expected_uavs:
                print(
                    f"[Topology] num_rsus={self.num_rsus}, num_uavs={self.num_uavs}, "
                    f"recommended {expected_rsus}/{expected_uavs} to match the paper setup."
                )
            print("[Topology] Central RSU configured as RSU_2 for coordination.")
        except (ValueError, TypeError) as e:
            logging.warning(f"Topology consistency check failed: {e}")

        self._init_mm1_predictor()
        self._refresh_spatial_index(update_static=True, update_vehicle=True)
    
    # ========== Phase 2æœ¬åœ°è°ƒåº¦é€»è¾‘ ==========
    
    def apply_resource_allocation(self, allocation_dict: Dict[str, np.ndarray]):
        """
        åº”ç”¨ä¸­å¤®æ™ºèƒ½ä½“çš„èµ„æºåˆ†é…å†³ç­–ï¼ˆPhase 1 -> Phase 2ï¼‰
        
        Args:
            allocation_dict: ä¸­å¤®æ™ºèƒ½ä½“ç”Ÿæˆçš„èµ„æºåˆ†é…å­—å…¸
                - 'bandwidth': [num_vehicles]  å¸¦å®½åˆ†é…æ¯”ä¾‹
                - 'vehicle_compute': [num_vehicles]  è½¦è¾†è®¡ç®—åˆ†é…æ¯”ä¾‹
                - 'rsu_compute': [num_rsus]  RSUè®¡ç®—åˆ†é…æ¯”ä¾‹
                - 'uav_compute': [num_uavs]  UAVè®¡ç®—åˆ†é…æ¯”ä¾‹
        """
        alloc_dict = dict(allocation_dict)
        base_bandwidth = self._prepare_bandwidth_vector(alloc_dict.get('bandwidth'))
        alloc_dict['bandwidth'] = base_bandwidth
        if self.dynamic_bandwidth_enabled:
            adjusted_bandwidth, stats = self._apply_dynamic_bandwidth(base_bandwidth)
            alloc_dict['bandwidth'] = adjusted_bandwidth
            self._last_dynamic_bandwidth = adjusted_bandwidth.copy()
            if stats:
                self.stats['bandwidth_allocator_utilization'] = stats.get('utilization', 0.0)
                self.stats['bandwidth_allocator_avg_bw'] = stats.get('avg_bandwidth', 0.0)
                self.stats['bandwidth_allocator_num_links'] = stats.get('num_links', 0)
                self.stats['bandwidth_allocator_updates'] = self.stats.get('bandwidth_allocator_updates', 0) + 1
        
        self.resource_pool.update_allocation(alloc_dict)
        
        for i, vehicle in enumerate(self.vehicles):
            vehicle['allocated_bandwidth'] = self.resource_pool.get_vehicle_bandwidth(i)
            # ğŸ”§ P2ä¿®å¤ï¼šç»Ÿä¸€å‘½å cpu_freq â†’ allocated_compute
            vehicle['allocated_compute'] = self.resource_pool.get_vehicle_compute(i)
            vehicle['cpu_freq'] = vehicle['allocated_compute']  # ä¿æŒå‘åå…¼å®¹
        
        for i, rsu in enumerate(self.rsus):
            rsu['allocated_compute'] = self.resource_pool.get_rsu_compute(i)
        
        for i, uav in enumerate(self.uavs):
            uav['allocated_compute'] = self.resource_pool.get_uav_compute(i)

    def _init_dynamic_bandwidth_support(self) -> None:
        """é…ç½®å¹¶åˆå§‹åŒ–åŠ¨æ€å¸¦å®½åˆ†é…åŠŸèƒ½ã€‚"""
        self.dynamic_bandwidth_enabled = False
        self.bandwidth_allocator = None
        self._bandwidth_allocator_mode = 'hybrid'
        self._bandwidth_allocation_blend = 0.6
        self._bandwidth_demand_floor_bits = 0.5e6 * 8.0
        self._bandwidth_idle_demand_bits = 0.1e6 * 8.0
        self._last_dynamic_bandwidth = np.ones(max(1, self.num_vehicles), dtype=float) / max(1, self.num_vehicles)

        env_blend = os.environ.get('BANDWIDTH_ALLOCATOR_BLEND')
        if env_blend:
            try:
                self._bandwidth_allocation_blend = float(env_blend)
            except ValueError:
                pass
        self._bandwidth_allocation_blend = float(np.clip(self._bandwidth_allocation_blend, 0.0, 1.0))

        comm_cfg_flag = bool(getattr(self.communication_config, 'use_bandwidth_allocator', False)) if self.communication_config is not None else False
        dict_flag = bool(self.config.get('use_bandwidth_allocator', False))
        env_flag = os.environ.get('USE_BANDWIDTH_ALLOCATOR')
        env_flag_active = bool(env_flag and env_flag.lower() in {'1', 'true', 'yes', 'on'})
        config_flag = False
        if self.sys_config is not None:
            try:
                from config import config as global_config  # type: ignore
                config_flag = bool(getattr(global_config.communication, 'use_bandwidth_allocator', False))
            except Exception:
                config_flag = False

        should_enable = comm_cfg_flag or dict_flag or env_flag_active or config_flag
        if should_enable and BandwidthAllocator is None:
            logging.warning("BandwidthAllocator module unavailable, dynamic bandwidth disabled.")
            should_enable = False
        if not should_enable:
            self.stats['dynamic_bandwidth_enabled'] = False
            return

        total_bw = float(getattr(self.resource_pool, 'total_bandwidth', max(1e6, self.bandwidth)))
        if self.communication_config is not None:
            min_channel = float(getattr(self.communication_config, 'channel_bandwidth', total_bw / max(1, self.num_vehicles)))
        else:
            min_channel = total_bw / max(1, self.num_vehicles)
        min_channel = max(0.25 * min_channel, 0.5e6)
        if BandwidthAllocator is None:
            logging.warning("BandwidthAllocator is not available")
            self.bandwidth_allocator = None
            self.stats['dynamic_bandwidth_enabled'] = False
            return
        try:
            self.bandwidth_allocator = BandwidthAllocator(total_bandwidth=total_bw, min_bandwidth=min_channel)
        except (TypeError, ValueError, AttributeError) as exc:
            logging.warning(f"Failed to initialize BandwidthAllocator: {exc}")
            self.bandwidth_allocator = None
            self.stats['dynamic_bandwidth_enabled'] = False
            return

        self.dynamic_bandwidth_enabled = True
        self.stats['dynamic_bandwidth_enabled'] = True
        print("âœ… åŠ¨æ€å¸¦å®½åˆ†é…å™¨å·²å¯ç”¨ï¼šç»“åˆRLåŠ¨ä½œä¸å®æ—¶é˜Ÿåˆ—/SINRéœ€æ±‚è‡ªåŠ¨è°ƒæ•´å¸¦å®½")

    def _prepare_bandwidth_vector(self, raw_vector: Optional[np.ndarray]) -> np.ndarray:
        """å½’ä¸€åŒ–ä¸­å¤®æ™ºèƒ½ä½“è¾“å‡ºçš„å¸¦å®½å‘é‡ï¼Œä¿è¯ç»´åº¦ä¸€è‡´ã€‚"""
        if raw_vector is None:
            base = np.array(self.resource_pool.bandwidth_allocation, copy=True)
            return self._normalize_vector(base)
        arr = np.asarray(raw_vector, dtype=float).flatten()
        if arr.size == self.num_vehicles:
            base = arr
        else:
            base = np.ones(self.num_vehicles, dtype=float)
            limit = min(arr.size, self.num_vehicles)
            if limit > 0:
                base[:limit] = arr[:limit]
            if limit < self.num_vehicles and limit > 0:
                base[limit:] = np.mean(arr[:limit])
        return self._normalize_vector(base)

    def _apply_dynamic_bandwidth(self, base_vector: np.ndarray) -> Tuple[np.ndarray, Optional[Dict[str, Any]]]:
        """æ‰§è¡ŒåŠ¨æ€å¸¦å®½åˆ†é…å¹¶ä¸RLæè®®æ··åˆã€‚"""
        if not self.dynamic_bandwidth_enabled or self.bandwidth_allocator is None:
            return base_vector, None
        requests = self._collect_bandwidth_requests(base_vector)
        if not requests:
            return base_vector, None
        allocations = self.bandwidth_allocator.allocate_bandwidth(
            requests, allocation_mode=self._bandwidth_allocator_mode
        )
        if not allocations:
            return base_vector, None

        dyn_vector = np.zeros_like(base_vector)
        total_bw = max(1e-9, float(self.bandwidth_allocator.total_bandwidth))
        for idx, vehicle in enumerate(self.vehicles):
            dyn_vector[idx] = float(allocations.get(vehicle['id'], 0.0)) / total_bw
        dyn_vector = self._normalize_vector(dyn_vector)
        blended = np.clip(
            self._bandwidth_allocation_blend * dyn_vector + (1.0 - self._bandwidth_allocation_blend) * base_vector,
            0.0,
            1.0,
        )
        blended = self._normalize_vector(blended)
        stats = self.bandwidth_allocator.get_allocation_stats(allocations)
        return blended, stats

    def _collect_bandwidth_requests(self, base_vector: np.ndarray) -> List[Dict[str, float]]:
        """æ„å»ºå¸¦å®½åˆ†é…å™¨éœ€è¦çš„æ´»è·ƒé“¾è·¯æè¿°ã€‚"""
        if self.num_vehicles <= 0:
            return []
        requests: List[Dict[str, float]] = []
        for idx, vehicle in enumerate(self.vehicles):
            queue = vehicle.get('task_queue_by_priority', {})
            total_bits = 0.0
            highest_priority = 4
            for priority in range(1, 5):
                tasks = queue.get(priority, [])
                if tasks and highest_priority == 4:
                    highest_priority = priority
                for task in tasks:
                    data_bytes = task.get('data_size_bytes')
                    if data_bytes is None:
                        data_bytes = task.get('data_size', 1.0) * 1e6
                    total_bits += max(0.0, float(data_bytes)) * 8.0
            if total_bits <= 0.0:
                total_bits = self._bandwidth_idle_demand_bits
            else:
                total_bits = max(total_bits, self._bandwidth_demand_floor_bits)
            rl_bias = float(base_vector[idx]) if idx < base_vector.size else 0.0
            total_bits *= max(0.2, 0.7 + 0.6 * rl_bias)
            request = {
                'task_id': vehicle['id'],
                'priority': min(max(highest_priority, 1), 4),
                'sinr': self._estimate_vehicle_sinr(vehicle),
                'data_size': total_bits,
                'node_type': 'vehicle',
            }
            requests.append(request)
        return requests

    def _estimate_vehicle_sinr(self, vehicle: Dict[str, Any]) -> float:
        """åŸºäºæœ€è¿‘çš„RSU/UAVè·ç¦»ä¼°ç®—è½¦è¾†é“¾è·¯SINRã€‚"""
        if not (self.rsus or self.uavs):
            return 10.0
        vehicle_pos = vehicle.get('position')
        if vehicle_pos is None:
            return 10.0
        position = np.asarray(vehicle_pos, dtype=float)
        freq_hz = self._get_comm_value('carrier_frequency', 3.5e9)
        freq_ghz = max(freq_hz / 1e9, 0.5)
        noise_density_dbm = self._get_comm_value('thermal_noise_density', -174.0)
        per_vehicle_bw = max(
            1e6, float(getattr(self.resource_pool, 'total_bandwidth', self.bandwidth)) / max(1, self.num_vehicles)
        )
        noise_dbm = noise_density_dbm + 10.0 * math.log10(per_vehicle_bw)
        best_linear = 0.5
        for node in list(self.rsus) + list(self.uavs):
            node_pos = node.get('position')
            if node_pos is None:
                continue
            dist = float(self.calculate_distance(position, np.asarray(node_pos, dtype=float)))
            d_km = max(dist / 1000.0, 0.001)
            path_loss_db = 32.4 + 21.0 * math.log10(d_km) + 20.0 * math.log10(freq_ghz)
            if node in self.rsus:
                tx_power_dbm = self._get_comm_value('rsu_tx_power', 46.0)
                tx_gain = self._get_comm_value('antenna_gain_rsu', 15.0)
            else:
                tx_power_dbm = self._get_comm_value('uav_tx_power', 30.0)
                tx_gain = self._get_comm_value('antenna_gain_uav', 5.0)
            rx_gain = self._get_comm_value('antenna_gain_vehicle', 3.0)
            rx_power_dbm = tx_power_dbm + tx_gain + rx_gain - path_loss_db
            sinr_db = rx_power_dbm - noise_dbm
            best_linear = max(best_linear, 10.0 ** (sinr_db / 10.0))
        return float(max(0.1, best_linear))

    def _get_comm_value(self, attr: str, default: float) -> float:
        """ä»é€šä¿¡é…ç½®ä¸­å®‰å…¨è·å–å‚æ•°ã€‚"""
        cfg = self.communication_config
        if cfg is not None and hasattr(cfg, attr):
            try:
                return float(getattr(cfg, attr))
            except Exception:
                return float(default)
        return float(default)

    def _normalize_vector(self, vector: np.ndarray) -> np.ndarray:
        """é€šç”¨å½’ä¸€åŒ–å·¥å…·ï¼Œç¡®ä¿å‘é‡æ±‚å’Œä¸º1ã€‚"""
        if vector.size == 0:
            return vector
        vec = np.clip(vector.astype(float), 0.0, None)
        total = vec.sum()
        if total <= 1e-9:
            return np.ones_like(vec) / len(vec)
        return vec / total
    def vehicle_priority_scheduling(self, vehicle: Dict):
        """
        è½¦è¾†ç«¯ä¼˜å…ˆçº§é˜Ÿåˆ—è°ƒåº¦ï¼ˆPhase 2æ‰§è¡Œå±‚ï¼‰
        
        ğŸš€ èåˆLuoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼š
        - è½¦è¾†ä¾§ç»´æŠ¤Lä¸ªç”Ÿå‘½å‘¨æœŸé˜Ÿåˆ—ï¼ˆé˜Ÿåˆ—lè¡¨ç¤ºè¿˜æœ‰lä¸ªæ—¶éš™åˆ°æˆªæ­¢æ—¶é—´ï¼‰
        - é˜Ÿåˆ—lè¾“å…¥ï¼š(1)æœ¬è½¦é˜Ÿåˆ—l+1æœªå¤„ç†çš„ (2)æ–°ç”Ÿæˆæ—¶å»¶çº¦æŸ=lçš„ (3)V2Vè¿ç§»æ¥çš„l+1æ•°æ®
        - é˜Ÿåˆ—lè¾“å‡ºï¼š(1)Offloadâ†’RSUé˜Ÿåˆ—l-1 (2)Migrateâ†’å…¶ä»–è½¦é˜Ÿåˆ—l-1 (3)Localå¤„ç† (4)Remainâ†’æœ¬è½¦é˜Ÿåˆ—l-1
        - æ¯ä¸ªæ—¶éš™ç»“æŸæ—¶ï¼Œæœªå¤„ç†ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸ-1ï¼ˆé™çº§åˆ°ä¸‹ä¸€é˜Ÿåˆ—ï¼‰
        
        ã€ç­–ç•¥ã€‘
        1. æŒ‰ä»»åŠ¡ä¼˜å…ˆçº§ï¼ˆç±»å‹1>2>3>4ï¼‰æ’åº
        2. ä¼˜å…ˆåˆ†é…è®¡ç®—èµ„æºç»™é«˜ä¼˜å…ˆçº§ä»»åŠ¡
        3. å¦‚æœæœ¬åœ°èµ„æºä¸è¶³ï¼Œæ ‡è®°ä¸ºå¾…å¸è½½
        
        Args:
            vehicle: è½¦è¾†å¯¹è±¡å­—å…¸
        """
        # è·å–åˆ†é…çš„è®¡ç®—èµ„æº
        # ğŸ”§ ä¿®å¤ï¼šç»Ÿä¸€ä½¿ç”¨allocated_computeå­—æ®µ
        allocated_cpu = vehicle.get('allocated_compute', vehicle.get('cpu_freq', self.vehicle_cpu_freq))
        time_slot = self.time_slot
        
        # ğŸ†• è®ºæ–‡æ¨¡å‹ï¼šåˆå§‹åŒ–ç”Ÿå‘½å‘¨æœŸé˜Ÿåˆ—ç»“æ„ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if 'lifetime_queues' not in vehicle:
            vehicle['lifetime_queues'] = self._init_lifetime_queues_vehicle()
        
        # åˆå¹¶æ‰€æœ‰ä¼˜å…ˆçº§é˜Ÿåˆ—åˆ°ä¸€ä¸ªåˆ—è¡¨ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
        all_tasks = []
        for priority in [1, 2, 3, 4]:  # ä»é«˜åˆ°ä½
            all_tasks.extend(vehicle['task_queue_by_priority'][priority])
        
        if not all_tasks:
            vehicle['compute_usage'] = 0.0
            return
        
        # è®¡ç®—æœ¬æ—¶éš™å¯ç”¨çš„æ€»è®¡ç®—å‘¨æœŸ
        available_cycles = allocated_cpu * time_slot
        used_cycles = 0.0
        
        for task in all_tasks:
            if 'compute_cycles' in task:
                task_cycles = task['compute_cycles']
                if used_cycles + task_cycles <= available_cycles:
                    # æœ¬åœ°å¯ä»¥å¤„ç†
                    task['processing_node'] = 'local'
                    task['can_process_local'] = True
                    used_cycles += task_cycles
                else:
                    # æœ¬åœ°èµ„æºä¸è¶³ï¼Œéœ€è¦å¸è½½
                    task['processing_node'] = 'offload'
                    task['can_process_local'] = False
        
        # æ›´æ–°è®¡ç®—ä½¿ç”¨ç‡
        vehicle['compute_usage'] = used_cycles / max(available_cycles, 1e-9)
    
    def rsu_dynamic_resource_allocation(self, rsu: Dict, rsu_idx: int):
        """
        RSUç«¯åŠ¨æ€èµ„æºåˆ†é…ï¼ˆPhase 2æ‰§è¡Œå±‚ï¼‰
        
        ğŸš€ èåˆLuoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼š
        - RSUä¾§ç»´æŠ¤L-1ä¸ªç”Ÿå‘½å‘¨æœŸé˜Ÿåˆ—ï¼ˆæœ€çŸ­1ä¸ªæ—¶éš™ä»è½¦ä¼ åˆ°RSUï¼‰
        - é˜Ÿåˆ—lè¾“å…¥ï¼š(1)è‡ªå·±é˜Ÿåˆ—l+1ä¸Šæ—¶éš™æœªå¤„ç†çš„ (2)è½¦è¾†V2Iå¸è½½æ¥çš„å‰©ä½™å¯¿å‘½l+1æ•°æ®
        - é˜Ÿåˆ—lè¾“å‡ºï¼š(1)ECNè®¡ç®—å¤„ç† (2)æœªå¤„ç†éƒ¨åˆ†â†’é˜Ÿåˆ—l-1ï¼ˆl=1æ—¶è¿‡æœŸåˆ é™¤ï¼‰
        - æ¯ä¸ªæ—¶éš™ç»“æŸæ—¶ï¼Œæœªå¤„ç†ä»»åŠ¡é™çº§åˆ°l-1é˜Ÿåˆ—
        
        ã€ç­–ç•¥ã€‘
        1. ä¸ºæ¥å…¥çš„è½¦è¾†åŠ¨æ€åˆ†é…å¸¦å®½
        2. æ ¹æ®ä»»åŠ¡ä¼˜å…ˆçº§åˆ†é…è®¡ç®—æ—¶é—´ç‰‡
        3. ä¼˜å…ˆæœåŠ¡é«˜ä¼˜å…ˆçº§ä»»åŠ¡
        
        Args:
            rsu: RSUå¯¹è±¡å­—å…¸
            rsu_idx: RSUç´¢å¼•
        """
        # è·å–åˆ†é…çš„è®¡ç®—èµ„æº
        allocated_compute = rsu['allocated_compute']
        time_slot = self.time_slot
        
        # ğŸ†• è®ºæ–‡æ¨¡å‹ï¼šåˆå§‹åŒ–ç”Ÿå‘½å‘¨æœŸé˜Ÿåˆ—ç»“æ„ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if 'lifetime_queues' not in rsu:
            rsu['lifetime_queues'] = self._init_lifetime_queues_rsu()
        
        # è®¡ç®—æœ¬æ—¶éš™å¯ç”¨çš„æ€»è®¡ç®—å‘¨æœŸ
        available_cycles = allocated_compute * time_slot
        
        # è·å–æ‰€æœ‰å¾…å¤„ç†ä»»åŠ¡ï¼ˆä»computation_queueï¼‰
        tasks = rsu['computation_queue']
        if not tasks:
            rsu['compute_usage'] = 0.0
            return
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆå‡è®¾ä»»åŠ¡æœ‰task_typeå­—æ®µï¼‰
        sorted_tasks = sorted(tasks, key=lambda t: t.get('task_type', 4))
        
        # åˆ†é…è®¡ç®—èµ„æº
        used_cycles = 0.0
        for task in sorted_tasks:
            if 'compute_cycles' in task:
                task_cycles = task['compute_cycles']
                if used_cycles + task_cycles <= available_cycles:
                    task['can_process'] = True
                    used_cycles += task_cycles
                else:
                    task['can_process'] = False  # èµ„æºä¸è¶³ï¼Œéœ€ç­‰å¾…ä¸‹ä¸€æ—¶éš™
        
        # æ›´æ–°è®¡ç®—ä½¿ç”¨ç‡
        rsu['compute_usage'] = used_cycles / max(available_cycles, 1e-9)
    
    def uav_dynamic_resource_allocation(self, uav: Dict, uav_idx: int):
        """
        UAVç«¯åŠ¨æ€èµ„æºåˆ†é…ï¼ˆPhase 2æ‰§è¡Œå±‚ï¼‰
        
        ğŸš€ èåˆLuoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼š
        - UAVä¾§ç±»ä¼¼RSUï¼Œç»´æŠ¤L-1ä¸ªç”Ÿå‘½å‘¨æœŸé˜Ÿåˆ—
        - é˜Ÿåˆ—æµè½¬é€»è¾‘åŒRSUï¼ˆè®ºæ–‡å°†UAVè§†ä¸ºç§»åŠ¨åŸºç«™ï¼‰
        
        ã€ç­–ç•¥ã€‘
        1. è€ƒè™‘ç”µé‡æ°´å¹³è°ƒæ•´æœåŠ¡èƒ½åŠ›
        2. ä¼˜å…ˆæœåŠ¡ä¿¡é“è´¨é‡å¥½çš„è½¦è¾†
        3. ä½ç”µé‡æ—¶é™ä½æœåŠ¡èŒƒå›´
        
        Args:
            uav: UAVå¯¹è±¡å­—å…¸
            uav_idx: UAVç´¢å¼•
        """
        # è·å–åˆ†é…çš„è®¡ç®—èµ„æºï¼ˆè€ƒè™‘ç”µé‡å› å­ï¼‰
        allocated_compute = uav['allocated_compute']
        battery_factor = max(0.5, uav['battery_level'])  # ä½ç”µé‡æ—¶æ€§èƒ½ä¸‹é™
        effective_compute = allocated_compute * battery_factor
        
        time_slot = self.time_slot
        # ğŸ”§ ä¿®å¤ï¼šåŸºäºåˆ†é…çš„è®¡ç®—èµ„æºè®¡ç®—å¯ç”¨å‘¨æœŸï¼Œè€Œéæœ‰æ•ˆè®¡ç®—èµ„æº
        # è¿™æ ·compute_usageå§‹ç»ˆåŸºäºallocated_computeï¼Œä¸ä¼šè¶…è¿‡100%
        available_cycles = allocated_compute * time_slot
        
        # è·å–æ‰€æœ‰å¾…å¤„ç†ä»»åŠ¡
        tasks = uav['computation_queue']
        if not tasks:
            uav['compute_usage'] = 0.0
            return
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        sorted_tasks = sorted(tasks, key=lambda t: t.get('task_type', 4))
        
        # åˆ†é…è®¡ç®—èµ„æº
        used_cycles = 0.0
        for task in sorted_tasks:
            if 'compute_cycles' in task:
                task_cycles = task['compute_cycles']
                if used_cycles + task_cycles <= available_cycles:
                    task['can_process'] = True
                    used_cycles += task_cycles
                else:
                    task['can_process'] = False
        
        # æ›´æ–°è®¡ç®—ä½¿ç”¨ç‡
        # ğŸ”§ ä¿®å¤ï¼šè€ƒè™‘ç”µé‡å› å­çš„å½±å“ï¼Œä½†ä½¿ç”¨ç‡ä»åŸºäºallocated_compute
        # å¦‚æœç”µé‡ä½ï¼Œå®é™…èƒ½å¤„ç†çš„cyclesä¼šå‡å°‘ï¼Œä½†reported usageåŸºäºæ€»åˆ†é…
        actual_processed = min(used_cycles, effective_compute * time_slot)
        uav['compute_usage'] = actual_processed / max(available_cycles, 1e-9)
    
    def execute_phase2_scheduling(self):
        """
        æ‰§è¡ŒPhase 2çš„æ‰€æœ‰æœ¬åœ°è°ƒåº¦é€»è¾‘
        
        ã€æµç¨‹ã€‘
        1. è½¦è¾†ç«¯ï¼šä¼˜å…ˆçº§è°ƒåº¦
        2. RSUç«¯ï¼šåŠ¨æ€èµ„æºåˆ†é…
        3. UAVç«¯ï¼šåŠ¨æ€èµ„æºåˆ†é…
        4. æ›´æ–°èµ„æºä½¿ç”¨ç»Ÿè®¡
        """
        # è½¦è¾†ç«¯è°ƒåº¦
        for vehicle in self.vehicles:
            self.vehicle_priority_scheduling(vehicle)
        
        # RSUç«¯è°ƒåº¦
        for i, rsu in enumerate(self.rsus):
            self.rsu_dynamic_resource_allocation(rsu, i)
        
        # UAVç«¯è°ƒåº¦
        for i, uav in enumerate(self.uavs):
            self.uav_dynamic_resource_allocation(uav, i)
        
        # æ›´æ–°èµ„æºæ± ç»Ÿè®¡
        vehicle_usage = np.array([v['compute_usage'] for v in self.vehicles])
        rsu_usage = np.array([r['compute_usage'] for r in self.rsus])
        uav_usage = np.array([u['compute_usage'] for u in self.uavs])
        self.resource_pool.update_usage_stats(vehicle_usage, rsu_usage, uav_usage)
    
    # ========== Phase 2ç»“æŸ ==========
    
    def _setup_scenario(self):
        """
        è®¾ç½®ä»¿çœŸåœºæ™¯
        
        é‡æ–°åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶å¹¶é‡ç½®è¿è¡Œæ—¶çŠ¶æ€ï¼Œç”¨äºå¼€å§‹æ–°çš„ä»¿çœŸå›åˆã€‚
        
        Setup simulation scenario for a new episode.
        """
        # é‡æ–°åˆå§‹åŒ–ç»„ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
        self.initialize_components()
        self._reset_runtime_states()
        self._init_dynamic_bandwidth_support()
        print("åˆå§‹åŒ–äº† 6 ä¸ªç¼“å­˜ç®¡ç†å™¨")

    def _fresh_stats_dict(self) -> Dict[str, Any]:
        """
        åˆ›å»ºæ–°çš„ç»Ÿè®¡å­—å…¸ï¼Œä¿è¯å…³é”®æŒ‡æ ‡é½å…¨
        
        Returns:
            åŒ…å«æ‰€æœ‰æ€§èƒ½æŒ‡æ ‡çš„å­—å…¸ï¼ŒåŒ…æ‹¬ä»»åŠ¡ç»Ÿè®¡ã€å»¶è¿Ÿã€èƒ½è€—ã€ç¼“å­˜å‘½ä¸­ç‡ç­‰
        """
        return {
            'total_tasks': 0,  # æ€»ä»»åŠ¡æ•°
            'processed_tasks': 0,  # å·²å¤„ç†ä»»åŠ¡æ•°
            'completed_tasks': 0,  # å·²å®Œæˆä»»åŠ¡æ•°
            'dropped_tasks': 0,  # ä¸¢å¼ƒä»»åŠ¡æ•°
            'generated_data_bytes': 0.0,  # ç”Ÿæˆçš„æ•°æ®æ€»é‡(å­—èŠ‚)
            'dropped_data_bytes': 0.0,  # ä¸¢å¼ƒçš„æ•°æ®æ€»é‡(å­—èŠ‚)
            'total_delay': 0.0,  # æ€»å»¶è¿Ÿ(ç§’)
            'total_energy': 0.0,  # æ€»èƒ½è€—(ç„¦è€³)
            'energy_uplink': 0.0,  # ä¸Šè¡Œèƒ½è€—(ç„¦è€³)
            'energy_downlink': 0.0,  # ä¸‹è¡Œèƒ½è€—(ç„¦è€³)
            'energy_transmit_uplink': 0.0,  # ä¸Šè¡Œä¼ è¾“èƒ½è€—
            'energy_transmit_downlink': 0.0,  # ä¸‹è¡Œä¼ è¾“èƒ½è€—
            'energy_compute': 0.0,  # è®¡ç®—èƒ½è€—(ç„¦è€³)
            'energy_cache': 0.0,  # ç¼“å­˜å‘½ä¸­èƒ½è€—
            'delay_processing': 0.0,  # è®¡ç®—é˜¶æ®µå»¶è¿Ÿ
            'delay_waiting': 0.0,  # æ’é˜Ÿç­‰å¾…å»¶è¿Ÿ
            'delay_uplink': 0.0,  # ä¸Šä¼ å»¶è¿Ÿ
            'delay_downlink': 0.0,  # ä¸‹è½½å»¶è¿Ÿ
            'delay_cache': 0.0,  # ç¼“å­˜å‘½ä¸­æä¾›çš„å»¶è¿Ÿ
            'local_cache_hits': 0,  # æœ¬åœ°ç¼“å­˜å‘½ä¸­æ¬¡æ•°
            'cache_hits': 0,  # ç¼“å­˜å‘½ä¸­æ¬¡æ•°
            'cache_misses': 0,  # ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°
            'cache_requests': 0,  # ç¼“å­˜è¯·æ±‚æ¬¡æ•°
            'cache_hit_rate': 0.0,  # ç¼“å­˜å‘½ä¸­ç‡
            'migrations_executed': 0,  # æ‰§è¡Œçš„è¿ç§»æ¬¡æ•°
            'migrations_successful': 0,  # æˆåŠŸçš„è¿ç§»æ¬¡æ•°
            'rsu_migration_delay': 0.0,  # RSUè¿ç§»å»¶è¿Ÿ(ç§’)
            'rsu_migration_energy': 0.0,  # RSUè¿ç§»èƒ½è€—(ç„¦è€³)
            'rsu_migration_data': 0.0,  # RSUè¿ç§»æ•°æ®é‡(MB)
            'uav_migration_distance': 0.0,  # UAVè¿ç§»è·ç¦»(ç±³)
            'uav_migration_count': 0,  # UAVè¿ç§»æ¬¡æ•°
            'task_generation': {'total': 0, 'by_type': {}, 'by_scenario': {}},  # ä»»åŠ¡ç”Ÿæˆç»Ÿè®¡
            'drop_stats': {  # ä»»åŠ¡ä¸¢å¼ƒè¯¦ç»†ç»Ÿè®¡
                'total': 0,
                'wait_time_sum': 0.0,
                'queue_sum': 0,
                'by_type': {},
                'by_scenario': {},
                'by_reason': {}
            },
            'remote_rejections': {
                'total': 0,
                'by_type': {'RSU': 0, 'UAV': 0},
                'by_reason': {}
            },
            'queue_rho_sum': 0.0,
            'queue_rho_max': 0.0,
            'queue_overload_flag': False,
            'queue_overload_events': 0,
            'queue_rho_by_node': {},
            'queue_overflow_drops': 0,
            'central_scheduler_calls': 0,
            'central_scheduler_last_decisions': 0,
            'central_scheduler_migrations': 0,
            # æŒ‰ä»»åŠ¡ç±»åˆ«ç»Ÿè®¡æ—¶å»¶æ€§èƒ½
            'task_type_delay_stats': {
                1: {'total_delay': 0.0, 'count': 0, 'max_delay': 0.0, 'deadline_violations': 0, 'deadline': 0.2},
                2: {'total_delay': 0.0, 'count': 0, 'max_delay': 0.0, 'deadline_violations': 0, 'deadline': 0.3},
                3: {'total_delay': 0.0, 'count': 0, 'max_delay': 0.0, 'deadline_violations': 0, 'deadline': 0.4},
                4: {'total_delay': 0.0, 'count': 0, 'max_delay': 0.0, 'deadline_violations': 0, 'deadline': 0.6}
            },
        }

    def _update_central_scheduler(self, step_summary: Dict[str, Any]) -> None:
        scheduler = getattr(self, 'central_scheduler', None)
        if scheduler is None:
            return
        try:
            rsu_snapshots: List[Dict[str, Any]] = []
            for idx, rsu in enumerate(self.rsus):
                rsu_snapshots.append({
                    'id': rsu.get('id', f'RSU_{idx}'),
                    'position': np.array(rsu.get('position', [0.0, 0.0])),
                    'computation_queue': rsu.get('computation_queue', []),
                    'cpu_usage': float(rsu.get('compute_usage', 0.0)),
                    'cpu_frequency': float(rsu.get('allocated_compute', rsu.get('cpu_freq', 0.0))),
                    'cache_usage': float(rsu.get('cache_utilization', 0.0)),
                    'cache_hit_rate': float(self.stats.get('cache_hit_rate', 0.0)),
                    'cached_content': rsu.get('cache', {}),
                    'served_vehicles': len(rsu.get('connected_vehicles', [])),
                    'coverage_vehicles': len(rsu.get('coverage_list', [])),
                    'bandwidth_usage': float(step_summary.get('remote_tasks', 0.0)) / max(1, len(self.vehicles)),
                    'avg_response_time': float(self.stats.get('avg_task_delay', 0.0)),
                    'task_completion_rate': float(self.stats.get('task_completion_rate', 0.0)),
                    'energy_consumption': float(rsu.get('energy_consumed', 0.0)),
                })
            scheduler.collect_all_rsu_loads(rsu_snapshots)
            incoming_tasks = max(1, int(step_summary.get('generated_tasks', 0)))
            decisions = scheduler.global_load_balance_scheduling(incoming_task_count=incoming_tasks)
            migrations = scheduler.intelligent_migration_coordination()
            
            # ğŸ”§ ä¿®å¤ï¼šå¤„ç†è¿ç§»æŒ‡ä»¤å¹¶è®°å½•èƒ½è€—ä¸å»¶è¿Ÿ
            for cmd in migrations:
                if 'wired_transmission' in cmd:
                    wired_stats = cmd['wired_transmission']
                    # è®°å½•è¿ç§»èƒ½è€— (J)
                    energy = wired_stats.get('energy_j', 0.0)
                    self._accumulate_energy('rsu_migration_energy', energy)
                    self.stats['energy_consumed'] = self.stats.get('energy_consumed', 0.0) + energy # ç¡®ä¿è®¡å…¥æ€»èƒ½è€—
                    
                    # è®°å½•è¿ç§»å»¶è¿Ÿ (s) - æ³¨æ„ï¼šè¿™æ˜¯åå°ä¼ è¾“å»¶è¿Ÿï¼Œä¸ç›´æ¥é˜»å¡ä»»åŠ¡ï¼Œä½†è®¡å…¥ç³»ç»Ÿå¼€é”€
                    delay_ms = wired_stats.get('delay_ms', 0.0)
                    delay_s = delay_ms / 1000.0
                    self._accumulate_delay('rsu_migration_delay', delay_s)
                    
                    # è®°å½•è¿ç§»æ•°æ®é‡
                    data_mb = wired_stats.get('data_size_mb', 0.0)
                    self.stats['rsu_migration_data'] = self.stats.get('rsu_migration_data', 0.0) + data_mb
            
            self.stats['central_scheduler_calls'] = self.stats.get('central_scheduler_calls', 0) + 1
            self.stats['central_scheduler_last_decisions'] = len(decisions)
            self.stats['central_scheduler_migrations'] = self.stats.get('central_scheduler_migrations', 0) + len(migrations)
            
            # ğŸš€ åˆ›æ–°: è½¨è¿¹æ„ŸçŸ¥é¢„è¿ç§» (Trajectory-Aware Pre-Migration)
            mobility_migrations = self._check_mobility_migration()
            self.stats['mobility_migrations'] = self.stats.get('mobility_migrations', 0) + mobility_migrations
            
        except Exception as exc:
            logging.debug("Central scheduler update failed: %s", exc)

    def _check_mobility_migration(self) -> int:
        """
        ğŸš€ åˆ›æ–°: è½¨è¿¹æ„ŸçŸ¥é¢„è¿ç§»æœºåˆ¶
        æ£€æµ‹è½¦è¾†æ˜¯å¦å³å°†ç¦»å¼€å½“å‰RSUè¦†ç›–èŒƒå›´ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™æå‰å°†ä»»åŠ¡è¿ç§»åˆ°ä¸‹ä¸€ä¸ªRSUã€‚
        """
        migration_count = 0
        if not self.rsus:
            return 0
            
        for vehicle in self.vehicles:
            # 1. ç¡®å®šå½“å‰è¿æ¥çš„RSU
            v_pos = vehicle.get('position')
            if v_pos is None:
                continue
            
            current_rsu = None
            min_dist = float('inf')
            
            # æ‰¾åˆ°æœ€è¿‘çš„RSU
            for rsu in self.rsus:
                dist = self.calculate_distance(v_pos, rsu['position'])
                if dist < min_dist:
                    min_dist = dist
                    current_rsu = rsu
            
            if not current_rsu or min_dist > current_rsu['coverage_radius']:
                continue
                
            # 2. æ£€æŸ¥æ˜¯å¦åœ¨è¾¹ç¼˜åŒºåŸŸ (è¦†ç›–åŠå¾„çš„90%)
            if min_dist > current_rsu['coverage_radius'] * 0.9:
                # è½¦è¾†å³å°†ç¦»å¼€ï¼Œè§¦å‘é¢„è¿ç§»
                
                # 3. é¢„æµ‹ä¸‹ä¸€ä¸ªRSU (åŸºäºç§»åŠ¨æ–¹å‘)
                direction = vehicle.get('direction', 0.0)
                next_rsu = None
                best_forward_dist = float('inf')
                
                for rsu in self.rsus:
                    if rsu['id'] == current_rsu['id']:
                        continue
                        
                    # æ£€æŸ¥æ˜¯å¦åœ¨å‰æ–¹
                    dx = rsu['position'][0] - v_pos[0]
                    # å¦‚æœå‘ä¸œ(direction ~ 0)ï¼Œdxåº”ä¸ºæ­£ï¼›å‘è¥¿(direction ~ pi)ï¼Œdxåº”ä¸ºè´Ÿ
                    is_forward = (abs(direction) < 1.0 and dx > 0) or (abs(direction) > 2.0 and dx < 0)
                    
                    if is_forward:
                        dist = self.calculate_distance(v_pos, rsu['position'])
                        if dist < best_forward_dist:
                            best_forward_dist = dist
                            next_rsu = rsu
                
                if next_rsu:
                    # 4. æ‰§è¡Œè¿ç§»ï¼šå°†è¯¥è½¦è¾†åœ¨å½“å‰RSUé˜Ÿåˆ—ä¸­çš„ä»»åŠ¡ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªRSU
                    queue = current_rsu.get('computation_queue', [])
                    tasks_to_move = []
                    
                    remaining_queue = []
                    for task in queue:
                        # æ£€æŸ¥ä»»åŠ¡å½’å±
                        tid = task.get('vehicle_id') or task.get('source_vehicle_id')
                        if tid == vehicle['id']:
                            tasks_to_move.append(task)
                        else:
                            remaining_queue.append(task)
                    
                    if tasks_to_move:
                        # æ›´æ–°é˜Ÿåˆ—
                        current_rsu['computation_queue'] = remaining_queue
                        next_rsu.setdefault('computation_queue', []).extend(tasks_to_move)
                        
                        migration_count += len(tasks_to_move)
                        # è®°å½•è¿ç§»å¼€é”€ (ç®€åŒ–)
                        # å‡è®¾æ¯ä»»åŠ¡è¿ç§»æ¶ˆè€— 0.05J (æ— çº¿ä¿¡ä»¤å¼€é”€)
                        migration_energy = 0.05 * len(tasks_to_move)
                        self._accumulate_delay('migration_delay', 0.02 * len(tasks_to_move)) # 20ms per task
                        self._accumulate_energy('uav_migration_energy', migration_energy) # å€Ÿç”¨uav_migration_energyå­—æ®µæˆ–æ–°å»ºå­—æ®µ
                        self.stats['energy_consumed'] = self.stats.get('energy_consumed', 0.0) + migration_energy
                else:
                    pass
                        
        return migration_count

    def _accumulate_delay(self, bucket: str, value: float) -> None:
        """Ensureåˆ†é¡¹å»¶è¿Ÿä¸æ€»å»¶è¿ŸåŒæ­¥ã€‚"""
        try:
            amount = max(0.0, float(value))
        except (TypeError, ValueError):
            return
        if amount <= 0.0:
            return
        self.stats[bucket] = self.stats.get(bucket, 0.0) + amount
        self.stats['total_delay'] = self.stats.get('total_delay', 0.0) + amount

    def _record_task_type_delay(self, task: Dict, actual_delay: float) -> None:
        """
        æŒ‰ä»»åŠ¡ç±»åˆ«è®°å½•æ—¶å»¶ç»Ÿè®¡
        
        Args:
            task: ä»»åŠ¡å­—å…¸ï¼Œå¿…é¡»åŒ…å« task_type å’Œ deadline å­—æ®µ
            actual_delay: å®é™…æ—¶å»¶(ç§’)
        """
        task_type = task.get('task_type')
        if task_type is None or task_type not in [1, 2, 3, 4]:
            return
        
        # è·å–è¯¥ä»»åŠ¡ç±»åˆ«çš„ç»Ÿè®¡æ•°æ®
        type_stats = self.stats['task_type_delay_stats'].get(task_type)
        if type_stats is None:
            # å¦‚æœä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤ç»Ÿè®¡
            default_deadlines = {1: 0.2, 2: 0.3, 3: 0.4, 4: 0.6}
            type_stats = {
                'total_delay': 0.0,
                'count': 0,
                'max_delay': 0.0,
                'deadline_violations': 0,
                'deadline': default_deadlines.get(task_type, 0.5)
            }
            self.stats['task_type_delay_stats'][task_type] = type_stats
        
        # æ›´æ–°ç»Ÿè®¡æ•°æ®
        type_stats['total_delay'] += actual_delay
        type_stats['count'] += 1
        type_stats['max_delay'] = max(type_stats['max_delay'], actual_delay)
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡deadline
        task_deadline = task.get('deadline')  # ä»»åŠ¡çš„å®é™…deadline(ç»å¯¹æ—¶é—´)
        arrival_time = task.get('arrival_time', 0.0)
        if task_deadline is not None:
            # deadlineæ˜¯ç»å¯¹æ—¶é—´ï¼Œéœ€è¦è½¬æ¢ä¸ºç›¸å¯¹æ—¶é—´é™åˆ¶
            deadline_limit = task_deadline - arrival_time
            if actual_delay > deadline_limit:
                type_stats['deadline_violations'] += 1
        else:
            # å¦‚æœdeadlineä¸å­˜åœ¨ï¼Œä½¿ç”¨ç±»åˆ«é»˜è®¤deadline
            if actual_delay > type_stats['deadline']:
                type_stats['deadline_violations'] += 1

    def _accumulate_energy(self, bucket: str, value: float) -> None:
        """Ensureåˆ†é¡¹èƒ½è€—ä¸æ€»èƒ½è€—åŒæ­¥ã€‚"""
        try:
            amount = max(0.0, float(value))
        except (TypeError, ValueError):
            return
        if amount <= 0.0:
            return
        self.stats[bucket] = self.stats.get(bucket, 0.0) + amount
        self.stats['total_energy'] = self.stats.get('total_energy', 0.0) + amount

    def _register_cache_request(self, hit: bool) -> None:
        """æ›´æ–°ç¼“å­˜å‘½ä¸­ç»Ÿè®¡ä¸å‘½ä¸­ç‡ã€‚"""
        self.stats['cache_requests'] = self.stats.get('cache_requests', 0) + 1
        if hit:
            self.stats['cache_hits'] = self.stats.get('cache_hits', 0) + 1
        else:
            self.stats['cache_misses'] = self.stats.get('cache_misses', 0) + 1
        total = self.stats['cache_hits'] + self.stats['cache_misses']
        self.stats['cache_hit_rate'] = self.stats['cache_hits'] / max(1, total)

    def _prepare_step_usage_counters(self) -> None:
        """åœ¨å•æ­¥å¼€å§‹å‰æ¸…é›¶æœ¬åœ°ä½¿ç”¨è®¡æ•°ã€‚"""
        for vehicle in self.vehicles:
            vehicle['local_cycle_used'] = 0.0
            vehicle['compute_usage'] = 0.0

    def _record_queue_drop(self, task: Dict, node_type: str) -> None:
        """è®°å½•å› é˜Ÿåˆ—æº¢å‡ºå¯¼è‡´çš„ä»»åŠ¡ä¸¢å¼ƒã€‚
        
        ğŸ”§ å…³é”®ä¿®å¤ï¼šé˜²æ­¢é‡å¤ç»Ÿè®¡å·²ä¸¢å¼ƒçš„ä»»åŠ¡
        """
        # ğŸ”§ å¦‚æœä»»åŠ¡å·²ç»è¢«æ ‡è®°ä¸ºä¸¢å¼ƒï¼Œç›´æ¥è¿”å›ï¼Œé¿å…é‡å¤è®¡æ•°
        if task.get('dropped', False):
            return
        
        self.stats['dropped_tasks'] = self.stats.get('dropped_tasks', 0) + 1
        self.stats['queue_overflow_drops'] = self.stats.get('queue_overflow_drops', 0) + 1
        data_bytes = float(task.get('data_size_bytes', task.get('data_size', 0.0) * 1e6))
        self.stats['dropped_data_bytes'] = self.stats.get('dropped_data_bytes', 0.0) + data_bytes
        task['dropped'] = True
        task['drop_reason'] = 'queue_overflow'
        drop_stats_default: Dict[str, Any] = {
            'total': 0,
            'wait_time_sum': 0.0,
            'queue_sum': 0,
            'by_type': {},
            'by_scenario': {},
            'by_reason': {}
        }
        drop_stats = self.stats.setdefault('drop_stats', drop_stats_default)
        if not isinstance(drop_stats, dict):
            drop_stats = drop_stats_default
        drop_stats['total'] = drop_stats.get('total', 0) + 1
        task_type = task.get('task_type', 'unknown')
        scenario = task.get('app_scenario', 'unknown')
        reason = 'queue_overflow'
        by_type = drop_stats.setdefault('by_type', {})
        by_scenario = drop_stats.setdefault('by_scenario', {})
        by_reason = drop_stats.setdefault('by_reason', {})
        by_type[task_type] = by_type.get(task_type, 0) + 1
        by_scenario[scenario] = by_scenario.get(scenario, 0) + 1
        by_reason[reason] = by_reason.get(reason, 0) + 1

    def _enforce_queue_capacity(self, node: Dict, node_type: str, step_summary: Dict[str, Any]) -> None:
        """åœ¨å…¥é˜Ÿåæ‰§è¡Œï¼Œç¡®ä¿é˜Ÿåˆ—å—æ§
        
        ğŸ”§ ç´§æ€¥ä¿®å¤ï¼šå¤§å¹…æé«˜é˜Ÿåˆ—æº¢å‡ºè¾¹ç•Œï¼Œå‡å°‘ä¸¢å¼ƒ
        """
        # ğŸ”§ ä¿®å¤ï¼šVehicleä½¿ç”¨task_queue_by_priorityç»“æ„
        if node_type == 'VEHICLE':
            queue_dict = node.get('task_queue_by_priority', {})
            if not isinstance(queue_dict, dict):
                return
            
            # è®¡ç®—æ€»é˜Ÿåˆ—é•¿åº¦
            total_queue_length = sum(len(tasks) for tasks in queue_dict.values())
            
            # ğŸ”§ ä¼˜åŒ–ï¼šä»é…ç½®è¯»å–Vehicleé˜Ÿåˆ—å®¹é‡ï¼Œä¸é…ç½®ç³»ç»Ÿç»Ÿä¸€
            vehicle_nominal_capacity = getattr(self, 'vehicle_nominal_capacity', 20.0)
            overflow_margin = 2.0  # å…è®¸é˜Ÿåˆ—è¾¾åˆ°åä¹‰å®¹é‡çš„2å€
            # æœ€å¤§å®¹é‡ = 20 Ã— 1.5(node_max_load_factor) Ã— 2.0(overflow_margin) = 60ä¸ªä»»åŠ¡
            max_queue = int(max(1, round(vehicle_nominal_capacity * self.node_max_load_factor * overflow_margin)))
            
            overflow = total_queue_length - max_queue
            if overflow <= 0:
                return
            
            # ä»ä½ä¼˜å…ˆçº§å¼€å§‹ä¸¢å¼ƒä»»åŠ¡
            dropped = 0
            for priority in [4, 3, 2, 1]:  # ä»ä½åˆ°é«˜
                if overflow <= 0:
                    break
                queue = queue_dict.get(priority, [])
                while overflow > 0 and queue:
                    dropped_task = queue.pop()  # ä¸¢å¼ƒæœ€æ–°çš„ä»»åŠ¡
                    # ğŸ†• Luoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼šä¸¢å¼ƒä»»åŠ¡æ—¶ä»lifetime_queuesåŒæ­¥ç§»é™¤
                    self._remove_task_from_lifetime_queues(node, dropped_task)
                    self._record_queue_drop(dropped_task, node_type)
                    dropped += 1
                    overflow -= 1
            
            if dropped:
                step_summary['dropped_tasks'] = step_summary.get('dropped_tasks', 0) + dropped
                step_summary['queue_overflow_drops'] = step_summary.get('queue_overflow_drops', 0) + dropped
            return
        
        # RSU/UAVä½¿ç”¨computation_queueç»“æ„
        queue = node.get('computation_queue', [])
        if not isinstance(queue, list):
            return
        nominal_capacity = self.rsu_nominal_capacity if node_type == 'RSU' else self.uav_nominal_capacity
        # ğŸ”§ ä¿®å¤ï¼šè°ƒæ•´æº¢å‡ºè¾¹ç•Œåˆ°åˆç†æ°´å¹³ (3.0 â†’ 2.0)
        # 2å€è¾¹ç•Œåœ¨ä¿è¯ç¼“å†²çš„åŒæ—¶ï¼Œé¿å…é˜Ÿåˆ—ç§¯å‹è¿‡é•¿å½±å“å®æ—¶æ€§
        # RSU: 50 Ã— 2.0 = 100ä¸ªä»»åŠ¡, UAV: 30 Ã— 2.0 = 60ä¸ªä»»åŠ¡
        overflow_margin = 2.0  # å…è®¸é˜Ÿåˆ—é•¿åº¦è¾¾åˆ°åä¹‰å®¹é‡çš„2å€
        max_queue = int(max(1, round(nominal_capacity * self.node_max_load_factor * overflow_margin)))
        overflow = len(queue) - max_queue
        if overflow <= 0:
            return
        dropped = 0
        while overflow > 0 and queue:
            dropped_task = queue.pop()  # ä¸¢å¼ƒæœ€æ–°çš„ä»»åŠ¡ï¼Œä¿æŠ¤æ—©åˆ°ä»»åŠ¡
            # ğŸ†• Luoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼šé˜Ÿåˆ—æº¢å‡ºä¸¢å¼ƒæ—¶ä»lifetime_queuesåŒæ­¥ç§»é™¤
            self._remove_task_from_lifetime_queues(node, dropped_task)
            self._record_queue_drop(dropped_task, node_type)
            dropped += 1
            overflow -= 1
        if dropped:
            step_summary['dropped_tasks'] = step_summary.get('dropped_tasks', 0) + dropped
            step_summary['queue_overflow_drops'] = step_summary.get('queue_overflow_drops', 0) + dropped

    def _try_serve_from_vehicle_cache(self, vehicle: Dict, task: Dict, step_summary: Dict[str, Any],
                                      cache_controller: Optional[Any]) -> bool:
        """å°è¯•ç›´æ¥ä½¿ç”¨è½¦è½½ç¼“å­˜æä¾›å†…å®¹ã€‚"""
        content_id = task.get('content_id')
        
        # ğŸ”§ ä¼˜åŒ–5: ä¸å¯ç¼“å­˜ä»»åŠ¡ç›´æ¥è·³è¿‡ç¼“å­˜æ£€æŸ¥
        if not content_id or not task.get('is_cacheable', False):
            return False
            
        cache = vehicle.get('device_cache') or {}
        cached_entry = cache.get(content_id)
        if cached_entry is None:
            return False
        hit_delay = max(0.002, min(0.05, 0.2 * self.time_slot))
        hit_energy = float(self.config.get('local_cache_energy', 0.15))
        vehicle['energy_consumed'] = vehicle.get('energy_consumed', 0.0) + hit_energy
        self.stats['local_cache_hits'] = self.stats.get('local_cache_hits', 0) + 1
        self._register_cache_request(True)
        self._accumulate_delay('delay_cache', hit_delay)
        self._accumulate_energy('energy_cache', hit_energy)
        self.stats['processed_tasks'] = self.stats.get('processed_tasks', 0) + 1
        self.stats['completed_tasks'] = self.stats.get('completed_tasks', 0) + 1
        step_summary['local_cache_hits'] = step_summary.get('local_cache_hits', 0) + 1
        
        # æŒ‰ä»»åŠ¡ç±»åˆ«è®°å½•æ—¶å»¶ç»Ÿè®¡
        self._record_task_type_delay(task, hit_delay)
        
        cached_entry['timestamp'] = self.current_time
        if cache_controller is not None:
            try:
                cache_controller.record_cache_result(content_id, was_hit=True)
            except (AttributeError, TypeError, ValueError) as e:
                logging.debug(f"Cache controller update failed: {e}")
        return True

    def _reset_runtime_states(self):
        """
        é‡ç½®è¿è¡Œæ—¶çŠ¶æ€ï¼ˆç”¨äºepisodeé‡å¯ï¼‰
        
        æ¸…ç©ºæ‰€æœ‰è¿è¡Œæ—¶æ•°æ®ï¼ŒåŒ…æ‹¬ä»¿çœŸæ—¶é—´ã€ä»»åŠ¡è®¡æ•°ã€ç»Ÿè®¡æ•°æ®ã€
        è½¦è¾†å’ŒèŠ‚ç‚¹çŠ¶æ€ç­‰ã€‚
        
        Reset runtime states for starting a new episode.
        """
        reset_simulation_time()
        self.current_step = 0
        self.current_time = 0.0
        self._queue_overload_warning_active = False
        self._queue_warning_triggered = False
        self.task_counter = 0
        self.stats = self._fresh_stats_dict()
        self.active_tasks = []
        self._scheduling_params = {
            'priority_bias': 0.5,
            'deadline_bias': 0.5,
            'reorder_window': 3,
        }
        self._last_app_name = 'unknown'

        # é–²å¶‡ç–†æï¹ç· /é‘ºå‚œå£é˜èˆµâ‚¬?
        for vehicle in self.vehicles:
            vehicle.setdefault('tasks', [])
            vehicle['tasks'].clear()
            vehicle['energy_consumed'] = 0.0
            vehicle['device_cache'] = {}
            vehicle['device_cache_capacity'] = vehicle.get('device_cache_capacity', 32.0)

        for idx, rsu in enumerate(self.rsus):
            rsu.setdefault('cache', {})
            rsu['computation_queue'] = []
            rsu['energy_consumed'] = 0.0

        for idx, uav in enumerate(self.uavs):
            uav.setdefault('cache', {})
            uav['computation_queue'] = []
            uav['energy_consumed'] = 0.0

        if hasattr(self, 'mm1_prediction_window'):
            self._build_mm1_trackers()
            self._reset_mm1_step_buffers()
            self._mm1_last_prediction_step = -self.mm1_prediction_interval
        self._prepare_step_usage_counters()

    def _update_scheduling_params(self, params: Optional[Dict[str, float]]) -> None:
        """??????????????????????"""
        if not isinstance(params, dict):
            return
        bias = params.get('priority_bias')
        if bias is not None:
            try:
                bias_val = float(bias)
            except (TypeError, ValueError):
                bias_val = None
            else:
                self._scheduling_params['priority_bias'] = float(np.clip(bias_val, 0.0, 1.0))
        deadline_bias = params.get('deadline_bias')
        if deadline_bias is not None:
            try:
                d_val = float(deadline_bias)
            except (TypeError, ValueError):
                d_val = None
            else:
                self._scheduling_params['deadline_bias'] = float(np.clip(d_val, 0.0, 1.0))
        window = params.get('reorder_window')
        if window is not None:
            try:
                window_val = int(round(float(window)))
            except (TypeError, ValueError):
                window_val = None
            else:
                self._scheduling_params['reorder_window'] = max(1, min(32, window_val))
    
    def _init_lifetime_queues_vehicle(self) -> Dict[int, List]:
        """
        ğŸ†• Luoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼šåˆå§‹åŒ–è½¦è¾†ä¾§ç”Ÿå‘½å‘¨æœŸé˜Ÿåˆ—
        
        è½¦è¾†ç»´æŠ¤Lä¸ªé˜Ÿåˆ—ï¼ˆé˜Ÿåˆ—l = è¿˜æœ‰1åˆ°Lä¸ªæ—¶éš™åˆ°æˆªæ­¢æ—¶é—´ï¼‰
        å¯¹åº”è®ºæ–‡å›¾2(a)ï¼šè½¦è¾†ä¾§å¤šé˜Ÿåˆ—ç»“æ„
        
        Returns:
            Dict[lifetime, List[Task]]: é”®ä¸ºå‰©ä½™ç”Ÿå‘½å‘¨æœŸï¼Œå€¼ä¸ºä»»åŠ¡åˆ—è¡¨
        """
        max_lifetime = getattr(self.queue_config, 'max_lifetime', 10) if hasattr(self, 'queue_config') else 10
        return {l: [] for l in range(1, max_lifetime + 1)}
    
    def _init_lifetime_queues_rsu(self) -> Dict[int, List]:
        """
        ğŸ†• Luoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼šRSUä¾§ç”Ÿå‘½å‘¨æœŸé˜Ÿåˆ—
        
        RSUç»´æŠ¤L-1ä¸ªé˜Ÿåˆ—ï¼ˆé˜Ÿåˆ—l = è¿˜æœ‰1åˆ°L-1ä¸ªæ—¶éš™ï¼Œå› ä¸ºRSUä¸äº§ç”Ÿæ•°æ®ï¼‰
        å¯¹åº”è®ºæ–‡å›¾2(b)ï¼šRSUä¾§å¤šé˜Ÿåˆ—ç»“æ„
        
        Returns:
            Dict[lifetime, List[Task]]: é”®ä¸ºå‰©ä½™ç”Ÿå‘½å‘¨æœŸï¼Œå€¼ä¸ºä»»åŠ¡åˆ—è¡¨
        """
        max_lifetime = getattr(self.queue_config, 'max_lifetime', 10) if hasattr(self, 'queue_config') else 10
        # RSUæœ€å¤§é˜Ÿåˆ—å·ä¸ºL-1ï¼ˆæœ€çŸ­1ä¸ªæ—¶éš™ä»è½¦ä¼ åˆ°RSUï¼‰
        return {l: [] for l in range(1, max_lifetime)}
    
    def _update_lifetime_queues(self, node: Dict, node_type: str, step_summary: Dict[str, Any]) -> None:
        """
        ğŸ†• Luoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼šæ¯ä¸ªæ—¶éš™æ›´æ–°ç”Ÿå‘½å‘¨æœŸé˜Ÿåˆ—
        
        æ ¸å¿ƒé€»è¾‘ï¼š
        1. é˜Ÿåˆ—lä¸­æœªå¤„ç†çš„ä»»åŠ¡ â†’ é™çº§åˆ°é˜Ÿåˆ—l-1
        2. l=1æ—¶æœªå¤„ç†çš„ä»»åŠ¡ â†’ è¿‡æœŸåˆ é™¤ï¼Œè®¡å…¥æƒ©ç½š
        
        å¯¹åº”è®ºæ–‡ç¬¬3.2èŠ‚ï¼šâ€œæ¯è¿‡ä¸€ä¸ªæ—¶éš™ï¼Œæ‰€æœ‰æ²¡è¢«å¤„ç†/è½¬ç§»çš„æ•°æ®é˜Ÿåˆ—ç´¢å¼•å‡1â€
        
        Args:
            node: è½¦è¾†/RSU/UAVèŠ‚ç‚¹å¯¹è±¡
            node_type: èŠ‚ç‚¹ç±»å‹
            step_summary: å½“å‰æ—¶éš™çš„ç»Ÿè®¡æ•°æ®
        """
        if 'lifetime_queues' not in node:
            return
        
        lifetime_queues = node['lifetime_queues']
        new_queues = {}
        dropped_count = 0
        urgency_promoted_count = 0  # ğŸš€ åˆ›æ–°ï¼šç»Ÿè®¡ç´§æ€¥æå‡çš„ä»»åŠ¡æ•°
        
        # ğŸš€ åˆ›æ–°1ï¼šè‡ªé€‚åº”é™çº§é€Ÿåº¦ - æ ¹æ®èŠ‚ç‚¹è´Ÿè½½è°ƒæ•´
        # é«˜è´Ÿè½½æ—¶åŠ é€Ÿé™çº§ï¼ˆè…¾å‡ºé˜Ÿåˆ—ç©ºé—´ï¼‰ï¼Œä½è´Ÿè½½æ—¶æ­£å¸¸é™çº§
        node_load = self._calculate_node_rho(node, node_type)
        if node_load > 0.8:  # é«˜è´Ÿè½½
            degradation_step = 2  # ç”Ÿå‘½å‘¨æœŸå‡2ï¼ˆåŠ é€Ÿè¿‡æœŸï¼‰
        elif node_load > 0.6:  # ä¸­ç­‰è´Ÿè½½
            degradation_step = 1  # æ­£å¸¸é™çº§
        else:  # ä½è´Ÿè½½
            degradation_step = 1  # æ­£å¸¸é™çº§
        
        # ä»é«˜åˆ°ä½éå†æ¯ä¸ªç”Ÿå‘½å‘¨æœŸé˜Ÿåˆ—
        for lifetime in sorted(lifetime_queues.keys(), reverse=True):
            tasks = lifetime_queues[lifetime]
            if not tasks:
                # ç©ºé˜Ÿåˆ—ï¼Œä¿æŒç»“æ„
                new_queues[lifetime] = []
                continue
            
            # ğŸš€ åˆ›æ–°2ï¼šè·¨é˜Ÿåˆ—ä¼˜å…ˆçº§æå‡æœºåˆ¶
            # å³å°†è¿‡æœŸçš„ä»»åŠ¡ï¼ˆlifetime <= 2ï¼‰è‡ªåŠ¨æå‡ä¼˜å…ˆçº§
            for task in tasks:
                if lifetime <= 2 and 'task_type' in task:
                    original_priority = task.get('task_type', 4)
                    # ç´§æ€¥æå‡ï¼šé™ä½task_typeæ•°å€¼ï¼ˆæ•°å€¼è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
                    if original_priority > 1 and not task.get('urgency_promoted', False):
                        task['task_type'] = max(1, original_priority - 1)
                        task['urgency_promoted'] = True  # æ ‡è®°ä¸ºç´§æ€¥æå‡
                        urgency_promoted_count += 1
            
            # ç”Ÿå‘½å‘¨æœŸé™çº§ï¼ˆè‡ªé€‚åº”æ­¥é•¿ï¼‰
            new_lifetime = max(0, lifetime - degradation_step)
            
            if new_lifetime > 0:
                # è¿˜æœ‰å‰©ä½™æ—¶é—´ï¼Œä»»åŠ¡é™çº§åˆ°ä¸‹ä¸€é˜Ÿåˆ—
                if new_lifetime not in new_queues:
                    new_queues[new_lifetime] = []
                # æ›´æ–°ä»»åŠ¡çš„å‰©ä½™ç”Ÿå‘½å‘¨æœŸå­—æ®µ
                for task in tasks:
                    if 'remaining_lifetime_slots' in task:
                        task['remaining_lifetime_slots'] = new_lifetime
                new_queues[new_lifetime].extend(tasks)
            else:
                # ç”Ÿå‘½å‘¨æœŸç”¨å°½ï¼Œä»»åŠ¡è¿‡æœŸåˆ é™¤
                for task in tasks:
                    task['is_dropped'] = True
                    task['drop_reason'] = 'lifetime_expired'
                    self._record_queue_drop(task, node_type)
                    dropped_count += 1
        
        # ç¡®ä¿æ‰€æœ‰é˜Ÿåˆ—ä½ç½®éƒ½å­˜åœ¨
        max_lifetime = getattr(self.queue_config, 'max_lifetime', 10) if hasattr(self, 'queue_config') else 10
        if node_type == 'VEHICLE':
            for l in range(1, max_lifetime + 1):
                if l not in new_queues:
                    new_queues[l] = []
        else:  # RSU/UAV
            for l in range(1, max_lifetime):
                if l not in new_queues:
                    new_queues[l] = []
        
        # æ›´æ–°èŠ‚ç‚¹çš„é˜Ÿåˆ—
        node['lifetime_queues'] = new_queues
        
        # ğŸš€ åˆ›æ–°3ï¼šæ™ºèƒ½é¢„æµ‹ä¸ä¸»åŠ¨è¿ç§»è§¦å‘
        # æ£€æŸ¥é˜Ÿåˆ—2å’Œé˜Ÿåˆ—1ä¸­çš„ä»»åŠ¡æ•°é‡ï¼Œå¦‚æœè¿‡å¤šåˆ™è§¦å‘è¿ç§»é¢„è­¦
        if node_type in ('RSU', 'UAV'):
            critical_tasks = len(new_queues.get(1, [])) + len(new_queues.get(2, []))
            total_tasks = sum(len(q) for q in new_queues.values())
            if critical_tasks > 0 and total_tasks > 0:
                urgency_ratio = critical_tasks / total_tasks
                if urgency_ratio > 0.3:  # è¶…è¿‡30%çš„ä»»åŠ¡å³å°†è¿‡æœŸ
                    node['migration_urgency'] = min(1.0, urgency_ratio * 2)  # è§¦å‘è¿ç§»ç´§æ€¥åº¦
                    step_summary['migration_triggers'] = step_summary.get('migration_triggers', 0) + 1
        
        # ç»Ÿè®¡è¿‡æœŸä»»åŠ¡å’Œä¼˜åŒ–æŒ‡æ ‡
        if dropped_count > 0:
            step_summary['lifetime_expired_tasks'] = step_summary.get('lifetime_expired_tasks', 0) + dropped_count
            step_summary['dropped_tasks'] = step_summary.get('dropped_tasks', 0) + dropped_count
        
        if urgency_promoted_count > 0:
            step_summary['urgency_promoted_tasks'] = step_summary.get('urgency_promoted_tasks', 0) + urgency_promoted_count
    
    def _remove_task_from_lifetime_queues(self, node: Dict, task: Dict) -> bool:
        """
        ğŸ†• Luoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼šä»clifetime_queuesä¸­ç§»é™¤å·²å®Œæˆ/è¿ç§»çš„ä»»åŠ¡
        
        é˜²æ­¢å·²å®Œæˆçš„ä»»åŠ¡ç»§ç»­åœ¨lifetime_queuesä¸­é™çº§ï¼Œé¿å…å†…å­˜æ³„æ¼å’Œæ•°æ®ä¸ä¸€è‡´
        
        Args:
            node: èŠ‚ç‚¹å¯¹è±¡
            task: è¦ç§»é™¤çš„ä»»åŠ¡
            
        Returns:
            æ˜¯å¦æˆåŠŸç§»é™¤
        """
        if 'lifetime_queues' not in node:
            return False
        
        lifetime_queues = node['lifetime_queues']
        task_id = task.get('id')
        
        # éå†æ‰€æœ‰ç”Ÿå‘½å‘¨æœŸé˜Ÿåˆ—æŸ¥æ‰¾å¹¶ç§»é™¤ä»»åŠ¡
        for lifetime, tasks in lifetime_queues.items():
            for i, t in enumerate(tasks):
                if t.get('id') == task_id:
                    tasks.pop(i)
                    return True
        
        return False

    def _init_mm1_predictor(self):
        """Initialize M/M/1 queue performance predictor settings and buffers."""
        if getattr(self, 'queue_config', None) is not None:
            window_cfg = getattr(self.queue_config, 'prediction_window', None)
            interval_cfg = getattr(self.queue_config, 'prediction_interval', None)
        else:
            window_cfg = None
            interval_cfg = None

        window = self.config.get('mm1_prediction_window', window_cfg if window_cfg is not None else 12)
        interval = self.config.get('mm1_prediction_interval', interval_cfg if interval_cfg is not None else 5)

        try:
            window = int(window)
        except (TypeError, ValueError):
            window = 12
        window = max(3, window)

        try:
            interval = int(interval)
        except (TypeError, ValueError):
            interval = 5
        interval = max(1, interval)

        self.mm1_prediction_window = window
        self.mm1_prediction_interval = interval
        self._mm1_last_prediction_step = -self.mm1_prediction_interval
        self._build_mm1_trackers()
        self._reset_mm1_step_buffers()

    def _mm1_node_key(self, node_type: str, node_idx: int) -> str:
        return f"{node_type}_{int(node_idx)}"

    def _build_mm1_trackers(self):
        """Create rolling buffers for each node participating in remote processing."""
        self._mm1_trackers: Dict[str, Dict[str, deque]] = {}
        node_keys = [self._mm1_node_key('RSU', idx) for idx, _ in enumerate(self.rsus)]
        node_keys.extend(self._mm1_node_key('UAV', idx) for idx, _ in enumerate(self.uavs))

        for key in node_keys:
            self._mm1_trackers[key] = {
                'arrivals': deque(maxlen=self.mm1_prediction_window),
                'services': deque(maxlen=self.mm1_prediction_window),
                'queue_lengths': deque(maxlen=self.mm1_prediction_window),
                'delays': deque(maxlen=self.mm1_prediction_window),
            }

    def _reset_mm1_step_buffers(self):
        """Reset per-step accumulation buffers for MM1 metrics."""
        if not hasattr(self, '_mm1_trackers'):
            return
        self._mm1_step_arrivals: defaultdict[str, int] = defaultdict(int)
        self._mm1_step_services: defaultdict[str, int] = defaultdict(int)
        self._mm1_step_delays: defaultdict[str, List[float]] = defaultdict(list)
        self._mm1_step_queue_lengths: Dict[str, int] = {}

    def _record_mm1_arrival(self, node_type: str, node_idx: int):
        if not hasattr(self, '_mm1_trackers'):
            return
        key = self._mm1_node_key(node_type, node_idx)
        self._mm1_step_arrivals[key] += 1

    def _record_mm1_service(self, node_type: str, node_idx: int, delay: float):
        if not hasattr(self, '_mm1_trackers'):
            return
        key = self._mm1_node_key(node_type, node_idx)
        self._mm1_step_services[key] += 1
        if delay is not None and delay >= 0.0:
            self._mm1_step_delays[key].append(float(delay))

    def _record_mm1_queue_length(self, node_type: str, node_idx: int, queue_len: int):
        if not hasattr(self, '_mm1_trackers'):
            return
        key = self._mm1_node_key(node_type, node_idx)
        self._mm1_step_queue_lengths[key] = int(queue_len)

    def _finalize_mm1_step(self, step: int) -> Dict[str, Any]:
        """Update rolling statistics and return predictions when scheduled."""
        if not hasattr(self, '_mm1_trackers'):
            return {}

        for key, tracker in self._mm1_trackers.items():
            tracker['arrivals'].append(self._mm1_step_arrivals.get(key, 0))
            tracker['services'].append(self._mm1_step_services.get(key, 0))
            tracker['queue_lengths'].append(self._mm1_step_queue_lengths.get(key, 0))
            delays = self._mm1_step_delays.get(key)
            avg_delay = float(np.mean(delays)) if delays else 0.0
            tracker['delays'].append(avg_delay)

        predictions: Dict[str, Any] = {}
        if step - self._mm1_last_prediction_step < self.mm1_prediction_interval:
            return predictions

        for key, tracker in self._mm1_trackers.items():
            window_steps = max(1, len(tracker['arrivals']))
            time_horizon = max(window_steps * float(self.time_slot), 1e-6)
            total_arrivals = sum(tracker['arrivals'])
            total_services = sum(tracker['services'])

            arrival_rate = total_arrivals / time_horizon
            service_rate = total_services / time_horizon
            if service_rate > 1e-6:
                rho = arrival_rate / service_rate
            else:
                rho = float('inf') if arrival_rate > 0.0 else 0.0
            stable = service_rate > arrival_rate and service_rate > 1e-6

            theoretical_queue = None
            theoretical_delay = None
            if stable:
                denom = max(1e-6, 1.0 - rho)
                theoretical_queue = (rho * rho) / denom
                theoretical_delay = 1.0 / max(1e-6, service_rate - arrival_rate)

            queue_samples = list(tracker['queue_lengths'])
            actual_queue = float(sum(queue_samples) / len(queue_samples)) if queue_samples else 0.0
            delay_samples = [d for d in tracker['delays'] if d > 0.0]
            actual_delay = float(sum(delay_samples) / len(delay_samples)) if delay_samples else 0.0

            predictions[key] = {
                'arrival_rate': arrival_rate,
                'service_rate': service_rate,
                'rho': rho,
                'stable': stable,
                'theoretical_queue': theoretical_queue,
                'actual_queue': actual_queue,
                'theoretical_delay': theoretical_delay,
                'actual_delay': actual_delay,
            }

        self._mm1_last_prediction_step = step
        return predictions
    
    def _get_realistic_content_size(self, content_id: str) -> float:
        """
        ğŸ”‘ ä¿®å¤ï¼šä½¿ç”¨realisticå†…å®¹ç”Ÿæˆå™¨è·å–å¤§å°
        
        æ ¹æ®å†…å®¹IDè·å–çœŸå®çš„å†…å®¹å¤§å°ï¼ˆMBï¼‰ï¼Œè€ƒè™‘ä¸åŒç±»å‹å†…å®¹çš„å®é™…å¤§å°åˆ†å¸ƒã€‚
        
        Args:
            content_id: å†…å®¹ID
            
        Returns:
            å†…å®¹å¤§å°ï¼ˆMBï¼‰
            
        Get realistic content size using content generator.
        """
        return get_realistic_content_size(content_id)
    
    def _calculate_available_cache_capacity(self, cache: Dict, cache_capacity_mb: float) -> float:
        """
        ğŸ”‘ ä¿®å¤ï¼šæ­£ç¡®è®¡ç®—å¯ç”¨ç¼“å­˜å®¹é‡(MB)
        
        éå†ç¼“å­˜ä¸­çš„æ‰€æœ‰é¡¹ç›®ï¼Œç´¯è®¡å·²ä½¿ç”¨çš„ç©ºé—´ï¼Œè®¡ç®—å‰©ä½™å¯ç”¨å®¹é‡ã€‚
        
        Args:
            cache: ç¼“å­˜å­—å…¸
            cache_capacity_mb: ç¼“å­˜æ€»å®¹é‡ï¼ˆMBï¼‰
            
        Returns:
            å¯ç”¨ç¼“å­˜å®¹é‡ï¼ˆMBï¼‰
            
        Calculate available cache capacity correctly.
        """
        if not cache or cache_capacity_mb <= 0:
            return cache_capacity_mb
        
        total_used_mb = 0.0
        for item in cache.values():
            if isinstance(item, dict) and 'size' in item:
                total_used_mb += float(item.get('size', 0.0))
            else:
                # å…¼å®¹æ—§æ ¼å¼
                # Compatible with old format
                total_used_mb += 1.0
        
        available_mb = cache_capacity_mb - total_used_mb
        return max(0.0, available_mb)
    
    def _infer_content_type(self, content_id: str) -> str:
        """
        ğŸ”‘ ä¿®å¤ï¼šæ ¹æ®å†…å®¹IDæ¨æ–­å†…å®¹ç±»å‹
        
        æ ¹æ®å†…å®¹IDä¸­çš„å…³é”®å­—æ¨æ–­å†…å®¹ç±»å‹ï¼Œç”¨äºç¼“å­˜ç­–ç•¥å†³ç­–ã€‚
        
        Args:
            content_id: å†…å®¹ID
            
        Returns:
            å†…å®¹ç±»å‹å­—ç¬¦ä¸²ï¼ˆå¦‚'traffic_info'ã€'navigation'ç­‰ï¼‰
            
        Infer content type from content ID.
        """
        content_id_lower = content_id.lower()
        
        if 'traffic' in content_id_lower:
            return 'traffic_info'  # äº¤é€šä¿¡æ¯
        elif 'nav' in content_id_lower or 'route' in content_id_lower:
            return 'navigation'  # å¯¼èˆªä¿¡æ¯
        elif 'safety' in content_id_lower or 'alert' in content_id_lower:
            return 'safety_alert'  # å®‰å…¨è­¦æŠ¥
        elif 'park' in content_id_lower:
            return 'parking_info'  # åœè½¦ä¿¡æ¯
        elif 'weather' in content_id_lower:
            return 'weather_info'  # å¤©æ°”ä¿¡æ¯
        elif 'map' in content_id_lower:
            return 'map_data'
        elif 'video' in content_id_lower or 'entertainment' in content_id_lower:
            return 'entertainment'
        elif 'sensor' in content_id_lower:
            return 'sensor_data'
        else:
            return 'general'
    
    def generate_task(self, vehicle_id: str) -> Dict:
        """
        ç”Ÿæˆè®¡ç®—ä»»åŠ¡ - ä½¿ç”¨é…ç½®é©±åŠ¨çš„ä»»åŠ¡åœºæ™¯å®šä¹‰
        
        æ ¹æ®é…ç½®çš„ä»»åŠ¡åœºæ™¯ï¼ˆå¦‚å¯¼èˆªã€è§†é¢‘ã€å®‰å…¨è­¦æŠ¥ç­‰ï¼‰ç”Ÿæˆå…·æœ‰
        ä¸åŒç‰¹å¾çš„è®¡ç®—ä»»åŠ¡ï¼ŒåŒ…æ‹¬æ•°æ®å¤§å°ã€è®¡ç®—éœ€æ±‚ã€æˆªæ­¢æ—¶é—´ç­‰ã€‚
        
        Args:
            vehicle_id: ç”Ÿæˆä»»åŠ¡çš„è½¦è¾†ID
            
        Returns:
            ä»»åŠ¡å­—å…¸ï¼ŒåŒ…å«ä»»åŠ¡çš„æ‰€æœ‰å±æ€§å’Œè¦æ±‚
            
        Generate computational tasks with scenario-driven configuration.
        """
        self.task_counter += 1

        task_cfg = getattr(self.sys_config, 'task', None) if self.sys_config is not None else None
        time_slot = getattr(self.sys_config.network, 'time_slot_duration', self.time_slot) if self.sys_config is not None else self.time_slot

        # ğŸ”§ ä¿®å¤: ä½¿ç”¨ RealisticContentGenerator ç»Ÿä¸€ç”Ÿæˆå†…å®¹ï¼Œç¡®ä¿é«˜æ¯”ä¾‹å¯ç¼“å­˜ä»»åŠ¡
        from utils.realistic_content_generator import generate_realistic_content
        
        # ç”ŸæˆçœŸå®çš„ VEC å†…å®¹ï¼ˆåŒ…æ‹¬ content_id, size, priorityï¼‰
        content_id, content_size_mb, content_priority = generate_realistic_content(vehicle_id, self.current_step)
        
        # ä» content_id æ¨æ–­ VEC åœºæ™¯ç±»å‹ï¼ˆå¦‚ traffic_info, navigation ç­‰ï¼‰
        # content_id æ ¼å¼ä¸º "{content_type}_{counter:04d}" (ä¾‹å¦‚ "traffic_info_0012" æˆ– "entertainment_0001")
        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ rsplit ä»å³ä¾§åˆ†å‰²ä¸€æ¬¡ï¼Œæ­£ç¡®æå–åŒ…å«ä¸‹åˆ’çº¿çš„ç±»å‹å
        if '_' in content_id:
            vec_content_type = content_id.rsplit('_', 1)[0]
        else:
            vec_content_type = 'general'
        
        # æ˜ å°„ VEC å†…å®¹ç±»å‹åˆ°ä»¿çœŸå™¨åœºæ™¯åç§°ï¼ˆç”¨äºç»Ÿè®¡å’Œæ—¥å¿—ï¼‰
        # è¿™äº›éƒ½æ˜¯å¯ç¼“å­˜çš„çœŸå® VEC åœºæ™¯
        scenario_name = vec_content_type
        
        # ğŸ”§ P0ä¿®å¤ï¼šå¯¹é½vec_type_configsä¸TaskConfig.task_profileså®šä¹‰
        # æ ¹æ® VEC å†…å®¹ç±»å‹è®¾ç½®è®¡ç®—å’Œæ—¶å»¶ç‰¹æ€§
        # task_profileså®šä¹‰ï¼š
        #   ç±»å‹1: 50-200KB, 60 cycles/bit, â‰¤0.2s (2 slots)
        #   ç±»å‹2: 600KB-1.5MB, 90 cycles/bit, â‰¤0.4s (4 slots)
        #   ç±»å‹3: 2-4MB, 120 cycles/bit, â‰¤0.5s (5 slots)
        #   ç±»å‹4: 4.5-8MB, 150 cycles/bit, â‰¤0.8s (8 slots)
        vec_type_configs = {
            # ç±»å‹1: æåº¦æ•æ„Ÿ - ç´§æ€¥åˆ¶åŠ¨ã€ç¢°æ’é¿å…
            'safety_alert': {'compute_density': 60, 'deadline_range': (0.18, 0.22), 'task_type': 1, 'cache_priority': 1.0},
            'sensor_data': {'compute_density': 60, 'deadline_range': (0.18, 0.22), 'task_type': 1, 'cache_priority': 0.95},
            
            # ç±»å‹2: æ•æ„Ÿ - å¯¼èˆªã€äº¤é€šä¿¡å·
            'navigation': {'compute_density': 90, 'deadline_range': (0.38, 0.42), 'task_type': 2, 'cache_priority': 0.85},
            'weather_info': {'compute_density': 90, 'deadline_range': (0.38, 0.42), 'task_type': 2, 'cache_priority': 0.7},
            
            # ç±»å‹3: ä¸­åº¦å®¹å¿ - è§†é¢‘å¤„ç†ã€å›¾åƒè¯†åˆ«
            'map_data': {'compute_density': 120, 'deadline_range': (0.48, 0.52), 'task_type': 3, 'cache_priority': 0.8},
            'parking_info': {'compute_density': 120, 'deadline_range': (0.48, 0.52), 'task_type': 3, 'cache_priority': 0.75},
            
            # ç±»å‹4: å®¹å¿ - æ•°æ®åˆ†æã€å¨±ä¹
            'traffic_info': {'compute_density': 150, 'deadline_range': (0.78, 0.84), 'task_type': 4, 'cache_priority': 0.9},
            'entertainment': {'compute_density': 150, 'deadline_range': (0.78, 0.84), 'task_type': 4, 'cache_priority': 0.5},
        }
        
        # è·å–è¯¥ VEC ç±»å‹çš„é…ç½®ï¼ˆå¦‚æœæœªçŸ¥ç±»å‹åˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼‰
        vec_config = vec_type_configs.get(vec_content_type, {
            'compute_density': 400,
            'deadline_range': (0.5, 3.0),
            'task_type': 3,
            'cache_priority': 0.5
        })
        
        # è®¾ç½®ä»»åŠ¡å‚æ•°
        compute_density = vec_config['compute_density']
        deadline_duration = np.random.uniform(*vec_config['deadline_range'])
        initial_type = vec_config['task_type']
        cache_priority = vec_config['cache_priority']
        
        # ä½¿ç”¨ä» RealisticContentGenerator è·å¾—çš„çœŸå®æ•°æ®å¤§å°
        data_size_mb = content_size_mb
        data_size_bytes = data_size_mb * 1e6
        
        # æ—¶é—´æ§½é…ç½®
        relax_factor_applied = self.config.get('deadline_relax_fallback', 1.3)
        deadline_duration *= relax_factor_applied
        max_delay_slots = max(
            1,
            int(deadline_duration / max(self.config.get('time_slot', self.time_slot), 0.1)),
        )

        # ä»»åŠ¡å¤æ‚åº¦æ§åˆ¶
        effective_density = compute_density
        complexity_multiplier = 1.0

        if self.config.get('high_load_mode', False):
            complexity_multiplier = self.config.get('task_complexity_multiplier', 1.5)
            data_size_mb = min(data_size_mb * 1.1, 12.0)
            data_size_bytes = data_size_mb * 1e6
            effective_density = min(effective_density * 1.05, 200)

        total_bits = data_size_bytes * 8
        base_cycles = total_bits * effective_density
        adjusted_cycles = base_cycles * complexity_multiplier
        computation_mips = adjusted_cycles / 1e6

        # æ‰€æœ‰ VEC å†…å®¹éƒ½æ˜¯å¯ç¼“å­˜çš„ï¼ˆè¿™æ˜¯ VEC ç¼“å­˜çš„æ ¸å¿ƒï¼‰
        cacheable_hint = True
        task_type = initial_type

        task = {
            'id': f'task_{self.task_counter}',
            'vehicle_id': vehicle_id,
            'arrival_time': self.current_time,
            'data_size': data_size_mb,
            'data_size_bytes': data_size_bytes,
            'computation_requirement': computation_mips,
            'compute_cycles': adjusted_cycles,
            'deadline': self.current_time + deadline_duration,
            'content_id': content_id,  # ğŸ”§ ä¼˜åŒ–: ä»…å¯ç¼“å­˜ä»»åŠ¡æœ‰content_id
            'is_cacheable': cacheable_hint,  # ğŸ”§ ä¼˜åŒ–3: æ·»åŠ æ˜ç¡®çš„ç¼“å­˜æ ‡è®°
            'cache_priority': cache_priority,  # ğŸ”§ ä¼˜åŒ–4: æ·»åŠ ç¼“å­˜ä¼˜å…ˆçº§
            'priority': np.random.uniform(0.1, 1.0),
            'task_type': task_type,
            'app_scenario': scenario_name,
            'app_name': scenario_name,
            'compute_density': effective_density,
            'complexity_multiplier': complexity_multiplier,
            'max_delay_slots': max_delay_slots,
            'deadline_relax_factor': relax_factor_applied,
            # ğŸ†• Luoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼šæ·»åŠ å‰©ä½™ç”Ÿå‘½å‘¨æœŸå­—æ®µ
            'remaining_lifetime_slots': max_delay_slots,  # åˆå§‹ç”Ÿå‘½å‘¨æœŸ = æœ€å¤§å»¶è¿Ÿæ—¶éš™æ•°
        }

        self._last_app_name = scenario_name

        # é¦ƒæ³ æµ è¯²å§Ÿç¼ç†»é€å •æ³¦
        gen_stats_default: Dict[str, Any] = {'total': 0, 'by_type': {}, 'by_scenario': {}}
        gen_stats = self.stats.setdefault('task_generation', gen_stats_default)
        if not isinstance(gen_stats, dict):
            gen_stats = gen_stats_default
        gen_stats['total'] = (gen_stats.get('total', 0) or 0) + 1
        by_type = gen_stats.setdefault('by_type', {})
        by_type[task_type] = by_type.get(task_type, 0) + 1
        by_scenario = gen_stats.setdefault('by_scenario', {})
        by_scenario[scenario_name] = by_scenario.get(scenario_name, 0) + 1

        stats_cfg = getattr(self, 'stats_config', None)
        report_interval = stats_cfg.task_report_interval if stats_cfg is not None else self.config.get('task_report_interval', 100)
        report_interval = max(1, int(report_interval))
        if gen_stats['total'] % report_interval == 0:
            total_classified = sum(by_type.values()) or 1
            type1_pct = by_type.get(1, 0) / total_classified * 100
            type2_pct = by_type.get(2, 0) / total_classified * 100
            type3_pct = by_type.get(3, 0) / total_classified * 100
            type4_pct = by_type.get(4, 0) / total_classified * 100
            print(
                f"ä»»åŠ¡åˆ†ç±»ç»Ÿè®¡({gen_stats['total']}): "
                f"ç±»å‹1={type1_pct:.1f}%, ç±»å‹2={type2_pct:.1f}%, ç±»å‹3={type3_pct:.1f}%, ç±»å‹4={type4_pct:.1f}%"
            )
            print(
                f"   å½“å‰ä»»åŠ¡: {scenario_name}, {deadline_duration:.2f}s â†’ "
                f"ç±»å‹{task_type}, æ•°æ®{data_size_mb:.2f}MB"
            )
            
            # ğŸ”§ ä¼˜åŒ–7: æ·»åŠ ç¼“å­˜ç»Ÿè®¡å®æ—¶ç›‘æ§
            cache_hits = self.stats.get('cache_hits', 0)
            cache_misses = self.stats.get('cache_misses', 0)
            total_cache_requests = cache_hits + cache_misses
            if total_cache_requests > 0:
                cache_hit_rate = cache_hits / total_cache_requests
                local_hits = self.stats.get('local_cache_hits', 0)
                print(
                    f"   ğŸ’¾ ç¼“å­˜ç»Ÿè®¡: å‘½ä¸­ç‡={cache_hit_rate:.2%} "
                    f"(æ€»å‘½ä¸­:{cache_hits}, æœ¬åœ°:{local_hits}, æœªå‘½ä¸­:{cache_misses})"
                )

        return task
    
    def calculate_distance(self, pos1: np.ndarray, pos2: np.ndarray) -> float:
        """
        è®¡ç®—ä¸¤ç‚¹ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»ï¼ˆæ”¯æŒ2Då’Œ3Dåæ ‡è‡ªåŠ¨è½¬æ¢ï¼‰
        Calculate Euclidean distance between two points (supports automatic 2D/3D conversion)
        
        è¯¥æ–¹æ³•èƒ½å¤Ÿæ™ºèƒ½å¤„ç†2Då’Œ3Dåæ ‡çš„æ··åˆæƒ…å†µï¼š
        - å¦‚æœå…¶ä¸­ä¸€ä¸ªç‚¹æ˜¯2Dï¼Œå¦ä¸€ä¸ªæ˜¯3Dï¼Œè‡ªåŠ¨å°†2Dç‚¹æ‰©å±•ä¸º3Dï¼ˆz=0ï¼‰
        - ç„¶åä½¿ç”¨NumPyçš„çº¿æ€§ä»£æ•°æ¨¡å—è®¡ç®—æ¬§å‡ é‡Œå¾—è·ç¦»
        
        This method intelligently handles mixed 2D/3D coordinates:
        - If one point is 2D and the other is 3D, automatically extends 2D to 3D (z=0)
        - Then uses NumPy's linear algebra module to calculate Euclidean distance
        
        å‚æ•° Args:
            pos1: ç¬¬ä¸€ä¸ªç‚¹çš„åæ ‡æ•°ç»„ (å¯ä»¥æ˜¯2Dæˆ–3D) | Coordinate array of first point (can be 2D or 3D)
            pos2: ç¬¬äºŒä¸ªç‚¹çš„åæ ‡æ•°ç»„ (å¯ä»¥æ˜¯2Dæˆ–3D) | Coordinate array of second point (can be 2D or 3D)
            
        è¿”å› Returns:
            float: ä¸¤ç‚¹ä¹‹é—´çš„è·ç¦»ï¼ˆç±³ï¼‰ | Distance between two points (meters)
        """
        # å¤„ç†ç»´åº¦ä¸åŒ¹é…çš„æƒ…å†µï¼šå°†2Dåæ ‡æ‰©å±•ä¸º3D
        # Handle dimension mismatch: extend 2D coordinates to 3D
        if len(pos1) == 3 and len(pos2) == 2:
            pos2 = np.append(pos2, 0)  # 2Dè½¬3Dï¼Œzåæ ‡è®¾ä¸º0 | 2D to 3D, set z=0
        elif len(pos1) == 2 and len(pos2) == 3:
            pos1 = np.append(pos1, 0)
        
        # ä½¿ç”¨NumPyè®¡ç®—L2èŒƒæ•°ï¼ˆæ¬§å‡ é‡Œå¾—è·ç¦»ï¼‰
        # Use NumPy to calculate L2 norm (Euclidean distance)
        distance = np.linalg.norm(pos1 - pos2)
        return float(distance)
    
    
    def _refresh_spatial_index(self, update_static: bool = True, update_vehicle: bool = True) -> None:
        """
        ä¿æŒç©ºé—´ç´¢å¼•ä¸å®ä½“ä½ç½®åŒæ­¥ã€‚
        update_static=False æ—¶ä»…åˆ·æ–°è½¦è¾†ç´¢å¼•ï¼Œé¿å…é‡å¤æ„å»ºé™æ€KD-treeã€‚
        """
        if not getattr(self, 'spatial_index', None):
            return
        try:
            if update_static and self.spatial_index is not None:
                self.spatial_index.update_static_nodes(self.rsus, self.uavs)
            if update_vehicle and self.spatial_index is not None:
                self.spatial_index.update_vehicle_nodes(self.vehicles)
        except (AttributeError, TypeError, ValueError) as e:
            # ç´¢å¼•åˆ·æ–°å¤±è´¥æ—¶å›é€€è‡³æœ´ç´ éå†é€»è¾‘
            logging.debug(f"Spatial index update failed, falling back to brute force: {e}")
    
    
    def _find_least_loaded_node(self, node_type: str, exclude_node: Optional[Dict] = None) -> Optional[Dict]:
        """
        å¯»æ‰¾è´Ÿè½½æœ€è½»çš„èŠ‚ç‚¹ï¼ˆç”¨äºä»»åŠ¡åˆ†é…å’Œè¿ç§»å†³ç­–ï¼‰
        Find the least loaded node (for task assignment and migration decisions)
        
        è¯¥æ–¹æ³•æ ¹æ®é˜Ÿåˆ—é•¿åº¦æ¥è¡¡é‡èŠ‚ç‚¹è´Ÿè½½ï¼Œé€‰æ‹©æœ€ç©ºé—²çš„èŠ‚ç‚¹ï¼š
        - æ”¯æŒRSUå’ŒUAVä¸¤ç§èŠ‚ç‚¹ç±»å‹
        - å¯ä»¥æ’é™¤ç‰¹å®šèŠ‚ç‚¹ï¼ˆå¦‚å½“å‰å·²è¿‡è½½èŠ‚ç‚¹ï¼‰
        - é€šè¿‡æ¯”è¾ƒcomputation_queueé•¿åº¦æ‰¾åˆ°æœ€ä½³å€™é€‰
        - ç”¨äºè´Ÿè½½å‡è¡¡å’Œæ™ºèƒ½ä»»åŠ¡è°ƒåº¦
        
        This method measures node load by queue length and selects the most idle node:
        - Supports both RSU and UAV node types
        - Can exclude specific nodes (e.g., currently overloaded node)
        - Finds best candidate by comparing computation_queue length
        - Used for load balancing and intelligent task scheduling
        
        å‚æ•° Args:
            node_type: èŠ‚ç‚¹ç±»å‹ 'RSU' æˆ– 'UAV' | Node type 'RSU' or 'UAV'
            exclude_node: éœ€è¦æ’é™¤çš„èŠ‚ç‚¹ï¼ˆå¯é€‰ï¼‰ | Node to exclude (optional)
            
        è¿”å› Returns:
            Dict: è´Ÿè½½æœ€è½»çš„èŠ‚ç‚¹å­—å…¸ï¼Œå¦‚æœæ²¡æœ‰å€™é€‰è¿”å›None | Least loaded node dict, or None if no candidates
        """
        # æ ¹æ®èŠ‚ç‚¹ç±»å‹ç­›é€‰å€™é€‰èŠ‚ç‚¹ï¼Œæ’é™¤æŒ‡å®šèŠ‚ç‚¹
        # Filter candidates by node type, excluding specified node
        if node_type == 'RSU':
            candidates = [rsu for rsu in self.rsus if rsu != exclude_node]
        elif node_type == 'UAV':
            candidates = [uav for uav in self.uavs if uav != exclude_node]
        else:
            return None
        
        if not candidates:
            return None
        
        # æ‰¾åˆ°é˜Ÿåˆ—é•¿åº¦æœ€çŸ­çš„èŠ‚ç‚¹ï¼ˆè´Ÿè½½æœ€è½»ï¼‰
        # Find the node with the shortest queue (least loaded)
        # ä½¿ç”¨minå‡½æ•°é…åˆlambdaè¡¨è¾¾å¼ï¼ŒæŒ‰computation_queueé•¿åº¦æ’åº
        # Use min function with lambda to sort by computation_queue length
        best_node: Optional[Dict] = min(candidates, key=lambda n: len(n.get('computation_queue', [])))
        return best_node
    
    def _process_node_queues(self):
        """
        ğŸ”‘ å…³é”®ä¿®å¤ï¼šå¤„ç†RSUå’ŒUAVé˜Ÿåˆ—ä¸­çš„ä»»åŠ¡ï¼Œé˜²æ­¢ä»»åŠ¡å †ç§¯
        
        éå†æ‰€æœ‰RSUå’ŒUAVèŠ‚ç‚¹ï¼Œå¤„ç†å®ƒä»¬è®¡ç®—é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡ã€‚
        è¿™æ˜¯ä»»åŠ¡æ‰§è¡Œçš„æ ¸å¿ƒé€»è¾‘ã€‚
        
        Process tasks in RSU and UAV queues to prevent task accumulation.
        """
        # å¤„ç†æ‰€æœ‰RSUé˜Ÿåˆ—
        for idx, rsu in enumerate(self.rsus):
            self._process_single_node_queue(rsu, 'RSU', idx)
        
        # å¤„ç†æ‰€æœ‰UAVé˜Ÿåˆ—
        for idx, uav in enumerate(self.uavs):
            self._process_single_node_queue(uav, 'UAV', idx)
    
    def _get_node_capacity_scale(self, node: Dict, node_type: str) -> float:
        """æ ¹æ®ä¸­å¤®èµ„æºåˆ†é…ç»“æœè®¡ç®—èŠ‚ç‚¹å¤„ç†èƒ½åŠ›ç¼©æ”¾å› å­ã€‚"""
        if node_type == 'RSU':
            reference = float(getattr(self, 'rsu_reference_freq', 15e9))
            baseline = float(getattr(self, 'rsu_cpu_freq', reference))
        else:
            reference = float(getattr(self, 'uav_reference_freq', 4e9))
            baseline = float(getattr(self, 'uav_cpu_freq', reference))
        allocated = float(node.get('allocated_compute', baseline))
        denominator = max(reference, 1e-9)
        scale = allocated / denominator
        return float(np.clip(scale, 0.2, 3.0))

    def _is_node_admissible(self, node: Dict, node_type: str) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å…è®¸æ–°çš„å¸è½½ä»»åŠ¡è¿›å…¥
        
        ğŸ”§ ç´§æ€¥ä¿®å¤ï¼šå¤§å¹…æ”¾å®½å‡†å…¥é˜ˆå€¼ï¼Œè®©UAVä¹Ÿèƒ½æ¥å—ä»»åŠ¡
        """
        queue_len = len(node.get('computation_queue', []))
        capacity = self.rsu_nominal_capacity if node_type == 'RSU' else self.uav_nominal_capacity
        ratio = queue_len / max(1.0, capacity)
        usage = float(node.get('compute_usage', 0.0))
        
        # ğŸ”§ ç´§æ€¥ä¿®å¤ï¼šå¤§å¹…æ”¾å®½é˜ˆå€¼ï¼Œè®©èŠ‚ç‚¹èƒ½å¤Ÿæ¥å—æ›´å¤šä»»åŠ¡
        # åŸé˜ˆå€¼è¿‡äºä¸¥æ ¼ï¼Œå¯¼è‡´å¤§é‡ä»»åŠ¡è¢«æ‹’ç»
        if node_type == 'UAV':
            queue_threshold = 5.0  # UAVé˜Ÿåˆ—å…è®¸500%å®¹é‡ï¼ˆæåº¦å®½æ¾ï¼‰
            usage_threshold = 5.0  # UAVä½¿ç”¨ç‡å…è®¸500%
        else:  # RSU
            queue_threshold = 3.0  # RSUé˜Ÿåˆ—å…è®¸300%å®¹é‡ï¼ˆå®½æ¾ï¼‰
            usage_threshold = 3.0  # RSUä½¿ç”¨ç‡å…è®¸300%
        
        # é˜Ÿåˆ—æ£€æŸ¥ï¼šé˜Ÿåˆ—é•¿åº¦ < é˜ˆå€¼
        queue_ok = ratio < queue_threshold
        # ä½¿ç”¨ç‡æ£€æŸ¥ï¼šä½¿ç”¨ç‡ < é˜ˆå€¼ æˆ–è€… ä½¿ç”¨ç‡ä¸º0ï¼ˆåˆå§‹çŠ¶æ€ï¼‰
        usage_ok = usage < usage_threshold or usage == 0.0
        
        return queue_ok and usage_ok

    def _record_offload_rejection(self, node_type: str, reason: str = 'unknown') -> None:
        """è®°å½•ç”±äºæ‹¥å¡/ç­–ç•¥å¯¼è‡´çš„è¿œç«¯å¸è½½æ‹’ç»ã€‚"""
        stats_default: Dict[str, Any] = {
            'total': 0,
            'by_type': {'RSU': 0, 'UAV': 0},
            'by_reason': {}
        }
        stats = self.stats.setdefault('remote_rejections', stats_default)
        if not isinstance(stats, dict):
            stats = stats_default
        stats['total'] = stats.get('total', 0) + 1
        by_type = stats.setdefault('by_type', {})
        if isinstance(by_type, dict):
            by_type[node_type] = by_type.get(node_type, 0) + 1
        by_reason = stats.setdefault('by_reason', {})
        if isinstance(by_reason, dict):
            by_reason[reason] = by_reason.get(reason, 0) + 1

    def _process_single_node_queue(self, node: Dict, node_type: str, node_idx: int) -> None:
        """
        å¤„ç†å•ä¸ªèŠ‚ç‚¹çš„è®¡ç®—é˜Ÿåˆ—
        
        å®ç°åŠ¨æ€ä»»åŠ¡è°ƒåº¦ï¼Œæ ¹æ®é˜Ÿåˆ—é•¿åº¦è‡ªé€‚åº”è°ƒæ•´å¤„ç†èƒ½åŠ›ï¼š
        - åŸºç¡€å¤„ç†èƒ½åŠ›ï¼šæ¯ä¸ªæ—¶éš™å¤„ç†å›ºå®šæ•°é‡çš„ä»»åŠ¡
        - åŠ¨æ€æå‡ï¼šé˜Ÿåˆ—è¿‡é•¿æ—¶å¢åŠ å¤„ç†èƒ½åŠ›
        - å·¥ä½œé‡è®¡ç®—ï¼šåŸºäºä»»åŠ¡çš„è®¡ç®—éœ€æ±‚
        
        Args:
            node: èŠ‚ç‚¹å­—å…¸ï¼ˆRSUæˆ–UAVï¼‰
            node_type: èŠ‚ç‚¹ç±»å‹ï¼ˆ'RSU'æˆ–'UAV'ï¼‰
            
        Process single node's computation queue with adaptive scheduling.
        """
        queue = node.get('computation_queue', [])
        queue_len = len(queue)
        if queue_len == 0:
            # ğŸ”§ ä¿®å¤ï¼šå³ä½¿é˜Ÿåˆ—ä¸ºç©ºï¼ŒRSU/UAVä¹Ÿæ¶ˆè€—é™æ€åŠŸè€—
            if node_type in ['RSU', 'UAV']:
                # è·å–é™æ€åŠŸè€—é…ç½®
                if node_type == 'RSU':
                    static_power = getattr(self.sys_config.compute, 'rsu_static_power', 25.0) if self.sys_config else 25.0
                else:
                    static_power = getattr(self.sys_config.compute, 'uav_static_power', 2.5) if self.sys_config else 2.5
                
                # è®¡ç®—é™æ€èƒ½è€—
                static_energy = static_power * self.time_slot
                
                # ç´¯åŠ èƒ½è€—
                self._accumulate_energy('energy_compute', static_energy)
                node['energy_consumed'] = node.get('energy_consumed', 0.0) + static_energy

            self._record_mm1_queue_length(node_type, node_idx, 0)
            return

        # æ ¹æ®èŠ‚ç‚¹ç±»å‹è·å–å¤„ç†èƒ½åŠ›é…ç½®
        # Get processing capacity configuration based on node type
        # ğŸ”§ ä¿®å¤: å¢å¼ºé…ç½®ä¸€è‡´æ€§æ£€æŸ¥
        if node_type == 'RSU':
            if self.service_config and hasattr(self.service_config, 'rsu_base_service'):
                base_capacity = int(self.service_config.rsu_base_service)  # åŸºç¡€å¤„ç†èƒ½åŠ›
                max_service = int(getattr(self.service_config, 'rsu_max_service', 9))  # æœ€å¤§å¤„ç†èƒ½åŠ›
                boost_divisor = float(getattr(self.service_config, 'rsu_queue_boost_divisor', 5.0))  # åŠ¨æ€æå‡é™¤æ•°
                work_capacity_cfg = float(getattr(self.service_config, 'rsu_work_capacity', 2.5))  # å·¥ä½œå®¹é‡
            else:
                base_capacity = int(self.config.get('rsu_base_service', 4))
                max_service = int(self.config.get('rsu_max_service', 9))
                boost_divisor = 5.0
                work_capacity_cfg = float(self.config.get('rsu_work_capacity', 2.5))
        elif node_type == 'UAV':
            if self.service_config and hasattr(self.service_config, 'uav_base_service'):
                base_capacity = int(self.service_config.uav_base_service)
                max_service = int(getattr(self.service_config, 'uav_max_service', 6))
                boost_divisor = float(getattr(self.service_config, 'uav_queue_boost_divisor', 4.0))
                work_capacity_cfg = float(getattr(self.service_config, 'uav_work_capacity', 1.7))
            else:
                base_capacity = int(self.config.get('uav_base_service', 3))
                max_service = int(self.config.get('uav_max_service', 6))
                boost_divisor = 4.0
                work_capacity_cfg = float(self.config.get('uav_work_capacity', 1.7))
        else:
            # æœªçŸ¥èŠ‚ç‚¹ç±»å‹ä½¿ç”¨é»˜è®¤å€¼
            base_capacity = 2
            max_service = 4
            boost_divisor = 5.0
            work_capacity_cfg = 1.2

        capacity_scale = self._get_node_capacity_scale(node, node_type)
        base_capacity = max(1, int(round(base_capacity * capacity_scale)))
        max_service = max(base_capacity, int(round(max_service * capacity_scale)))
        work_capacity_cfg *= capacity_scale

        if queue_len > base_capacity:
            dynamic_boost = int(np.ceil((queue_len - base_capacity) / boost_divisor))
        else:
            dynamic_boost = 0

        tasks_to_process = min(queue_len, base_capacity + dynamic_boost)
        tasks_to_process = min(tasks_to_process, max_service)
        tasks_to_process = max(tasks_to_process, min(queue_len, base_capacity))

        new_queue: List[Dict] = []
        current_time = getattr(self, 'current_time', 0.0)
        
        # ğŸ”§ ä¿®å¤v3ï¼šåŸºäºå®é™…è®¡ç®—å‘¨æœŸå’ŒCPUé¢‘ç‡è®¡ç®—å¤„ç†è¿›åº¦
        # é—®é¢˜åŸå› ï¼šåŸwork_remaining=0.5æ˜¯æŠ½è±¡å€¼ï¼Œå¯¼è‡´ä»»åŠ¡æ€»æ˜¯4-5ä¸ªæ—¶éš™å®Œæˆ
        # è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨å®é™…çš„compute_cycleså’Œcpu_freqè®¡ç®—
        
        # è·å–èŠ‚ç‚¹CPUé¢‘ç‡
        if node_type == 'RSU':
            cpu_freq = getattr(self.sys_config.compute, 'rsu_cpu_freq', 12.5e9) if self.sys_config else 12.5e9
        elif node_type == 'UAV':
            cpu_freq = getattr(self.sys_config.compute, 'uav_cpu_freq', 5.0e9) if self.sys_config else 5.0e9
        else:
            cpu_freq = 2.5e9  # Vehicleé»˜è®¤
        
        # æ¯ä¸ªæ—¶éš™å¯å¤„ç†çš„è®¡ç®—å‘¨æœŸæ•°
        cycles_per_slot = cpu_freq * self.time_slot
        
        # æœ¬æ—¶éš™å·²ä½¿ç”¨çš„å‘¨æœŸï¼ˆç”¨äºå®¹é‡é™åˆ¶ï¼‰
        total_cycles_used = 0.0

        for idx, task in enumerate(queue):
            if current_time - task.get('queued_at', -1e9) < self.time_slot:
                new_queue.append(task)
                continue

            if idx >= tasks_to_process:
                new_queue.append(task)
                continue
            
            # ğŸ”§ ä¿®å¤v3ï¼šä½¿ç”¨å®é™…å‰©ä½™è®¡ç®—å‘¨æœŸ
            # é¦–æ¬¡å¤„ç†æ—¶ï¼Œä»compute_cyclesåˆå§‹åŒ–
            if 'remaining_cycles' not in task:
                task['remaining_cycles'] = float(task.get('compute_cycles', 1e9))
            
            previous_cycles = task['remaining_cycles']
            
            # è®¡ç®—æœ¬æ—¶éš™å¯åˆ†é…ç»™æ­¤ä»»åŠ¡çš„å‘¨æœŸæ•°
            # å®¹é‡é™åˆ¶ï¼šèŠ‚ç‚¹æ¯æ—¶éš™åªèƒ½å¤„ç† cycles_per_slot å‘¨æœŸ
            available_cycles = max(0.0, cycles_per_slot - total_cycles_used)
            cycles_to_process = min(previous_cycles, available_cycles)
            
            remaining_cycles = max(0.0, previous_cycles - cycles_to_process)
            task['remaining_cycles'] = remaining_cycles
            total_cycles_used += cycles_to_process
            
            # è®¡ç®—å®é™…å¤„ç†æ—¶é—´å’ŒæœåŠ¡æ—¶é—´
            actual_processing_time = cycles_to_process / cpu_freq if cpu_freq > 0 else 0.0
            task['service_time'] = task.get('service_time', 0.0) + actual_processing_time
            
            # å…¼å®¹æ€§ï¼šä¿ç•™work_remainingç”¨äºå…¶ä»–æ¨¡å—
            original_cycles = float(task.get('compute_cycles', 1e9))
            if original_cycles > 0:
                task['work_remaining'] = remaining_cycles / original_cycles
            else:
                task['work_remaining'] = 0.0
            
            consumed_ratio = cycles_to_process / max(previous_cycles, 1e-9)
            consumed_ratio = float(np.clip(consumed_ratio, 0.0, 1.0))
            incremental_service = actual_processing_time

            # ğŸ”§ ä¿®å¤ï¼šè®¡ç®—RSU/UAVå¤„ç†èƒ½è€—
            # Fix: Calculate energy consumption for RSU/UAV processing
            if node_type in ['RSU', 'UAV']:
                # è·å–èŠ‚ç‚¹é…ç½®
                if node_type == 'RSU':
                    cpu_freq = getattr(self.sys_config.compute, 'rsu_cpu_freq', 12.5e9) if self.sys_config else 12.5e9
                    static_power = getattr(self.sys_config.compute, 'rsu_static_power', 25.0) if self.sys_config else 25.0
                else:
                    cpu_freq = getattr(self.sys_config.compute, 'uav_cpu_freq', 5.0e9) if self.sys_config else 5.0e9
                    static_power = getattr(self.sys_config.compute, 'uav_static_power', 2.5) if self.sys_config else 2.5
                
                # åŠ¨æ€åŠŸè€—ç³»æ•°
                kappa = 1e-28
                dynamic_power = kappa * (cpu_freq ** 3)
                
                # è®¡ç®—æœ¬æ—¶éš™æ¶ˆè€—çš„èƒ½è€—
                step_energy = (dynamic_power + static_power) * incremental_service
                
                # ç´¯åŠ èƒ½è€—
                self._accumulate_energy('energy_compute', step_energy)
                node['energy_consumed'] = node.get('energy_consumed', 0.0) + step_energy

            if task.get('remaining_cycles', 0.0) > 0.0:
                new_queue.append(task)
                continue

            # ğŸ†• Luoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼šä»»åŠ¡å®Œæˆæ—¶åŒæ­¥ä»clifetime_queuesä¸­ç§»é™¤
            self._remove_task_from_lifetime_queues(node, task)
            
            # DEBUG LOGGING - ENTRY
            # print(f"[DEBUG] Processing task {task.get('id')} at {node_type}, Content: {task.get('content_id')}")

            # ğŸ”§ ä¿®å¤ï¼šä»»åŠ¡å®Œæˆåå°è¯•ç¼“å­˜å†…å®¹
            if node_type in ['RSU', 'UAV']:
                cache_ctrl = getattr(self, 'adaptive_cache_controller', None)
                content_id = task.get('content_id')
                if cache_ctrl and content_id:
                    try:
                        # è·å–å†…å®¹å¤§å°å’Œç¼“å­˜çŠ¶æ€
                        data_size = self._get_realistic_content_size(content_id)
                        cache_snapshot = node.get('cache', {})
                        capacity = float(node.get('cache_capacity', 1000.0 if node_type == 'RSU' else 200.0))
                        used = sum(float(item.get('size', 0.0)) for item in cache_snapshot.values())
                        available = max(0.0, capacity - used)
                        
                        # å†³ç­–æ˜¯å¦ç¼“å­˜
                        should_cache, reason, evictions = cache_ctrl.should_cache_content(
                            content_id, data_size, available, cache_snapshot, capacity,
                            cache_priority=task.get('priority', 0.5)
                        )
                        
                        # DEBUG LOGGING
                        print(f"[DEBUG] Content: {content_id}, Should: {should_cache}, Reason: {reason}")
                        
                        if should_cache:
                            if 'cache' not in node:
                                node['cache'] = {}
                            cache_dict = node['cache']
                            
                            # æ‰§è¡Œæ·˜æ±°
                            reclaimed = 0.0
                            for evict_id in evictions:
                                removed = cache_dict.pop(evict_id, None)
                                if removed:
                                    reclaimed += float(removed.get('size', 0.0) or 0.0)
                                    cache_ctrl.cache_stats['evicted_items'] += 1
                            
                            if reclaimed > 0.0:
                                available += reclaimed
                                
                            # å†™å…¥ç¼“å­˜
                            if available >= data_size:
                                cache_dict[content_id] = {
                                    'size': data_size,
                                    'timestamp': self.current_time,
                                    'reason': reason or 'post_process_cache',
                                    'content_type': self._infer_content_type(content_id)
                                }
                                # æ›´æ–°çƒ­åº¦
                                cache_ctrl.update_content_heat(content_id)
                                print(f"[DEBUG] Cached {content_id} at {node_type}")
                    except Exception as e:
                        print(f"[DEBUG] Cache error: {e}")
                        pass

            self.stats['completed_tasks'] += 1
            self.stats['processed_tasks'] = self.stats.get('processed_tasks', 0) + 1

            actual_delay = current_time - task.get('arrival_time', current_time)
            clip_upper = getattr(self, 'delay_clip_upper', 0.0)
            if clip_upper > 0.0:
                actual_delay = min(actual_delay, clip_upper)
            actual_delay = max(0.0, actual_delay)
            service_time = min(actual_delay, task.get('service_time', actual_delay))
            wait_delay = max(0.0, actual_delay - service_time)
            self._accumulate_delay('delay_processing', service_time)
            if wait_delay > 0.0:
                self._accumulate_delay('delay_waiting', wait_delay)
            self._record_mm1_service(node_type, node_idx, actual_delay)
            
            # æŒ‰ä»»åŠ¡ç±»åˆ«è®°å½•æ—¶å»¶ç»Ÿè®¡
            self._record_task_type_delay(task, actual_delay)

            vehicle_id = task.get('vehicle_id', 'V_0')
            vehicle = next((v for v in self.vehicles if v['id'] == vehicle_id), None)

            # ğŸ”¥ æ·±åº¦ä¿®å¤ï¼šæ­£ç¡®çš„CMOSèƒ½è€—æ¨¡å‹
            # E_total = (P_dynamic + P_static) Ã— t_processing
            # P_dynamic = Îº Ã— fÂ³ï¼Œä½† t_processing = C / f
            # å› æ­¤èƒ½è€—åº”éšé¢‘ç‡å¢åŠ è€Œä¼˜åŒ–ï¼Œè€Œéæš´æ¶¨
            
            if node_type == 'RSU':
                # RSUèƒ½è€—å‚æ•°
                cpu_freq = node.get('cpu_freq', 12.5e9)  # 12.5 GHz
                kappa = 5.0e-32  # W/(Hz)Â³
                static_power = 25.0  # W
                
                # ğŸ”§ ä¿®å¤: å¢å¼ºé…ç½®ä¸€è‡´æ€§æ£€æŸ¥
                if self.sys_config is not None and hasattr(self.sys_config, 'compute'):
                    cpu_freq = getattr(self.sys_config.compute, 'rsu_cpu_freq', cpu_freq)
                    kappa = getattr(self.sys_config.compute, 'rsu_kappa', kappa)
                    static_power = getattr(self.sys_config.compute, 'rsu_static_power', static_power)
                
                # ğŸ”§ ä¿®å¤v3ï¼šä½¿ç”¨ä»»åŠ¡å®é™…çš„compute_cyclesè®¡ç®—å¤„ç†æ—¶é—´å’Œèƒ½è€—
                task_compute_cycles = float(task.get('compute_cycles', 1e9))
                # å®é™…å¤„ç†æ—¶é—´ = è®¡ç®—å‘¨æœŸ / CPUé¢‘ç‡
                task_processing_time = task_compute_cycles / cpu_freq
                
                # åŠ¨æ€åŠŸè€— = Îº Ã— fÂ³
                dynamic_power = kappa * (cpu_freq ** 3)
                # æ€»èƒ½è€— = (åŠ¨æ€åŠŸè€— + é™æ€åŠŸè€—) Ã— å®é™…å¤„ç†æ—¶é—´
                task_energy = (dynamic_power + static_power) * task_processing_time
                
            elif node_type == 'UAV':
                # ğŸ”§ ä¼˜åŒ–: ç»Ÿä¸€ä»é…ç½®è¯»å–UAVèƒ½è€—å‚æ•°
                # UAVèƒ½è€—å‚æ•°ï¼ˆåŒ…å«æ‚¬åœåŠŸè€—ï¼‰
                
                # é»˜è®¤å€¼ï¼šåŸºäºNVIDIA Jetson Xavier NX
                default_cpu_freq = 3.5e9   # 3.5 GHzï¼ˆåŒ¹é…é…ç½®ï¼‰
                default_kappa3 = 8.89e-31  # W/(Hz)Â³
                default_static = 2.5       # W
                default_hover = 15.0       # W - è½»é‡çº§å››æ—‹ç¿¼ï¼ˆåŒ¹é…é…ç½®ï¼‰
                
                # ä¼˜å…ˆä»é…ç½®è¯»å–
                if self.sys_config is not None and hasattr(self.sys_config, 'compute'):
                    cpu_freq = getattr(self.sys_config.compute, 'uav_cpu_freq', default_cpu_freq)
                    kappa3 = getattr(self.sys_config.compute, 'uav_kappa3', default_kappa3)
                    static_power = getattr(self.sys_config.compute, 'uav_static_power', default_static)
                    hover_power = getattr(self.sys_config.compute, 'uav_hover_power', default_hover)
                else:
                    cpu_freq = node.get('cpu_freq', default_cpu_freq)
                    kappa3 = default_kappa3
                    static_power = default_static
                    hover_power = default_hover
                
                # ğŸ”§ ä¿®å¤v3ï¼šä½¿ç”¨ä»»åŠ¡å®é™…çš„compute_cycles
                task_compute_cycles = float(task.get('compute_cycles', 1e9))
                task_processing_time = task_compute_cycles / cpu_freq
                
                # åŠ¨æ€åŠŸè€— = Îº Ã— fÂ³
                dynamic_power = kappa3 * (cpu_freq ** 3)
                # UAVæ€»èƒ½è€— = (åŠ¨æ€ + é™æ€ + æ‚¬åœ) Ã— å®é™…å¤„ç†æ—¶é—´
                task_energy = (dynamic_power + static_power + hover_power) * task_processing_time
                
            else:
                # å…¶ä»–èŠ‚ç‚¹ç±»å‹ä½¿ç”¨ç®€åŒ–æ¨¡å‹
                task_compute_cycles = float(task.get('compute_cycles', 1e9))
                task_energy = 1e-9 * task_compute_cycles  # ç®€åŒ–ï¼šæ¯cycleçº¦1nJ
            self._accumulate_energy('energy_compute', task_energy)
            node['energy_consumed'] = node.get('energy_consumed', 0.0) + task_energy

            # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ ä¸‹è¡Œä¼ è¾“èƒ½è€—ï¼ˆå°†å¤„ç†ç»“æœä¼ å›è½¦è¾†ï¼‰
            # Fix: Add downlink transmission energy (return result to vehicle)
            result_size = task.get('data_size_bytes', 1e6) * 0.05  # Result is typically 5% of input
            if result_size > 0:
                # Find the vehicle to calculate distance
                vehicle_id = task.get('vehicle_id', 'V_0')
                vehicle = next((v for v in self.vehicles if v['id'] == vehicle_id), None)
                
                if vehicle:
                    v_pos = np.array(vehicle.get('position', [0.0, 0.0, 0.0]))
                    n_pos = np.array(node.get('position', [0.0, 0.0, 0.0]))
                    distance = self.calculate_distance(v_pos, n_pos)
                    
                    down_delay, down_energy = self._estimate_transmission(
                        result_size, distance, node_type.lower()
                    )
                    
                    # Accumulate downlink delay and energy
                    self._accumulate_delay('delay_downlink', down_delay)
                    self._accumulate_energy('energy_transmit_downlink', down_energy)
                    self.stats['energy_downlink'] = self.stats.get('energy_downlink', 0.0) + down_energy
                    node['energy_consumed'] = node.get('energy_consumed', 0.0) + down_energy

            task['completed'] = True

        node['computation_queue'] = new_queue
        self._record_mm1_queue_length(node_type, node_idx, len(new_queue))


    def find_nearest_rsu(self, vehicle_pos: np.ndarray) -> Optional[Dict]:
        """
        ??????????????????RSU?
        Fallback to brute-force iteration when the index is unavailable.
        """
        if not self.rsus:
            return None

        vehicle_vec = np.asarray(vehicle_pos, dtype=float)
        best_node: Optional[Dict] = None
        best_distance = float('inf')

        spatial_index = getattr(self, 'spatial_index', None)
        if spatial_index is not None:
            nearest = spatial_index.find_nearest_rsu(vehicle_vec, return_distance=True)
            if nearest:
                _, node, dist = nearest
                coverage = float(node.get('coverage_radius', self.coverage_radius))
                if dist <= coverage:
                    return node
                best_node = node
                best_distance = dist

            max_radius = spatial_index.rsu_max_radius or max(
                (float(rsu.get('coverage_radius', self.coverage_radius)) for rsu in self.rsus),
                default=self.coverage_radius,
            )
            neighbors = spatial_index.query_rsus_within_radius(vehicle_vec, max_radius)
            for _, node, dist in neighbors:
                coverage = float(node.get('coverage_radius', self.coverage_radius))
                if dist <= coverage and dist < best_distance:
                    best_node = node
                    best_distance = dist

            if best_node and best_distance <= best_node.get('coverage_radius', self.coverage_radius):
                return best_node

        for rsu in self.rsus:
            distance = self.calculate_distance(vehicle_vec, rsu['position'])
            coverage = float(rsu.get('coverage_radius', self.coverage_radius))
            if distance <= coverage and distance < best_distance:
                best_node = rsu
                best_distance = distance

        return best_node

    def find_nearest_uav(self, vehicle_pos: np.ndarray) -> Optional[Dict]:
        """
        ???????????UAV???
        """
        if not self.uavs:
            return None

        vehicle_vec = np.asarray(vehicle_pos, dtype=float)
        spatial_index = getattr(self, 'spatial_index', None)
        if spatial_index is not None:
            nearest = spatial_index.find_nearest_uav(vehicle_vec, return_distance=True)
            if nearest:
                return nearest[1]

        min_distance = float('inf')
        nearest_uav: Optional[Dict] = None
        for uav in self.uavs:
            distance = self.calculate_distance(vehicle_vec, uav['position'])
            if distance < min_distance:
                min_distance = distance
                nearest_uav = uav

        return nearest_uav

    def check_cache_hit(self, content_id: str, node: Dict) -> bool:
        """
        æ£€æŸ¥ç¼“å­˜å‘½ä¸­
        
        Args:
            content_id: å†…å®¹ID
            node: èŠ‚ç‚¹å­—å…¸
            
        Returns:
            Trueè¡¨ç¤ºå‘½ä¸­ï¼ŒFalseè¡¨ç¤ºæœªå‘½ä¸­
            
        Check if content is cached in the node.
        """
        if content_id in node.get('cache', {}):
            self.stats['cache_hits'] += 1
            return True
        else:
            self.stats['cache_misses'] += 1
            return False
    
    def check_cache_hit_adaptive(
        self,
        content_id: str,
        node: Dict,
        agents_actions: Optional[Dict] = None,
        node_type: str = 'RSU',
        task: Optional[Dict] = None  # ğŸ”§ ä¼˜åŒ–9: æ·»åŠ taskå‚æ•°ä»¥è·å–cache_priority
    ) -> bool:
        """
        ğŸŒŸ æ™ºèƒ½ä½“æ§åˆ¶çš„è‡ªé€‚åº”ç¼“å­˜æ£€æŸ¥
        
        ç»“åˆæ™ºèƒ½ç¼“å­˜æ§åˆ¶å™¨ï¼Œå®ç°è‡ªé€‚åº”çš„ç¼“å­˜ç­–ç•¥ï¼š
        - åŸºç¡€ç¼“å­˜å‘½ä¸­æ£€æŸ¥
        - ç¼“å­˜æœªå‘½ä¸­æ—¶çš„æ™ºèƒ½å†³ç­–ï¼ˆæ˜¯å¦ç¼“å­˜ã€å¦‚ä½•æ·˜æ±°ï¼‰
        - ååŒç¼“å­˜ä¼ æ’­ï¼ˆRSUåˆ°è½¦è¾†ã€RSUåˆ°RSUï¼‰
        - å†…å®¹çƒ­åº¦è¿½è¸ª
        
        Args:
            content_id: å†…å®¹ID
            node: èŠ‚ç‚¹å­—å…¸
            agents_actions: æ™ºèƒ½ä½“åŠ¨ä½œå­—å…¸ï¼ˆåŒ…å«cache_controllerï¼‰
            node_type: èŠ‚ç‚¹ç±»å‹ï¼ˆ'RSU'æˆ–'UAV'ï¼‰
            
        Returns:
            Trueè¡¨ç¤ºå‘½ä¸­ï¼ŒFalseè¡¨ç¤ºæœªå‘½ä¸­
            
        Adaptive cache checking with intelligent caching controller.
        """
        # ğŸ”§ ä¼˜åŒ–6: ä¸å¯ç¼“å­˜å†…å®¹ç›´æ¥è¿”å›æœªå‘½ä¸­ï¼Œä¸å‚ä¸ç»Ÿè®¡
        if not content_id:
            return False
        
        # åŸºç¡€ç¼“å­˜æ£€æŸ¥
        # Basic cache check
        cache = node.get('cache', {})
        cache_hit = bool(content_id and cache and content_id in cache)
        
        # ğŸ”§ ä¿®å¤ï¼šåªç»Ÿè®¡æœ‰content_idçš„ä»»åŠ¡ï¼Œé¿å…ç»Ÿè®¡æ‰­æ›²
        # ä¸å¯ç¼“å­˜çš„ä»»åŠ¡ä¸åº”è¯¥å½±å“ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡
        self._register_cache_request(cache_hit)
        
        # æ›´æ–°ç»Ÿè®¡
        # Update statistics
        if cache_hit:
            self.stats['cache_hits'] += 1
            # ğŸ”§ æ–°å¢ï¼šæ›´æ–°RSUç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡ï¼ˆç”¨äºçŠ¶æ€ç¼–ç ï¼‰
            if node_type == 'RSU':
                node['cache_hits_window'] = node.get('cache_hits_window', 0) + 1
                node['cache_requests_window'] = node.get('cache_requests_window', 0) + 1
                # æ¯100æ¬¡è¯·æ±‚æ›´æ–°ä¸€æ¬¡å‘½ä¸­ç‡ï¼ˆæ»šåŠ¨çª—å£ï¼‰
                if node['cache_requests_window'] >= 100:
                    node['recent_cache_hit_rate'] = node['cache_hits_window'] / node['cache_requests_window']
                    # é‡ç½®çª—å£
                    node['cache_hits_window'] = 0
                    node['cache_requests_window'] = 0
                elif node['cache_requests_window'] > 0:
                    # å®æ—¶æ›´æ–°ï¼ˆä½†ä¸é‡ç½®ï¼‰
                    node['recent_cache_hit_rate'] = node['cache_hits_window'] / node['cache_requests_window']
                self._propagate_cache_after_hit(content_id, node, agents_actions)
        else:
            self.stats['cache_misses'] += 1
            # ğŸ”§ æ–°å¢ï¼šæ›´æ–°RSUç¼“å­˜ç»Ÿè®¡ï¼ˆæœªå‘½ä¸­ï¼‰
            if node_type == 'RSU':
                node['cache_requests_window'] = node.get('cache_requests_window', 0) + 1
                if node['cache_requests_window'] >= 100:
                    node['recent_cache_hit_rate'] = node.get('cache_hits_window', 0) / node['cache_requests_window']
                    node['cache_hits_window'] = 0
                    node['cache_requests_window'] = 0
                elif node['cache_requests_window'] > 0:
                    node['recent_cache_hit_rate'] = node.get('cache_hits_window', 0) / node['cache_requests_window']
            
            # ğŸŒŸ å¦‚æœæœ‰æ™ºèƒ½ä½“æ§åˆ¶å™¨ï¼Œæ‰§è¡Œè‡ªé€‚åº”ç¼“å­˜ç­–ç•¥
            # Execute adaptive caching strategy with intelligent controller
            if agents_actions and 'cache_controller' in agents_actions:
                cache_controller = agents_actions['cache_controller']
                rl_guidance = agents_actions.get('rl_guidance') if isinstance(agents_actions, dict) else None
                cache_preference = 0.5
                if isinstance(rl_guidance, dict):
                    tradeoff_weights = rl_guidance.get('tradeoff_weights')
                    if isinstance(tradeoff_weights, (list, tuple)) and len(tradeoff_weights) >= 2:
                        cache_preference = float(np.clip(tradeoff_weights[1], 0.0, 1.0))
                    else:
                        cache_bias = rl_guidance.get('cache_bias')
                        if isinstance(cache_bias, (list, tuple)) and len(cache_bias) > 0:
                            cache_preference = float(np.clip(np.mean(cache_bias), 0.0, 1.0))
                    energy_pressure_vec = rl_guidance.get('energy_pressure')
                    if isinstance(energy_pressure_vec, (list, tuple, np.ndarray)):
                        energy_pressure = float(np.clip(np.asarray(energy_pressure_vec, dtype=float).reshape(-1)[0], 0.35, 1.8))
                        cache_preference = float(np.clip(cache_preference * energy_pressure, 0.0, 1.0))

                
                # æ›´æ–°å†…å®¹çƒ­åº¦
                # Update content heat
                cache_controller.update_content_heat(content_id)
                cache_controller.record_cache_result(content_id, was_hit=False)
                
                # ğŸ”‘ ä¿®å¤ï¼šä½¿ç”¨realisticå†…å®¹å¤§å°å’Œæ­£ç¡®å®¹é‡è®¡ç®—
                # Fix: Use realistic content size and correct capacity calculation
                data_size = self._get_realistic_content_size(content_id)
                capacity_limit = node.get('cache_capacity', 1000.0 if node_type == 'RSU' else 200.0)
                available_capacity = self._calculate_available_cache_capacity(
                    node.get('cache', {}), capacity_limit
                )
                
                guard_ratio = getattr(self, 'cache_pressure_guard', 0.05)
                pressure_ratio = available_capacity / max(1.0, capacity_limit)
                severe_pressure = pressure_ratio < guard_ratio

                # è°ƒç”¨æ™ºèƒ½æ§åˆ¶å™¨åˆ¤æ–­æ˜¯å¦ç¼“å­˜ï¼ˆåœ¨æç«¯å‹åŠ›ä¸‹ç›´æ¥è·³è¿‡å†™å…¥ï¼‰
                if severe_pressure:
                    should_cache = False
                    reason = 'pressure_guard'
                    evictions = []
                else:
                    # ğŸ”§ ä¼˜åŒ–10: ä¼ å…¥cache_priorityåŠ å¼ºç¼“å­˜å†³ç­–
                    cache_priority = task.get('cache_priority', 0.0) if task else 0.0
                    should_cache, reason, evictions = cache_controller.should_cache_content(
                        content_id,
                        data_size,
                        available_capacity,
                        node.get('cache', {}),
                        capacity_limit,
                        cache_priority  # ä¼ å…¥ä¼˜å…ˆçº§
                    )
                
                # ç¼“å­˜å†™å…¥æ¸©å¯åŠ¨ï¼šå‰warmupæ¬¡è¯·æ±‚å°½é‡ç¼“å­˜ï¼Œé¿å…å†·å¯åŠ¨é•¿æœŸ0å‘½ä¸­
                total_requests_so_far = cache_controller.cache_stats.get('total_requests', 0)
                warmup_threshold = 100
                if total_requests_so_far < warmup_threshold and available_capacity >= data_size:
                    should_cache = True
                    reason = reason or 'warmup_cache'
                    evictions = []

                # RLå¼•å¯¼ï¼šæ¦‚ç‡ç¼©æ”¾è€Œä¸æ˜¯ç¡¬æ€§æ‹¦æˆª
                if not should_cache and cache_preference > 0.7 and available_capacity >= data_size:
                    should_cache = True
                    reason = reason or 'RL-guided cache'
                    evictions = []
                elif should_cache and cache_preference < 0.2:
                    # åœ¨æä½åå¥½æ—¶å¯æ”¾å¼ƒ
                    should_cache = False
                elif should_cache and available_capacity < data_size and not evictions:
                    should_cache = False

                # If decided to cache, perform eviction and write operations
                if should_cache:
                    if 'cache' not in node:
                        node['cache'] = {}
                    cache_dict = node['cache']
                    reclaimed = 0.0
                    # æ‰§è¡Œæ·˜æ±°æ“ä½œï¼Œå›æ”¶ç©ºé—´
                    # Perform eviction to reclaim space
                    for evict_id in evictions:
                        removed = cache_dict.pop(evict_id, None)
                        if removed:
                            reclaimed += float(removed.get('size', 0.0) or 0.0)
                            cache_controller.cache_stats['evicted_items'] += 1
                    if reclaimed > 0.0:
                        available_capacity += reclaimed
                    if available_capacity < data_size:
                        return cache_hit
                    # å†™å…¥æ–°å†…å®¹åˆ°ç¼“å­˜
                    # Write new content to cache
                    cache_dict[content_id] = {
                        'size': data_size,
                        'timestamp': self.current_time,
                        'reason': reason,
                        'content_type': self._infer_content_type(content_id)
                    }
                    # ç»Ÿè®¡ååŒç¼“å­˜å†™å…¥
                    # Count collaborative cache writes
                    if 'Collaborative cache' in reason:
                        cache_controller.cache_stats['collaborative_writes'] += 1
        
        # è®°å½•ç¼“å­˜æ§åˆ¶å™¨ç»Ÿè®¡ï¼ˆç¼“å­˜å‘½ä¸­æƒ…å†µï¼‰
        # Record cache controller statistics (cache hit case)
        if agents_actions and 'cache_controller' in agents_actions and cache_hit:
            cache_controller = agents_actions['cache_controller'] 
            cache_controller.record_cache_result(content_id, was_hit=True)
            cache_controller.update_content_heat(content_id)
            
        return cache_hit
    
    def _calculate_node_rho(self, node: Dict, node_type: str) -> float:
        """Estimate queue utilization (?) based on nominal capacities."""
        if node_type == 'RSU':
            capacity = max(1.0, float(self.rsu_nominal_capacity))
        elif node_type == 'UAV':
            capacity = max(1.0, float(self.uav_nominal_capacity))
        else:
            capacity = 1.0
        queue_length = len(node.get('computation_queue', []))
        return float(queue_length / capacity)

    def _calculate_enhanced_load_factor(self, node: Dict, node_type: str) -> float:
        """
        é¦ƒæ•¡ æ·‡é”›æ°±ç²ºæ¶“â‚¬éœå®ºealisticé¨å‹®ç¤‹æè—‰æ´œç€›æ„¯ç» ?
        é©è½°ç°¬ç€¹ç‚ºæª¯é—ƒç†·åªç’ç†»æµ‡é”›å±¼ç¬‰æµ£è·¨æ•¤é“æ°¬äº£é¨å‹¯æªºé’?
        """
        queue_length = len(node.get('computation_queue', []))
        
        # é¦ƒæ•¡ é©è½°ç°¬ç€¹ç‚ºæª¯ç‘™å‚šç™‚ç’‹å†©æš£ç€¹å½’å™ºé©å“„å™¯
        if node_type == 'RSU':
            # é©è½°ç°¬ç€¹ç‚ºæª¯å¨´å¬­ç˜¯é”›å­¯SUæ¾¶å‹­æ‚Šé‘³è—‰å§ç»¾?0æ¶“æ¢é”â€²è´Ÿå©ŠÂ¤ç¤‹æ?
            queue_factor = self._calculate_node_rho(node, 'RSU')
        else:  # UAV
            # UAVæ¾¶å‹­æ‚Šé‘³è—‰å§ç»¾?0æ¶“æ¢é”â€²è´Ÿå©ŠÂ¤ç¤‹æ?
            queue_factor = self._calculate_node_rho(node, 'UAV')
        
        # é¦ƒæ•¡ æ·‡é”›æ°«å¨‡é¢ã„¦çº­æ®‘ç¼‚æ’³ç“¨ç’ï¼„ç•»
        cache_utilization = self._calculate_correct_cache_utilization(
            node.get('cache', {}), 
            node.get('cache_capacity', 1000.0 if node_type == 'RSU' else 200.0)
        )
        
        # é¦ƒæ•¡ ç» â‚¬é–æ ¦çµ¾é‘å—™â€˜é¨å‹®ç¤‹æå€Ÿç» ?
        load_factor = (
            0.8 * queue_factor +           # é—ƒç†·åªé„å¯Œç‘•ä½½ç¤‹æèŠ¥å¯šé?0%
            0.2 * cache_utilization       # ç¼‚æ’³ç“¨é’â•ƒæ•¤éœ?0%
        )
        
        # é¦ƒæ•¡ æ¶“å¶‰æªºé’è·ºæ¹ª1.0é”›å±½å‘ç’å‘Šæ¨‰ç»€è™¹æ¹¡ç€¹ç‚¶ç¹ƒæç•Œâ–¼æ´?
        return max(0.0, load_factor)
    
    def _monitor_queue_stability(self) -> Dict[str, Any]:
        """Monitor aggregate queue load and report stability metrics."""
        node_rhos: Dict[str, float] = {}
        overloaded_nodes: Dict[str, float] = {}
        approaching_nodes: Dict[str, float] = {}
        total_rho = 0.0
        max_rho = 0.0
        warning_threshold = self.queue_warning_ratio * self.node_max_load_factor if self.node_max_load_factor > 0 else self.queue_warning_ratio

        for idx, rsu in enumerate(self.rsus):
            rho = self._calculate_node_rho(rsu, 'RSU')
            node_id = f'RSU_{idx}'
            node_rhos[node_id] = rho
            total_rho += rho
            max_rho = max(max_rho, rho)
            if rho >= self.node_max_load_factor:
                overloaded_nodes[node_id] = rho
            elif rho >= warning_threshold:
                approaching_nodes[node_id] = rho

        for idx, uav in enumerate(self.uavs):
            rho = self._calculate_node_rho(uav, 'UAV')
            node_id = f'UAV_{idx}'
            node_rhos[node_id] = rho
            total_rho += rho
            max_rho = max(max_rho, rho)
            if rho >= self.node_max_load_factor:
                overloaded_nodes[node_id] = rho
            elif rho >= warning_threshold:
                approaching_nodes[node_id] = rho

        overloaded = total_rho >= self.queue_stability_threshold
        self.stats['queue_rho_sum'] = total_rho
        self.stats['queue_rho_max'] = max_rho
        self.stats['queue_overload_flag'] = overloaded
        self.stats['queue_rho_by_node'] = dict(node_rhos)
        if overloaded:
            self.stats['queue_overload_events'] = self.stats.get('queue_overload_events', 0) + 1

        if overloaded and not self._queue_overload_warning_active:
            detail = ', '.join(f"{node}:{rho:.2f}" for node, rho in overloaded_nodes.items()) or 'none'
            print(f"[Stability] Î£Ï={total_rho:.2f} exceeds threshold {self.queue_stability_threshold:.2f}. Overloaded nodes: {detail}")
        elif not overloaded and self._queue_overload_warning_active:
            print('[Stability] Queue load returned below stability threshold.')

        if not overloaded:
            if approaching_nodes and not self._queue_warning_triggered:
                detail = ', '.join(f"{node}:{rho:.2f}" for node, rho in approaching_nodes.items())
                print(f"[Stability] Queue load approaching limit: {detail}")
                self._queue_warning_triggered = True
            elif not approaching_nodes:
                self._queue_warning_triggered = False
        else:
            self._queue_warning_triggered = True

        self._queue_overload_warning_active = overloaded

        return {
            'queue_rho_sum': total_rho,
            'queue_rho_max': max_rho,
            'queue_overload_flag': overloaded,
            'queue_rho_by_node': node_rhos,
            'queue_overloaded_nodes': overloaded_nodes,
            'queue_warning_nodes': approaching_nodes
        }


    def _summarize_task_types(self) -> Dict[str, Any]:
        """Aggregate per-task-type queues, active counts, and deadline slack."""
        num_types = 4
        queue_counts = np.zeros(num_types, dtype=float)
        active_counts = np.zeros(num_types, dtype=float)
        deadline_sums = np.zeros(num_types, dtype=float)
        deadline_counts = np.zeros(num_types, dtype=float)

        current_time = getattr(self, "current_time", 0.0)

        def _record(entry: Dict[str, Any]) -> Optional[int]:
            task_type = int(entry.get("task_type", 0) or 0) - 1
            if 0 <= task_type < num_types:
                remaining = max(0.0, entry.get("deadline", current_time) - current_time)
                deadline_sums[task_type] += remaining
                deadline_counts[task_type] += 1.0
                return task_type
            return None

        for node in list(self.rsus) + list(self.uavs):
            for task in node.get("computation_queue", []):
                idx = _record(task)
                if idx is not None:
                    queue_counts[idx] += 1.0

        for task in self.active_tasks:
            idx = _record(task)
            if idx is not None:
                active_counts[idx] += 1.0

        if self.task_config is not None and hasattr(self.task_config, "deadline_range"):
            deadline_upper = float(getattr(self.task_config, "deadline_range", (1.0, 10.0))[1])
        else:
            fallback_range = self.config.get("deadline_range", (1.0, 10.0))
            if isinstance(fallback_range, (list, tuple)) and len(fallback_range) >= 2:
                deadline_upper = float(fallback_range[1])
            else:
                deadline_upper = float(self.config.get("deadline_range_max", 10.0))
        deadline_upper = max(deadline_upper, 1.0)

        queue_total = float(queue_counts.sum())
        active_total = float(active_counts.sum())

        def _normalize(counts: np.ndarray, total: float) -> List[float]:
            if total <= 0.0:
                return [0.0] * num_types
            return [float(np.clip(val / total, 0.0, 1.0)) for val in counts]

        deadline_features = []
        for idx in range(num_types):
            if deadline_counts[idx] > 0.0:
                avg_remaining = deadline_sums[idx] / deadline_counts[idx]
                deadline_features.append(float(np.clip(avg_remaining / deadline_upper, 0.0, 1.0)))
            else:
                deadline_features.append(0.0)

        return {
            "task_type_queue_distribution": _normalize(queue_counts, queue_total),
            "task_type_active_distribution": _normalize(active_counts, active_total),
            "task_type_deadline_remaining": deadline_features,
            "task_type_queue_counts": [float(c) for c in queue_counts],
            "task_type_active_counts": [float(c) for c in active_counts],
        }
    
    def _calculate_correct_cache_utilization(self, cache: Dict, cache_capacity_mb: float) -> float:
        """
        é¦ƒæ•¡ ç’ï¼„ç•»å§ï½‡â€˜é¨å‹­ç´¦ç€›æ¨ºåŸ„é¢ã„§å·¼
        """
        if not cache or cache_capacity_mb <= 0:
            return 0.0
        
        total_used_mb = 0.0
        for item in cache.values():
            if isinstance(item, dict) and 'size' in item:
                total_used_mb += float(item.get('size', 0.0))
            else:
                total_used_mb += 1.0  # å…¼å®¹æ—§æ ¼å¼
        
        utilization = total_used_mb / cache_capacity_mb
        return min(1.0, max(0.0, utilization))

    # ==================== æ–°å¢ï¼šä¸€æ­¥ä»¿çœŸæ¶‰åŠçš„æ ¸å¿ƒè¾…åŠ©å‡½æ•° ====================
    # Core helper functions for single-step simulation

    def _update_node_connections(self):
        """
        ğŸ”§ ä¿®å¤: æ›´æ–°RSUå’ŒUAVçš„å³æ—¶è¿æ¥è®¡æ•°
        
        æ ¹æ®å½“å‰è½¦è¾†ä½ç½®è®¡ç®—å“ªäº›è½¦è¾†åœ¨å„èŠ‚ç‚¹çš„è¦†ç›–èŒƒå›´å†…ï¼Œ
        å¹¶æ›´æ–° served_vehicles å’Œ coverage_vehicles è®¡æ•°å™¨ã€‚
        
        ä¼˜å…ˆçº§ï¼šRSU > UAVï¼ˆé¿å…é‡å¤è®¡æ•°ï¼‰
        
        Update immediate connection counts for RSUs and UAVs based on coverage.
        Priority: RSU > UAV (avoid double counting).
        """
        # æ¸…ç©ºè¿æ¥åˆ—è¡¨ï¼ˆå·²ç»åœ¨run_simulation_stepå¼€å¤´é‡ç½®äº†è®¡æ•°å™¨ï¼‰
        for rsu in self.rsus:
            rsu['connected_vehicles'] = []
        for uav in self.uavs:
            uav['connected_vehicles'] = []
        
        # éå†æ‰€æœ‰è½¦è¾†ï¼Œæ£€æŸ¥è¦†ç›–
        for vehicle in self.vehicles:
            v_pos = vehicle.get('position')
            if v_pos is None or len(v_pos) < 2:
                continue
            
            vehicle_id = vehicle.get('id', '')
            connected_to_rsu = False
            
            # 1. æ£€æŸ¥RSUè¦†ç›–ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
            for rsu in self.rsus:
                distance = self.calculate_distance(v_pos, rsu['position'])
                rsu_radius = rsu.get('coverage_radius', self.coverage_radius)
                if distance <= rsu_radius:
                    rsu['served_vehicles'] += 1
                    rsu['coverage_vehicles'] += 1
                    rsu['connected_vehicles'].append(vehicle_id)
                    connected_to_rsu = True
                    break  # åªè¿æ¥åˆ°æœ€è¿‘çš„RSU
            
            # 2. å¦‚æœæ²¡æœ‰RSUè¦†ç›–ï¼Œæ£€æŸ¥UAVè¦†ç›–
            if not connected_to_rsu:
                for uav in self.uavs:
                    uav_pos = uav['position']
                    # 3Dè·ç¦»è®¡ç®—
                    if len(uav_pos) >= 3 and len(v_pos) == 2:
                        distance_2d = np.sqrt((v_pos[0] - uav_pos[0])**2 + (v_pos[1] - uav_pos[1])**2)
                        distance_3d = np.sqrt(distance_2d**2 + uav_pos[2]**2)
                    else:
                        distance_3d = self.calculate_distance(v_pos, uav_pos[:2] if len(uav_pos) >= 2 else uav_pos)
                    
                    uav_radius = uav.get('coverage_radius', self.uav_coverage_radius)
                    if distance_3d <= uav_radius:
                        uav['served_vehicles'] += 1
                        uav['connected_vehicles'].append(vehicle_id)
                        break  # åªè¿æ¥åˆ°æœ€è¿‘çš„UAV

    def _update_vehicle_positions(self):
        """
        ç®€å•æ›´æ–°è½¦è¾†ä½ç½®ï¼Œæ¨¡æ‹Ÿè½¦è¾†æ²¿ä¸»å¹²é“ç§»åŠ¨
        
        å®ç°äº†é€¼çœŸçš„è½¦è¾†ç§»åŠ¨æ¨¡å‹ï¼ŒåŒ…æ‹¬ï¼š
        - é€Ÿåº¦çš„åŠ å‡é€Ÿå˜åŒ–
        - è·¯å£å‡é€Ÿè¡Œä¸ºï¼ˆæ ¹æ®è½¦è¾†è¡Œé©¶æ–¹å‘æ™ºèƒ½åˆ¤æ–­ï¼‰
        - è½¦é“åˆ‡æ¢å’Œæ¨ªå‘æ¼‚ç§»
        - å‘¨æœŸæ€§è¾¹ç•Œæ¡ä»¶ï¼ˆç¯å½¢é“è·¯ï¼‰
        
        Simple vehicle position update with realistic movement simulation.
        """
        for vehicle in self.vehicles:
            position = vehicle.get('position')
            if position is None or len(position) < 2:
                continue

            # === 1) æ›´æ–°é€Ÿåº¦ï¼ˆç¼“æ…¢åŠ å‡é€Ÿ + äº¤å‰å£å‡é€Ÿï¼‰ ===
            # Update velocity with gradual acceleration and intersection slowdown
            base_speed = float(vehicle.get('velocity', 15.0))
            accel_state = vehicle.setdefault('speed_accel', 0.0)
            accel_state = 0.7 * accel_state + np.random.uniform(-0.4, 0.4)

            # ğŸ”§ ä¿®å¤ï¼šåœ¨æ¥è¿‘è·¯å£æ—¶é™ä½é€Ÿåº¦ï¼Œæ ¹æ®è½¦è¾†è¡Œé©¶æ–¹å‘æ™ºèƒ½åˆ¤æ–­è·ç¦»
            # Slow down near intersections based on vehicle heading direction
            direction = vehicle.get('direction', 0.0)
            for intersection in self.intersections.values():
                # åˆ¤æ–­è½¦è¾†ä¸»è¦è¡Œé©¶æ–¹å‘ï¼šä¸œè¥¿å‘(0æˆ–Ï€) vs å—åŒ—å‘(Ï€/2æˆ–-Ï€/2)
                is_horizontal = abs(np.cos(direction)) > abs(np.sin(direction))  # ä¸œè¥¿å‘
                
                if is_horizontal:
                    # æ¨ªå‘è¡Œé©¶çš„è½¦è¾†æ£€æŸ¥Yåæ ‡è·ç¦»
                    dist_to_signal = abs(position[1] - intersection['y'])
                else:
                    # çºµå‘è¡Œé©¶çš„è½¦è¾†æ£€æŸ¥Xåæ ‡è·ç¦»
                    dist_to_signal = abs(position[0] - intersection['x'])
                
                if dist_to_signal < 40.0:
                    accel_state = min(accel_state, -0.8)
                    break

            new_speed = np.clip(base_speed + accel_state, 5.0, 20.0)  # é™ä½æœ€å¤§é€Ÿåº¦åˆ°20m/s (~72km/h)
            vehicle['speed_accel'] = accel_state
            vehicle['velocity'] = new_speed

            # === 2) æ–¹å‘ä¿æŒï¼ŒåŒæ—¶å…è®¸è½»å¾®æ‰°åŠ¨ ===
            heading_jitter = vehicle.setdefault('heading_jitter', 0.0)
            heading_jitter = 0.6 * heading_jitter + np.random.uniform(-0.01, 0.01)
            direction = (direction + heading_jitter) % (2 * np.pi)
            vehicle['direction'] = direction
            vehicle['heading_jitter'] = heading_jitter

            dx = np.cos(direction) * new_speed * self.time_slot
            dy = np.sin(direction) * new_speed * self.time_slot

            # === 3) æ¨ªå‘æ¼‚ç§»ï¼ˆæ¨¡æ‹Ÿè½»å¾®æ¢é“ï¼‰ ===
            # æ ¹æ®è½¦è¾†è¡Œé©¶æ–¹å‘å†³å®šè½¦é“åç§»çš„åº”ç”¨æ–¹å¼
            is_horizontal = abs(np.cos(direction)) > abs(np.sin(direction))
            lane_bias = vehicle.get('lane_bias', 0.0)
            lane_switch_timer = vehicle.setdefault('lane_switch_timer', np.random.randint(80, 160))
            lane_switch_timer -= 1
            if lane_switch_timer <= 0 and np.random.rand() < 0.1:
                lane_bias = np.clip(lane_bias + np.random.choice([-1.0, 1.0]) * np.random.uniform(0.5, 1.5),
                                    -6.0, 6.0)
                lane_switch_timer = np.random.randint(120, 220)
            vehicle['lane_switch_timer'] = lane_switch_timer
            vehicle['lane_bias'] = lane_bias

            lateral_state = vehicle.setdefault('lateral_state', 0.0)
            lateral_state = 0.5 * lateral_state + np.random.uniform(-0.25, 0.25)
            vehicle['lateral_state'] = np.clip(lateral_state, -2.0, 2.0)

            # === 4) åº”ç”¨ä½ç½®æ›´æ–° ===
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„åœºæ™¯å°ºå¯¸è¾¹ç•Œ (1030 x 2060)
            new_x = position[0] + dx
            new_y = position[1] + dy
            
            # ğŸ”§ ä¿®å¤ï¼šåº”ç”¨è½¦é“åç§»ï¼ˆå‚ç›´äºè½¦è¾†å‰è¿›æ–¹å‘ï¼‰
            # è½¦é“åç§»åº”è¯¥å‚ç›´äºå‰è¿›æ–¹å‘ï¼Œæ¨¡æ‹Ÿè½¦é“å†…çš„å·¦å³å¾®è°ƒ
            if is_horizontal:
                # æ¨ªå‘è¡Œé©¶ï¼ˆä¸œè¥¿å‘ï¼‰ï¼šè½¦é“åç§»åº”ç”¨åˆ°Yæ–¹å‘ï¼ˆå‚ç›´äºå‰è¿›æ–¹å‘ï¼‰
                new_y += lane_bias + lateral_state
            else:
                # çºµå‘è¡Œé©¶ï¼ˆå—åŒ—å‘ï¼‰ï¼šè½¦é“åç§»åº”ç”¨åˆ°Xæ–¹å‘ï¼ˆå‚ç›´äºå‰è¿›æ–¹å‘ï¼‰
                new_x += lane_bias + lateral_state
            
            # ğŸ”§ ä¿®å¤ï¼šå‘¨æœŸæ€§è¾¹ç•Œæ¡ä»¶ï¼ˆåŒ¹é…åœºæ™¯å®é™…å°ºå¯¸ï¼‰
            new_x = new_x % self.scenario_width   # 0 ~ 1030m
            new_y = new_y % self.scenario_height  # 0 ~ 2060m

            vehicle['position'][0] = new_x
            vehicle['position'][1] = new_y

        self._refresh_spatial_index(update_static=False, update_vehicle=True)
        
        # ğŸ”§ ä¿®å¤2: æ›´æ–°RSU/UAVçš„å³æ—¶è¿æ¥è®¡æ•°
        # Update immediate connection counts after vehicle movement
        self._update_node_connections()

    def _sample_arrivals(self) -> int:
        """é¸å¤‹ç¡¦é‰æç¹ƒç»‹å¬®å™°éé”‹ç˜¡æï¸½ç˜¡éƒå •æ®­é¨å‹ªæ¢é”â€³åŸŒæˆç‚¬æšŸ"""
        lam = max(1e-6, float(self.task_arrival_rate) * float(self.time_slot))
        return int(np.random.poisson(lam))

    def _choose_offload_target(self, actions: Dict, rsu_available: bool, uav_available: bool) -> str:
        """
        æ ¹æ®æ™ºèƒ½ä½“åå¥½é€‰æ‹©å¸è½½ç›®æ ‡
        
        ğŸ”§ ä¼˜åŒ–ï¼šæ·»åŠ é˜Ÿåˆ—æ„ŸçŸ¥çš„å†³ç­–é€»è¾‘
        - è€ƒè™‘å„ç±»èŠ‚ç‚¹çš„é˜Ÿåˆ—è´Ÿè½½çŠ¶æ€
        - åŠ¨æ€è°ƒæ•´å¸è½½æ¦‚ç‡é¿å…è¿‡è½½èŠ‚ç‚¹
        - æ™ºèƒ½ä½“åå¥½ä»ç„¶æ˜¯ä¸»è¦å†³ç­–å› ç´ 
        """
        import os
        
        prefs = actions.get('vehicle_offload_pref') or {}
        base_probs = np.array([
            max(0.0, float(prefs.get('local', 0.0))),
            max(0.0, float(prefs.get('rsu', 0.0))) if rsu_available else 0.0,
            max(0.0, float(prefs.get('uav', 0.0))) if uav_available else 0.0,
        ], dtype=float)
        
        # ğŸ”§ ä¿®å¤NaNé—®é¢˜ï¼šæ¸…ç†åˆå§‹æ¦‚ç‡ä¸­çš„NaNå€¼
        base_probs = np.nan_to_num(base_probs, nan=0.0, posinf=0.0, neginf=0.0)
        
        # ğŸ”§ ä¼˜åŒ–ï¼šé˜Ÿåˆ—æ„ŸçŸ¥çš„å†³ç­–è°ƒæ•´
        # è®¡ç®—å„ç±»èŠ‚ç‚¹çš„å¹³å‡é˜Ÿåˆ—è´Ÿè½½
        queue_factors = np.ones(3, dtype=float)
        
        # 1. è®¡ç®—RSUå¹³å‡é˜Ÿåˆ—è´Ÿè½½ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if rsu_available and self.rsus:
            rsu_queue_loads = []
            for rsu in self.rsus:
                queue_len = len(rsu.get('computation_queue', []))
                capacity = self.rsu_nominal_capacity
                load = queue_len / max(1.0, capacity)
                rsu_queue_loads.append(load)
            avg_rsu_load = np.mean(rsu_queue_loads) if rsu_queue_loads else 0.0
            # è´Ÿè½½è¶Šé«˜ï¼Œé€‰æ‹©æ¦‚ç‡è¶Šä½ï¼ˆä½†ä¸å®Œå…¨æ‹’ç»ï¼‰
            # ä½¿ç”¨sigmoid-likeè¡°å‡ï¼šå½“è´Ÿè½½>1æ—¶å¼€å§‹æ˜¾è‘—é™ä½
            queue_factors[1] = 1.0 / (1.0 + max(0.0, avg_rsu_load - 0.5))
        
        # 2. è®¡ç®—UAVå¹³å‡é˜Ÿåˆ—è´Ÿè½½ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if uav_available and self.uavs:
            uav_queue_loads = []
            for uav in self.uavs:
                queue_len = len(uav.get('computation_queue', []))
                capacity = self.uav_nominal_capacity
                load = queue_len / max(1.0, capacity)
                uav_queue_loads.append(load)
            avg_uav_load = np.mean(uav_queue_loads) if uav_queue_loads else 0.0
            queue_factors[2] = 1.0 / (1.0 + max(0.0, avg_uav_load - 0.5))
        
        # 3. æœ¬åœ°å¤„ç†ï¼ˆè½¦è¾†ï¼‰çš„è´Ÿè½½å› å­ä¿æŒä¸º1.0
        # æœ¬åœ°å¤„ç†é€šå¸¸ä½œä¸ºfallbackï¼Œä¸éœ€è¦é¢å¤–è°ƒæ•´
        
        # ğŸ”§ æ§åˆ¶é˜Ÿåˆ—æ„ŸçŸ¥çš„å½±å“ç¨‹åº¦ï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡è°ƒæ•´ï¼‰
        queue_weight = float(os.environ.get('QUEUE_AWARE_WEIGHT', '0.3'))
        adjusted_factors = 1.0 - queue_weight + queue_weight * queue_factors
        
        # åº”ç”¨é˜Ÿåˆ—æ„ŸçŸ¥è°ƒæ•´
        probs = base_probs * adjusted_factors
        probs = np.nan_to_num(probs, nan=0.0, posinf=0.0, neginf=0.0)

        # ğŸ”§ ç¦ç”¨guidanceå¹²æ‰°ï¼šå¯¹æ¯”å®éªŒæ—¶ä¸åº”ç”¨guidanceä¿®æ­£ï¼Œä¿æŒæ™ºèƒ½ä½“åŸå§‹å†³ç­–
        apply_guidance = os.environ.get('APPLY_RL_GUIDANCE', '0') == '1'
        
        if apply_guidance:
            guidance = actions.get('rl_guidance') or {}
            if isinstance(guidance, dict):
                guide_prior = np.array(guidance.get('offload_prior', []), dtype=float)
                if guide_prior.size >= 3:
                    guide_prior = np.nan_to_num(guide_prior[:3], nan=1.0, posinf=1.0, neginf=1.0)
                    probs *= np.clip(guide_prior, 1e-4, None)
                    probs = np.nan_to_num(probs, nan=0.0, posinf=0.0, neginf=0.0)
                
                distance_focus = np.array(guidance.get('distance_focus', []), dtype=float)
                if distance_focus.size >= 3:
                    distance_focus = np.nan_to_num(distance_focus[:3], nan=1.0, posinf=1.0, neginf=1.0)
                    probs *= np.clip(distance_focus, 0.2, None)
                    probs = np.nan_to_num(probs, nan=0.0, posinf=0.0, neginf=0.0)
                
                cache_focus = np.array(guidance.get('cache_focus', []), dtype=float)
                if cache_focus.size >= 3:
                    cache_focus = np.nan_to_num(cache_focus[:3], nan=1.0, posinf=1.0, neginf=1.0)
                    probs *= np.clip(cache_focus, 0.2, None)
                    probs = np.nan_to_num(probs, nan=0.0, posinf=0.0, neginf=0.0)
                
                energy_pressure_vec = guidance.get('energy_pressure')
                if isinstance(energy_pressure_vec, (list, tuple, np.ndarray)):
                    pressure_arr = np.asarray(energy_pressure_vec, dtype=float).reshape(-1)
                    pressure_arr = np.nan_to_num(pressure_arr, nan=1.0, posinf=1.0, neginf=1.0)
                    pressure = float(np.clip(pressure_arr[0], 0.35, 1.8))
                    energy_weights = np.array([1.0 / pressure, pressure, pressure], dtype=float)
                    energy_weights = np.nan_to_num(energy_weights, nan=1.0, posinf=1.0, neginf=1.0)
                    probs *= energy_weights
                    probs = np.nan_to_num(probs, nan=0.0, posinf=0.0, neginf=0.0)

        # æœ€ç»ˆæ£€æŸ¥ï¼šå¦‚æœæ¦‚ç‡æ€»å’Œä»ç„¶ä¸º0æˆ–æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤æ¦‚ç‡
        if not np.isfinite(probs).all() or probs.sum() <= 0:
            probs = np.array([
                0.34,
                0.33 if rsu_available else 0.0,
                0.33 if uav_available else 0.0
            ], dtype=float)

        if probs.sum() <= 0:
            return 'local'

        # å½’ä¸€åŒ–å‰å†æ¬¡æ¸…ç†NaN
        probs = np.nan_to_num(probs, nan=0.0, posinf=0.0, neginf=0.0)
        probs = probs / probs.sum()
        
        # æœ€åä¸€æ¬¡å®‰å…¨æ£€æŸ¥
        if not np.isfinite(probs).all():
            return 'local'
        
        target_labels = np.array(['local', 'rsu', 'uav'])
        return str(np.random.choice(target_labels, p=probs))

    def _estimate_remote_work_units(self, task: Dict, node_type: str) -> float:
        """
        ä¼°è®¡è¿œç¨‹èŠ‚ç‚¹çš„å·¥ä½œé‡å•ä½ï¼ˆä¾›é˜Ÿåˆ—è°ƒåº¦ä½¿ç”¨ï¼‰
        
        ğŸ”§ ä¿®å¤v2ï¼šä¸å†ä½¿ç”¨é¢‘ç‡ç¼©æ”¾ï¼Œç›´æ¥ä½¿ç”¨å›ºå®šçš„base_divisor
        åŸå› ï¼šbase_divisoræ˜¯ç»éªŒæ ¡å‡†å€¼ï¼Œå·²ç»åŒ…å«äº†ç¡¬ä»¶å·®å¼‚
        """
        requirement = float(task.get('computation_requirement', 1500.0))
        
        # ä½¿ç”¨å›ºå®šçš„base_divisorï¼ˆè¿™äº›å€¼æ˜¯åŸºäºå®é™…ç¡¬ä»¶æ ¡å‡†çš„ï¼‰
        # RSU: é«˜æ€§èƒ½è¾¹ç¼˜æœåŠ¡å™¨ï¼Œbase_divisorè¾ƒå¤§
        # UAV: ä½åŠŸè€—æ— äººæœºèŠ¯ç‰‡ï¼Œbase_divisorè¾ƒå°ï¼ˆæ‰§è¡Œæ›´æ…¢ï¼‰
        if node_type == 'RSU':
            base_divisor = 1200.0  # RSUå›ºå®šå€¼
        else:  # UAV
            base_divisor = 1600.0  # UAVå›ºå®šå€¼
        
        work_units = requirement / base_divisor
        return float(np.clip(work_units, 0.5, 12.0))

    def _estimate_local_processing(self, task: Dict, vehicle: Dict) -> Tuple[float, float]:
        """æµ¼æ‹Œéˆæ¹´æ¾¶å‹­æ‚Šé¨å‹«æ¬¢æ©ç†¶ç¬Œé‘³å€Ÿâ‚¬?"""
        cpu_freq = 2.5e9
        power = 6.5
        # ğŸ”§ ä¿®å¤: å¢å¼ºé…ç½®ä¸€è‡´æ€§æ£€æŸ¥
        if self.sys_config is not None and hasattr(self.sys_config, 'compute'):
            cpu_freq = getattr(self.sys_config.compute, 'vehicle_cpu_freq', cpu_freq)
            power = getattr(self.sys_config.compute, 'vehicle_static_power', power)
        else:
            cpu_freq = float(self.config.get('vehicle_cpu_freq', cpu_freq))
            power = float(self.config.get('vehicle_static_power', power))

        requirement = float(task.get('computation_requirement', 1500.0)) * 1e6  # cycles
        # ğŸ”§ ä¿®å¤é—®é¢˜2ï¼šåº”ç”¨å¹¶è¡Œæ•ˆç‡å‚æ•°ï¼ˆä¸èƒ½è€—æ¨¡å‹ä¿æŒä¸€è‡´ï¼‰
        parallel_eff = 0.8
        if self.sys_config is not None and hasattr(self.sys_config, 'compute'):
            parallel_eff = getattr(self.sys_config.compute, 'parallel_efficiency', 0.8)
        else:
            parallel_eff = float(self.config.get('parallel_efficiency', 0.8))
        processing_time = requirement / max(cpu_freq * parallel_eff, 1e6)
        # Allow genuine compute latency to surface by avoiding artificial clipping
        processing_time = max(float(processing_time), 1e-6)
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä½¿ç”¨å®Œæ•´çš„åŠ¨æ€+é™æ€åŠŸè€—æ¨¡å‹
        # E_total = P_dynamic Ã— t_active + P_static Ã— t_active
        # P_dynamic = Îºâ‚ Ã— fÂ³
        kappa1 = 1.5e-28  # W/(Hz)Â³ - åŠ¨æ€åŠŸè€—ç³»æ•°
        if self.sys_config is not None and hasattr(self.sys_config, 'compute'):
            kappa1 = getattr(self.sys_config.compute, 'vehicle_kappa1', kappa1)
        else:
            kappa1 = float(self.config.get('vehicle_kappa1', kappa1))
        
        dynamic_power = kappa1 * (cpu_freq ** 3)  # åŠ¨æ€åŠŸè€—ï¼šP = Îºâ‚ Ã— fÂ³
        energy = (dynamic_power + power) * processing_time  # æ€»èƒ½è€— = (åŠ¨æ€+é™æ€) Ã— æ—¶é—´
        
        vehicle['energy_consumed'] = vehicle.get('energy_consumed', 0.0) + energy
        return processing_time, energy

    def _estimate_transmission(self, data_size_bytes: float, distance: float, link: str, 
                              vehicle: Optional[Dict] = None) -> Tuple[float, float]:
        """
        ä¼°è®¡ä¸Šä¼ è€—æ—¶ä¸èƒ½è€—
        
        ğŸ”§ P0ä¿®å¤ï¼šæ”¯æŒåŠ¨æ€å¸¦å®½åˆ†é…ï¼Œä½¿ç”¨vehicle['allocated_bandwidth']
        """
        # ğŸ”§ P0ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨è½¦è¾†çš„åŠ¨æ€åˆ†é…å¸¦å®½
        if vehicle is not None and 'allocated_bandwidth' in vehicle:
            # ä½¿ç”¨åŠ¨æ€åˆ†é…çš„å¸¦å®½
            allocated_bandwidth = float(vehicle['allocated_bandwidth'])
            total_bandwidth = float(getattr(self.resource_pool, 'total_bandwidth', self.bandwidth))
            base_rate = allocated_bandwidth * total_bandwidth
            # print(f"âœ… ä½¿ç”¨åŠ¨æ€åˆ†é…å¸¦å®½: {base_rate/1e6:.2f} MHz (ratio={allocated_bandwidth:.3f})")
        else:
            # å›é€€åˆ°é»˜è®¤å¸¦å®½ï¼ˆä»é…ç½®è¯»å–ï¼‰
            if link == 'uav':
                # UAVä¸‹è¡Œå¸¦å®½ï¼šä¼˜å…ˆä»é…ç½®è¯»å–ï¼Œé»˜è®¤50 MHz
                if self.sys_config is not None and hasattr(self.sys_config, 'communication'):
                    base_rate = getattr(self.sys_config.communication, 'uav_downlink_bandwidth', 50e6)
                else:
                    base_rate = float(self.config.get('uav_downlink_bandwidth', 50e6))
            else:  # RSU
                # RSUä¸‹è¡Œå¸¦å®½ï¼šä¼˜å…ˆä»é…ç½®è¯»å–ï¼Œé»˜è®¤1000 MHz (1 GHz)
                if self.sys_config is not None and hasattr(self.sys_config, 'communication'):
                    base_rate = getattr(self.sys_config.communication, 'rsu_downlink_bandwidth', 1000e6)
                else:
                    base_rate = float(self.config.get('rsu_downlink_bandwidth', 1000e6))
        
        # è®¾ç½®å‘å°„åŠŸç‡
        if link == 'uav':
            power_w = 0.12
        else:  # RSU
            power_w = 0.18

        # è€ƒè™‘è·ç¦»è¡°å‡
        attenuation = 1.0 + max(0.0, distance) / 800.0
        rate = base_rate / attenuation
        delay = (float(data_size_bytes) * 8.0) / max(rate, 1e6)
        delay = float(np.clip(delay, 0.01, 1.2))
        energy = power_w * delay
        return delay, energy

    def _append_active_task(self, task_entry: Dict):
        """çå—•æ¢é”Â¤è¤°æ›å§éãƒ¦æ¤¿ç’ºå†¨åªç›?"""
        self.active_tasks.append(task_entry)

    def _cleanup_active_tasks(self):
        """ç»‰å©šæ«å®¸èŒ¬ç²¡ç€¹å±¾åšé´æ ¦æ¶ªå¯®å†ªæ®‘æµ è¯²å§Ÿ"""
        self.active_tasks = [
            task for task in self.active_tasks
            if not task.get('completed') and not task.get('dropped')
        ]

    def _handle_deadlines(self):
        """å¦«â‚¬éŒãƒ©æ§¦é’æ¤¾æ¢é”â„ƒæ§¸éšï¹ç§´éˆç†·è‹Ÿæ¶“ãˆ ç´”"""
        for node_list, node_type in ((self.rsus, 'RSU'), (self.uavs, 'UAV')):
            for idx, node in enumerate(node_list):
                queue = node.get('computation_queue', [])
                if not queue:
                    continue

                remaining = []
                drop_stats = self.stats.setdefault('drop_stats', {
                    'total': 0,
                    'wait_time_sum': 0.0,
                    'queue_sum': 0,
                    'by_type': {},
                    'by_scenario': {},
                    'by_reason': {}
                })
                by_type = drop_stats.setdefault('by_type', {})
                by_scenario = drop_stats.setdefault('by_scenario', {})
                stats_cfg = getattr(self, 'stats_config', None)
                # ğŸ”§ ä¿®å¤: å¢å¼ºé…ç½®ä¸€è‡´æ€§æ£€æŸ¥
                log_interval = 400  # é»˜è®¤å€¼
                if stats_cfg is not None and hasattr(stats_cfg, 'drop_log_interval'):
                    log_interval = stats_cfg.drop_log_interval
                else:
                    log_interval = self.config.get('drop_log_interval', 400)
                log_interval = max(1, int(log_interval))
                for task in queue:
                    # ğŸ”§ ä¿®å¤:æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²ç»è¢«ä¸¢å¼ƒ,é¿å…é‡å¤è®¡æ•°
                    if task.get('dropped', False):
                        continue
                    
                    if self.current_time > task.get('deadline', float('inf')):
                        task['dropped'] = True
                        task['drop_reason'] = 'deadline_exceeded'
                        
                        # ğŸ†• Luoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼šè¿‡æœŸä»»åŠ¡ä»clifetime_queuesä¸­ç§»é™¤
                        self._remove_task_from_lifetime_queues(node, task)
                        
                        self.stats['dropped_tasks'] += 1
                        self.stats['dropped_data_bytes'] += float(task.get('data_size_bytes', 0.0))

                        drop_stats['total'] += 1
                        wait_time = max(0.0, self.current_time - task.get('queued_at', task.get('arrival_time', self.current_time)))
                        drop_stats['wait_time_sum'] += wait_time
                        drop_stats['queue_sum'] += len(queue)
                        task_type = task.get('task_type', 'unknown')
                        by_type[task_type] = by_type.get(task_type, 0) + 1
                        scenario_name = task.get('app_scenario', 'unknown')
                        by_scenario[scenario_name] = by_scenario.get(scenario_name, 0) + 1

                        if drop_stats['total'] % log_interval == 0:
                            avg_wait = drop_stats['wait_time_sum'] / max(1, drop_stats['total'])
                            avg_queue = drop_stats['queue_sum'] / max(1, drop_stats['total'])
                            print(
                                f"éˆ¿ç‹…ç¬ Dropped tasks: {drop_stats['total']} "
                                f"(avg wait {avg_wait:.2f}s, avg queue {avg_queue:.1f}) "
                                f"latest type {task_type}, scenario {scenario_name}"
                            )
                        continue
                    remaining.append(task)
                node['computation_queue'] = remaining

    def _store_in_vehicle_cache(self, vehicle: Dict, content_id: str, size_mb: float,
                                cache_controller: Optional[Any] = None):
        """çå——å”´ç€¹è§„å¸¹é–«ä½¸åŸŒæï¹æµ‡ç¼‚æ’³ç“¨é”›å±¼å¨‡é¢ã„§ç•é—æ˜„RUå¨£æ¨»å‘"""
        if size_mb <= 0.0:
            return
        capacity = float(vehicle.get('device_cache_capacity', 32.0))
        if size_mb > capacity:
            return
        cache = vehicle.setdefault('device_cache', {})
        total_used = sum(float(meta.get('size', 0.0) or 0.0) for meta in cache.values())
        if total_used + size_mb > capacity:
            # LRUå¨£æ¨»å‘
            ordered = sorted(cache.items(), key=lambda item: item[1].get('timestamp', 0.0))
            for cid, meta in ordered:
                removed_size = float(meta.get('size', 0.0) or 0.0)
                cache.pop(cid, None)
                total_used -= removed_size
                if cache_controller:
                    cache_controller.cache_stats['evicted_items'] += 1
                if total_used + size_mb <= capacity:
                    break
        if total_used + size_mb > capacity:
            return
        cache[content_id] = {
            'size': size_mb,
            'timestamp': self.current_time,
            'source': 'rsu_push'
        }
        if cache_controller:
            cache_controller.cache_stats['collaborative_writes'] += 1

    def _store_in_neighbor_rsu_cache(self, neighbor: Dict, content_id: str, size_mb: float,
                                     content_meta: Dict, cache_controller: Optional[Any]):
        """çæ¿Šç˜¯çå——å”´ç€¹è§„å¸¹é–«ä½¸åŸŒé–­æ˜ç¹RSU"""
        if size_mb <= 0.0:
            return
        cache = neighbor.setdefault('cache', {})
        if content_id in cache:
            return
        capacity = neighbor.get('cache_capacity', 1000.0)
        available = self._calculate_available_cache_capacity(cache, capacity)
        cache_snapshot = dict(cache)
        should_store = available >= size_mb
        evictions: List[str] = []
        reason = 'RSU_push_neighbor'
        if cache_controller is not None:
            should_store, reason, evictions = cache_controller.should_cache_content(
                content_id, size_mb, available, cache_snapshot, capacity
            )
        if not should_store:
            return
        for cid in evictions:
            removed = cache.pop(cid, None)
            if removed:
                available += float(removed.get('size', 0.0) or 0.0)
                if cache_controller:
                    cache_controller.cache_stats['evicted_items'] += 1
        if available < size_mb:
            return
        cache[content_id] = {
            'size': size_mb,
            'timestamp': self.current_time,
            'reason': reason,
            'source': content_meta.get('source', 'rsu_hit')
        }
        if cache_controller:
            cache_controller.cache_stats['collaborative_writes'] += 1

    def _propagate_cache_after_hit(self, content_id: str, rsu_node: Dict, agents_actions: Optional[Dict]):
        """RSUé›æˆ’è…‘éšåº¡æ‚œæï¹ç· éœå²„å¦æ©æ… SUéºã„©â‚¬ä½¸å”´ç€¹?"""
        cache_meta = rsu_node.get('cache', {}).get(content_id)
        if not cache_meta:
            return
        size_mb = float(cache_meta.get('size', 0.0) or self._get_realistic_content_size(content_id))
        cache_controller = None
        if agents_actions:
            cache_controller = agents_actions.get('cache_controller')

        # ä»…åœ¨RSUä¹‹é—´ä¼ æ’­ç¼“å­˜
        coverage = rsu_node.get('coverage_radius', 300.0)
        spatial_index = getattr(self, 'spatial_index', None)
        if spatial_index is not None:
            neighbor_candidates = spatial_index.query_rsus_within_radius(rsu_node['position'], coverage * 1.2)
            for _, neighbor, _ in neighbor_candidates:
                if neighbor is rsu_node:
                    continue
                self._store_in_neighbor_rsu_cache(neighbor, content_id, size_mb, cache_meta, cache_controller)
        else:
            for neighbor in self.rsus:
                if neighbor is rsu_node:
                    continue
                distance = self.calculate_distance(neighbor['position'], rsu_node['position'])
                if distance <= coverage * 1.2:
                    self._store_in_neighbor_rsu_cache(neighbor, content_id, size_mb, cache_meta, cache_controller)

    def _dispatch_task(self, vehicle: Dict, task: Dict, actions: Dict, step_summary: Dict):
        """æ ¹æ®åŠ¨ä½œåˆ†é…ä»»åŠ¡"""
        cache_controller = None
        if isinstance(actions, dict):
            cache_controller = actions.get('cache_controller')
        if cache_controller is None:
            cache_controller = getattr(self, 'adaptive_cache_controller', None)

        content_id = task.get('content_id')
        
        # ğŸ”§ ä¿®å¤ï¼šæ›´æ–°å†…å®¹çƒ­åº¦ï¼Œç¡®ä¿ç¼“å­˜æ§åˆ¶å™¨èƒ½æ„ŸçŸ¥åˆ°å†…å®¹è®¿é—®
        if cache_controller is not None and content_id:
            try:
                cache_controller.update_content_heat(content_id)
            except Exception:
                pass

        # è½¦è¾†ç«¯ä¸å†ç»´æŠ¤æœ¬åœ°ç¼“å­˜ï¼Œç›´æ¥æ ¹æ®ç­–ç•¥å†³å®šå¸è½½æˆ–æœ¬åœ°è®¡ç®—
        forced_mode = getattr(self, 'forced_offload_mode', '')
        if forced_mode != 'remote_only':
            if self._try_serve_from_vehicle_cache(vehicle, task, step_summary, cache_controller):
                return
        if forced_mode == 'local_only':
            self._handle_local_processing(vehicle, task, step_summary)
            return

        # ğŸ”§ ä¿®å¤ï¼šremote_onlyæ¨¡å¼çš„æ­£ç¡®å¤„ç†
        if forced_mode == 'remote_only':
            rsu_available = len(self.rsus) > 0
            uav_available = len(self.uavs) > 0
            
            assigned = False
            if rsu_available or uav_available:
                target = self._choose_offload_target(actions, rsu_available, uav_available)
                if target == 'rsu' and rsu_available:
                    assigned = self._assign_to_rsu(vehicle, task, actions, step_summary)
                elif target == 'uav' and uav_available:
                    assigned = self._assign_to_uav(vehicle, task, actions, step_summary)
            
            if not assigned:
                # remote_onlyæ¨¡å¼ä¸‹å¸è½½å¤±è´¥ï¼Œä¸¢å¼ƒä»»åŠ¡ï¼ˆä¸fallbackåˆ°æœ¬åœ°å¤„ç†ï¼‰
                self._record_forced_drop(vehicle, task, step_summary, reason='remote_only_offload_failed')
            return

        # æ­£å¸¸æ¨¡å¼ï¼šå°è¯•å¸è½½ï¼Œå¤±è´¥åˆ™æœ¬åœ°å¤„ç†
        rsu_available = len(self.rsus) > 0
        uav_available = len(self.uavs) > 0
        target = self._choose_offload_target(actions, rsu_available, uav_available)

        assigned = False
        if target == 'rsu' and rsu_available:
            assigned = self._assign_to_rsu(vehicle, task, actions, step_summary)
        elif target == 'uav' and uav_available:
            assigned = self._assign_to_uav(vehicle, task, actions, step_summary)

        if not assigned:
            self._handle_local_processing(vehicle, task, step_summary)

    def _assign_to_rsu(self, vehicle: Dict, task: Dict, actions: Dict, step_summary: Dict) -> bool:
        """
        å°†ä»»åŠ¡åˆ†é…åˆ°RSUå¤„ç†
        
        ğŸ”§ ä¼˜åŒ–ï¼šå¢å¼ºé˜Ÿåˆ—æ„ŸçŸ¥çš„èŠ‚ç‚¹é€‰æ‹©é€»è¾‘
        - ç»“åˆæ™ºèƒ½ä½“åå¥½å’Œé˜Ÿåˆ—è´Ÿè½½çŠ¶æ€
        - è·ç¦»å› ç´ ä½œä¸ºè¾…åŠ©å‚è€ƒ
        - é¿å…å‘è¿‡è½½èŠ‚ç‚¹å¸è½½ä»»åŠ¡
        """
        if not self.rsus:
            return False

        vehicle_pos = np.asarray(vehicle.get('position', [0.0, 0.0]), dtype=float)
        candidates = []
        spatial_index = getattr(self, 'spatial_index', None)
        if spatial_index is not None:
            max_radius = spatial_index.rsu_max_radius or max(
                (float(rsu.get('coverage_radius', self.coverage_radius)) for rsu in self.rsus),
                default=self.coverage_radius,
            )
            candidates = spatial_index.query_rsus_within_radius(vehicle_pos, max_radius)
            if not candidates:
                nearest = spatial_index.find_nearest_rsu(vehicle_pos, return_distance=True)
                if nearest:
                    candidates = [nearest]

        if not candidates:
            candidates = [
                (idx, rsu, self.calculate_distance(vehicle_pos, rsu['position']))
                for idx, rsu in enumerate(self.rsus)
            ]

        filtered = [
            (idx, node, dist)
            for idx, node, dist in candidates
            if dist <= float(node.get('coverage_radius', self.coverage_radius))
        ]
        if not filtered:
            return False

        candidate_indices = np.array([idx for idx, _, _ in filtered], dtype=int)
        distances = np.array([dist for _, _, dist in filtered], dtype=float)

        # ğŸ”§ ä¼˜åŒ–ï¼šåˆå§‹åŒ–æƒé‡æ•°ç»„
        probs = np.ones_like(distances)
        
        # 1. åº”ç”¨æ™ºèƒ½ä½“çš„RSUé€‰æ‹©åå¥½
        rsu_pref = actions.get('rsu_selection_probs')
        if isinstance(rsu_pref, (list, tuple, np.ndarray)) and len(rsu_pref) == len(self.rsus):
            pref_values = np.array([max(0.0, float(rsu_pref[idx])) for idx in candidate_indices], dtype=float)
            pref_values = np.nan_to_num(pref_values, nan=1.0, posinf=1.0, neginf=1.0)
            pref_values = np.maximum(pref_values, 1e-10)
            # ğŸ”§ ä¼˜åŒ–ï¼šå¢å¼ºæ™ºèƒ½ä½“åå¥½çš„å½±å“åŠ›ï¼ˆä½¿ç”¨å¹‚æ¬¡æ”¾å¤§ï¼‰
            pref_values = np.power(pref_values, 1.5)  # æ”¾å¤§åå¥½å·®å¼‚
            probs *= pref_values
            probs = np.nan_to_num(probs, nan=1.0, posinf=1.0, neginf=1.0)
        
        # 2. ğŸ”§ ä¼˜åŒ–ï¼šæ·»åŠ é˜Ÿåˆ—è´Ÿè½½å› å­
        queue_factors = np.ones_like(distances)
        for i, idx in enumerate(candidate_indices):
            rsu = self.rsus[idx]
            queue_len = len(rsu.get('computation_queue', []))
            capacity = self.rsu_nominal_capacity
            load = queue_len / max(1.0, capacity)
            # è´Ÿè½½è¶Šé«˜ï¼Œé€‰æ‹©æ¦‚ç‡è¶Šä½
            # ä½¿ç”¨è½¯è¡°å‡ï¼šqueue_factor = exp(-load * decay_rate)
            queue_factors[i] = np.exp(-load * 0.5)  # decay_rate=0.5
        
        probs *= queue_factors
        probs = np.nan_to_num(probs, nan=1.0, posinf=1.0, neginf=1.0)
        
        # 3. ğŸ”§ ä¼˜åŒ–ï¼šæ·»åŠ è·ç¦»å› å­ï¼ˆè·ç¦»è¶Šè¿‘è¶Šå¥½ï¼‰
        max_dist = max(distances) if len(distances) > 0 else 1.0
        distance_factors = 1.0 - 0.3 * (distances / max(max_dist, 1e-6))  # æœ€è¿œèŠ‚ç‚¹è¡°å‡30%
        distance_factors = np.clip(distance_factors, 0.5, 1.0)
        probs *= distance_factors
        probs = np.nan_to_num(probs, nan=1.0, posinf=1.0, neginf=1.0)

        # 4. åº”ç”¨rl_guidanceï¼ˆå¦‚æœå¯ç”¨ï¼‰
        guidance = actions.get('rl_guidance') or {}
        if isinstance(guidance, dict):
            rsu_prior = np.array(guidance.get('rsu_prior', []), dtype=float)
            if rsu_prior.size >= len(self.rsus):
                rsu_prior = np.nan_to_num(rsu_prior, nan=1.0, posinf=1.0, neginf=1.0)
                prior_vals = np.clip(rsu_prior[candidate_indices], 1e-4, None)
                probs *= prior_vals
                probs = np.nan_to_num(probs, nan=1.0, posinf=1.0, neginf=1.0)
                probs = np.maximum(probs, 1e-10)
            
            cache_focus = guidance.get('cache_focus')
            if isinstance(cache_focus, (list, tuple)) and len(cache_focus) >= 2:
                cache_weight = float(np.clip(cache_focus[1], 0.0, 1.0))
                cache_weight = np.nan_to_num(cache_weight, nan=0.0)
                power_val = 0.8 + 0.4 * cache_weight
                probs = np.maximum(probs, 1e-10)
                probs = np.power(probs, power_val)
                probs = np.nan_to_num(probs, nan=1.0, posinf=1.0, neginf=1.0)
                probs = np.maximum(probs, 1e-10)
            
            distance_focus = guidance.get('distance_focus')
            if isinstance(distance_focus, (list, tuple)) and len(distance_focus) >= 2:
                distance_weight = float(np.clip(distance_focus[1], 0.0, 1.0))
                distance_weight = np.nan_to_num(distance_weight, nan=0.0)
                power_val = 0.8 + 0.4 * distance_weight
                probs = np.maximum(probs, 1e-10)
                probs = np.power(probs, power_val)
                probs = np.nan_to_num(probs, nan=1.0, posinf=1.0, neginf=1.0)
                probs = np.maximum(probs, 1e-10)

        weights = probs
        weights = np.nan_to_num(weights, nan=1.0, posinf=1.0, neginf=1.0)
        weights = np.maximum(weights, 1e-10)
        
        weight_sum = weights.sum()
        if weight_sum <= 0 or not np.isfinite(weight_sum):
            weights = np.ones_like(weights)
            weight_sum = weights.sum()

        weights = weights / weight_sum
        weights = np.nan_to_num(weights, nan=1.0/len(weights), posinf=0.0, neginf=0.0)
        weights = np.clip(weights, 0.0, 1.0)
        
        final_sum = weights.sum()
        if final_sum > 0 and np.isfinite(final_sum):
            weights = weights / final_sum
        else:
            weights = np.ones_like(weights) / len(weights)
        
        if not np.isfinite(weights).all():
            weights = np.ones_like(weights) / len(weights)
        ordered_choices = list(np.random.choice(
            np.arange(len(candidate_indices)),
            size=len(candidate_indices),
            replace=False,
            p=weights
        ))
        attempted = False
        for choice in ordered_choices:
            rsu_idx = int(candidate_indices[choice])
            distance = float(distances[choice])
            node = self.rsus[rsu_idx]
            if not self._is_node_admissible(node, 'RSU'):
                continue
            attempted = True
            success = self._handle_remote_assignment(vehicle, task, node, 'RSU', rsu_idx, distance, actions, step_summary)
            if success:
                step_summary['remote_tasks'] += 1
                return True
        reason = 'rsu_overloaded' if not attempted else 'assignment_failed'
        self._record_offload_rejection('RSU', reason)
        step_summary['remote_refusals'] = step_summary.get('remote_refusals', 0) + 1
        return False


    def _assign_to_uav(self, vehicle: Dict, task: Dict, actions: Dict, step_summary: Dict) -> bool:
        """
        å°†ä»»åŠ¡åˆ†é…åˆ°UAVå¤„ç†
        
        ğŸ”§ ä¼˜åŒ–ï¼šå¢å¼ºé˜Ÿåˆ—æ„ŸçŸ¥çš„èŠ‚ç‚¹é€‰æ‹©é€»è¾‘
        - ç»“åˆæ™ºèƒ½ä½“åå¥½å’Œé˜Ÿåˆ—è´Ÿè½½çŠ¶æ€
        - è·ç¦»å› ç´ ä½œä¸ºè¾…åŠ©å‚è€ƒ
        - é¿å…å‘è¿‡è½½èŠ‚ç‚¹å¸è½½ä»»åŠ¡
        """
        if not self.uavs:
            return False

        vehicle_pos = np.asarray(vehicle.get('position', [0.0, 0.0]), dtype=float)
        candidates = []
        spatial_index = getattr(self, 'spatial_index', None)
        if spatial_index is not None:
            max_radius = spatial_index.uav_max_radius or max(
                (float(uav.get('coverage_radius', 350.0)) for uav in self.uavs),
                default=350.0,
            )
            candidates = spatial_index.query_uavs_within_radius(vehicle_pos, max_radius)
            if not candidates:
                nearest = spatial_index.find_nearest_uav(vehicle_pos, return_distance=True)
                if nearest:
                    candidates = [nearest]

        if not candidates:
            candidates = [
                (idx, uav, self.calculate_distance(vehicle_pos, uav['position']))
                for idx, uav in enumerate(self.uavs)
            ]

        filtered = [
            (idx, node, dist)
            for idx, node, dist in candidates
            if dist <= float(node.get('coverage_radius', 350.0))
        ]
        if not filtered:
            return False

        candidate_indices = np.array([idx for idx, _, _ in filtered], dtype=int)
        distances = np.array([dist for _, _, dist in filtered], dtype=float)

        # ğŸ”§ ä¼˜åŒ–ï¼šåˆå§‹åŒ–æƒé‡æ•°ç»„
        probs = np.ones_like(distances)
        
        # 1. åº”ç”¨æ™ºèƒ½ä½“çš„UAVé€‰æ‹©åå¥½
        uav_pref = actions.get('uav_selection_probs')
        if isinstance(uav_pref, (list, tuple, np.ndarray)) and len(uav_pref) == len(self.uavs):
            pref_values = np.array([max(0.0, float(uav_pref[idx])) for idx in candidate_indices], dtype=float)
            pref_values = np.nan_to_num(pref_values, nan=1.0, posinf=1.0, neginf=1.0)
            pref_values = np.maximum(pref_values, 1e-10)
            # ğŸ”§ ä¼˜åŒ–ï¼šå¢å¼ºæ™ºèƒ½ä½“åå¥½çš„å½±å“åŠ›ï¼ˆä½¿ç”¨å¹‚æ¬¡æ”¾å¤§ï¼‰
            pref_values = np.power(pref_values, 1.5)  # æ”¾å¤§åå¥½å·®å¼‚
            probs *= pref_values
            probs = np.nan_to_num(probs, nan=1.0, posinf=1.0, neginf=1.0)
        
        # 2. ğŸ”§ ä¼˜åŒ–ï¼šæ·»åŠ é˜Ÿåˆ—è´Ÿè½½å› å­
        queue_factors = np.ones_like(distances)
        for i, idx in enumerate(candidate_indices):
            uav = self.uavs[idx]
            queue_len = len(uav.get('computation_queue', []))
            capacity = self.uav_nominal_capacity
            load = queue_len / max(1.0, capacity)
            # è´Ÿè½½è¶Šé«˜ï¼Œé€‰æ‹©æ¦‚ç‡è¶Šä½
            # UAVå®¹é‡è¾ƒå°ï¼Œä½¿ç”¨æ›´å¼ºçš„è¡°å‡
            queue_factors[i] = np.exp(-load * 0.7)  # decay_rate=0.7 (æ¯”RSUæ›´å¼º)
        
        probs *= queue_factors
        probs = np.nan_to_num(probs, nan=1.0, posinf=1.0, neginf=1.0)
        
        # 3. ğŸ”§ ä¼˜åŒ–ï¼šæ·»åŠ è·ç¦»å› å­ï¼ˆè·ç¦»è¶Šè¿‘è¶Šå¥½ï¼‰
        max_dist = max(distances) if len(distances) > 0 else 1.0
        distance_factors = 1.0 - 0.4 * (distances / max(max_dist, 1e-6))  # UAVè·ç¦»å½±å“æ›´å¤§
        distance_factors = np.clip(distance_factors, 0.4, 1.0)
        probs *= distance_factors
        probs = np.nan_to_num(probs, nan=1.0, posinf=1.0, neginf=1.0)

        # 4. åº”ç”¨rl_guidanceï¼ˆå¦‚æœå¯ç”¨ï¼‰
        guidance = actions.get('rl_guidance') or {}
        if isinstance(guidance, dict):
            uav_prior = np.array(guidance.get('uav_prior', []), dtype=float)
            if uav_prior.size >= len(self.uavs):
                uav_prior = np.nan_to_num(uav_prior, nan=1.0, posinf=1.0, neginf=1.0)
                prior_vals = np.clip(uav_prior[candidate_indices], 1e-4, None)
                probs *= prior_vals
                probs = np.nan_to_num(probs, nan=1.0, posinf=1.0, neginf=1.0)
                probs = np.maximum(probs, 1e-10)
            
            distance_focus = guidance.get('distance_focus')
            if isinstance(distance_focus, (list, tuple)) and len(distance_focus) >= 3:
                distance_weight = float(np.clip(distance_focus[2], 0.0, 1.0))
                distance_weight = np.nan_to_num(distance_weight, nan=0.0)
                power_val = 0.8 + 0.4 * distance_weight
                probs = np.maximum(probs, 1e-10)
                probs = np.power(probs, power_val)
                probs = np.nan_to_num(probs, nan=1.0, posinf=1.0, neginf=1.0)
                probs = np.maximum(probs, 1e-10)

        weights = probs
        weights = np.nan_to_num(weights, nan=1.0, posinf=1.0, neginf=1.0)
        weights = np.maximum(weights, 1e-10)
        
        weight_sum = weights.sum()
        if weight_sum <= 0 or not np.isfinite(weight_sum):
            weights = np.ones_like(weights)
            weight_sum = weights.sum()

        weights = weights / weight_sum
        weights = np.nan_to_num(weights, nan=1.0/len(weights), posinf=0.0, neginf=0.0)
        weights = np.clip(weights, 0.0, 1.0)
        
        final_sum = weights.sum()
        if final_sum > 0 and np.isfinite(final_sum):
            weights = weights / final_sum
        else:
            weights = np.ones_like(weights) / len(weights)
        
        if not np.isfinite(weights).all():
            weights = np.ones_like(weights) / len(weights)
        
        ordered_choices = list(np.random.choice(
            np.arange(len(candidate_indices)),
            size=len(candidate_indices),
            replace=False,
            p=weights
        ))
        attempted = False
        for choice in ordered_choices:
            uav_idx = int(candidate_indices[choice])
            distance = float(distances[choice])
            node = self.uavs[uav_idx]
            if not self._is_node_admissible(node, 'UAV'):
                continue
            attempted = True
            success = self._handle_remote_assignment(vehicle, task, node, 'UAV', uav_idx, distance, actions, step_summary)
            if success:
                step_summary['remote_tasks'] += 1
                return True
        reason = 'uav_overloaded' if not attempted else 'assignment_failed'
        self._record_offload_rejection('UAV', reason)
        step_summary['remote_refusals'] = step_summary.get('remote_refusals', 0) + 1
        return False


    def _handle_remote_assignment(
        self,
        vehicle: Dict,
        task: Dict,
        node: Dict,
        node_type: str,
        node_idx: int,
        distance: float,
        actions: Dict,
        step_summary: Dict
    ) -> bool:
        """
        æ‰§è¡Œè¿œç¨‹å¸è½½ï¼šç¼“å­˜åˆ¤å®šã€å»ºç«‹é˜Ÿåˆ—å¹¶è®°å½•ç»Ÿè®¡
        
        å¤„ç†ä»»åŠ¡åˆ°è¿œç¨‹èŠ‚ç‚¹ï¼ˆRSUæˆ–UAVï¼‰çš„å¸è½½è¿‡ç¨‹ï¼š
        1. æ£€æŸ¥ç¼“å­˜å‘½ä¸­
        2. è®¡ç®—ä¸Šä¼ å»¶è¿Ÿå’Œèƒ½è€—
        3. ä¼°ç®—ä»»åŠ¡å·¥ä½œé‡
        4. å°†ä»»åŠ¡åŠ å…¥èŠ‚ç‚¹é˜Ÿåˆ—
        
        Args:
            vehicle: è½¦è¾†å­—å…¸
            task: ä»»åŠ¡å­—å…¸
            node: ç›®æ ‡èŠ‚ç‚¹å­—å…¸
            node_type: èŠ‚ç‚¹ç±»å‹ï¼ˆ'RSU'æˆ–'UAV'ï¼‰
            node_idx: èŠ‚ç‚¹ç´¢å¼•
            distance: è½¦è¾†åˆ°èŠ‚ç‚¹çš„è·ç¦»
            actions: æ™ºèƒ½ä½“åŠ¨ä½œå­—å…¸
            step_summary: æ­¥éª¤ç»Ÿè®¡æ‘˜è¦
            
        Returns:
            Trueè¡¨ç¤ºæˆåŠŸå¸è½½ï¼ŒFalseè¡¨ç¤ºå¤±è´¥
            
        Execute remote offloading with cache checking and queue management.
        """
        actions = actions or {}
        self._reset_mm1_step_buffers()
        cache_hit = False

        # æ£€æŸ¥ç¼“å­˜å‘½ä¸­
        # ğŸ”§ ä¼˜åŒ–11: ä¼ å…¥taskå‚æ•°ä»¥ä½¿ç”¨cache_priority
        if node_type == 'RSU':
            cache_hit = self.check_cache_hit_adaptive(task['content_id'], node, actions, node_type='RSU', task=task)
        else:
            cache_hit = self.check_cache_hit_adaptive(task['content_id'], node, actions, node_type='UAV', task=task)

        if cache_hit:
            # âœ… ä¿®å¤ï¼šç¼“å­˜å‘½ä¸­å‡ ä¹æ— èƒ½è€—ï¼Œåªæœ‰æçŸ­çš„å†…å­˜è®¿é—®å»¶è¿Ÿ
            # Cache hit: minimal delay (memory access ~1ms), negligible energy
            delay = 0.001  # 1ms - å†…å­˜è®¿é—®å»¶è¿Ÿ
            
            # âœ… ç¼“å­˜è¯»å–èƒ½è€—å¯å¿½ç•¥ä¸è®¡ï¼ˆå­˜å‚¨å™¨è®¿é—®åŠŸè€— << 0.01Jï¼‰
            # Cache read energy is negligible (memory access power << 0.01J)
            energy = 0.0  # ç¼“å­˜å‘½ä¸­æ— æ˜¾è‘—èƒ½è€—
            
            # âœ… å¦‚æœéœ€è¦è¿”å›ç»“æœï¼Œè®¡ç®—ä¸‹è¡Œä¼ è¾“èƒ½è€—ï¼ˆå¾ˆå°ï¼Œç»“æœåªæœ‰è¾“å…¥çš„5%ï¼‰
            # If result needs to be returned, calculate downlink transmission energy
            result_size = task.get('data_size_bytes', 1e6) * 0.05  # ç»“æœæ˜¯è¾“å…¥çš„5%
            if result_size > 0:
                down_delay, down_energy = self._estimate_transmission(result_size, float(distance), node_type.lower())
                delay += down_delay  # åŠ ä¸Šä¸‹è¡Œå»¶è¿Ÿ
                energy = down_energy  # åªæœ‰ä¸‹è¡Œä¼ è¾“æœ‰èƒ½è€—
            
            self.stats['processed_tasks'] += 1
            self.stats['completed_tasks'] += 1
            self._accumulate_delay('delay_cache', delay)
            self._accumulate_energy('energy_cache', energy)
            
            # ğŸ”§ å¢å¼ºçŠ¶æ€è½¬ç§»é€æ˜åº¦ï¼šè®°å½•ç¼“å­˜å‘½ä¸­ä»»åŠ¡è¯¦æƒ…
            target_key = 'rsu' if node_type == 'RSU' else 'uav'
            execution_detail = {
                'task_id': task.get('id', 'unknown'),
                'vehicle_id': vehicle.get('id', 'unknown'),
                'target_type': target_key,
                'target_id': node_idx,
                'result': 'completed',
                'delay': delay,
                'energy': energy,
                'data_size_mb': task.get('data_size', 0.0),
                'task_type': task.get('task_type', 0),
                'cache_hit': True,
            }
            step_summary['task_execution_details'].append(execution_detail)
            
            # æ›´æ–°æ‰§è¡Œæ‘˜è¦
            exec_summary = step_summary['execution_summary']
            exec_summary['completed'] += 1
            exec_summary['cache_hits'] += 1
            exec_summary['offload_distribution'][target_key] += 1
            
            # è®¡ç®—å¹³å‡å»¶è¿Ÿå’Œèƒ½è€—ï¼ˆåŠ æƒå¹³å‡ï¼‰
            target_count = exec_summary['offload_distribution'][target_key]
            prev_avg_delay = exec_summary['avg_delay_by_target'][target_key]
            prev_avg_energy = exec_summary['avg_energy_by_target'][target_key]
            exec_summary['avg_delay_by_target'][target_key] = ((target_count - 1) * prev_avg_delay + delay) / target_count
            exec_summary['avg_energy_by_target'][target_key] = ((target_count - 1) * prev_avg_energy + energy) / target_count
        # ğŸ”§ è®°å½•å¯è§†åŒ–äº‹ä»¶ (ç¼“å­˜å‘½ä¸­)
        if 'step_events' in step_summary:
            try:
                v_id = int(vehicle['id'].split('_')[1])
                step_summary['step_events'].append({
                    'type': node_type.lower(),
                    'vehicle_id': v_id,
                    'target_id': node_idx
                })
            except (IndexError, ValueError):
                pass
            return True

        # ç¼“å­˜æœªå‘½ä¸­ï¼šè®¡ç®—ä¸Šä¼ å¼€é”€
        # Cache miss: calculate upload overhead
        # ğŸ”§ P0ä¿®å¤ï¼šä¼ é€’vehicleå‚æ•°ä»¥ä½¿ç”¨åŠ¨æ€åˆ†é…å¸¦å®½
        upload_delay, upload_energy = self._estimate_transmission(
            task.get('data_size_bytes', 1e6), distance, node_type.lower(), vehicle=vehicle
        )
        self._accumulate_delay('delay_uplink', upload_delay)
        self.stats['energy_uplink'] += upload_energy
        self._accumulate_energy('energy_transmit_uplink', upload_energy)
        vehicle['energy_consumed'] = vehicle.get('energy_consumed', 0.0) + upload_energy

        # ä¼°ç®—è¿œç¨‹å·¥ä½œé‡å¹¶åˆ›å»ºä»»åŠ¡æ¡ç›®
        # Estimate remote workload and create task entry
        work_units = self._estimate_remote_work_units(task, node_type)
        task_entry = {
            'id': task['id'],
            'vehicle_id': task['vehicle_id'],
            'arrival_time': self.current_time + upload_delay,
            'deadline': task['deadline'],
            'data_size': task.get('data_size', 1.0),
            'data_size_bytes': task.get('data_size_bytes', 1e6),
            'content_id': task.get('content_id'),
            'computation_requirement': task.get('computation_requirement', 1500.0),
            # ä¿ç•™åŸå§‹è®¡ç®—å‘¨æœŸä»¥ä¾¿èµ„æºåˆ©ç”¨ç‡ç»Ÿè®¡ï¼ˆRSU/UAV compute_usageï¼‰
            'compute_cycles': float(task.get('compute_cycles', 0.0) or task.get('computation_requirement', 1500.0) * 1e6),
            'work_remaining': work_units,
            'queued_at': self.current_time,
            'node_type': node_type,
            'node_idx': node_idx,
            'upload_delay': upload_delay,
            'priority': task.get('priority', 0.5),
            'task_type': task.get('task_type'),
            'app_scenario': task.get('app_scenario'),
            'deadline_relax_factor': task.get('deadline_relax_factor', 1.0),
            # ğŸ†• Luoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼šä¿ç•™å‰©ä½™ç”Ÿå‘½å‘¨æœŸå­—æ®µ
            'remaining_lifetime_slots': task.get('remaining_lifetime_slots', task.get('max_delay_slots', 5)),
        }

        # åŸæœ‰é˜Ÿåˆ—ç³»ç»Ÿï¼šæ·»åŠ åˆ° computation_queue
        queue = node.setdefault('computation_queue', [])
        queue.append(task_entry)
        
        # ğŸ†• Luoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼šåŒæ­¥æ·»åŠ åˆ° lifetime_queues
        # æ ¹æ®ä»»åŠ¡çš„å‰©ä½™ç”Ÿå‘½å‘¨æœŸï¼ŒåŠ å…¥ç›¸åº”é˜Ÿåˆ—
        if 'lifetime_queues' in node:
            lifetime = task_entry.get('remaining_lifetime_slots', 5)
            # ç¡®ä¿ lifetime åœ¨åˆç†èŒƒå›´å†…
            max_lifetime = getattr(self.queue_config, 'max_lifetime', 10) if hasattr(self, 'queue_config') else 10
            if node_type in ('RSU', 'UAV'):
                # RSU/UAV æœ€å¤§ L-1
                lifetime = max(1, min(lifetime, max_lifetime - 1))
            else:
                # Vehicle æœ€å¤§ L
                lifetime = max(1, min(lifetime, max_lifetime))
            
            # æ·»åŠ ä»»åŠ¡åˆ°å¯¹åº”çš„ç”Ÿå‘½å‘¨æœŸé˜Ÿåˆ—
            if lifetime in node['lifetime_queues']:
                node['lifetime_queues'][lifetime].append(task_entry)
        
        self._enforce_queue_capacity(node, node_type, step_summary)
        self._apply_queue_scheduling(node, node_type)
        self._append_active_task(task_entry)
        self._record_mm1_arrival(node_type, node_idx)
        # ğŸ”¥ è®°å½•RSU/UAVä»»åŠ¡ç»Ÿè®¡
        if node_type == 'RSU':
            step_summary['rsu_tasks'] = step_summary.get('rsu_tasks', 0) + 1
        elif node_type == 'UAV':
            step_summary['uav_tasks'] = step_summary.get('uav_tasks', 0) + 1
        
        # ğŸ”§ å¢å¼ºçŠ¶æ€è½¬ç§»é€æ˜åº¦ï¼šè®°å½•è¿œç¨‹å¸è½½ä»»åŠ¡è¯¦æƒ…ï¼ˆæ’é˜Ÿä¸­ï¼‰
        target_key = 'rsu' if node_type == 'RSU' else 'uav'
        execution_detail = {
            'task_id': task.get('id', 'unknown'),
            'vehicle_id': vehicle.get('id', 'unknown'),
            'target_type': target_key,
            'target_id': node_idx,
            'result': 'queued',  # ä»»åŠ¡è¢«æ’é˜Ÿï¼Œç¨åå¤„ç†
            'delay': upload_delay,  # å·²çŸ¥çš„ä¸Šä¼ å»¶è¿Ÿ
            'energy': upload_energy,  # å·²çŸ¥çš„ä¸Šä¼ èƒ½è€—
            'data_size_mb': task.get('data_size', 0.0),
            'task_type': task.get('task_type', 0),
            'cache_hit': False,
            'queue_position': len(queue),  # é˜Ÿåˆ—ä½ç½®
        }
        step_summary['task_execution_details'].append(execution_detail)
        
        # æ›´æ–°æ‰§è¡Œæ‘˜è¦
        exec_summary = step_summary['execution_summary']
        exec_summary['offload_distribution'][target_key] += 1
        
        # ğŸ”§ è®°å½•å¯è§†åŒ–äº‹ä»¶ (è¿œç¨‹å¸è½½)
        if 'step_events' in step_summary:
            try:
                v_id = int(vehicle['id'].split('_')[1])
                step_summary['step_events'].append({
                    'type': node_type.lower(),
                    'vehicle_id': v_id,
                    'target_id': node_idx
                })
            except (IndexError, ValueError):
                pass
        return True

    def _apply_queue_scheduling(self, node: Dict, node_type: str) -> None:
        """??????????????????"""
        if node_type not in ('RSU', 'UAV'):
            return
        queue = node.get('computation_queue')
        if not isinstance(queue, list) or len(queue) <= 1:
            return
        params = getattr(self, '_scheduling_params', None)
        if not params:
            return
        priority_bias = float(np.clip(params.get('priority_bias', 0.5), 0.0, 1.0))
        deadline_bias = float(np.clip(params.get('deadline_bias', 0.5), 0.0, 1.0))
        window = int(max(1, params.get('reorder_window', 1)))
        window = min(window, len(queue))
        if window <= 1:
            return
        current_time = getattr(self, 'current_time', 0.0)
        scored: List[Tuple[float, float, int]] = []
        for idx, task in enumerate(queue):
            try:
                priority_raw = float(task.get('priority', 4.0))
            except (TypeError, ValueError):
                priority_raw = 4.0
            priority_score = 1.0 - float(np.clip((priority_raw - 1.0) / 3.0, 0.0, 1.0))
            deadline_value = float(task.get('deadline', current_time))
            slack = deadline_value - current_time
            slack_norm = float(np.clip(slack / max(self.time_slot * 8.0, 1e-6), 0.0, 1.0))
            deadline_score = 1.0 - slack_norm
            wait = current_time - float(task.get('queued_at', current_time))
            wait_norm = float(np.clip(wait / max(self.time_slot * 8.0, 1e-6), 0.0, 1.0))
            weight_delay = priority_bias
            weight_deadline = deadline_bias
            weight_wait = max(0.0, 1.0 - (weight_delay + weight_deadline))
            total = weight_delay + weight_deadline + weight_wait
            if total <= 0.0:
                weight_delay, weight_deadline, weight_wait = 0.4, 0.4, 0.2
                total = 1.0
            weight_delay /= total
            weight_deadline /= total
            weight_wait /= total
            score = (weight_delay * priority_score) + (weight_deadline * deadline_score) + (weight_wait * wait_norm)
            scored.append((score, -wait, idx))
        scored.sort(key=lambda item: (item[0], item[1]), reverse=True)
        selected_indices = [entry[2] for entry in scored[:window]]
        selected_set = set(selected_indices)
        reordered = [queue[idx] for idx in selected_indices]
        remainder = [queue[i] for i in range(len(queue)) if i not in selected_set]
        queue[:] = reordered + remainder

    def _handle_local_processing(self, vehicle: Dict, task: Dict, step_summary: Dict):
        """
        æœ¬åœ°å¤„ç†ä»»åŠ¡
        
        åœ¨è½¦è¾†æœ¬åœ°è®¾å¤‡ä¸Šå¤„ç†ä»»åŠ¡ï¼Œè®¡ç®—å»¶è¿Ÿå’Œèƒ½è€—ã€‚
        ğŸ”§ 2024-12-02 ä¿®å¤ï¼šæ£€æŸ¥ä»»åŠ¡æ˜¯å¦åœ¨deadlineå†…å®Œæˆ
        
        Args:
            vehicle: è½¦è¾†å­—å…¸
            task: ä»»åŠ¡å­—å…¸
            step_summary: æ­¥éª¤ç»Ÿè®¡æ‘˜è¦
            
        Handle task processing on local vehicle device.
        """
        if not getattr(self, 'allow_local_processing', True):
            self._record_forced_drop(vehicle, task, step_summary, reason='local_processing_disabled')
            return

        processing_delay, energy = self._estimate_local_processing(task, vehicle)
        
        # ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥æœ¬åœ°å¤„ç†æ˜¯å¦åœ¨deadlineå†…å®Œæˆ
        # ä»»åŠ¡å®Œæˆæ—¶é—´ = å½“å‰æ—¶é—´ + å¤„ç†å»¶è¿Ÿ
        completion_time = self.current_time + processing_delay
        task_deadline = task.get('deadline', float('inf'))
        
        if completion_time > task_deadline:
            # ä»»åŠ¡æ— æ³•åœ¨deadlineå†…å®Œæˆï¼Œæ ‡è®°ä¸ºä¸¢å¼ƒ
            self.stats['dropped_tasks'] = self.stats.get('dropped_tasks', 0) + 1
            self.stats['dropped_data_bytes'] = self.stats.get('dropped_data_bytes', 0.0) + float(task.get('data_size_bytes', 0.0))
            task['dropped'] = True
            task['drop_reason'] = 'local_deadline_exceeded'
            step_summary['dropped_tasks'] = step_summary.get('dropped_tasks', 0) + 1
            step_summary['local_drops'] = step_summary.get('local_drops', 0) + 1
            return
        
        self.stats['processed_tasks'] += 1
        self.stats['completed_tasks'] += 1
        self._accumulate_delay('delay_processing', processing_delay)
        self._accumulate_energy('energy_compute', energy)
        
        # æŒ‰ä»»åŠ¡ç±»åˆ«è®°å½•æ—¶å»¶ç»Ÿè®¡
        self._record_task_type_delay(task, processing_delay)
        
        cpu_freq = float(vehicle.get('cpu_freq', self.vehicle_cpu_freq))
        cycles_consumed = processing_delay * cpu_freq
        vehicle['local_cycle_used'] = vehicle.get('local_cycle_used', 0.0) + cycles_consumed
        available_cycles = max(1e-6, cpu_freq * self.time_slot)
        vehicle['compute_usage'] = float(np.clip(vehicle['local_cycle_used'] / available_cycles, 0.0, 1.0))
        
        # ğŸ”§ æ–°å¢ï¼šæ›´æ–°è½¦è¾†é˜Ÿåˆ—é•¿åº¦ï¼ˆç”¨äºçŠ¶æ€ç¼–ç ï¼‰
        # ç»Ÿè®¡æ‰€æœ‰ä¼˜å…ˆçº§é˜Ÿåˆ—çš„æ€»é•¿åº¦
        queue_length = sum(len(queue) for queue in vehicle.get('task_queue_by_priority', {}).values())
        vehicle['queue_length'] = queue_length
        
        # ğŸ”§ ä¿®å¤ï¼šæœ¬åœ°å¤„ç†å®Œæˆåå°è¯•ç¼“å­˜å†…å®¹
        cache_ctrl = getattr(self, 'adaptive_cache_controller', None)
        content_id = task.get('content_id')
        if cache_ctrl and content_id:
            try:
                # è·å–å†…å®¹å¤§å°å’Œç¼“å­˜çŠ¶æ€
                data_size = self._get_realistic_content_size(content_id)
                if 'device_cache' not in vehicle:
                    vehicle['device_cache'] = {}
                cache_snapshot = vehicle['device_cache']
                
                # è½¦è¾†ç¼“å­˜å®¹é‡ (é»˜è®¤ 500MB)
                capacity = float(vehicle.get('cache_capacity', 500.0)) 
                used = sum(float(item.get('size', 0.0)) for item in cache_snapshot.values())
                available = max(0.0, capacity - used)
                
                # å†³ç­–æ˜¯å¦ç¼“å­˜
                should_cache, reason, evictions = cache_ctrl.should_cache_content(
                    content_id, data_size, available, cache_snapshot, capacity,
                    cache_priority=task.get('priority', 0.5)
                )
                
                if should_cache:
                    # æ‰§è¡Œæ·˜æ±°
                    reclaimed = 0.0
                    for evict_id in evictions:
                        removed = cache_snapshot.pop(evict_id, None)
                        if removed:
                            reclaimed += float(removed.get('size', 0.0) or 0.0)
                            cache_ctrl.cache_stats['evicted_items'] += 1
                    
                    if reclaimed > 0.0:
                        available += reclaimed
                        
                    # å†™å…¥ç¼“å­˜
                    if available >= data_size:
                        cache_snapshot[content_id] = {
                            'size': data_size,
                            'timestamp': getattr(self, 'current_time', 0.0),
                            'reason': reason or 'local_process_cache',
                            'content_type': self._infer_content_type(content_id)
                        }
                        # æ›´æ–°çƒ­åº¦
                        cache_ctrl.update_content_heat(content_id)
            except Exception:
                pass
        
        step_summary['local_tasks'] += 1
        
        # ğŸ”§ å¢å¼ºçŠ¶æ€è½¬ç§»é€æ˜åº¦ï¼šè®°å½•æœ¬åœ°å¤„ç†ä»»åŠ¡è¯¦æƒ…
        execution_detail = {
            'task_id': task.get('id', 'unknown'),
            'vehicle_id': vehicle.get('id', 'unknown'),
            'target_type': 'local',
            'target_id': None,
            'result': 'completed',
            'delay': processing_delay,
            'energy': energy,
            'data_size_mb': task.get('data_size', 0.0),
            'task_type': task.get('task_type', 0),
            'cache_hit': False,
        }
        step_summary['task_execution_details'].append(execution_detail)
        
        # æ›´æ–°æ‰§è¡Œæ‘˜è¦
        exec_summary = step_summary['execution_summary']
        exec_summary['completed'] += 1
        exec_summary['offload_distribution']['local'] += 1
        
        # è®¡ç®—å¹³å‡å»¶è¿Ÿå’Œèƒ½è€—ï¼ˆåŠ æƒå¹³å‡ï¼‰
        local_count = exec_summary['offload_distribution']['local']
        prev_avg_delay = exec_summary['avg_delay_by_target']['local']
        prev_avg_energy = exec_summary['avg_energy_by_target']['local']
        exec_summary['avg_delay_by_target']['local'] = ((local_count - 1) * prev_avg_delay + processing_delay) / local_count
        exec_summary['avg_energy_by_target']['local'] = ((local_count - 1) * prev_avg_energy + energy) / local_count
        
        # ğŸ”§ è®°å½•å¯è§†åŒ–äº‹ä»¶
        if 'step_events' in step_summary:
            try:
                v_id = int(vehicle['id'].split('_')[1])
                step_summary['step_events'].append({
                    'type': 'local',
                    'vehicle_id': v_id,
                    'target_id': 0
                })
            except (IndexError, ValueError):
                pass

    def _record_forced_drop(self, vehicle: Dict, task: Dict, step_summary: Dict, reason: str = 'forced_drop') -> None:
        """è®°å½•å› ç­–ç•¥çº¦æŸå¯¼è‡´çš„ä»»åŠ¡ä¸¢å¼ƒäº‹ä»¶
        
        ğŸ”§ å…³é”®ä¿®å¤ï¼šé˜²æ­¢é‡å¤ç»Ÿè®¡å·²ä¸¢å¼ƒçš„ä»»åŠ¡
        """
        # ğŸ”§ å¦‚æœä»»åŠ¡å·²ç»è¢«æ ‡è®°ä¸ºä¸¢å¼ƒï¼Œç›´æ¥è¿”å›ï¼Œé¿å…é‡å¤è®¡æ•°
        if task.get('dropped', False):
            return
        
        task['dropped'] = True  # ç«‹å³æ ‡è®°ï¼Œé˜²æ­¢åç»­é‡å¤å¤„ç†
        task['drop_reason'] = reason
        
        self.stats['dropped_tasks'] = self.stats.get('dropped_tasks', 0) + 1
        self.stats['dropped_data_bytes'] = self.stats.get('dropped_data_bytes', 0.0) + float(task.get('data_size_bytes', 0.0))

        drop_stats = self.stats.setdefault('drop_stats', {
            'total': 0,
            'wait_time_sum': 0.0,
            'queue_sum': 0,
            'by_type': {},
            'by_scenario': {},
            'by_reason': {}
        })
        drop_stats['total'] = drop_stats.get('total', 0) + 1
        task_type = task.get('task_type', 'unknown')
        scenario_name = task.get('app_scenario', 'unknown')
        by_type = drop_stats.setdefault('by_type', {})
        by_type[task_type] = by_type.get(task_type, 0) + 1
        by_scenario = drop_stats.setdefault('by_scenario', {})
        by_scenario[scenario_name] = by_scenario.get(scenario_name, 0) + 1
        by_reason = drop_stats.setdefault('by_reason', {})
        by_reason[reason] = by_reason.get(reason, 0) + 1

        step_summary['dropped_tasks'] = step_summary.get('dropped_tasks', 0) + 1
        forced_key = 'forced_drops'
        step_summary[forced_key] = step_summary.get(forced_key, 0) + 1
        step_summary['last_forced_drop_reason'] = reason
        
        # ğŸ”§ å¢å¼ºçŠ¶æ€è½¬ç§»é€æ˜åº¦ï¼šè®°å½•ä¸¢å¼ƒä»»åŠ¡è¯¦æƒ…
        execution_detail = {
            'task_id': task.get('id', 'unknown'),
            'vehicle_id': vehicle.get('id', 'unknown'),
            'target_type': 'dropped',
            'target_id': None,
            'result': 'dropped',
            'delay': 0.0,
            'energy': 0.0,
            'data_size_mb': task.get('data_size', 0.0),
            'task_type': task.get('task_type', 0),
            'cache_hit': False,
            'drop_reason': reason,
        }
        step_summary['task_execution_details'].append(execution_detail)
        
        # æ›´æ–°æ‰§è¡Œæ‘˜è¦
        exec_summary = step_summary['execution_summary']
        exec_summary['dropped'] += 1
        drop_reasons = exec_summary['drop_reasons']
        drop_reasons[reason] = drop_reasons.get(reason, 0) + 1

    
    def check_adaptive_migration(self, agents_actions: Optional[Dict] = None):
        """é¦ƒå¹† æ¾¶æ°±æ·®æ´ï¸½æ«¤é‘³å€Ÿç¸¼ç»‰ç»˜éŒ?(é—ƒå â‚¬è‰°Ğ•é™?ç’ç†»æµ‡å®¸Ğ•é™?ç’ºç†¼æ®¢æ©ä½ºĞ©)"""
        if not agents_actions or 'migration_controller' not in agents_actions:
            return
        
        migration_controller = agents_actions['migration_controller']
        coordinator = getattr(self, 'strategy_coordinator', None)
        joint_params = agents_actions.get('joint_strategy_params', {}) if isinstance(agents_actions, dict) else {}
        
        hotspot_map: Dict[str, float] = {}
        collaborative_system = getattr(self, 'collaborative_cache', None)
        if collaborative_system is not None and hasattr(collaborative_system, 'get_hotspot_intensity'):
            try:
                hotspot_map = collaborative_system.get_hotspot_intensity()
            except (AttributeError, TypeError, RuntimeError) as e:
                logging.debug(f"Failed to get hotspot intensity: {e}")
                hotspot_map = {}
        
        # é¦ƒæ”³ é€å •æ³¦éµâ‚¬éˆå¤å¦­éåœ­å§¸é¬ä½ºæ•¤æµœåº¨å¦çå‘®ç˜®æˆ?
        all_node_states = {}
        
        # RSUé˜èˆµâ‚¬ä½¹æ•¹é—†?
        for i, rsu in enumerate(self.rsus):
            queue = rsu.get('computation_queue', [])
            queue_len = len(queue)
            cache_capacity = rsu.get('cache_capacity', 1000.0)
            available_cache = self._calculate_available_cache_capacity(rsu.get('cache', {}), cache_capacity)
            storage_load = 0.0 if cache_capacity <= 0 else 1.0 - (available_cache / max(1.0, cache_capacity))
            total_data = sum(task.get('data_size', 1.0) for task in queue)
            bandwidth_capacity = rsu.get('bandwidth_capacity', 50.0)
            bandwidth_load = float(np.clip(total_data / max(1.0, bandwidth_capacity), 0.0, 0.99))
            cpu_load = float(np.clip(queue_len / 10.0, 0.0, 0.99))

            all_node_states[f'rsu_{i}'] = {
                'cpu_load': cpu_load,
                'bandwidth_load': bandwidth_load,
                'storage_load': float(np.clip(storage_load, 0.0, 0.99)),
                'load_factor': self._calculate_enhanced_load_factor(rsu, 'RSU'),
                'battery_level': 1.0,
                'node_type': 'RSU',
                'queue_length': queue_len,
                'cache_capacity': cache_capacity,
                'cache_available': available_cache,
                'hotspot_intensity': float(np.clip(hotspot_map.get(f'RSU_{i}', 0.0), 0.0, 1.0)),
                # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ cpu_frequencyå­—æ®µä¾›æ™ºèƒ½ä½“ä½¿ç”¨
                'cpu_frequency': rsu.get('cpu_freq', 12.5e9),  # RSUè®¡ç®—é¢‘ç‡
                'cpu_utilization': cpu_load,  # CPUåˆ©ç”¨ç‡ï¼ˆä¸td3_optimized.pyä¿æŒä¸€è‡´ï¼‰
                'queue_utilization': cpu_load,  # é˜Ÿåˆ—åˆ©ç”¨ç‡
                'cache_utilization': storage_load,  # ç¼“å­˜åˆ©ç”¨ç‡
                'energy_consumption': rsu.get('energy_consumed', 0.0),  # èƒ½è€—
            }

        # UAVé˜èˆµâ‚¬ä½¹æ•¹é—†?
        for i, uav in enumerate(self.uavs):
            queue = uav.get('computation_queue', [])
            queue_len = len(queue)
            cache_capacity = uav.get('cache_capacity', 200.0)
            available_cache = self._calculate_available_cache_capacity(uav.get('cache', {}), cache_capacity)
            storage_load = 0.0 if cache_capacity <= 0 else 1.0 - (available_cache / max(1.0, cache_capacity))
            total_data = sum(task.get('data_size', 1.0) for task in queue)
            bandwidth_capacity = uav.get('bandwidth_capacity', 15.0)
            bandwidth_load = float(np.clip(total_data / max(1.0, bandwidth_capacity), 0.0, 0.99))
            cpu_load = float(np.clip(queue_len / 12.0, 0.0, 0.99))

            all_node_states[f'uav_{i}'] = {
                'cpu_load': cpu_load,
                'bandwidth_load': bandwidth_load,
                'storage_load': float(np.clip(storage_load, 0.0, 0.99)),
                'load_factor': self._calculate_enhanced_load_factor(uav, 'UAV'),
                'battery_level': uav.get('battery_level', 1.0),
                'node_type': 'UAV',
                'queue_length': queue_len,
                'cache_capacity': cache_capacity,
                'cache_available': available_cache,
                'hotspot_intensity': 0.0,
                # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ cpu_frequencyå­—æ®µä¾›æ™ºèƒ½ä½“ä½¿ç”¨
                'cpu_frequency': uav.get('cpu_freq', 5.0e9),  # UAVè®¡ç®—é¢‘ç‡
                'cpu_utilization': cpu_load,  # CPUåˆ©ç”¨ç‡
                'queue_utilization': cpu_load,  # é˜Ÿåˆ—åˆ©ç”¨ç‡
                'energy_consumption': uav.get('energy_consumed', 0.0),  # èƒ½è€—
            }
        
        # é¦ƒå½š RSUæ©ä½ºĞ©å¦«â‚¬éŒ?(é—ƒå â‚¬?ç’ç†»æµ‡å®¸Ğ•é™?
        for i, rsu in enumerate(self.rsus):
            node_id = f'rsu_{i}'
            current_state = all_node_states[node_id]
            
            # æ›´æ–°è´Ÿè½½å†å²
            migration_controller.update_node_load(node_id, current_state['load_factor'])
            
            # ğŸ”„ å¤šç»´åº¦è¿ç§»è§¦å‘æ£€æŸ¥
            should_migrate, reason, urgency = migration_controller.should_trigger_migration(
                node_id, current_state, all_node_states
            )
            
            if should_migrate:
                self.stats['migrations_executed'] = self.stats.get('migrations_executed', 0) + 1
                print(f"é¦ƒå¹† {node_id} ç‘™ï¹€å½‚æ©ä½ºĞ©: {reason} (ç»±Ñ„â‚¬ãƒ¥å®³:{urgency:.3f})")
                if coordinator is not None:
                    try:
                        coordinator.notify_migration_triggered(node_id, reason, urgency, current_state)
                    except (AttributeError, RuntimeError) as exc:
                        logging.warning(f"âš ï¸ è”åˆç­–ç•¥åè°ƒå™¨è®°å½•RSUè¿ç§»å¼‚å¸¸: {exc}")
                
                # éµÑ†RSUé—‚ç£‹ç¸¼ç»‰?
                result = self.execute_rsu_migration(i, urgency, coordinator=coordinator, joint_params=joint_params)
                if result.get('success'):
                    self.stats['migrations_successful'] = self.stats.get('migrations_successful', 0) + 1
                    migration_controller.record_migration_result(True, cost=result.get('cost', 0.0), delay_saved=result.get('delay_saved', 0.0))
                else:
                    migration_controller.record_migration_result(False)
                if coordinator is not None:
                    try:
                        coordinator.notify_migration_result(
                            node_id,
                            bool(result.get('success')),
                            {'type': 'rsu', 'metadata': result}
                        )
                    except (AttributeError, RuntimeError) as exc:
                        logging.warning(f"âš ï¸ è”åˆç­–ç•¥åè°ƒå™¨è®°å½•RSUè¿ç§»ç»“æœå¼‚å¸¸: {exc}")
        
        # é¦ƒæ® UAVæ©ä½ºĞ©å¦«â‚¬éŒ?
        for i, uav in enumerate(self.uavs):
            node_id = f'uav_{i}'
            current_state = all_node_states[node_id]
            
            # æ›´æ–°è´Ÿè½½å†å²
            migration_controller.update_node_load(node_id, current_state['load_factor'], current_state['battery_level'])
            
            # ğŸ”„ å¤šç»´åº¦è¿ç§»è§¦å‘æ£€æŸ¥
            should_migrate, reason, urgency = migration_controller.should_trigger_migration(
                node_id, current_state, all_node_states
            )
            
            if should_migrate:
                self.stats['migrations_executed'] = self.stats.get('migrations_executed', 0) + 1
                print(f"é¦ƒå¹† {node_id} ç‘™ï¹€å½‚æ©ä½ºĞ©: {reason} (ç»±Ñ„â‚¬ãƒ¥å®³:{urgency:.3f})")
                if coordinator is not None:
                    try:
                        coordinator.notify_migration_triggered(node_id, reason, urgency, current_state)
                    except (AttributeError, RuntimeError) as exc:
                        logging.warning(f"âš ï¸ è”åˆç­–ç•¥åè°ƒå™¨è®°å½•UAVè¿ç§»å¼‚å¸¸: {exc}")
                
                # UAVæ©ä½ºĞ©é’ç™›SU
                result = self.execute_uav_migration(i, urgency, coordinator=coordinator, joint_params=joint_params)
                if result.get('success'):
                    self.stats['migrations_successful'] = self.stats.get('migrations_successful', 0) + 1
                    migration_controller.record_migration_result(True, cost=result.get('cost', 0.0), delay_saved=result.get('delay_saved', 0.0))
                else:
                    migration_controller.record_migration_result(False)
                if coordinator is not None:
                    try:
                        coordinator.notify_migration_result(
                            node_id,
                            bool(result.get('success')),
                            {'type': 'uav', 'metadata': result}
                        )
                    except (AttributeError, RuntimeError) as exc:
                        logging.warning(f"âš ï¸ è”åˆç­–ç•¥åè°ƒå™¨è®°å½•UAVè¿ç§»ç»“æœå¼‚å¸¸: {exc}")
        
        # é¦ƒæ®« æï¹ç· ç’ºç†¼æ®¢æ©ä½ºĞ©å¦«â‚¬éŒ?
        self._check_vehicle_handover_migration(migration_controller)
    
    def _check_vehicle_handover_migration(self, migration_controller):
        """è½¦è¾†è·Ÿéšè¿ç§»ï¼šå½“è½¦è¾†è¿œç¦»å½“å‰è¾¹ç¼˜èŠ‚ç‚¹è¦†ç›–æ—¶è§¦å‘è¿ç§»ã€‚"""
        handover_count = 0

        for task in list(self.active_tasks):
            if task.get('node_type') not in ('RSU', 'UAV'):
                continue

            try:
                vehicle = next(v for v in self.vehicles if v['id'] == task['vehicle_id'])
            except StopIteration:
                continue

            origin_node_type = task['node_type']
            origin_node_idx = task.get('node_idx')
            if origin_node_type == 'RSU' and origin_node_idx is not None and 0 <= origin_node_idx < len(self.rsus):
                current_node = self.rsus[origin_node_idx]
            elif origin_node_type == 'UAV' and origin_node_idx is not None and 0 <= origin_node_idx < len(self.uavs):
                current_node = self.uavs[origin_node_idx]
            else:
                continue

            current_pos = np.array(vehicle.get('position', [0.0, 0.0, 0.0]))
            distance_to_current = self.calculate_distance(current_pos, current_node['position'])
            coverage_radius = current_node.get('coverage_radius', 500.0)

            vehicle_speed = float(np.linalg.norm(vehicle.get('velocity', [0.0, 0.0, 0.0])))
            speed_factor = max(0.70, 1.0 - vehicle_speed / 200.0)
            trigger_threshold = coverage_radius * speed_factor

            if distance_to_current <= trigger_threshold:
                continue

            current_queue_before = len(current_node.get('computation_queue', []))
            current_load = float(current_node.get('cpu_usage', 0.5))
            current_score = distance_to_current + current_queue_before * 30 + current_load * 200

            best_new_node = None
            best_node_idx = None
            best_node_type = None
            best_metric = float('inf')

            for idx, rsu in enumerate(self.rsus):
                dist = self.calculate_distance(current_pos, rsu['position'])
                if dist > rsu.get('coverage_radius', 500.0):
                    continue
                queue_len = len(rsu.get('computation_queue', []))
                cpu_load = float(rsu.get('cpu_usage', 0.5))
                score = dist + queue_len * 30 + cpu_load * 200
                if score < best_metric:
                    best_metric = score
                    best_new_node = rsu
                    best_node_idx = idx
                    best_node_type = 'RSU'

            if best_new_node is None or best_metric > current_score * 0.7:
                for idx, uav in enumerate(self.uavs):
                    dist = self.calculate_distance(current_pos, uav['position'])
                    if dist > uav.get('coverage_radius', 350.0):
                        continue
                    queue_len = len(uav.get('computation_queue', []))
                    cpu_load = float(uav.get('cpu_usage', 0.5))
                    score = dist + queue_len * 40 + cpu_load * 220
                    if score < best_metric:
                        best_metric = score
                        best_new_node = uav
                        best_node_idx = idx
                        best_node_type = 'UAV'

            if not best_new_node:
                continue

            should_switch = (best_node_type != task['node_type'] or best_node_idx != origin_node_idx) and best_metric < current_score * 0.7
            if not should_switch:
                continue

            origin_queue_after = current_queue_before
            if origin_node_idx is not None:
                if task['node_type'] == 'RSU':
                    origin_node = self.rsus[origin_node_idx]
                    origin_queue = origin_node.get('computation_queue', [])
                    filtered = [t for t in origin_queue if t.get('id') != task['id']]
                    origin_node['computation_queue'] = filtered
                    # ğŸ†• Luoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼šè¿ç§»ä»»åŠ¡ä»æºèŠ‚ç‚¹lifetime_queuesç§»é™¤
                    self._remove_task_from_lifetime_queues(origin_node, task)
                    origin_queue_after = len(filtered)
                elif task['node_type'] == 'UAV':
                    origin_node = self.uavs[origin_node_idx]
                    origin_queue = origin_node.get('computation_queue', [])
                    filtered = [t for t in origin_queue if t.get('id') != task['id']]
                    origin_node['computation_queue'] = filtered
                    # ğŸ†• Luoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼šè¿ç§»ä»»åŠ¡ä»æºèŠ‚ç‚¹lifetime_queuesç§»é™¤
                    self._remove_task_from_lifetime_queues(origin_node, task)
                    origin_queue_after = len(filtered)

            best_new_node.setdefault('computation_queue', [])
            target_queue_before = len(best_new_node['computation_queue'])
            migrated_task = {
                'id': task['id'],
                'vehicle_id': task['vehicle_id'],
                'arrival_time': task['arrival_time'],
                'deadline': task['deadline'],
                'data_size': task.get('data_size', 2.0),
                'computation_requirement': task.get('computation_requirement', 1000),
                'content_id': task.get('content_id'),
                'compute_time_needed': task.get('compute_time_needed', 1.0),
                'work_remaining': task.get('work_remaining', 0.5),
                'cache_hit': task.get('cache_hit', False),
                'queued_at': self.current_time,
                'migrated_from': f"{task['node_type']}_{task.get('node_idx')}",
                'task_type': task.get('task_type'),
                'app_scenario': task.get('app_scenario'),
                'deadline_relax_factor': task.get('deadline_relax_factor', 1.0),
                # ğŸ†• Luoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼šè¿ç§»ä»»åŠ¡ä¿ç•™remaining_lifetime_slots
                'remaining_lifetime_slots': task.get('remaining_lifetime_slots', task.get('max_delay_slots', 5)),
            }
            best_new_node['computation_queue'].append(migrated_task)
            
            # ğŸ†• Luoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼šè¿ç§»ä»»åŠ¡ä¹Ÿéœ€æ·»åŠ åˆ°ç›®æ ‡èŠ‚ç‚¹çš„lifetime_queues
            if 'lifetime_queues' in best_new_node:
                lifetime = migrated_task.get('remaining_lifetime_slots', 5)
                max_lifetime = getattr(self.queue_config, 'max_lifetime', 10) if hasattr(self, 'queue_config') else 10
                if best_node_type in ('RSU', 'UAV'):
                    lifetime = max(1, min(lifetime, max_lifetime - 1))
                else:
                    lifetime = max(1, min(lifetime, max_lifetime))
                if lifetime in best_new_node['lifetime_queues']:
                    best_new_node['lifetime_queues'][lifetime].append(migrated_task)
            
            best_node_type = best_node_type or 'RSU'
            self._apply_queue_scheduling(best_new_node, best_node_type)
            target_queue_after = len(best_new_node['computation_queue'])

            handover_count += 1

            print(
                f"[VehicleMigration] handover #{handover_count}: vehicle {task['vehicle_id']} task {task['id']} "
                f"{origin_node_type}_{origin_node_idx} -> {best_node_type}_{best_node_idx}"
            )
            print(
                f"   Trigger: distance {distance_to_current:.1f}m > threshold {trigger_threshold:.1f}m "
                f"(speed {vehicle_speed:.1f} m/s)"
            )
            improvement = 0.0
            if current_score > 1e-6:
                improvement = (1 - best_metric / current_score) * 100.0
            print(
                f"   Score: {current_score:.1f} -> {best_metric:.1f} (improvement {improvement:.1f}%)"
            )
            print(
                f"   Queue trend: {origin_node_type}_{origin_node_idx}: {current_queue_before} -> {origin_queue_after}, "
                f"{best_node_type}_{best_node_idx}: {target_queue_before} -> {target_queue_after}"
            )

            task['node_type'] = best_node_type
            task['node_idx'] = best_node_idx

            # ğŸ”§ ä¿®å¤ï¼šè®¡ç®—å¹¶è®°å½•è¿ç§»çš„æ•°æ®é‡ã€å»¶è¿Ÿå’Œèƒ½è€—
            migration_data_mb = task.get('data_size', 2.0)  # MB
            migration_delay_s = migration_data_mb * 8.0 / 50.0  # æ— çº¿ä¼ è¾“ï¼Œ50 Mbpså¸¦å®½
            migration_energy_j = 0.2 * migration_delay_s  # ä¼ è¾“åŠŸç‡0.2W
            
            # ç´¯åŠ åˆ°ç»Ÿè®¡æ•°æ®
            self.stats['rsu_migration_data'] = self.stats.get('rsu_migration_data', 0.0) + migration_data_mb
            self._accumulate_delay('rsu_migration_delay', migration_delay_s)
            self._accumulate_energy('rsu_migration_energy', migration_energy_j)

            self.stats['migrations_executed'] = self.stats.get('migrations_executed', 0) + 1
            self.stats['migrations_successful'] = self.stats.get('migrations_successful', 0) + 1
            self.stats['handover_migrations'] = self.stats.get('handover_migrations', 0) + 1
            migration_controller.record_migration_result(True, cost=5.0, delay_saved=0.3)

        if handover_count > 0:
            print(f"[Migration] Executed {handover_count} vehicle-following migrations.")

    def run_simulation_step(self, step: int, actions: Optional[Dict] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ªä»¿çœŸæ­¥ï¼Œè¿”å›æˆªè‡³å½“å‰çš„ç´¯è®¡ç»Ÿè®¡æ•°æ®
        
        è¿™æ˜¯ä»¿çœŸçš„æ ¸å¿ƒæ–¹æ³•ï¼Œæ‰§è¡Œä¸€ä¸ªæ—¶é—´æ­¥çš„æ‰€æœ‰æ“ä½œï¼š
        1. æ›´æ–°è½¦è¾†ä½ç½®
        2. ç”Ÿæˆå¹¶åˆ†é…æ–°ä»»åŠ¡
        3. æ‰§è¡Œæ™ºèƒ½è¿ç§»ç­–ç•¥
        4. å¤„ç†èŠ‚ç‚¹é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        5. æ£€æŸ¥è¶…æ—¶å¹¶æ¸…ç†
        
        Args:
            step: å½“å‰ä»¿çœŸæ­¥æ•°
            actions: æ™ºèƒ½ä½“çš„åŠ¨ä½œå­—å…¸ï¼ˆå¯é€‰ï¼‰ï¼ŒåŒ…å«ç¼“å­˜æ§åˆ¶å™¨ã€è¿ç§»æ§åˆ¶å™¨ç­‰
            
        Returns:
            åŒ…å«ç´¯è®¡ç»Ÿè®¡æ•°æ®çš„å­—å…¸
            
        Execute a single simulation step and return cumulative statistics.
        """
        actions = actions or {}
        self._update_scheduling_params(actions.get('scheduling_params'))
        self._prepare_step_usage_counters()
        
        # ğŸ”§ ä¿®å¤1: é‡ç½®RSU/UAVå³æ—¶è¿æ¥è®¡æ•°å™¨
        # Reset immediate connection counters for RSUs and UAVs at the start of each step
        for rsu in self.rsus:
            rsu['served_vehicles'] = 0
            rsu['coverage_vehicles'] = 0
        
        for uav in self.uavs:
            uav['served_vehicles'] = 0
        
        if self._central_resource_enabled and hasattr(self, 'resource_pool'):
            try:
                self.execute_phase2_scheduling()
            except (AttributeError, RuntimeError) as exc:
                logging.debug(f"Phase-2 scheduling execution failed: {exc}")

        # æ¨è¿›ä»¿çœŸæ—¶é—´
        advance_simulation_time()
        self.current_step += 1
        self.current_time = get_simulation_time()

        # å½“å‰æ­¥éª¤çš„ç»Ÿè®¡æ‘˜è¦
        step_summary: Dict[str, Any] = {
            'generated_tasks': 0,  # æœ¬æ­¥ç”Ÿæˆçš„ä»»åŠ¡æ•°
            'local_tasks': 0,  # æœ¬åœ°å¤„ç†çš„ä»»åŠ¡æ•°
            'remote_tasks': 0,  # è¿œç¨‹å¸è½½çš„ä»»åŠ¡æ•°
            'rsu_tasks': 0,  # RSUå¤„ç†çš„ä»»åŠ¡æ•°
            'uav_tasks': 0,  # UAVå¤„ç†çš„ä»»åŠ¡æ•°
            'local_cache_hits': 0,  # æœ¬åœ°ç¼“å­˜å‘½ä¸­æ¬¡æ•°
            'queue_overflow_drops': 0,  # æœ¬æ­¥å› é˜Ÿåˆ—æº¢å‡ºçš„ä¸¢å¼ƒ
            'step_events': [],  # ğŸ”§ æ–°å¢ï¼šç”¨äºå®æ—¶å¯è§†åŒ–çš„äº‹ä»¶åˆ—è¡¨
            'vehicle_positions': [],  # ğŸ”§ æ–°å¢ï¼šç”¨äºå®æ—¶å¯è§†åŒ–çš„è½¦è¾†ä½ç½®
            # ğŸ”§ å¢å¼ºçŠ¶æ€è½¬ç§»é€æ˜åº¦ï¼šè¯¦ç»†ä»»åŠ¡æ‰§è¡Œåé¦ˆ
            'task_execution_details': [],  # æ¯ä¸ªä»»åŠ¡çš„è¯¦ç»†æ‰§è¡Œä¿¡æ¯
            'execution_summary': {  # æœ¬æ­¥æ‰§è¡Œæ‘˜è¦
                'completed': 0,  # æˆåŠŸå®Œæˆçš„ä»»åŠ¡æ•°
                'dropped': 0,  # ä¸¢å¼ƒçš„ä»»åŠ¡æ•°
                'cache_hits': 0,  # ç¼“å­˜å‘½ä¸­æ•°
                'offload_distribution': {'local': 0, 'rsu': 0, 'uav': 0},
                'avg_delay_by_target': {'local': 0.0, 'rsu': 0.0, 'uav': 0.0},
                'avg_energy_by_target': {'local': 0.0, 'rsu': 0.0, 'uav': 0.0},
                'drop_reasons': {},  # ä¸¢å¼ƒåŸå› ç»Ÿè®¡
            }
        }

        # 1. æ›´æ–°è½¦è¾†ä½ç½®
        # Update vehicle positions based on movement model
        self._update_vehicle_positions()
        
        # ğŸ”§ è®°å½•è½¦è¾†ä½ç½®ä¾›å¯è§†åŒ–ä½¿ç”¨
        for v in self.vehicles:
            try:
                v_id = int(v['id'].split('_')[1])
                step_summary['vehicle_positions'].append({
                    'id': v_id,
                    'x': float(v['position'][0]),
                    'y': float(v['position'][1]),
                    'dir': float(v.get('direction', 0.0))
                })
            except (IndexError, ValueError):
                pass

        # 2. ç”Ÿæˆä»»åŠ¡å¹¶ï¼ˆå¯é€‰ï¼‰ä¸¤é˜¶æ®µè§„åˆ’ååˆ†é…
        # Generate new tasks for each vehicle first (batch), then optionally plan
        tasks_batch: List[Tuple[int, Dict, Dict]] = []
        for vidx, vehicle in enumerate(self.vehicles):
            arrivals = self._sample_arrivals()
            if arrivals <= 0:
                continue
            vehicle_id = vehicle['id']
            for _ in range(arrivals):
                task = self.generate_task(vehicle_id)
                step_summary['generated_tasks'] += 1
                self.stats['total_tasks'] += 1
                self.stats['generated_data_bytes'] += float(task.get('data_size_bytes', 0.0))
                tasks_batch.append((vidx, vehicle, task))

        # Stage-1 planning (coarse assignment + resource estimation)
        # If STAGE1_ALG is present (Dual-stage controller mode), we skip heuristic
        # planning here because Stage-1 decisions are embedded in the action vector.
        plan_map: Dict[str, PlanEntry] = {}
        if self._two_stage_enabled and tasks_batch and (os.environ.get('STAGE1_ALG', '').strip() == ''):
            if self._two_stage_planner is None:
                self._two_stage_planner = TwoStagePlanner()
            plan_map = self._two_stage_planner.build_plan(self, tasks_batch)

        # Dispatch tasks (use plan if available)
        for vidx, vehicle, task in tasks_batch:
            plan_entry = plan_map.get(task.get('id') or task.get('task_id', '')) if plan_map else None
            if plan_entry is not None:
                self._dispatch_task_with_plan(vehicle, task, plan_entry, actions, step_summary)
            else:
                self._dispatch_task(vehicle, task, actions, step_summary)

        # 3. æ™ºèƒ½è¿ç§»ç­–ç•¥
        # Execute intelligent migration strategy
        if actions:
            self.check_adaptive_migration(actions)

        # ğŸ†• Luoè®ºæ–‡é˜Ÿåˆ—æ¨¡å‹ï¼šæ¯ä¸ªæ—¶éš™å¼€å§‹å‰ï¼Œæ›´æ–°æ‰€æœ‰èŠ‚ç‚¹çš„ç”Ÿå‘½å‘¨æœŸé˜Ÿåˆ—
        # æ ¸å¿ƒæœºåˆ¶ï¼šé˜Ÿåˆ—lä¸­æœªå¤„ç†çš„ä»»åŠ¡é™çº§åˆ°é˜Ÿåˆ—l-1ï¼Œl=1æ—¶è¿‡æœŸä»»åŠ¡è¢«åˆ é™¤
        for vehicle in self.vehicles:
            self._update_lifetime_queues(vehicle, 'VEHICLE', step_summary)
        
        for idx, rsu in enumerate(self.rsus):
            self._update_lifetime_queues(rsu, 'RSU', step_summary)
        
        for idx, uav in enumerate(self.uavs):
            self._update_lifetime_queues(uav, 'UAV', step_summary)

        # 4. å¤„ç†é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        # Process tasks in node queues
        self._process_node_queues()

        # 5. å¦«â‚¬éŒãƒ¨ç§´éƒè·ºè‹Ÿå¨“å‘¯æ‚Š
        self._handle_deadlines()
        self._cleanup_active_tasks()

        # æ±‡æ€»ä¿¡æ¯
        step_summary['current_time'] = self.current_time
        step_summary['rsu_queue_lengths'] = [len(rsu.get('computation_queue', [])) for rsu in self.rsus]
        step_summary['uav_queue_lengths'] = [len(uav.get('computation_queue', [])) for uav in self.uavs]
        step_summary['active_tasks'] = len(self.active_tasks)
        
        # ğŸ”§ æ–°å¢ï¼šè®¡ç®—å¸è½½æ¯”ä¾‹æŒ‡æ ‡ï¼ˆç”¨äºå¥–åŠ±å‡½æ•°ï¼‰
        total_tasks = step_summary['local_tasks'] + step_summary['rsu_tasks'] + step_summary['uav_tasks']
        if total_tasks > 0:
            step_summary['local_offload_ratio'] = step_summary['local_tasks'] / total_tasks
            step_summary['rsu_offload_ratio'] = step_summary['rsu_tasks'] / total_tasks
            step_summary['uav_offload_ratio'] = step_summary['uav_tasks'] / total_tasks
        else:
            # é»˜è®¤å€¼ï¼ˆæ²¡æœ‰ä»»åŠ¡æ—¶ï¼‰
            step_summary['local_offload_ratio'] = 0.33
            step_summary['rsu_offload_ratio'] = 0.33
            step_summary['uav_offload_ratio'] = 0.34

        stability_metrics = self._monitor_queue_stability()
        for key, value in stability_metrics.items():
            step_summary[key] = value
        task_type_summary = self._summarize_task_types()
        for key, value in task_type_summary.items():
            step_summary[key] = value
        mm1_predictions = self._finalize_mm1_step(self.current_step)
        if isinstance(mm1_predictions, dict):
            step_summary['mm1_predictions'] = mm1_predictions

        if self._central_resource_enabled:
            self._update_central_scheduler(step_summary)

        cumulative_stats = dict(self.stats)
        cumulative_stats.update(step_summary)
        return cumulative_stats

    def _dispatch_task_with_plan(self, vehicle: Dict, task: Dict, plan: PlanEntry,
                                 actions: Dict, step_summary: Dict):
        """Dispatch a task following the Stage-1 plan entry.

        Falls back to legacy dispatch if the target is not feasible.
        """
        try:
            # Local processing
            if plan.target_type == 'local' or plan.target_idx is None:
                return self._handle_local_processing(vehicle, task, step_summary)

            # Remote: RSU/UAV explicit target
            if plan.target_type == 'rsu':
                idx = int(plan.target_idx)
                if 0 <= idx < len(self.rsus):
                    node = self.rsus[idx]
                    distance = self.calculate_distance(vehicle.get('position', np.zeros(2)), node['position'])
                    ok = self._handle_remote_assignment(vehicle, task, node, 'RSU', idx, distance, actions or {}, step_summary)
                    if ok:
                        step_summary['remote_tasks'] += 1
                        return True
            elif plan.target_type == 'uav':
                idx = int(plan.target_idx)
                if 0 <= idx < len(self.uavs):
                    node = self.uavs[idx]
                    distance = self.calculate_distance(vehicle.get('position', np.zeros(2)), node['position'])
                    ok = self._handle_remote_assignment(vehicle, task, node, 'UAV', idx, distance, actions or {}, step_summary)
                    if ok:
                        step_summary['remote_tasks'] += 1
                        return True
        except (AttributeError, TypeError, ValueError):
            # On any failure, fall back to legacy path
            pass

        # Fallback: legacy selection
        return self._dispatch_task(vehicle, task, actions, step_summary)
    
    def execute_rsu_migration(self, source_rsu_idx: int, urgency: float,
                              coordinator: Optional['StrategyCoordinator'] = None,
                              joint_params: Optional[Dict] = None) -> Dict[str, float]:
        """
        æ‰§è¡ŒRSUåˆ°RSUçš„è¿ç§»å¹¶è¿”å›æˆæœ¬/å»¶è¿ŸæŒ‡æ ‡
        
        å®ç°RSUé—´çš„ä»»åŠ¡è¿ç§»ï¼Œé€šè¿‡æœ‰çº¿å›ç¨‹ç½‘ç»œä¼ è¾“ä»»åŠ¡ï¼š
        1. é€‰æ‹©è´Ÿè½½æœ€è½»çš„ç›®æ ‡RSU
        2. æ£€æŸ¥è¿ç§»å®¹å¿åº¦ï¼ˆé¿å…ä¸å¿…è¦çš„è¿ç§»ï¼‰
        3. æ ¹æ®ç´§æ€¥åº¦ç¡®å®šè¿ç§»ä»»åŠ¡æ•°é‡
        4. é€šè¿‡æœ‰çº¿ç½‘ç»œä¼ è¾“ä»»åŠ¡
        5. è®°å½•è¿ç§»æˆæœ¬å’Œå»¶è¿ŸèŠ‚çœ
        
        Args:
            source_rsu_idx: æºRSUçš„ç´¢å¼•
            urgency: è¿ç§»ç´§æ€¥åº¦ï¼ˆ0.0-1.0ï¼‰
            
        Returns:
            åŒ…å«è¿ç§»ç»“æœçš„å­—å…¸ï¼š
            - success: æ˜¯å¦æˆåŠŸ
            - cost: è¿ç§»æˆæœ¬ï¼ˆèƒ½è€—+å»¶è¿Ÿï¼‰
            - delay_saved: èŠ‚çœçš„å»¶è¿Ÿ
            
        Execute RSU-to-RSU migration via wired backhaul network.
        """
        source_rsu = self.rsus[source_rsu_idx]
        source_queue = source_rsu.get('computation_queue', [])
        if not source_queue:
            return {'success': False, 'cost': 0.0, 'delay_saved': 0.0}

        candidates = []
        for i, rsu in enumerate(self.rsus):
            if i == source_rsu_idx:
                continue
            queue_len = len(rsu.get('computation_queue', []))
            cpu_load = min(0.99, queue_len / 10.0)
            score = queue_len + cpu_load * 10.0
            candidates.append((i, queue_len, cpu_load, score))

        if not candidates:
            return {'success': False, 'cost': 0.0, 'delay_saved': 0.0}

        target_idx, target_queue_len, target_cpu_load, _ = min(candidates, key=lambda x: x[3])
        source_queue_len = len(source_queue)
        queue_diff = target_queue_len - source_queue_len

        all_queue_lens = [len(rsu.get('computation_queue', [])) for rsu in self.rsus]
        system_queue_variance = np.var(all_queue_lens)
        if system_queue_variance > 50:
            migration_tolerance = 8
        elif system_queue_variance > 20:
            migration_tolerance = 5
        else:
            migration_tolerance = 3
        if queue_diff > migration_tolerance:
            return {'success': False, 'cost': 0.0, 'delay_saved': 0.0}

        backoff = 0.0
        if joint_params:
            try:
                backoff = float(joint_params.get('migration_backoff', 0.0) or 0.0)
            except (TypeError, ValueError):
                backoff = 0.0
        backoff = float(np.clip(backoff, 0.0, 1.0))

        migration_ratio = max(0.1, min(0.5, urgency * (1.0 - 0.4 * backoff) + 0.05))
        tasks_to_migrate = max(1, int(source_queue_len * migration_ratio))
        tasks_to_migrate = min(tasks_to_migrate, source_queue_len)
        if tasks_to_migrate <= 0:
            return {'success': False, 'cost': 0.0, 'delay_saved': 0.0}

        target_rsu = self.rsus[target_idx]
        if 'computation_queue' not in target_rsu:
            target_rsu['computation_queue'] = []

        source_rsu_id = source_rsu['id']
        target_rsu_id = target_rsu['id']
        migrated_tasks = source_queue[:tasks_to_migrate]
        total_data_size = sum(task.get('data_size', 1.0) for task in migrated_tasks)
        if total_data_size <= 0.0:
            total_data_size = tasks_to_migrate * 1.0
        if coordinator is not None and migrated_tasks:
            try:
                coordinator.prepare_prefetch(source_rsu, target_rsu, migrated_tasks, urgency)
            except (AttributeError, RuntimeError) as exc:
                logging.warning(f"âš ï¸ è¿ç§»å‰é¢„å–åè°ƒå¤±è´¥({source_rsu_id}->{target_rsu_id}): {exc}")

        source_rsu['computation_queue'] = source_queue[tasks_to_migrate:]
        target_rsu['computation_queue'].extend(migrated_tasks)

        queue_relief = max(0.0, source_queue_len - len(source_rsu['computation_queue']))
        delay_saved = max(0.0, queue_relief * self.time_slot)
        migration_cost = 0.0
        try:
            from utils.wired_backhaul_model import calculate_rsu_to_rsu_delay, calculate_rsu_to_rsu_energy
            wired_delay = calculate_rsu_to_rsu_delay(total_data_size, source_rsu_id, target_rsu_id)
            wired_energy = calculate_rsu_to_rsu_energy(total_data_size, source_rsu_id, target_rsu_id, wired_delay)
            self.stats['rsu_migration_delay'] = self.stats.get('rsu_migration_delay', 0.0) + wired_delay
            self.stats['rsu_migration_energy'] = self.stats.get('rsu_migration_energy', 0.0) + wired_energy
            self.stats['rsu_migration_data'] = self.stats.get('rsu_migration_data', 0.0) + total_data_size
            migration_cost = (self.migration_energy_weight * wired_energy) + (self.migration_delay_weight * wired_delay)
        except (ImportError, AttributeError, ValueError) as e:
            logging.debug(f"Wired backhaul model not available, using fallback: {e}")
            migration_cost = total_data_size * 0.2

        return {
            'success': True,
            'cost': migration_cost,
            'delay_saved': delay_saved,
            'target_node': target_rsu_id,
            'tasks_migrated': tasks_to_migrate
        }
    
    def execute_uav_migration(self, source_uav_idx: int, urgency: float,
                              coordinator: Optional['StrategyCoordinator'] = None,
                              joint_params: Optional[Dict] = None) -> Dict[str, float]:
        """
        æ‰§è¡ŒUAVåˆ°RSUçš„è¿ç§»å¹¶è¿”å›æˆæœ¬/å»¶è¿ŸæŒ‡æ ‡
        æ‰§è¡ŒUAVåˆ°RSUçš„è¿ç§»å¹¶è¿”å›æˆæœ¬/å»¶è¿ŸæŒ‡æ ‡
        
        å®ç°UAVåˆ°RSUçš„ä»»åŠ¡è¿ç§»ï¼Œé€šè¿‡æ— çº¿é“¾è·¯ä¼ è¾“ä»»åŠ¡ï¼š
        1. æ ¹æ®è·ç¦»å’Œè´Ÿè½½é€‰æ‹©ç›®æ ‡RSU
        2. è€ƒè™‘æ— çº¿ä¼ è¾“çš„å¯é æ€§ï¼ˆåŸºäºè·ç¦»å’Œè´Ÿè½½ï¼‰
        3. åŠ¨æ€è°ƒæ•´è¿ç§»æ¯”ä¾‹ï¼ˆUAVæ›´æ¿€è¿›ï¼‰
        4. æ¨¡æ‹Ÿæ— çº¿ä¼ è¾“å»¶è¿Ÿå’Œèƒ½è€—
        5. è®°å½•è¿ç§»ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            source_uav_idx: æºUAVçš„ç´¢å¼•
            urgency: è¿ç§»ç´§æ€¥åº¦ï¼ˆ0.0-1.0ï¼‰
            
        Returns:
            åŒ…å«è¿ç§»ç»“æœçš„å­—å…¸ï¼š
            - success: æ˜¯å¦æˆåŠŸï¼ˆè€ƒè™‘æ— çº¿é“¾è·¯å¯é æ€§ï¼‰
            - cost: è¿ç§»æˆæœ¬ï¼ˆèƒ½è€—+å»¶è¿Ÿï¼‰
            - delay_saved: èŠ‚çœçš„å»¶è¿Ÿ
            
        Execute UAV-to-RSU migration via wireless link.
        """
        source_uav = self.uavs[source_uav_idx]
        source_queue = source_uav.get('computation_queue', [])
        if not source_queue:
            return {'success': False, 'cost': 0.0, 'delay_saved': 0.0}

        # å¯»æ‰¾å€™é€‰ç›®æ ‡RSUï¼Œè€ƒè™‘è·ç¦»å’Œè´Ÿè½½
        # Find candidate target RSUs considering distance and load
        uav_position = source_uav['position']
        candidates = []
        for i, rsu in enumerate(self.rsus):
            queue_len = len(rsu.get('computation_queue', []))
            distance = self.calculate_distance(uav_position, rsu['position'])
            cpu_load = min(0.99, queue_len / 10.0)
            score = distance * 0.01 + queue_len + cpu_load * 10.0
            candidates.append((i, queue_len, cpu_load, distance, score))

        if not candidates:
            return {'success': False, 'cost': 0.0, 'delay_saved': 0.0}

        # é€‰æ‹©ç»¼åˆå¾—åˆ†æœ€ä½³çš„ç›®æ ‡RSU
        # Select the best target RSU based on composite score
        target_idx, target_queue_len, target_cpu_load, distance, _ = min(candidates, key=lambda x: x[4])
        target_rsu = self.rsus[target_idx]
        if 'computation_queue' not in target_rsu:
            target_rsu['computation_queue'] = []

        # UAVè¿ç§»æ›´æ¿€è¿›ï¼ˆæ¯”ä¾‹æ›´é«˜ï¼‰ï¼Œå¹¶ç»“åˆè¿ç§»é€€é¿å‚æ•°
        source_queue_len = len(source_queue)
        backoff = 0.0
        if joint_params:
            try:
                backoff = float(joint_params.get('migration_backoff', 0.0) or 0.0)
            except (TypeError, ValueError):
                backoff = 0.0
        backoff = float(np.clip(backoff, 0.0, 1.0))
        migration_ratio = max(0.2, min(0.6, (urgency + 0.1) * (1.0 - 0.3 * backoff)))
        tasks_to_migrate = max(1, int(source_queue_len * migration_ratio))
        tasks_to_migrate = min(tasks_to_migrate, source_queue_len)
        if tasks_to_migrate <= 0:
            return {'success': False, 'cost': 0.0, 'delay_saved': 0.0}

        # æ— çº¿é“¾è·¯å¯é æ€§æ¨¡å‹ï¼šè€ƒè™‘è·ç¦»ã€è´Ÿè½½å’Œç´§æ€¥åº¦
        # Wireless link reliability model: consider distance, load, and urgency
        base_success_rate = 0.75
        distance_penalty = min(0.35, distance / 1200.0)  # è·ç¦»è¶Šè¿œæˆåŠŸç‡è¶Šä½
        load_penalty = min(0.25, target_queue_len / 16.0)  # ç›®æ ‡è´Ÿè½½è¶Šé«˜æˆåŠŸç‡è¶Šä½
        urgency_bonus = min(0.2, urgency)  # ç´§æ€¥åº¦æä¾›é¢å¤–æˆåŠŸç‡
        actual_success_rate = np.clip(base_success_rate - distance_penalty - load_penalty + urgency_bonus, 0.35, 0.95)
        if np.random.random() > actual_success_rate:
            return {'success': False, 'cost': 0.0, 'delay_saved': 0.0}

        # æ‰§è¡Œè¿ç§»
        # Execute migration
        migrated_tasks = source_queue[:tasks_to_migrate]
        source_uav['computation_queue'] = source_queue[tasks_to_migrate:]
        target_rsu['computation_queue'].extend(migrated_tasks)
        if coordinator is not None and migrated_tasks:
            try:
                coordinator.prepare_prefetch(source_uav, target_rsu, migrated_tasks, urgency)
            except (AttributeError, RuntimeError) as exc:
                logging.warning(f"âš ï¸ UAVè¿ç§»å‰é¢„å–åè°ƒå¤±è´¥(UAV_{source_uav_idx}->{target_rsu.get('id')}): {exc}")

        total_data_size = sum(task.get('data_size', 1.0) for task in migrated_tasks)
        if total_data_size <= 0.0:
            total_data_size = tasks_to_migrate * 1.0
        # Estimate wireless transfer characteristics
        wireless_rate = 12.0  # MB/s
        wireless_delay = (total_data_size / wireless_rate)
        wireless_energy = total_data_size * 0.15 + distance * 0.01
        queue_relief = max(0.0, source_queue_len - len(source_uav['computation_queue']))
        delay_saved = max(0.0, queue_relief * self.time_slot)

        self.stats['uav_migration_distance'] = self.stats.get('uav_migration_distance', 0.0) + distance
        self.stats['uav_migration_count'] = self.stats.get('uav_migration_count', 0) + 1

        migration_cost = (self.migration_energy_weight * wireless_energy) + (self.migration_delay_weight * wireless_delay)
        return {
            'success': True,
            'cost': migration_cost,
            'delay_saved': delay_saved,
            'target_node': target_rsu.get('id'),
            'tasks_migrated': tasks_to_migrate
        }

    def get_central_scheduling_report(self) -> Dict[str, Any]:
        scheduler = getattr(self, 'central_scheduler', None)
        if scheduler is None:
            return {'status': 'not_available', 'message': 'ä¸­å¤®è°ƒåº¦å™¨æœªå¯ç”¨'}
        try:
            status = scheduler.get_global_scheduling_status()
            rsu_details: Dict[str, Dict[str, float]] = {}
            for rsu_id, load_info in scheduler.rsu_loads.items():
                rsu_details[rsu_id] = {
                    'cpu_usage': float(getattr(load_info, 'cpu_usage', 0.0)),
                    'queue_length': int(getattr(load_info, 'queue_length', 0)),
                    'cache_usage': float(getattr(load_info, 'cache_usage', 0.0)),
                    'served_vehicles': int(getattr(load_info, 'served_vehicles', 0)),
                    'bandwidth_usage': float(getattr(load_info, 'network_bandwidth_usage', 0.0)),
                }
            return {
                'status': 'ok',
                'message': 'ä¸­å¤®è°ƒåº¦å™¨è¿è¡Œä¸­',
                'scheduling_calls': status.get('global_metrics', {}).get('scheduling_decisions_count', 0),
                'central_scheduler_status': status,
                'rsu_details': rsu_details,
                'migrations_triggered': self.stats.get('central_scheduler_migrations', 0),
            }
        except Exception as exc:
            logging.debug("Central scheduling report failed: %s", exc)
            return {'status': 'error', 'message': str(exc)}

    def get_task_type_delay_report(self) -> str:
        """
        ç”ŸæˆæŒ‰ä»»åŠ¡ç±»åˆ«çš„æ—¶å»¶æ€§èƒ½æŠ¥å‘Š
        
        Returns:
            æ ¼å¼åŒ–çš„æŠ¥å‘Šå­—ç¬¦ä¸²
        """
        stats = self.stats.get('task_type_delay_stats', {})
        if not stats:
            return "âš ï¸ æœªæ”¶é›†åˆ°æŒ‰ä»»åŠ¡ç±»åˆ«çš„æ—¶å»¶ç»Ÿè®¡æ•°æ®"
        
        report_lines = []
        report_lines.append("\n" + "="*80)
        report_lines.append("ğŸ“Š æŒ‰ä»»åŠ¡ç±»åˆ«çš„æ—¶å»¶æ€§èƒ½ç»Ÿè®¡")
        report_lines.append("="*80)
        report_lines.append(f"{'Type':<10} {'Count':<10} {'Avg Delay(s)':<15} {'Max Delay(s)':<15} {'Violations':<12} {'Vio Rate':<10} {'Deadline(s)'}")
        report_lines.append("-"*80)
        
        task_type_names = {
            1: "æåº¦æ•æ„Ÿ",
            2: "æ•æ„Ÿ",
            3: "ä¸­åº¦å®¹å¿",
            4: "å®¹å¿"
        }
        
        total_tasks = 0
        total_violations = 0
        
        for task_type in sorted(stats.keys()):
            type_stats = stats[task_type]
            count = type_stats.get('count', 0)
            total_delay = type_stats.get('total_delay', 0.0)
            max_delay = type_stats.get('max_delay', 0.0)
            violations = type_stats.get('deadline_violations', 0)
            deadline = type_stats.get('deadline', 0.0)
            
            if count > 0:
                avg_delay = total_delay / count
                vio_rate = violations / count
            else:
                avg_delay = 0.0
                vio_rate = 0.0
            
            total_tasks += count
            total_violations += violations
            
            type_name = task_type_names.get(task_type, f"Type-{task_type}")
            report_lines.append(
                f"{type_name:<10} {count:<10} {avg_delay:<15.4f} {max_delay:<15.4f} {violations:<12} "
                f"{vio_rate:<10.1%} {deadline:<.2f}"
            )
        
        report_lines.append("-"*80)
        overall_vio_rate = total_violations / total_tasks if total_tasks > 0 else 0.0
        report_lines.append(f"æ€»è®¡: {total_tasks} ä¸ªä»»åŠ¡, {total_violations} ä¸ªè¶…deadline ({overall_vio_rate:.1%})")
        report_lines.append("="*80)
        
        return "\n".join(report_lines)

    def visualize_task_type_delay_stats(self, output_dir: str = 'test_results'):
        """
        ç”Ÿæˆä»»åŠ¡ç±»åˆ«æ—¶å»¶ç»Ÿè®¡çš„å¯è§†åŒ–å›¾è¡¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        try:
            from tools.visualize_task_type_delay import visualize_task_type_delay_stats
            visualize_task_type_delay_stats(self.stats, output_dir)
        except ImportError as e:
            print(f"âš ï¸ æ— æ³•å¯¼å…¥å¯è§†åŒ–æ¨¡å—: {e}")
            print("è¯·ç¡®ä¿ tools/visualize_task_type_delay.py æ–‡ä»¶å­˜åœ¨")
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨æ—¶å‡ºé”™: {e}")
